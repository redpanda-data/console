{
  "bloblang-functions": [
    {
      "category": "Message Info",
      "description": "Returns the index of the mapped message within a batch. This is useful for applying maps only on certain messages of a batch.",
      "examples": [
        {
          "mapping": "root = if batch_index() > 0 { deleted() }",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "batch_index",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns the size of the message batch.",
      "examples": [
        {
          "mapping": "root.foo = batch_size()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "batch_size",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns the full raw contents of the mapping target message as a byte array. When mapping to a JSON field the value should be encoded using the method xref:guides:bloblang/methods.adoc#encode[`encode`], or cast to a string directly using the method xref:guides:bloblang/methods.adoc#string[`string`], otherwise it will be base64 encoded by default.",
      "examples": [
        {
          "mapping": "root.doc = content().string()",
          "results": [
            [
              "{\"foo\":\"bar\"}",
              "{\"doc\":\"{\\\"foo\\\":\\\"bar\\\"}\"}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "content",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Deprecated",
      "description": "The `count` function is a counter starting at 1 which increments after each time it is called. Count takes an argument which is an identifier for the counter, allowing you to specify multiple unique counters in your configuration.",
      "examples": [
        {
          "mapping": "root = this\nroot.id = count(\"bloblang_function_example\")",
          "results": [
            [
              "{\"message\":\"foo\"}",
              "{\"id\":1,\"message\":\"foo\"}"
            ],
            [
              "{\"message\":\"bar\"}",
              "{\"id\":2,\"message\":\"bar\"}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": true,
      "name": "count",
      "params": {
        "named": [
          {
            "description": "An identifier for the counter.",
            "name": "name",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "category": "General",
      "description": "Returns a non-negative integer that increments each time it is resolved, yielding the minimum (`1` by default) as the first value. Each instantiation of `counter` has its own independent count. Once the maximum integer (or `max` argument) is reached the counter resets back to the minimum.",
      "examples": [
        {
          "mapping": "root.id = counter()",
          "results": [
            [
              "{}",
              "{\"id\":1}"
            ],
            [
              "{}",
              "{\"id\":2}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "\nmap foos {\n  root = counter()\n}\n\nroot.meow_id = null.apply(\"foos\")\nroot.woof_id = null.apply(\"foos\")\n",
          "results": [
            [
              "{}",
              "{\"meow_id\":1,\"woof_id\":2}"
            ],
            [
              "{}",
              "{\"meow_id\":3,\"woof_id\":4}"
            ]
          ],
          "skip_testing": false,
          "summary": "It's possible to increment a counter multiple times within a single mapping invocation using a map."
        },
        {
          "mapping": "root.consecutive_doggos = counter(min: 1, set: if !this.sound.lowercase().contains(\"woof\") { 0 })",
          "results": [
            [
              "{\"sound\":\"woof woof\"}",
              "{\"consecutive_doggos\":1}"
            ],
            [
              "{\"sound\":\"woofer wooooo\"}",
              "{\"consecutive_doggos\":2}"
            ],
            [
              "{\"sound\":\"meow\"}",
              "{\"consecutive_doggos\":0}"
            ],
            [
              "{\"sound\":\"uuuuh uh uh woof uhhhhhh\"}",
              "{\"consecutive_doggos\":1}"
            ]
          ],
          "skip_testing": false,
          "summary": "By specifying an optional `set` parameter it is possible to dynamically reset the counter based on input data."
        },
        {
          "mapping": "root.things = counter(set: if this.id == null { null })",
          "results": [
            [
              "{\"id\":\"a\"}",
              "{\"things\":1}"
            ],
            [
              "{\"id\":\"b\"}",
              "{\"things\":2}"
            ],
            [
              "{\"what\":\"just checking\"}",
              "{\"things\":2}"
            ],
            [
              "{\"id\":\"c\"}",
              "{\"things\":3}"
            ]
          ],
          "skip_testing": false,
          "summary": "The `set` parameter can also be utilized to peek at the counter without mutating it by returning `null`."
        }
      ],
      "impure": false,
      "name": "counter",
      "params": {
        "named": [
          {
            "default": 1,
            "description": "The minimum value of the counter, this is the first value that will be yielded. If this parameter is dynamic it will be resolved only once during the lifetime of the mapping.",
            "name": "min",
            "no_dynamic": false,
            "scalars_to_literal": true,
            "type": "query expression"
          },
          {
            "default": 9223372036854775807,
            "description": "The maximum value of the counter, once this value is yielded the counter will reset back to the min. If this parameter is dynamic it will be resolved only once during the lifetime of the mapping.",
            "name": "max",
            "no_dynamic": false,
            "scalars_to_literal": true,
            "type": "query expression"
          },
          {
            "description": "An optional mapping that when specified will be executed each time the counter is resolved. When this mapping resolves to a non-negative integer value it will cause the counter to reset to this value and yield it. If this mapping is omitted or doesn't resolve to anything then the counter will increment and yield the value as normal. If this mapping resolves to `null` then the counter is not incremented and the current value is yielded. If this mapping resolves to a deletion then the counter is reset to the `min` value.",
            "is_optional": true,
            "name": "set",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "category": "General",
      "description": "A function that returns a result indicating that the mapping target should be deleted. Deleting, also known as dropping, messages will result in them being acknowledged as successfully processed to inputs in a Redpanda Connect pipeline. For more information about error handling patterns read xref:configuration:error_handling.adoc[].",
      "examples": [
        {
          "mapping": "root = this\nroot.bar = deleted()",
          "results": [
            [
              "{\"bar\":\"bar_value\",\"baz\":\"baz_value\",\"foo\":\"foo value\"}",
              "{\"baz\":\"baz_value\",\"foo\":\"foo value\"}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.new_nums = this.nums.map_each(num -> if num < 10 { deleted() } else { num - 10 })",
          "results": [
            [
              "{\"nums\":[3,11,4,17]}",
              "{\"new_nums\":[1,7]}"
            ]
          ],
          "skip_testing": false,
          "summary": "Since the result is a value it can be used to do things like remove elements of an array within `map_each`."
        }
      ],
      "impure": false,
      "name": "deleted",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Returns the value of an environment variable, or `null` if the environment variable does not exist.",
      "examples": [
        {
          "mapping": "root.thing.key = env(\"key\").or(\"default value\")",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.thing.key = env(this.thing.key_name)",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.thing.key = env(name: \"key\", no_cache: true)",
          "results": [],
          "skip_testing": false,
          "summary": "When the name parameter is static this function will only resolve once and yield the same result for each invocation as an optimization, this means that updates to env vars during runtime will not be reflected. You can disable this cache with the optional parameter `no_cache`, which when set to `true` will cause the variable lookup to be performed for each execution of the mapping."
        }
      ],
      "impure": true,
      "name": "env",
      "params": {
        "named": [
          {
            "description": "The name of an environment variable.",
            "name": "name",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": false,
            "description": "Force the variable lookup to occur for each mapping invocation.",
            "name": "no_cache",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "If an error has occurred during the processing of a message this function returns the reported cause of the error as a string, otherwise `null`. For more information about error handling patterns read xref:configuration:error_handling.adoc[].",
      "examples": [
        {
          "mapping": "root.doc.error = error()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "error",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns the label of the source component which raised the error during the processing of a message or an empty string if not set. `null` is returned when the error is null or no source component is associated with it. For more information about error handling patterns read xref:configuration:error_handling.adoc[].",
      "examples": [
        {
          "mapping": "root.doc.error_source_label = error_source_label()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "error_source_label",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns the name of the source component which raised the error during the processing of a message. `null` is returned when the error is null or no source component is associated with it. For more information about error handling patterns read xref:configuration:error_handling.adoc[].",
      "examples": [
        {
          "mapping": "root.doc.error_source_name = error_source_name()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "error_source_name",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns the path of the source component which raised the error during the processing of a message. `null` is returned when the error is null or no source component is associated with it. For more information about error handling patterns read xref:configuration:error_handling.adoc[].",
      "examples": [
        {
          "mapping": "root.doc.error_source_path = error_source_path()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "error_source_path",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns a boolean value indicating whether an error has occurred during the processing of a message. For more information about error handling patterns read xref:configuration:error_handling.adoc[].",
      "examples": [
        {
          "mapping": "root.doc.status = if errored() { 400 } else { 200 }",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "errored",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Fake Data Generation",
      "description": "Takes in a string that maps to a https://github.com/go-faker/faker[faker^] function and returns the result from that faker function. Returns an error if the given string doesn't match a supported faker function. Supported functions: `latitude`, `longitude`, `unix_time`, `date`, `time_string`, `month_name`, `year_string`, `day_of_week`, `day_of_month`, `timestamp`, `century`, `timezone`, `time_period`, `email`, `mac_address`, `domain_name`, `url`, `username`, `ipv4`, `ipv6`, `password`, `jwt`, `word`, `sentence`, `paragraph`, `cc_type`, `cc_number`, `currency`, `amount_with_currency`, `title_male`, `title_female`, `first_name`, `first_name_male`, `first_name_female`, `last_name`, `name`, `gender`, `chinese_first_name`, `chinese_last_name`, `chinese_name`, `phone_number`, `toll_free_phone_number`, `e164_phone_number`, `uuid_hyphenated`, `uuid_digit`. Refer to the https://github.com/go-faker/faker[faker^] docs for details on these functions.",
      "examples": [
        {
          "mapping": "root.time = fake(\"time_string\")",
          "results": [],
          "skip_testing": false,
          "summary": "Use `time_string` to generate a time in the format `00:00:00`:"
        },
        {
          "mapping": "root.email = fake(\"email\")",
          "results": [],
          "skip_testing": false,
          "summary": "Use `email` to generate a string in email address format:"
        },
        {
          "mapping": "root.jwt = fake(\"jwt\")",
          "results": [],
          "skip_testing": false,
          "summary": "Use `jwt` to generate a JWT token:"
        },
        {
          "mapping": "root.uuid = fake(\"uuid_hyphenated\")",
          "results": [],
          "skip_testing": false,
          "summary": "Use `uuid_hyphenated` to generate a hyphenated UUID:"
        }
      ],
      "impure": false,
      "name": "fake",
      "params": {
        "named": [
          {
            "default": "",
            "description": "The name of the function to use to generate the value.",
            "name": "function",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "category": "Environment",
      "description": "Reads a file and returns its contents. Relative paths are resolved from the directory of the process executing the mapping. In order to read files relative to the mapping file use the newer <<file_rel, `file_rel` function>>",
      "examples": [
        {
          "mapping": "root.doc = file(env(\"BENTHOS_TEST_BLOBLANG_FILE\")).parse_json()",
          "results": [
            [
              "{}",
              "{\"doc\":{\"foo\":\"bar\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.doc = file(path: env(\"BENTHOS_TEST_BLOBLANG_FILE\"), no_cache: true).parse_json()",
          "results": [
            [
              "{}",
              "{\"doc\":{\"foo\":\"bar\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": "When the path parameter is static this function will only read the specified file once and yield the same result for each invocation as an optimization, this means that updates to files during runtime will not be reflected. You can disable this cache with the optional parameter `no_cache`, which when set to `true` will cause the file to be read for each execution of the mapping."
        }
      ],
      "impure": true,
      "name": "file",
      "params": {
        "named": [
          {
            "description": "The path of the target file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": false,
            "description": "Force the file to be read for each mapping invocation.",
            "name": "no_cache",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Reads a file and returns its contents. Relative paths are resolved from the directory of the mapping.",
      "examples": [
        {
          "mapping": "root.doc = file_rel(env(\"BENTHOS_TEST_BLOBLANG_FILE\")).parse_json()",
          "results": [
            [
              "{}",
              "{\"doc\":{\"foo\":\"bar\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.doc = file_rel(path: env(\"BENTHOS_TEST_BLOBLANG_FILE\"), no_cache: true).parse_json()",
          "results": [
            [
              "{}",
              "{\"doc\":{\"foo\":\"bar\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": "When the path parameter is static this function will only read the specified file once and yield the same result for each invocation as an optimization, this means that updates to files during runtime will not be reflected. You can disable this cache with the optional parameter `no_cache`, which when set to `true` will cause the file to be read for each execution of the mapping."
        }
      ],
      "impure": true,
      "name": "file_rel",
      "params": {
        "named": [
          {
            "description": "The path of the target file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": false,
            "description": "Force the file to be read for each mapping invocation.",
            "name": "no_cache",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Returns a string matching the hostname of the machine running Benthos.",
      "examples": [
        {
          "mapping": "root.thing.host = hostname()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": true,
      "name": "hostname",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Returns the value of a field within a JSON message located by a [dot path][field_paths] argument. This function always targets the entire source JSON document regardless of the mapping context.",
      "examples": [
        {
          "mapping": "root.mapped = json(\"foo.bar\")",
          "results": [
            [
              "{\"foo\":{\"bar\":\"hello world\"}}",
              "{\"mapped\":\"hello world\"}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.doc = json()",
          "results": [
            [
              "{\"foo\":{\"bar\":\"hello world\"}}",
              "{\"doc\":{\"foo\":{\"bar\":\"hello world\"}}}"
            ]
          ],
          "skip_testing": false,
          "summary": "The path argument is optional and if omitted the entire JSON payload is returned."
        }
      ],
      "impure": false,
      "name": "json",
      "params": {
        "named": [
          {
            "default": "",
            "description": "An optional [dot path][field_paths] identifying a field to obtain.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "General",
      "description": "Generates a new ksuid each time it is invoked and prints a string representation.",
      "examples": [
        {
          "mapping": "root.id = ksuid()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "ksuid",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Deprecated",
      "description": "Returns the value of a metadata key from the input message as a string, or `null` if the key does not exist. Since values are extracted from the read-only input message they do NOT reflect changes made from within the map. In order to query metadata mutations made within a mapping use the <<root_meta, `root_meta` function>>. This function supports extracting metadata from other messages of a batch with the `from` method.",
      "examples": [
        {
          "mapping": "root.topic = meta(\"kafka_topic\")",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.all_metadata = meta()",
          "results": [],
          "skip_testing": false,
          "summary": "The key parameter is optional and if omitted the entire metadata contents are returned as an object."
        }
      ],
      "impure": false,
      "name": "meta",
      "params": {
        "named": [
          {
            "default": "",
            "description": "An optional key of a metadata value to obtain.",
            "name": "key",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "category": "Message Info",
      "description": "Returns the value of a metadata key from the input message, or `null` if the key does not exist. Since values are extracted from the read-only input message they do NOT reflect changes made from within the map, in order to query metadata mutations made within a mapping use the xref:guides:bloblang/about.adoc#metadata[`@` operator]. This function supports extracting metadata from other messages of a batch with the `from` method.",
      "examples": [
        {
          "mapping": "root.topic = metadata(\"kafka_topic\")",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.all_metadata = metadata()",
          "results": [],
          "skip_testing": false,
          "summary": "The key parameter is optional and if omitted the entire metadata contents are returned as an object."
        }
      ],
      "impure": false,
      "name": "metadata",
      "params": {
        "named": [
          {
            "default": "",
            "description": "An optional key of a metadata value to obtain.",
            "name": "key",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "General",
      "description": "Generates a new nanoid each time it is invoked and prints a string representation.",
      "examples": [
        {
          "mapping": "root.id = nanoid()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.id = nanoid(54)",
          "results": [],
          "skip_testing": false,
          "summary": "It is possible to specify an optional length parameter."
        },
        {
          "mapping": "root.id = nanoid(54, \"abcde\")",
          "results": [],
          "skip_testing": false,
          "summary": "It is also possible to specify an optional custom alphabet after the length parameter."
        }
      ],
      "impure": false,
      "name": "nanoid",
      "params": {
        "named": [
          {
            "description": "An optional length.",
            "is_optional": true,
            "name": "length",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          },
          {
            "description": "An optional custom alphabet to use for generating IDs. When specified the field `length` must also be present.",
            "is_optional": true,
            "name": "alphabet",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "",
      "impure": false,
      "name": "nothing",
      "params": {},
      "status": "hidden"
    },
    {
      "category": "Environment",
      "description": "Returns the current timestamp as a string in RFC 3339 format with the local timezone. Use the method `ts_format` in order to change the format and timezone.",
      "examples": [
        {
          "mapping": "root.received_at = now()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.received_at = now().ts_format(\"Mon Jan 2 15:04:05 -0700 MST 2006\", \"UTC\")",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "now",
      "params": {},
      "status": "stable"
    },
    {
      "category": "General",
      "description": "Returns the value of the mathematical constant Pi.",
      "examples": [
        {
          "mapping": "root.radians = this.degrees * (pi() / 180)",
          "results": [
            [
              "{\"degrees\":45}",
              "{\"radians\":0.7853981633974483}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.degrees = this.radians * (180 / pi())",
          "results": [
            [
              "{\"radians\":0.78540}",
              "{\"degrees\":45.00010522957486}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "pi",
      "params": {},
      "status": "stable"
    },
    {
      "category": "General",
      "description": "\nGenerates a non-negative pseudo-random 64-bit integer. An optional integer argument can be provided in order to seed the random number generator.\n\nOptional `min` and `max` arguments can be provided in order to only generate numbers within a range. Neither of these parameters can be set via a dynamic expression (i.e. from values taken from mapped data). Instead, for dynamic ranges extract a min and max manually using a modulo operator (`random_int() % a + b`).",
      "examples": [
        {
          "mapping": "root.first = random_int()\nroot.second = random_int(1)\nroot.third = random_int(max:20)\nroot.fourth = random_int(min:10, max:20)\nroot.fifth = random_int(timestamp_unix_nano(), 5, 20)\nroot.sixth = random_int(seed:timestamp_unix_nano(), max:20)\n",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.first = random_int(timestamp_unix_nano())",
          "results": [],
          "skip_testing": false,
          "summary": "It is possible to specify a dynamic seed argument, in which case the argument will only be resolved once during the lifetime of the mapping."
        }
      ],
      "impure": false,
      "name": "random_int",
      "params": {
        "named": [
          {
            "default": {
              "Value": 0
            },
            "description": "A seed to use, if a query is provided it will only be resolved once during the lifetime of the mapping.",
            "name": "seed",
            "no_dynamic": false,
            "scalars_to_literal": true,
            "type": "query expression"
          },
          {
            "default": 0,
            "description": "The minimum value the random generated number will have. The default value is 0.",
            "name": "min",
            "no_dynamic": true,
            "scalars_to_literal": false,
            "type": "integer"
          },
          {
            "default": 9223372036854775806,
            "description": "The maximum value the random generated number will have. The default value is 9223372036854775806 (math.MaxInt64 - 1).",
            "name": "max",
            "no_dynamic": true,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "General",
      "description": "The `range` function creates an array of integers following a range between a start, stop and optional step integer argument. If the step argument is omitted then it defaults to 1. A negative step can be provided as long as stop < start.",
      "examples": [
        {
          "mapping": "root.a = range(0, 10)\nroot.b = range(start: 0, stop: this.max, step: 2) # Using named params\nroot.c = range(0, -this.max, -2)",
          "results": [
            [
              "{\"max\":10}",
              "{\"a\":[0,1,2,3,4,5,6,7,8,9],\"b\":[0,2,4,6,8],\"c\":[0,-2,-4,-6,-8]}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "range",
      "params": {
        "named": [
          {
            "description": "The start value.",
            "name": "start",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          },
          {
            "description": "The stop value.",
            "name": "stop",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          },
          {
            "default": 1,
            "description": "The step value.",
            "name": "step",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "Deprecated",
      "description": "Returns the value of a metadata key from the new message being created as a string, or `null` if the key does not exist. Changes made to metadata during a mapping will be reflected by this function.",
      "examples": [
        {
          "mapping": "root.topic = root_meta(\"kafka_topic\")",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.all_metadata = root_meta()",
          "results": [],
          "skip_testing": false,
          "summary": "The key parameter is optional and if omitted the entire metadata contents are returned as an object."
        }
      ],
      "impure": false,
      "name": "root_meta",
      "params": {
        "named": [
          {
            "default": "",
            "description": "An optional key of a metadata value to obtain.",
            "name": "key",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "category": "General",
      "description": "Generate a new snowflake ID each time it is invoked and prints a string representation. I.e.: 1559229974454472704",
      "examples": [
        {
          "mapping": "root.id = snowflake_id()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.id = snowflake_id(2)",
          "results": [],
          "skip_testing": false,
          "summary": "It is possible to specify the node_id."
        }
      ],
      "impure": false,
      "name": "snowflake_id",
      "params": {
        "named": [
          {
            "default": 1,
            "description": "It is possible to specify the node_id.",
            "name": "node_id",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "General",
      "description": "Throws an error similar to a regular mapping error. This is useful for abandoning a mapping entirely given certain conditions.",
      "examples": [
        {
          "mapping": "root.doc.type = match {\n  this.exists(\"header.id\") => \"foo\"\n  this.exists(\"body.data\") => \"bar\"\n  _ => throw(\"unknown type\")\n}\nroot.doc.contents = (this.body.content | this.thing.body)",
          "results": [
            [
              "{\"header\":{\"id\":\"first\"},\"thing\":{\"body\":\"hello world\"}}",
              "{\"doc\":{\"contents\":\"hello world\",\"type\":\"foo\"}}"
            ],
            [
              "{\"nothing\":\"matches\"}",
              "Error(\"failed assignment (line 1): unknown type\")"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "throw",
      "params": {
        "named": [
          {
            "description": "A string explanation for why an error was thrown, this will be added to the resulting error message.",
            "name": "why",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Returns the current unix timestamp in seconds.",
      "examples": [
        {
          "mapping": "root.received_at = timestamp_unix()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "timestamp_unix",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Returns the current unix timestamp in microseconds.",
      "examples": [
        {
          "mapping": "root.received_at = timestamp_unix_micro()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "timestamp_unix_micro",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Returns the current unix timestamp in milliseconds.",
      "examples": [
        {
          "mapping": "root.received_at = timestamp_unix_milli()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "timestamp_unix_milli",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Environment",
      "description": "Returns the current unix timestamp in nanoseconds.",
      "examples": [
        {
          "mapping": "root.received_at = timestamp_unix_nano()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "timestamp_unix_nano",
      "params": {},
      "status": "stable"
    },
    {
      "category": "Message Info",
      "description": "Provides the message trace id. The returned value will be zeroed if the message does not contain a span.",
      "examples": [
        {
          "mapping": "meta trace_id = tracing_id()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "tracing_id",
      "params": {},
      "status": "experimental"
    },
    {
      "category": "Message Info",
      "description": "Provides the message tracing span xref:components:tracers/about.adoc[(created via Open Telemetry APIs)] as an object serialized via text map formatting. The returned value will be `null` if the message does not have a span.",
      "examples": [
        {
          "mapping": "root.headers.traceparent = tracing_span().traceparent",
          "results": [
            [
              "{\"some_stuff\":\"just can't be explained by science\"}",
              "{\"headers\":{\"traceparent\":\"00-4bf92f3577b34da6a3ce929d0e0e4736-00f067aa0ba902b7-01\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "tracing_span",
      "params": {},
      "status": "experimental"
    },
    {
      "category": "General",
      "description": "Generate a random ULID.",
      "examples": [
        {
          "mapping": "root.id = ulid()",
          "results": [],
          "skip_testing": false,
          "summary": "Using the defaults of Crockford Base32 encoding and secure random source"
        },
        {
          "mapping": "root.id = ulid(\"hex\")",
          "results": [],
          "skip_testing": false,
          "summary": "ULIDs can be hex-encoded too."
        },
        {
          "mapping": "root.id = ulid(\"crockford\", \"fast_random\")",
          "results": [],
          "skip_testing": false,
          "summary": "They can be generated using a fast, but unsafe, random source for use cases that are not security-sensitive."
        }
      ],
      "impure": false,
      "name": "ulid",
      "params": {
        "named": [
          {
            "default": "crockford",
            "description": "The format to encode a ULID into. Valid options are: crockford, hex",
            "name": "encoding",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": "secure_random",
            "description": "The source of randomness to use for generating ULIDs. \"secure_random\" is recommended for most use cases. \"fast_random\" can be used if security is not a concern.",
            "name": "random_source",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "category": "General",
      "description": "Generates a new RFC-4122 UUID each time it is invoked and prints a string representation.",
      "examples": [
        {
          "mapping": "root.id = uuid_v4()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "uuid_v4",
      "params": {},
      "status": "stable"
    },
    {
      "category": "General",
      "description": "Generates a new time ordered UUID each time it is invoked and prints a string representation.",
      "examples": [
        {
          "mapping": "root.id = uuid_v7()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.id = uuid_v7(now().ts_sub_iso8601(\"PT1M\"))",
          "results": [],
          "skip_testing": false,
          "summary": "It is also possible to specify the timestamp for the uuid_v7"
        }
      ],
      "impure": false,
      "name": "uuid_v7",
      "params": {
        "named": [
          {
            "description": "An optional timestamp to use for the time ordered portion of the UUID.",
            "is_optional": true,
            "name": "time",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "timestamp"
          }
        ]
      },
      "status": "stable"
    },
    {
      "category": "",
      "impure": false,
      "name": "var",
      "params": {
        "named": [
          {
            "description": "The name of the target variable.",
            "name": "name",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "hidden"
    }
  ],
  "bloblang-methods": [
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.outs = this.ins.map_each(ele -> ele.abs())\n",
              "results": [
                [
                  "{\"ins\":[9,-18,1.23,-4.56]}",
                  "{\"outs\":[9,18,1.23,4.56]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the absolute value of an int64 or float64 number. As a special case, when an integer is provided that is the minimum value it is converted to the maximum value.",
      "impure": false,
      "name": "abs",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.all_over_21 = this.patrons.all(patron -> patron.age >= 21)",
              "results": [
                [
                  "{\"patrons\":[{\"id\":\"1\",\"age\":18},{\"id\":\"2\",\"age\":23}]}",
                  "{\"all_over_21\":false}"
                ],
                [
                  "{\"patrons\":[{\"id\":\"1\",\"age\":45},{\"id\":\"2\",\"age\":23}]}",
                  "{\"all_over_21\":true}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Checks each element of an array against a query and returns true if all elements passed. An error occurs if the target is not an array, or if any element results in the provided query returning a non-boolean result. Returns false if the target array is empty.",
      "impure": false,
      "name": "all",
      "params": {
        "named": [
          {
            "description": "A test query to apply to each element.",
            "name": "test",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.any_over_21 = this.patrons.any(patron -> patron.age >= 21)",
              "results": [
                [
                  "{\"patrons\":[{\"id\":\"1\",\"age\":18},{\"id\":\"2\",\"age\":23}]}",
                  "{\"any_over_21\":true}"
                ],
                [
                  "{\"patrons\":[{\"id\":\"1\",\"age\":10},{\"id\":\"2\",\"age\":12}]}",
                  "{\"any_over_21\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Checks the elements of an array against a query and returns true if any element passes. An error occurs if the target is not an array, or if an element results in the provided query returning a non-boolean result. Returns false if the target array is empty.",
      "impure": false,
      "name": "any",
      "params": {
        "named": [
          {
            "description": "A test query to apply to each element.",
            "name": "test",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo = this.foo.append(\"and\", \"this\")",
              "results": [
                [
                  "{\"foo\":[\"bar\",\"baz\"]}",
                  "{\"foo\":[\"bar\",\"baz\",\"and\",\"this\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns an array with new elements appended to the end.",
      "impure": false,
      "name": "append",
      "params": {
        "variadic": true
      },
      "status": "stable"
    },
    {
      "description": "Apply a declared mapping to a target value.",
      "examples": [
        {
          "mapping": "map thing {\n  root.inner = this.first\n}\n\nroot.foo = this.doc.apply(\"thing\")",
          "results": [
            [
              "{\"doc\":{\"first\":\"hello world\"}}",
              "{\"foo\":{\"inner\":\"hello world\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "map create_foo {\n  root.name = \"a foo\"\n  root.purpose = \"to be a foo\"\n}\n\nroot = this\nroot.foo = null.apply(\"create_foo\")",
          "results": [
            [
              "{\"id\":\"1234\"}",
              "{\"foo\":{\"name\":\"a foo\",\"purpose\":\"to be a foo\"},\"id\":\"1234\"}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "apply",
      "params": {
        "named": [
          {
            "description": "The mapping to apply.",
            "name": "mapping",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Return an array containing the target value. If the value is already an array it is unchanged.",
          "Examples": [
            {
              "mapping": "root.my_array = this.name.array()",
              "results": [
                [
                  "{\"name\":\"foobar bazson\"}",
                  "{\"my_array\":[\"foobar bazson\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "array",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.foo.assign(this.bar)",
              "results": [
                [
                  "{\"foo\":{\"first_name\":\"fooer\",\"likes\":\"bars\"},\"bar\":{\"second_name\":\"barer\",\"likes\":\"foos\"}}",
                  "{\"first_name\":\"fooer\",\"likes\":\"foos\",\"second_name\":\"barer\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Merge a source object into an existing destination object. When a collision is found within the merged structures (both a source and destination object contain the same non-object keys) the value in the destination object will be overwritten by that of source object. In order to preserve both values on collision use the <<merge, `merge`>> method.",
      "impure": false,
      "name": "assign",
      "params": {
        "named": [
          {
            "description": "A value to merge the target value with.",
            "name": "with",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.bitwise_and(6)",
              "results": [
                [
                  "{\"value\":12}",
                  "{\"new_value\":4}"
                ],
                [
                  "{\"value\":0}",
                  "{\"new_value\":0}"
                ],
                [
                  "{\"value\":-4}",
                  "{\"new_value\":4}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the number bitwise AND-ed with the specified value.",
      "impure": false,
      "name": "bitwise_and",
      "params": {
        "named": [
          {
            "description": "The value to AND with",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.bitwise_or(6)",
              "results": [
                [
                  "{\"value\":12}",
                  "{\"new_value\":14}"
                ],
                [
                  "{\"value\":0}",
                  "{\"new_value\":6}"
                ],
                [
                  "{\"value\":-2}",
                  "{\"new_value\":-2}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the number bitwise OR-ed with the specified value.",
      "impure": false,
      "name": "bitwise_or",
      "params": {
        "named": [
          {
            "description": "The value to OR with",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.bitwise_xor(6)",
              "results": [
                [
                  "{\"value\":12}",
                  "{\"new_value\":10}"
                ],
                [
                  "{\"value\":0}",
                  "{\"new_value\":6}"
                ],
                [
                  "{\"value\":-2}",
                  "{\"new_value\":-8}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the number bitwise eXclusive-OR-ed with the specified value.",
      "impure": false,
      "name": "bitwise_xor",
      "params": {
        "named": [
          {
            "description": "The value to XOR with",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.body = this.body.bloblang(this.mapping)",
              "results": [
                [
                  "{\"body\":{\"foo\":\"hello world\"},\"mapping\":\"root.foo = this.foo.uppercase()\"}",
                  "{\"body\":{\"foo\":\"HELLO WORLD\"}}"
                ],
                [
                  "{\"body\":{\"foo\":\"hello world 2\"},\"mapping\":\"root.foo = this.foo.capitalize()\"}",
                  "{\"body\":{\"foo\":\"Hello World 2\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Executes an argument Bloblang mapping on the target. This method can be used in order to execute dynamic mappings. Imports and functions that interact with the environment, such as `file` and `env`, or that access message information directly, such as `content` or `json`, are not enabled for dynamic Bloblang mappings.",
      "impure": false,
      "name": "bloblang",
      "params": {
        "named": [
          {
            "description": "The mapping to execute.",
            "name": "mapping",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Attempt to parse a value into a boolean. An optional argument can be provided, in which case if the value cannot be parsed the argument will be returned instead. If the value is a number then any non-zero value will resolve to `true`, if the value is a string then any of the following values are considered valid: `1, t, T, TRUE, true, True, 0, f, F, FALSE`.",
          "Examples": [
            {
              "mapping": "root.foo = this.thing.bool()\nroot.bar = this.thing.bool(true)",
              "results": [],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "bool",
      "params": {
        "named": [
          {
            "description": "An optional value to yield if the target cannot be parsed as a boolean.",
            "is_optional": true,
            "name": "default",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Marshal a value into a byte array. If the value is already a byte array it is unchanged.",
          "Examples": [
            {
              "mapping": "root.first_byte = this.name.bytes().index(0)",
              "results": [
                [
                  "{\"name\":\"foobar bazson\"}",
                  "{\"first_byte\":102}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "bytes",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Takes a string value and returns a copy with all Unicode letters that begin words mapped to their Unicode title case.",
          "Examples": [
            {
              "mapping": "root.title = this.title.capitalize()",
              "results": [
                [
                  "{\"title\":\"the foo bar\"}",
                  "{\"title\":\"The Foo Bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "capitalize",
      "params": {},
      "status": "stable"
    },
    {
      "description": "If the result of a target query fails (due to incorrect types, failed parsing, etc) the argument is returned instead.",
      "examples": [
        {
          "mapping": "root.doc.id = this.thing.id.string().catch(uuid_v4())",
          "results": [],
          "skip_testing": false,
          "summary": ""
        },
        {
          "mapping": "root.url = this.url.parse_url().catch(err -> {\"error\":err,\"input\":this.url})",
          "results": [
            [
              "{\"url\":\"invalid %&# url\"}",
              "{\"url\":{\"error\":\"field `this.url`: parse \\\"invalid %&\\\": invalid URL escape \\\"%&\\\"\",\"input\":\"invalid %&# url\"}}"
            ]
          ],
          "skip_testing": false,
          "summary": "The fallback argument can be a mapping, allowing you to capture the error string and yield structured data back."
        },
        {
          "mapping": "root = this.catch(deleted())",
          "results": [
            [
              "{\"doc\":{\"foo\":\"bar\"}}",
              "{\"doc\":{\"foo\":\"bar\"}}"
            ],
            [
              "not structured data",
              "<Message deleted>"
            ]
          ],
          "skip_testing": false,
          "summary": "When the input document is not structured attempting to reference structured fields with `this` will result in an error. Therefore, a convenient way to delete non-structured data is with a catch."
        }
      ],
      "impure": false,
      "name": "catch",
      "params": {
        "named": [
          {
            "description": "A value to yield, or query to execute, if the target query fails.",
            "name": "fallback",
            "no_dynamic": false,
            "scalars_to_literal": true,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.ceil()",
              "results": [
                [
                  "{\"value\":5.3}",
                  "{\"new_value\":6}"
                ],
                [
                  "{\"value\":-5.9}",
                  "{\"new_value\":-5}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the least integer value greater than or equal to a number. If the resulting value fits within a 64-bit integer then that is returned, otherwise a new floating point number is returned.",
      "impure": false,
      "name": "ceil",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Collapse an array or object into an object of key/value pairs for each field, where the key is the full path of the structured field in dot path notation. Empty arrays an objects are ignored by default.",
          "Examples": [
            {
              "mapping": "root.result = this.collapse()",
              "results": [
                [
                  "{\"foo\":[{\"bar\":\"1\"},{\"bar\":{}},{\"bar\":\"2\"},{\"bar\":[]}]}",
                  "{\"result\":{\"foo.0.bar\":\"1\",\"foo.2.bar\":\"2\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.result = this.collapse(include_empty: true)",
              "results": [
                [
                  "{\"foo\":[{\"bar\":\"1\"},{\"bar\":{}},{\"bar\":\"2\"},{\"bar\":[]}]}",
                  "{\"result\":{\"foo.0.bar\":\"1\",\"foo.1.bar\":{},\"foo.2.bar\":\"2\",\"foo.3.bar\":[]}}"
                ]
              ],
              "skip_testing": false,
              "summary": "An optional boolean parameter can be set to true in order to include empty objects and arrays."
            }
          ]
        }
      ],
      "impure": false,
      "name": "collapse",
      "params": {
        "named": [
          {
            "default": false,
            "description": "Whether to include empty objects and arrays in the resulting object.",
            "name": "include_empty",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.match = this.secret.compare_argon2(\"$argon2id$v=19$m=4096,t=3,p=1$c2FsdHktbWNzYWx0ZmFjZQ$RMUMwgtS32/mbszd+ke4o4Ej1jFpYiUqY6MHWa69X7Y\")",
              "results": [
                [
                  "{\"secret\":\"there-are-many-blobs-in-the-sea\"}",
                  "{\"match\":true}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.match = this.secret.compare_argon2(\"$argon2id$v=19$m=4096,t=3,p=1$c2FsdHktbWNzYWx0ZmFjZQ$RMUMwgtS32/mbszd+ke4o4Ej1jFpYiUqY6MHWa69X7Y\")",
              "results": [
                [
                  "{\"secret\":\"will-i-ever-find-love\"}",
                  "{\"match\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Checks whether a string matches a hashed secret using Argon2.",
      "impure": false,
      "name": "compare_argon2",
      "params": {
        "named": [
          {
            "description": "The hashed secret to compare with the input. This must be a fully-qualified string which encodes the Argon2 options used to generate the hash.",
            "name": "hashed_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.match = this.secret.compare_bcrypt(\"$2y$10$Dtnt5NNzVtMCOZONT705tOcS8It6krJX8bEjnDJnwxiFKsz1C.3Ay\")",
              "results": [
                [
                  "{\"secret\":\"there-are-many-blobs-in-the-sea\"}",
                  "{\"match\":true}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.match = this.secret.compare_bcrypt(\"$2y$10$Dtnt5NNzVtMCOZONT705tOcS8It6krJX8bEjnDJnwxiFKsz1C.3Ay\")",
              "results": [
                [
                  "{\"secret\":\"will-i-ever-find-love\"}",
                  "{\"match\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Checks whether a string matches a hashed secret using bcrypt.",
      "impure": false,
      "name": "compare_bcrypt",
      "params": {
        "named": [
          {
            "description": "The hashed secret value to compare with the input.",
            "name": "hashed_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "",
          "Examples": [
            {
              "mapping": "let long_content = range(0, 1000).map_each(content()).join(\" \")\nroot.a_len = $long_content.length()\nroot.b_len = $long_content.compress(\"gzip\").length()\n",
              "results": [
                [
                  "hello world this is some content",
                  "{\"a_len\":32999,\"b_len\":161}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.compressed = content().compress(\"lz4\").encode(\"base64\")",
              "results": [
                [
                  "hello world I love space",
                  "{\"compressed\":\"BCJNGGRwuRgAAIBoZWxsbyB3b3JsZCBJIGxvdmUgc3BhY2UAAAAAGoETLg==\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Compresses a string or byte array value according to a specified algorithm.",
      "impure": false,
      "name": "compress",
      "params": {
        "named": [
          {
            "description": "One of `flate`, `gzip`, `pgzip`, `lz4`, `snappy`, `zlib`, `zstd`.",
            "name": "algorithm",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": -1,
            "description": "The level of compression to use. May not be applicable to all algorithms.",
            "name": "level",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo = this.foo.concat(this.bar, this.baz)",
              "results": [
                [
                  "{\"foo\":[\"a\",\"b\"],\"bar\":[\"c\"],\"baz\":[\"d\",\"e\",\"f\"]}",
                  "{\"foo\":[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Concatenates an array value with one or more argument arrays.",
      "impure": false,
      "name": "concat",
      "params": {
        "variadic": true
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Checks whether an array contains an element matching the argument, or an object contains a value matching the argument, and returns a boolean result. Numerical comparisons are made irrespective of the representation type (float versus integer).",
          "Examples": [
            {
              "mapping": "root.has_foo = this.thing.contains(\"foo\")",
              "results": [
                [
                  "{\"thing\":[\"this\",\"foo\",\"that\"]}",
                  "{\"has_foo\":true}"
                ],
                [
                  "{\"thing\":[\"this\",\"bar\",\"that\"]}",
                  "{\"has_foo\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.has_bar = this.thing.contains(20)",
              "results": [
                [
                  "{\"thing\":[10.3,20.0,\"huh\",3]}",
                  "{\"has_bar\":true}"
                ],
                [
                  "{\"thing\":[2,3,40,67]}",
                  "{\"has_bar\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        },
        {
          "Category": "String Manipulation",
          "Description": "Checks whether a string contains a substring and returns a boolean result.",
          "Examples": [
            {
              "mapping": "root.has_foo = this.thing.contains(\"foo\")",
              "results": [
                [
                  "{\"thing\":\"this foo that\"}",
                  "{\"has_foo\":true}"
                ],
                [
                  "{\"thing\":\"this bar that\"}",
                  "{\"has_foo\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "contains",
      "params": {
        "named": [
          {
            "description": "A value to test against elements of the target.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = (this.value * (pi() / 180)).cos()",
              "results": [
                [
                  "{\"value\":45}",
                  "{\"new_value\":0.7071067811865476}"
                ],
                [
                  "{\"value\":0}",
                  "{\"new_value\":1}"
                ],
                [
                  "{\"value\":180}",
                  "{\"new_value\":-1}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Calculates the cosine of a given angle specified in radians.",
      "impure": false,
      "name": "cos",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "Decodes an encoded string target according to a chosen scheme and returns the result as a byte array. When mapping the result to a JSON field the value should be cast to a string using the method `string`, or encoded using the method `encode`, otherwise it will be base64 encoded by default.\n\nAvailable schemes are: `base64`, `base64url` https://rfc-editor.org/rfc/rfc4648.html[(RFC 4648 with padding characters)], `base64rawurl` https://rfc-editor.org/rfc/rfc4648.html[(RFC 4648 without padding characters)], `hex`, `ascii85`.",
          "Examples": [
            {
              "mapping": "root.decoded = this.value.decode(\"hex\").string()",
              "results": [
                [
                  "{\"value\":\"68656c6c6f20776f726c64\"}",
                  "{\"decoded\":\"hello world\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root = this.encoded.decode(\"ascii85\")",
              "results": [
                [
                  "{\"encoded\":\"FD,B0+DGm>FDl80Ci\\\"A>F`)8BEckl6F`M&(+Cno&@/\"}",
                  "this is totally unstructured data"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "decode",
      "params": {
        "named": [
          {
            "description": "The decoding scheme to use.",
            "name": "scheme",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.compressed.decode(\"base64\").decompress(\"lz4\")",
              "results": [
                [
                  "{\"compressed\":\"BCJNGGRwuRgAAIBoZWxsbyB3b3JsZCBJIGxvdmUgc3BhY2UAAAAAGoETLg==\"}",
                  "hello world I love space"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.result = this.compressed.decode(\"base64\").decompress(\"lz4\").string()",
              "results": [
                [
                  "{\"compressed\":\"BCJNGGRwuRgAAIBoZWxsbyB3b3JsZCBJIGxvdmUgc3BhY2UAAAAAGoETLg==\"}",
                  "{\"result\":\"hello world I love space\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Use the `.string()` method in order to coerce the result into a string, this makes it possible to place the data within a JSON document without automatic base64 encoding."
            }
          ]
        }
      ],
      "description": "Decompresses a string or byte array value according to a specified algorithm. The result of decompression ",
      "impure": false,
      "name": "decompress",
      "params": {
        "named": [
          {
            "description": "One of `gzip`, `pgzip`, `zlib`, `bzip2`, `flate`, `snappy`, `lz4`, `zstd`.",
            "name": "algorithm",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "Decrypts an encrypted string or byte array target according to a chosen AES encryption method and returns the result as a byte array. The algorithms require a key and an initialization vector / nonce. Available schemes are: `ctr`, `gcm`, `ofb`, `cbc`.",
          "Examples": [
            {
              "mapping": "let key = \"2b7e151628aed2a6abf7158809cf4f3c\".decode(\"hex\")\nlet vector = \"f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff\".decode(\"hex\")\nroot.decrypted = this.value.decode(\"hex\").decrypt_aes(\"ctr\", $key, $vector).string()",
              "results": [
                [
                  "{\"value\":\"84e9b31ff7400bdf80be7254\"}",
                  "{\"decrypted\":\"hello world!\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "decrypt_aes",
      "params": {
        "named": [
          {
            "description": "The scheme to use for decryption, one of `ctr`, `gcm`, `ofb`, `cbc`.",
            "name": "scheme",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "A key to decrypt with.",
            "name": "key",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An initialization vector / nonce.",
            "name": "iv",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Create a diff by comparing the current value with the given one. Wraps the github.com/r3labs/diff/v3 package. See its https://pkg.go.dev/github.com/r3labs/diff/v3[docs^] for more information.",
      "impure": false,
      "name": "diff",
      "params": {
        "named": [
          {
            "description": "The value to compare against.",
            "name": "other",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "beta",
      "version": "4.25.0"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "Encodes a string or byte array target according to a chosen scheme and returns a string result. Available schemes are: `base64`, `base64url` https://rfc-editor.org/rfc/rfc4648.html[(RFC 4648 with padding characters)], `base64rawurl` https://rfc-editor.org/rfc/rfc4648.html[(RFC 4648 without padding characters)], `hex`, `ascii85`.",
          "Examples": [
            {
              "mapping": "root.encoded = this.value.encode(\"hex\")",
              "results": [
                [
                  "{\"value\":\"hello world\"}",
                  "{\"encoded\":\"68656c6c6f20776f726c64\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.encoded = content().encode(\"ascii85\")",
              "results": [
                [
                  "this is totally unstructured data",
                  "{\"encoded\":\"FD,B0+DGm>FDl80Ci\\\"A>F`)8BEckl6F`M&(+Cno&@/\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "encode",
      "params": {
        "named": [
          {
            "description": "The encoding scheme to use.",
            "name": "scheme",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "Encrypts a string or byte array target according to a chosen AES encryption method and returns a string result. The algorithms require a key and an initialization vector / nonce. Available schemes are: `ctr`, `gcm`, `ofb`, `cbc`.",
          "Examples": [
            {
              "mapping": "let key = \"2b7e151628aed2a6abf7158809cf4f3c\".decode(\"hex\")\nlet vector = \"f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff\".decode(\"hex\")\nroot.encrypted = this.value.encrypt_aes(\"ctr\", $key, $vector).encode(\"hex\")",
              "results": [
                [
                  "{\"value\":\"hello world!\"}",
                  "{\"encrypted\":\"84e9b31ff7400bdf80be7254\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "encrypt_aes",
      "params": {
        "named": [
          {
            "description": "The scheme to use for encryption, one of `ctr`, `gcm`, `ofb`, `cbc`.",
            "name": "scheme",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "A key to encrypt with.",
            "name": "key",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An initialization vector / nonce.",
            "name": "iv",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo = this.foo.enumerated()",
              "results": [
                [
                  "{\"foo\":[\"bar\",\"baz\"]}",
                  "{\"foo\":[{\"index\":0,\"value\":\"bar\"},{\"index\":1,\"value\":\"baz\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Converts an array into a new array of objects, where each object has a field index containing the `index` of the element and a field `value` containing the original value of the element.",
      "impure": false,
      "name": "enumerated",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Escapes a string so that special characters like `<` to become `&lt;`. It escapes only five such characters: `<`, `>`, `&`, `'` and `\"` so that it can be safely placed within an HTML entity.",
          "Examples": [
            {
              "mapping": "root.escaped = this.value.escape_html()",
              "results": [
                [
                  "{\"value\":\"foo & bar\"}",
                  "{\"escaped\":\"foo &amp; bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "escape_html",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Escapes a string so that it can be safely placed within a URL query.",
          "Examples": [
            {
              "mapping": "root.escaped = this.value.escape_url_query()",
              "results": [
                [
                  "{\"value\":\"foo & bar\"}",
                  "{\"escaped\":\"foo+%26+bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "escape_url_query",
      "params": {},
      "status": "stable"
    },
    {
      "description": "Checks that a field, identified via a xref:configuration:field_paths.adoc[dot path], exists in an object.",
      "examples": [
        {
          "mapping": "root.result = this.foo.exists(\"bar.baz\")",
          "results": [
            [
              "{\"foo\":{\"bar\":{\"baz\":\"yep, I exist\"}}}",
              "{\"result\":true}"
            ],
            [
              "{\"foo\":{\"bar\":{}}}",
              "{\"result\":false}"
            ],
            [
              "{\"foo\":{}}",
              "{\"result\":false}"
            ]
          ],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "exists",
      "params": {
        "named": [
          {
            "description": "A xref:configuration:field_paths.adoc[dot path] to a field.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Explodes an array or object at a xref:configuration:field_paths.adoc[field path].",
          "Examples": [
            {
              "mapping": "root = this.explode(\"value\")",
              "results": [
                [
                  "{\"id\":1,\"value\":[\"foo\",\"bar\",\"baz\"]}",
                  "[{\"id\":1,\"value\":\"foo\"},{\"id\":1,\"value\":\"bar\"},{\"id\":1,\"value\":\"baz\"}]"
                ]
              ],
              "skip_testing": false,
              "summary": "##### On arrays\n\nExploding arrays results in an array containing elements matching the original document, where the target field of each element is an element of the exploded array:"
            },
            {
              "mapping": "root = this.explode(\"value\")",
              "results": [
                [
                  "{\"id\":1,\"value\":{\"foo\":2,\"bar\":[3,4],\"baz\":{\"bev\":5}}}",
                  "{\"bar\":{\"id\":1,\"value\":[3,4]},\"baz\":{\"id\":1,\"value\":{\"bev\":5}},\"foo\":{\"id\":1,\"value\":2}}"
                ]
              ],
              "skip_testing": false,
              "summary": "##### On objects\n\nExploding objects results in an object where the keys match the target object, and the values match the original document but with the target field replaced by the exploded value:"
            }
          ]
        }
      ],
      "impure": false,
      "name": "explode",
      "params": {
        "named": [
          {
            "description": "A xref:configuration:field_paths.adoc[dot path] to a field to explode.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Joins an array of path elements into a single file path. The separator depends on the operating system of the machine.",
          "Examples": [
            {
              "mapping": "root.path = this.path_elements.filepath_join()",
              "results": [
                [
                  "{\"path_elements\":[\"/foo/\",\"bar.txt\"]}",
                  "{\"path\":\"/foo/bar.txt\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "filepath_join",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Splits a file path immediately following the final Separator, separating it into a directory and file name component returned as a two element array of strings. If there is no Separator in the path, the first element will be empty and the second will contain the path. The separator depends on the operating system of the machine.",
          "Examples": [
            {
              "mapping": "root.path_sep = this.path.filepath_split()",
              "results": [
                [
                  "{\"path\":\"/foo/bar.txt\"}",
                  "{\"path_sep\":[\"/foo/\",\"bar.txt\"]}"
                ],
                [
                  "{\"path\":\"baz.txt\"}",
                  "{\"path_sep\":[\"\",\"baz.txt\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "filepath_split",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Executes a mapping query argument for each element of an array or key/value pair of an object. If the query returns `false` the item is removed from the resulting array or object. The item will also be removed if the query returns any non-boolean value.",
          "Examples": [
            {
              "mapping": "root.new_nums = this.nums.filter(num -> num > 10)",
              "results": [
                [
                  "{\"nums\":[3,11,4,17]}",
                  "{\"new_nums\":[11,17]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.new_dict = this.dict.filter(item -> item.value.contains(\"foo\"))",
              "results": [
                [
                  "{\"dict\":{\"first\":\"hello foo\",\"second\":\"world\",\"third\":\"this foo is great\"}}",
                  "{\"new_dict\":{\"first\":\"hello foo\",\"third\":\"this foo is great\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": "##### On objects\n\nWhen filtering objects the mapping query argument is provided a context with a field `key` containing the value key, and a field `value` containing the value."
            }
          ]
        }
      ],
      "impure": false,
      "name": "filter",
      "params": {
        "named": [
          {
            "description": "A query to apply to each element, if this query resolves to any value other than a boolean `true` the element will be removed from the result.",
            "name": "test",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.index = this.find(\"bar\")",
              "results": [
                [
                  "[\"foo\", \"bar\", \"baz\"]",
                  "{\"index\":1}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.index = this.things.find(this.goal)",
              "results": [
                [
                  "{\"goal\":\"bar\",\"things\":[\"foo\", \"bar\", \"baz\"]}",
                  "{\"index\":1}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the index of the first occurrence of a value in an array. `-1` is returned if there are no matches. Numerical comparisons are made irrespective of the representation type (float versus integer).",
      "impure": false,
      "name": "find",
      "params": {
        "named": [
          {
            "description": "A value to find.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.index = this.find_all(\"bar\")",
              "results": [
                [
                  "[\"foo\", \"bar\", \"baz\", \"bar\"]",
                  "{\"index\":[1,3]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.indexes = this.things.find_all(this.goal)",
              "results": [
                [
                  "{\"goal\":\"bar\",\"things\":[\"foo\", \"bar\", \"baz\", \"bar\", \"buz\"]}",
                  "{\"indexes\":[1,3]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns an array containing the indexes of all occurrences of a value in an array. An empty array is returned if there are no matches. Numerical comparisons are made irrespective of the representation type (float versus integer).",
      "impure": false,
      "name": "find_all",
      "params": {
        "named": [
          {
            "description": "A value to find.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.index = this.find_all_by(v -> v != \"bar\")",
              "results": [
                [
                  "[\"foo\", \"bar\", \"baz\"]",
                  "{\"index\":[0,2]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns an array containing the indexes of all occurrences of an array where the provided query resolves to a boolean `true`. An empty array is returned if there are no matches. Numerical comparisons are made irrespective of the representation type (float versus integer).",
      "impure": false,
      "name": "find_all_by",
      "params": {
        "named": [
          {
            "description": "A query to execute for each element.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.index = this.find_by(v -> v != \"bar\")",
              "results": [
                [
                  "[\"foo\", \"bar\", \"baz\"]",
                  "{\"index\":0}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the index of the first occurrence of an array where the provided query resolves to a boolean `true`. `-1` is returned if there are no matches.",
      "impure": false,
      "name": "find_by",
      "params": {
        "named": [
          {
            "description": "A query to execute for each element.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.result = this.flatten()",
              "results": [
                [
                  "[\"foo\",[\"bar\",\"baz\"],\"buz\"]",
                  "{\"result\":[\"foo\",\"bar\",\"baz\",\"buz\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Iterates an array and any element that is itself an array is removed and has its elements inserted directly in the resulting array.",
      "impure": false,
      "name": "flatten",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.out = this.in.float32()\n",
              "results": [
                [
                  "{\"in\":\"6.674282313423543523453425345e-11\"}",
                  "{\"out\":6.674283e-11}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 32-bit floating point number, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 32-bit floating point number. Please refer to the https://pkg.go.dev/strconv#ParseFloat[`strconv.ParseFloat` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "float32",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.out = this.in.float64()\n",
              "results": [
                [
                  "{\"in\":\"6.674282313423543523453425345e-11\"}",
                  "{\"out\":6.674282313423544e-11}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 64-bit floating point number, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 64-bit floating point number. Please refer to the https://pkg.go.dev/strconv#ParseFloat[`strconv.ParseFloat` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "float64",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.floor()",
              "results": [
                [
                  "{\"value\":5.7}",
                  "{\"new_value\":5}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the greatest integer value less than or equal to the target number. If the resulting value fits within a 64-bit integer then that is returned, otherwise a new floating point number is returned.",
      "impure": false,
      "name": "floor",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.sum = this.foo.fold(0, item -> item.tally + item.value)",
              "results": [
                [
                  "{\"foo\":[3,8,11]}",
                  "{\"sum\":22}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.result = this.foo.fold(\"\", item -> \"%v%v\".format(item.tally, item.value))",
              "results": [
                [
                  "{\"foo\":[\"hello \", \"world\"]}",
                  "{\"result\":\"hello world\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.smoothie = this.fruits.fold({}, item -> item.tally.merge(item.value))",
              "results": [
                [
                  "{\"fruits\":[{\"apple\":5},{\"banana\":3},{\"orange\":8}]}",
                  "{\"smoothie\":{\"apple\":5,\"banana\":3,\"orange\":8}}"
                ]
              ],
              "skip_testing": false,
              "summary": "You can use fold to merge an array of objects together:"
            }
          ]
        }
      ],
      "description": "Takes two arguments: an initial value, and a mapping query. For each element of an array the mapping context is an object with two fields `tally` and `value`, where `tally` contains the current accumulated value and `value` is the value of the current element. The mapping must return the result of adding the value to the tally.\n\nThe first argument is the value that `tally` will have on the first call.",
      "impure": false,
      "name": "fold",
      "params": {
        "named": [
          {
            "description": "The initial value to start the fold with. For example, an empty object `{}`, a zero count `0`, or an empty string `\"\"`.",
            "name": "initial",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          },
          {
            "description": "A query to apply for each element. The query is provided an object with two fields; `tally` containing the current tally, and `value` containing the value of the current element. The query should result in a new tally to be passed to the next element query.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Use a value string as a format specifier in order to produce a new string, using any number of provided arguments. Please refer to the Go https://pkg.go.dev/fmt[`fmt` package documentation^] for the list of valid format verbs.",
          "Examples": [
            {
              "mapping": "root.foo = \"%s(%v): %v\".format(this.name, this.age, this.fingers)",
              "results": [
                [
                  "{\"name\":\"lance\",\"age\":37,\"fingers\":13}",
                  "{\"foo\":\"lance(37): 13\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "format",
      "params": {
        "variadic": true
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "Serializes a target value into a pretty-printed JSON byte array (with 4 space indentation by default).",
          "Examples": [
            {
              "mapping": "root = this.doc.format_json()",
              "results": [
                [
                  "{\"doc\":{\"foo\":\"bar\"}}",
                  "{\n    \"foo\": \"bar\"\n}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root = this.format_json(\"  \")",
              "results": [
                [
                  "{\"doc\":{\"foo\":\"bar\"}}",
                  "{\n  \"doc\": {\n    \"foo\": \"bar\"\n  }\n}"
                ]
              ],
              "skip_testing": false,
              "summary": "Pass a string to the `indent` parameter in order to customise the indentation."
            },
            {
              "mapping": "root.doc = this.doc.format_json().string()",
              "results": [
                [
                  "{\"doc\":{\"foo\":\"bar\"}}",
                  "{\"doc\":\"{\\n    \\\"foo\\\": \\\"bar\\\"\\n}\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Use the `.string()` method in order to coerce the result into a string."
            },
            {
              "mapping": "root = this.doc.format_json(no_indent: true)",
              "results": [
                [
                  "{\"doc\":{\"foo\":\"bar\"}}",
                  "{\"foo\":\"bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Set the `no_indent` parameter to true to disable indentation. The result is equivalent to calling `bytes()`."
            },
            {
              "mapping": "root = this.doc.format_json()",
              "results": [
                [
                  "{\"doc\":{\"email\":\"foo&bar@benthos.dev\",\"name\":\"foo>bar\"}}",
                  "{\n    \"email\": \"foo\\u0026bar@benthos.dev\",\n    \"name\": \"foo\\u003ebar\"\n}"
                ]
              ],
              "skip_testing": false,
              "summary": "Escapes problematic HTML characters."
            },
            {
              "mapping": "root = this.doc.format_json(escape_html: false)",
              "results": [
                [
                  "{\"doc\":{\"email\":\"foo&bar@benthos.dev\",\"name\":\"foo>bar\"}}",
                  "{\n    \"email\": \"foo&bar@benthos.dev\",\n    \"name\": \"foo>bar\"\n}"
                ]
              ],
              "skip_testing": false,
              "summary": "Set the `escape_html` parameter to false to disable escaping of problematic HTML characters."
            }
          ]
        }
      ],
      "impure": false,
      "name": "format_json",
      "params": {
        "named": [
          {
            "default": "    ",
            "description": "Indentation string. Each element in a JSON object or array will begin on a new, indented line followed by one or more copies of indent according to the indentation nesting.",
            "name": "indent",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": false,
            "description": "Disable indentation.",
            "name": "no_indent",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          },
          {
            "default": true,
            "description": "Escape problematic HTML characters.",
            "name": "escape_html",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.format_msgpack().encode(\"hex\")",
              "results": [
                [
                  "{\"foo\":\"bar\"}",
                  "81a3666f6fa3626172"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.encoded = this.format_msgpack().encode(\"base64\")",
              "results": [
                [
                  "{\"foo\":\"bar\"}",
                  "{\"encoded\":\"gaNmb2+jYmFy\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Formats data as a https://msgpack.org/[MessagePack^] message in bytes format.",
      "impure": false,
      "name": "format_msgpack",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to format a timestamp value as a string according to a specified format, or RFC 3339 by default. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format.\n\nThe output format is defined by showing how the reference time, defined to be Mon Jan 2 15:04:05 -0700 MST 2006, would be displayed if it were the value. For an alternative way to specify formats check out the <<ts_strftime, `ts_strftime`>> method.",
      "impure": false,
      "name": "format_timestamp",
      "params": {
        "named": [
          {
            "default": "2006-01-02T15:04:05.999999999Z07:00",
            "description": "The output format to use.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An optional timezone to use, otherwise the timezone of the input string is used, or in the case of unix timestamps the local timezone is used.",
            "is_optional": true,
            "name": "tz",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to format a timestamp value as a string according to a specified strftime-compatible format. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format.",
      "impure": false,
      "name": "format_timestamp_strftime",
      "params": {
        "named": [
          {
            "description": "The output format to use.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An optional timezone to use, otherwise the timezone of the input string is used.",
            "is_optional": true,
            "name": "tz",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "format_timestamp_unix",
      "params": {},
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp with microsecond precision. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "format_timestamp_unix_micro",
      "params": {},
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp with millisecond precision. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "format_timestamp_unix_milli",
      "params": {},
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp with nanosecond precision. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "format_timestamp_unix_nano",
      "params": {},
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.format_xml()",
              "results": [
                [
                  "{\"foo\":{\"bar\":{\"baz\":\"foo bar baz\"}}}",
                  "<foo>\n    <bar>\n        <baz>foo bar baz</baz>\n    </bar>\n</foo>"
                ],
                [
                  "{\"-foo\":\"bar\",\"fizz\":\"buzz\"}",
                  "<doc foo=\"bar\">\n    <fizz>buzz</fizz>\n</doc>"
                ],
                [
                  "{\"foo\":[{\"bar\":\"baz\"},{\"fizz\":\"buzz\"}]}",
                  "<doc>\n    <foo>\n        <bar>baz</bar>\n    </foo>\n    <foo>\n        <fizz>buzz</fizz>\n    </foo>\n</doc>"
                ]
              ],
              "skip_testing": false,
              "summary": "Serializes a target value into a pretty-printed XML byte array (with 4 space indentation by default)."
            },
            {
              "mapping": "root = this.format_xml(\"  \")",
              "results": [
                [
                  "{\"foo\":{\"bar\":{\"baz\":\"foo bar baz\"}}}",
                  "<foo>\n  <bar>\n    <baz>foo bar baz</baz>\n  </bar>\n</foo>"
                ]
              ],
              "skip_testing": false,
              "summary": "Pass a string to the `indent` parameter in order to customise the indentation."
            },
            {
              "mapping": "root.doc = this.format_xml(\"\").string()",
              "results": [
                [
                  "{\"foo\":{\"bar\":{\"baz\":\"foo bar baz\"}}}",
                  "{\"doc\":\"<foo>\\n<bar>\\n<baz>foo bar baz</baz>\\n</bar>\\n</foo>\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Use the `.string()` method in order to coerce the result into a string."
            },
            {
              "mapping": "root = this.format_xml(no_indent: true)",
              "results": [
                [
                  "{\"foo\":{\"bar\":{\"baz\":\"foo bar baz\"}}}",
                  "<foo><bar><baz>foo bar baz</baz></bar></foo>"
                ]
              ],
              "skip_testing": false,
              "summary": "Set the `no_indent` parameter to true to disable indentation."
            },
            {
              "mapping": "root = this.format_xml(root_tag: \"blobfish\")",
              "results": [
                [
                  "{\"foo\":{\"bar\":{\"baz\":\"foo bar baz\"}}}",
                  "<blobfish>\n    <foo>\n        <bar>\n            <baz>foo bar baz</baz>\n        </bar>\n    </foo>\n</blobfish>"
                ],
                [
                  "{\"-foo\":\"bar\",\"fizz\":\"buzz\"}",
                  "<blobfish foo=\"bar\">\n    <fizz>buzz</fizz>\n</blobfish>"
                ],
                [
                  "{\"foo\":[{\"bar\":\"baz\"},{\"fizz\":\"buzz\"}]}",
                  "<blobfish>\n    <foo>\n        <bar>baz</bar>\n    </foo>\n    <foo>\n        <fizz>buzz</fizz>\n    </foo>\n</blobfish>"
                ]
              ],
              "skip_testing": false,
              "summary": "Set a custom root tag."
            }
          ]
        }
      ],
      "description": "\nSerializes a target value into an XML byte array.\n",
      "impure": false,
      "name": "format_xml",
      "params": {
        "named": [
          {
            "default": "    ",
            "description": "Indentation string. Each element in an XML object or array will begin on a new, indented line followed by one or more copies of indent according to the indentation nesting.",
            "name": "indent",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": false,
            "description": "Disable indentation.",
            "name": "no_indent",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          },
          {
            "description": "Root tag. Set this if you wish to override the root tag of the document.",
            "is_optional": true,
            "name": "root_tag",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "Serializes a target value into a YAML byte array.",
          "Examples": [
            {
              "mapping": "root = this.doc.format_yaml()",
              "results": [
                [
                  "{\"doc\":{\"foo\":\"bar\"}}",
                  "foo: bar\n"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.doc = this.doc.format_yaml().string()",
              "results": [
                [
                  "{\"doc\":{\"foo\":\"bar\"}}",
                  "{\"doc\":\"foo: bar\\n\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Use the `.string()` method in order to coerce the result into a string."
            }
          ]
        }
      ],
      "impure": false,
      "name": "format_yaml",
      "params": {},
      "status": "stable"
    },
    {
      "description": "Modifies a target query such that certain functions are executed from the perspective of another message in the batch. This allows you to mutate events based on the contents of other messages. Functions that support this behavior are `content`, `json` and `meta`.",
      "examples": [
        {
          "mapping": "root = this\nroot.foo = json(\"foo\").from(1)",
          "results": [],
          "skip_testing": false,
          "summary": "For example, the following map extracts the contents of the JSON field `foo` specifically from message index `1` of a batch, effectively overriding the field `foo` for all messages of a batch to that of message 1:"
        }
      ],
      "impure": false,
      "name": "from",
      "params": {
        "named": [
          {
            "description": "The message index to use as a perspective.",
            "name": "index",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "description": "Modifies a target query such that certain functions are executed from the perspective of each message in the batch, and returns the set of results as an array. Functions that support this behavior are `content`, `json` and `meta`.",
      "examples": [
        {
          "mapping": "root = this\nroot.foo_summed = json(\"foo\").from_all().sum()",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "from_all",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the anonymous IP associated with it.",
      "impure": false,
      "name": "geoip_anonymous_ip",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the ASN associated with it.",
      "impure": false,
      "name": "geoip_asn",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the city associated with it.",
      "impure": false,
      "name": "geoip_city",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the connection type associated with it.",
      "impure": false,
      "name": "geoip_connection_type",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the country associated with it.",
      "impure": false,
      "name": "geoip_country",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the domain associated with it.",
      "impure": false,
      "name": "geoip_domain",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the enterprise associated with it.",
      "impure": false,
      "name": "geoip_enterprise",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "GeoIP",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Looks up an IP address against a https://www.maxmind.com/en/home[MaxMind database file^] and, if found, returns an object describing the ISP associated with it.",
      "impure": false,
      "name": "geoip_isp",
      "params": {
        "named": [
          {
            "description": "A path to an mmdb (maxmind) file.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.result = this.foo.get(this.target)",
              "results": [
                [
                  "{\"foo\":{\"bar\":\"from bar\",\"baz\":\"from baz\"},\"target\":\"bar\"}",
                  "{\"result\":\"from bar\"}"
                ],
                [
                  "{\"foo\":{\"bar\":\"from bar\",\"baz\":\"from baz\"},\"target\":\"baz\"}",
                  "{\"result\":\"from baz\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Extract a field value, identified via a xref:configuration:field_paths.adoc[dot path], from an object.",
      "impure": false,
      "name": "get",
      "params": {
        "named": [
          {
            "description": "A xref:configuration:field_paths.adoc[dot path] identifying a field to obtain.",
            "name": "path",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Checks whether a string has a prefix argument and returns a bool.",
          "Examples": [
            {
              "mapping": "root.t1 = this.v1.has_prefix(\"foo\")\nroot.t2 = this.v2.has_prefix(\"foo\")",
              "results": [
                [
                  "{\"v1\":\"foobar\",\"v2\":\"barfoo\"}",
                  "{\"t1\":true,\"t2\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "has_prefix",
      "params": {
        "named": [
          {
            "description": "The string to test.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Checks whether a string has a suffix argument and returns a bool.",
          "Examples": [
            {
              "mapping": "root.t1 = this.v1.has_suffix(\"foo\")\nroot.t2 = this.v2.has_suffix(\"foo\")",
              "results": [
                [
                  "{\"v1\":\"foobar\",\"v2\":\"barfoo\"}",
                  "{\"t1\":false,\"t2\":true}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "has_suffix",
      "params": {
        "named": [
          {
            "description": "The string to test.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "\nHashes a string or byte array according to a chosen algorithm and returns the result as a byte array. When mapping the result to a JSON field the value should be cast to a string using the method xref:guides:bloblang/methods.adoc#string[`string`], or encoded using the method xref:guides:bloblang/methods.adoc#encode[`encode`], otherwise it will be base64 encoded by default.\n\nAvailable algorithms are: `hmac_sha1`, `hmac_sha256`, `hmac_sha512`, `md5`, `sha1`, `sha256`, `sha512`, `xxhash64`, `crc32`, `fnv32`.\n\nThe following algorithms require a key, which is specified as a second argument: `hmac_sha1`, `hmac_sha256`, `hmac_sha512`.",
          "Examples": [
            {
              "mapping": "root.h1 = this.value.hash(\"sha1\").encode(\"hex\")\nroot.h2 = this.value.hash(\"hmac_sha1\",\"static-key\").encode(\"hex\")",
              "results": [
                [
                  "{\"value\":\"hello world\"}",
                  "{\"h1\":\"2aae6c35c94fcfb415dbe95f408b9ce91ee846ed\",\"h2\":\"d87e5f068fa08fe90bb95bc7c8344cb809179d76\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.h1 = this.value.hash(algorithm: \"crc32\", polynomial: \"Castagnoli\").encode(\"hex\")\nroot.h2 = this.value.hash(algorithm: \"crc32\", polynomial: \"Koopman\").encode(\"hex\")",
              "results": [
                [
                  "{\"value\":\"hello world\"}",
                  "{\"h1\":\"c99465aa\",\"h2\":\"df373d3c\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "The `crc32` algorithm supports options for the polynomial."
            }
          ]
        }
      ],
      "impure": false,
      "name": "hash",
      "params": {
        "named": [
          {
            "description": "The hasing algorithm to use.",
            "name": "algorithm",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An optional key to use.",
            "is_optional": true,
            "name": "key",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": "IEEE",
            "description": "An optional polynomial key to use when selecting the `crc32` algorithm, otherwise ignored. Options are `IEEE` (default), `Castagnoli` and `Koopman`",
            "name": "polynomial",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.last_name = this.names.index(-1)",
              "results": [
                [
                  "{\"names\":[\"rachel\",\"stevens\"]}",
                  "{\"last_name\":\"stevens\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.last_byte = this.name.bytes().index(-1)",
              "results": [
                [
                  "{\"name\":\"foobar bazson\"}",
                  "{\"last_byte\":110}"
                ]
              ],
              "skip_testing": false,
              "summary": "It is also possible to use this method on byte arrays, in which case the selected element will be returned as an integer."
            }
          ]
        }
      ],
      "description": "Extract an element from an array by an index. The index can be negative, and if so the element will be selected from the end counting backwards starting from -1. E.g. an index of -1 returns the last element, an index of -2 returns the element before the last, and so on.",
      "impure": false,
      "name": "index",
      "params": {
        "named": [
          {
            "description": "The index to obtain from an array.",
            "name": "index",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Returns the starting index of the argument substring in a string target, or `-1` if the target doesn't contain the argument.",
          "Examples": [
            {
              "mapping": "root.index = this.thing.index_of(\"bar\")",
              "results": [
                [
                  "{\"thing\":\"foobar\"}",
                  "{\"index\":3}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.index = content().index_of(\"meow\")",
              "results": [
                [
                  "the cat meowed, the dog woofed",
                  "{\"index\":8}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "index_of",
      "params": {
        "named": [
          {
            "description": "A string to search for.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempt to infer the schema of a given value. The resulting schema can then be used as an input to schema conversion and enforcement methods.",
      "impure": false,
      "name": "infer_schema",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.int16()\nroot.b = this.b.round().int16()\nroot.c = this.c.int16()\nroot.d = this.d.int16().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":-12}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.int16()\n",
              "results": [
                [
                  "\"0xDE\"",
                  "222"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 16-bit signed integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 16-bit signed integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "int16",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.int32()\nroot.b = this.b.round().int32()\nroot.c = this.c.int32()\nroot.d = this.d.int32().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":-12}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.int32()\n",
              "results": [
                [
                  "\"0xDEAD\"",
                  "57005"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 32-bit signed integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 32-bit signed integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "int32",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.int64()\nroot.b = this.b.round().int64()\nroot.c = this.c.int64()\nroot.d = this.d.int64().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":-12}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.int64()\n",
              "results": [
                [
                  "\"0xDEADBEEF\"",
                  "3735928559"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 64-bit signed integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 64-bit signed integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "int64",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.int8()\nroot.b = this.b.round().int8()\nroot.c = this.c.int8()\nroot.d = this.d.int8().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":-12}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.int8()\n",
              "results": [
                [
                  "\"0xD\"",
                  "13"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 8-bit signed integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 8-bit signed integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "int8",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Join an array of strings with an optional delimiter into a single string.",
          "Examples": [
            {
              "mapping": "root.joined_words = this.words.join()\nroot.joined_numbers = this.numbers.map_each(this.string()).join(\",\")",
              "results": [
                [
                  "{\"words\":[\"hello\",\"world\"],\"numbers\":[3,8,11]}",
                  "{\"joined_numbers\":\"3,8,11\",\"joined_words\":\"helloworld\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "join",
      "params": {
        "named": [
          {
            "description": "An optional delimiter to add between each string.",
            "is_optional": true,
            "name": "delimiter",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.all_names = this.json_path(\"$..name\")",
              "results": [
                [
                  "{\"name\":\"alice\",\"foo\":{\"name\":\"bob\"}}",
                  "{\"all_names\":[\"alice\",\"bob\"]}"
                ],
                [
                  "{\"thing\":[\"this\",\"bar\",{\"name\":\"alice\"}]}",
                  "{\"all_names\":[\"alice\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.text_objects = this.json_path(\"$.body[?(@.type=='text')]\")",
              "results": [
                [
                  "{\"body\":[{\"type\":\"image\",\"id\":\"foo\"},{\"type\":\"text\",\"id\":\"bar\"}]}",
                  "{\"text_objects\":[{\"id\":\"bar\",\"type\":\"text\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Executes the given JSONPath expression on an object or array and returns the result. The JSONPath expression syntax can be found at https://goessner.net/articles/JsonPath/. For more complex logic, you can use Gval expressions (https://github.com/PaesslerAG/gval).",
      "impure": false,
      "name": "json_path",
      "params": {
        "named": [
          {
            "description": "The JSONPath expression to execute.",
            "name": "expression",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "experimental"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.json_schema(\"\"\"{\n  \"type\":\"object\",\n  \"properties\":{\n    \"foo\":{\n      \"type\":\"string\"\n    }\n  }\n}\"\"\")",
              "results": [
                [
                  "{\"foo\":\"bar\"}",
                  "{\"foo\":\"bar\"}"
                ],
                [
                  "{\"foo\":5}",
                  "Error(\"failed assignment (line 1): field `this`: foo invalid type. expected: string, given: integer\")"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root = this.json_schema(file(env(\"BENTHOS_TEST_BLOBLANG_SCHEMA_FILE\")))",
              "results": [],
              "skip_testing": false,
              "summary": "In order to load a schema from a file use the `file` function."
            }
          ]
        }
      ],
      "description": "Checks a https://json-schema.org/[JSON schema^] against a value and returns the value if it matches or throws and error if it does not.",
      "impure": false,
      "name": "json_schema",
      "params": {
        "named": [
          {
            "description": "The schema to check values against.",
            "name": "schema",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo_key_values = this.foo.key_values().sort_by(pair -> pair.key)",
              "results": [
                [
                  "{\"foo\":{\"bar\":1,\"baz\":2}}",
                  "{\"foo_key_values\":[{\"key\":\"bar\",\"value\":1},{\"key\":\"baz\",\"value\":2}]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the key/value pairs of an object as an array, where each element is an object with a `key` field and a `value` field. The order of the resulting array will be random.",
      "impure": false,
      "name": "key_values",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo_keys = this.foo.keys()",
              "results": [
                [
                  "{\"foo\":{\"bar\":1,\"baz\":2}}",
                  "{\"foo_keys\":[\"bar\",\"baz\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the keys of an object as an array.",
      "impure": false,
      "name": "keys",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Returns the length of a string.",
          "Examples": [
            {
              "mapping": "root.foo_len = this.foo.length()",
              "results": [
                [
                  "{\"foo\":\"hello world\"}",
                  "{\"foo_len\":11}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        },
        {
          "Category": "Object & Array Manipulation",
          "Description": "Returns the length of an array or object (number of keys).",
          "Examples": [
            {
              "mapping": "root.foo_len = this.foo.length()",
              "results": [
                [
                  "{\"foo\":[\"first\",\"second\"]}",
                  "{\"foo_len\":2}"
                ],
                [
                  "{\"foo\":{\"first\":\"bar\",\"second\":\"baz\"}}",
                  "{\"foo_len\":2}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "length",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.log().round()",
              "results": [
                [
                  "{\"value\":1}",
                  "{\"new_value\":0}"
                ],
                [
                  "{\"value\":2.7183}",
                  "{\"new_value\":1}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the natural logarithm of a number.",
      "impure": false,
      "name": "log",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.log10()",
              "results": [
                [
                  "{\"value\":100}",
                  "{\"new_value\":2}"
                ],
                [
                  "{\"value\":1000}",
                  "{\"new_value\":3}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the decimal logarithm of a number.",
      "impure": false,
      "name": "log10",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Convert a string value into lowercase.",
          "Examples": [
            {
              "mapping": "root.foo = this.foo.lowercase()",
              "results": [
                [
                  "{\"foo\":\"HELLO WORLD\"}",
                  "{\"foo\":\"hello world\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "lowercase",
      "params": {},
      "status": "stable"
    },
    {
      "impure": false,
      "name": "map",
      "params": {
        "named": [
          {
            "description": "A query to execute on the target.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "hidden"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_nums = this.nums.map_each(num -> if num < 10 {\n  deleted()\n} else {\n  num - 10\n})",
              "results": [
                [
                  "{\"nums\":[3,11,4,17]}",
                  "{\"new_nums\":[1,7]}"
                ]
              ],
              "skip_testing": false,
              "summary": "##### On arrays\n\nApply a mapping to each element of an array and replace the element with the result. Within the argument mapping the context is the value of the element being mapped."
            },
            {
              "mapping": "root.new_dict = this.dict.map_each(item -> item.value.uppercase())",
              "results": [
                [
                  "{\"dict\":{\"foo\":\"hello\",\"bar\":\"world\"}}",
                  "{\"new_dict\":{\"bar\":\"WORLD\",\"foo\":\"HELLO\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": "##### On objects\n\nApply a mapping to each value of an object and replace the value with the result. Within the argument mapping the context is an object with a field `key` containing the value key, and a field `value`."
            }
          ]
        }
      ],
      "impure": false,
      "name": "map_each",
      "params": {
        "named": [
          {
            "description": "A query that will be used to map each element.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Apply a mapping to each key of an object, and replace the key with the result, which must be a string.",
          "Examples": [
            {
              "mapping": "root.new_dict = this.dict.map_each_key(key -> key.uppercase())",
              "results": [
                [
                  "{\"dict\":{\"keya\":\"hello\",\"keyb\":\"world\"}}",
                  "{\"new_dict\":{\"KEYA\":\"hello\",\"KEYB\":\"world\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root = this.map_each_key(key -> if key.contains(\"kafka\") { \"_\" + key })",
              "results": [
                [
                  "{\"amqp_key\":\"foo\",\"kafka_key\":\"bar\",\"kafka_topic\":\"baz\"}",
                  "{\"_kafka_key\":\"bar\",\"_kafka_topic\":\"baz\",\"amqp_key\":\"foo\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "map_each_key",
      "params": {
        "named": [
          {
            "description": "A query that will be used to map each key.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.biggest = this.values.max()",
              "results": [
                [
                  "{\"values\":[0,3,2.5,7,5]}",
                  "{\"biggest\":7}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.new_value = [0,this.value].max()",
              "results": [
                [
                  "{\"value\":-1}",
                  "{\"new_value\":0}"
                ],
                [
                  "{\"value\":7}",
                  "{\"new_value\":7}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the largest numerical value found within an array. All values must be numerical and the array must not be empty, otherwise an error is returned.",
      "impure": false,
      "name": "max",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.foo.merge(this.bar)",
              "results": [
                [
                  "{\"foo\":{\"first_name\":\"fooer\",\"likes\":\"bars\"},\"bar\":{\"second_name\":\"barer\",\"likes\":\"foos\"}}",
                  "{\"first_name\":\"fooer\",\"likes\":[\"bars\",\"foos\"],\"second_name\":\"barer\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Merge a source object into an existing destination object. When a collision is found within the merged structures (both a source and destination object contain the same non-object keys) the result will be an array containing both values, where values that are already arrays will be expanded into the resulting array. In order to simply override destination fields on collision use the <<assign, `assign`>> method.",
      "impure": false,
      "name": "merge",
      "params": {
        "named": [
          {
            "description": "A value to merge the target value with.",
            "name": "with",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.smallest = this.values.min()",
              "results": [
                [
                  "{\"values\":[0,3,-2.5,7,5]}",
                  "{\"smallest\":-2.5}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.new_value = [10,this.value].min()",
              "results": [
                [
                  "{\"value\":2}",
                  "{\"new_value\":2}"
                ],
                [
                  "{\"value\":23}",
                  "{\"new_value\":10}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the smallest numerical value found within an array. All values must be numerical and the array must not be empty, otherwise an error is returned.",
      "impure": false,
      "name": "min",
      "params": {},
      "status": "stable"
    },
    {
      "impure": false,
      "name": "not",
      "params": {},
      "status": "hidden"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Ensures that the given string, array or object value is not empty, and if so returns it, otherwise an error is returned.",
          "Examples": [
            {
              "mapping": "root.a = this.a.not_empty()",
              "results": [
                [
                  "{\"a\":\"foo\"}",
                  "{\"a\":\"foo\"}"
                ],
                [
                  "{\"a\":\"\"}",
                  "Error(\"failed assignment (line 1): field `this.a`: string value is empty\")"
                ],
                [
                  "{\"a\":[\"foo\",\"bar\"]}",
                  "{\"a\":[\"foo\",\"bar\"]}"
                ],
                [
                  "{\"a\":[]}",
                  "Error(\"failed assignment (line 1): field `this.a`: array value is empty\")"
                ],
                [
                  "{\"a\":{\"b\":\"foo\",\"c\":\"bar\"}}",
                  "{\"a\":{\"b\":\"foo\",\"c\":\"bar\"}}"
                ],
                [
                  "{\"a\":{}}",
                  "Error(\"failed assignment (line 1): field `this.a`: object value is empty\")"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "not_empty",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Ensures that the given value is not `null`, and if so returns it, otherwise an error is returned.",
          "Examples": [
            {
              "mapping": "root.a = this.a.not_null()",
              "results": [
                [
                  "{\"a\":\"foobar\",\"b\":\"barbaz\"}",
                  "{\"a\":\"foobar\"}"
                ],
                [
                  "{\"b\":\"barbaz\"}",
                  "Error(\"failed assignment (line 1): field `this.a`: value is null\")"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "not_null",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Attempt to parse a value into a number. An optional argument can be provided, in which case if the value cannot be parsed into a number the argument will be returned instead.",
          "Examples": [
            {
              "mapping": "root.foo = this.thing.number() + 10\nroot.bar = this.thing.number(5) * 10",
              "results": [],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "number",
      "params": {
        "named": [
          {
            "description": "An optional value to yield if the target cannot be parsed as a number.",
            "is_optional": true,
            "name": "default",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "float"
          }
        ]
      },
      "status": "stable"
    },
    {
      "description": "If the result of the target query fails or resolves to `null`, returns the argument instead. This is an explicit method alternative to the coalesce pipe operator `|`.",
      "examples": [
        {
          "mapping": "root.doc.id = this.thing.id.or(uuid_v4())",
          "results": [],
          "skip_testing": false,
          "summary": ""
        }
      ],
      "impure": false,
      "name": "or",
      "params": {
        "named": [
          {
            "description": "A value to yield, or query to execute, if the target query fails or resolves to `null`.",
            "name": "fallback",
            "no_dynamic": false,
            "scalars_to_literal": true,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "Attempts to parse a string into an array of objects by following the CSV format described in RFC 4180.",
          "Examples": [
            {
              "mapping": "root.orders = this.orders.parse_csv()",
              "results": [
                [
                  "{\"orders\":\"foo,bar\\nfoo 1,bar 1\\nfoo 2,bar 2\"}",
                  "{\"orders\":[{\"bar\":\"bar 1\",\"foo\":\"foo 1\"},{\"bar\":\"bar 2\",\"foo\":\"foo 2\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Parses CSV data with a header row"
            },
            {
              "mapping": "root.orders = this.orders.parse_csv(false)",
              "results": [
                [
                  "{\"orders\":\"foo 1,bar 1\\nfoo 2,bar 2\"}",
                  "{\"orders\":[[\"foo 1\",\"bar 1\"],[\"foo 2\",\"bar 2\"]]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Parses CSV data without a header row"
            },
            {
              "mapping": "root.orders = this.orders.parse_csv(delimiter:\".\")",
              "results": [
                [
                  "{\"orders\":\"foo.bar\\nfoo 1.bar 1\\nfoo 2.bar 2\"}",
                  "{\"orders\":[{\"bar\":\"bar 1\",\"foo\":\"foo 1\"},{\"bar\":\"bar 2\",\"foo\":\"foo 2\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Parses CSV data delimited by dots"
            },
            {
              "mapping": "root.orders = this.orders.parse_csv(lazy_quotes:true)",
              "results": [
                [
                  "{\"orders\":\"foo,bar\\nfoo 1,bar 1\\nfoo\\\" \\\"2,bar\\\" \\\"2\"}",
                  "{\"orders\":[{\"bar\":\"bar 1\",\"foo\":\"foo 1\"},{\"bar\":\"bar\\\" \\\"2\",\"foo\":\"foo\\\" \\\"2\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Parses CSV data containing a quote in an unquoted field"
            }
          ]
        }
      ],
      "impure": false,
      "name": "parse_csv",
      "params": {
        "named": [
          {
            "default": true,
            "description": "Whether to reference the first row as a header row. If set to true the output structure for messages will be an object where field keys are determined by the header row. Otherwise, the output will be an array of row arrays.",
            "name": "parse_header_row",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          },
          {
            "default": ",",
            "description": "The delimiter to use for splitting values in each record. It must be a single character.",
            "name": "delimiter",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "default": false,
            "description": "If set to `true`, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field.",
            "name": "lazy_quotes",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.delay_for_ns = this.delay_for.parse_duration()",
              "results": [
                [
                  "{\"delay_for\":\"50us\"}",
                  "{\"delay_for_ns\":50000}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.delay_for_s = this.delay_for.parse_duration() / 1000000000",
              "results": [
                [
                  "{\"delay_for\":\"2h\"}",
                  "{\"delay_for_s\":7200}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to parse a string as a duration and returns an integer of nanoseconds. A duration string is a possibly signed sequence of decimal numbers, each with an optional fraction and a unit suffix, such as \"300ms\", \"-1.5h\" or \"2h45m\". Valid time units are \"ns\", \"us\" (or \"µs\"), \"ms\", \"s\", \"m\", \"h\".",
      "impure": false,
      "name": "parse_duration",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.delay_for_ns = this.delay_for.parse_duration_iso8601()",
              "results": [
                [
                  "{\"delay_for\":\"P3Y6M4DT12H30M5S\"}",
                  "{\"delay_for_ns\":110839937000000000}"
                ]
              ],
              "skip_testing": false,
              "summary": "Arbitrary ISO-8601 duration string to nanoseconds:"
            },
            {
              "mapping": "root.delay_for_s = this.delay_for.parse_duration_iso8601() / 1000000000",
              "results": [
                [
                  "{\"delay_for\":\"PT2H\"}",
                  "{\"delay_for_s\":7200}"
                ]
              ],
              "skip_testing": false,
              "summary": "Two hours ISO-8601 duration string to seconds:"
            },
            {
              "mapping": "root.delay_for_s = this.delay_for.parse_duration_iso8601() / 1000000000",
              "results": [
                [
                  "{\"delay_for\":\"PT2.5S\"}",
                  "{\"delay_for_s\":2.5}"
                ]
              ],
              "skip_testing": false,
              "summary": "Two and a half seconds ISO-8601 duration string to seconds:"
            }
          ]
        }
      ],
      "description": "Attempts to parse a string using ISO-8601 rules as a duration and returns an integer of nanoseconds. A duration string is represented by the format \"P[n]Y[n]M[n]DT[n]H[n]M[n]S\" or \"P[n]W\". In these representations, the \"[n]\" is replaced by the value for each of the date and time elements that follow the \"[n]\". For example, \"P3Y6M4DT12H30M5S\" represents a duration of \"three years, six months, four days, twelve hours, thirty minutes, and five seconds\". The last field of the format allows fractions with one decimal place, so \"P3.5S\" will return 3500000000ns. Any additional decimals will be truncated.",
      "impure": false,
      "name": "parse_duration_iso8601",
      "params": {},
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.values = this.body.parse_form_url_encoded()",
              "results": [
                [
                  "{\"body\":\"noise=meow&animal=cat&fur=orange&fur=fluffy\"}",
                  "{\"values\":{\"animal\":\"cat\",\"fur\":[\"orange\",\"fluffy\"],\"noise\":\"meow\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to parse a url-encoded query string (from an x-www-form-urlencoded request body) and returns a structured result.",
      "impure": false,
      "name": "parse_form_url_encoded",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "Attempts to parse a string as a JSON document and returns the result.",
          "Examples": [
            {
              "mapping": "root.doc = this.doc.parse_json()",
              "results": [
                [
                  "{\"doc\":\"{\\\"foo\\\":\\\"bar\\\"}\"}",
                  "{\"doc\":{\"foo\":\"bar\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.doc = this.doc.parse_json(use_number: true)",
              "results": [
                [
                  "{\"doc\":\"{\\\"foo\\\":\\\"11380878173205700000000000000000000000000000000\\\"}\"}",
                  "{\"doc\":{\"foo\":\"11380878173205700000000000000000000000000000000\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "parse_json",
      "params": {
        "named": [
          {
            "description": "An optional flag that when set makes parsing numbers as json.Number instead of the default float64.",
            "is_optional": true,
            "name": "use_number",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_es256(\"\"\"-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEGtLqIBePHmIhQcf0JLgc+F/4W/oI\ndp0Gta53G35VerNDgUUXmp78J2kfh4qLdh0XtmOMI587tCaqjvDAXfs//w==\n-----END PUBLIC KEY-----\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.GIRajP9JJbpTlqSCdNEz4qpQkRvzX4Q51YnTwVyxLDM9tKjR_a8ggHWn9CWj7KG0x8J56OWtmUxn112SRTZVhQ\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with ES256. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_es256",
      "params": {
        "named": [
          {
            "description": "The ES256 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_es384(\"\"\"-----BEGIN PUBLIC KEY-----\nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAERoz74/B6SwmLhs8X7CWhnrWyRrB13AuU\n8OYeqy0qHRu9JWNw8NIavqpTmu6XPT4xcFanYjq8FbeuM11eq06C52mNmS4LLwzA\n2imlFEgn85bvJoC3bnkuq4mQjwt9VxdH\n-----END PUBLIC KEY-----\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJFUzM4NCIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.H2HBSlrvQBaov2tdreGonbBexxtQB-xzaPL4-tNQZ6TVh7VH8VBcSwcWHYa1lBAHmdsKOFcB2Wk0SB7QWeGT3ptSgr-_EhDMaZ8bA5spgdpq5DsKfaKHrd7DbbQlmxNq\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with ES384. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_es384",
      "params": {
        "named": [
          {
            "description": "The ES384 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_es512(\"\"\"-----BEGIN PUBLIC KEY-----\nMIGbMBAGByqGSM49AgEGBSuBBAAjA4GGAAQAkHLdts9P56fFkyhpYQ31M/Stwt3w\nvpaxhlfudxnXgTO1IP4RQRgryRxZ19EUzhvWDcG3GQIckoNMY5PelsnCGnIBT2Xh\n9NQkjWF5K6xS4upFsbGSAwQ+GIyyk5IPJ2LHgOyMSCVh5gRZXV3CZLzXujx/umC9\nUeYyTt05zRRWuD+p5bY=\n-----END PUBLIC KEY-----\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJFUzUxMiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.ACrpLuU7TKpAnncDCpN9m85nkL55MJ45NFOBl6-nEXmNT1eIxWjiP4pwWVbFH9et_BgN14119jbL_KqEJInPYc9nAXC6dDLq0aBU-dalvNl4-O5YWpP43-Y-TBGAsWnbMTrchILJ4-AEiICe73Ck5yWPleKg9c3LtkEFWfGs7BoPRguZ\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with ES512. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_es512",
      "params": {
        "named": [
          {
            "description": "The ES512 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_hs256(\"\"\"dont-tell-anyone\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.YwXOM8v3gHVWcQRRRQc_zDlhmLnM62fwhFYGpiA0J1A\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with HS256. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_hs256",
      "params": {
        "named": [
          {
            "description": "The HS256 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.12.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_hs384(\"\"\"dont-tell-anyone\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJIUzM4NCIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.2Y8rf_ijwN4t8hOGGViON_GrirLkCQVbCOuax6EoZ3nluX0tCGezcJxbctlIfsQ2\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with HS384. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_hs384",
      "params": {
        "named": [
          {
            "description": "The HS384 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.12.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_hs512(\"\"\"dont-tell-anyone\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.utRb0urG6LGGyranZJVo5Dk0Fns1QNcSUYPN0TObQ-YzsGGB8jrxHwM5NAJccjJZzKectEUqmmKCaETZvuX4Fg\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with HS512. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_hs512",
      "params": {
        "named": [
          {
            "description": "The HS512 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.12.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_rs256(\"\"\"-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs/ibN8r68pLMR6gRzg4S\n8v8l6Q7yi8qURjkEbcNeM1rkokC7xh0I4JVTwxYSVv/JIW8qJdyspl5NIfuAVi32\nWfKvSAs+NIs+DMsNPYw3yuQals4AX8hith1YDvYpr8SD44jxhz/DR9lYKZFGhXGB\n+7NqQ7vpTWp3BceLYocazWJgusZt7CgecIq57ycM5hjM93BvlrUJ8nQ1a46wfL/8\nCy4P0et70hzZrsjjN41KFhKY0iUwlyU41yEiDHvHDDsTMBxAZosWjSREGfJL6Mfp\nXOInTHs/Gg6DZMkbxjQu6L06EdJ+Q/NwglJdAXM7Zo9rNELqRig6DdvG5JesdMsO\n+QIDAQAB\n-----END PUBLIC KEY-----\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.b0lH3jEupZZ4zoaly4Y_GCvu94HH6UKdKY96zfGNsIkPZpQLHIkZ7jMWlLlNOAd8qXlsBGP_i8H2qCKI4zlWJBGyPZgxXDzNRPVrTDfFpn4t4nBcA1WK2-ntXP3ehQxsaHcQU8Z_nsogId7Pme5iJRnoHWEnWtbwz5DLSXL3ZZNnRdrHM9MdI7QSDz9mojKDCaMpGN9sG7Xl-tGdBp1XzXuUOzG8S03mtZ1IgVR1uiBL2N6oohHIAunk8DIAmNWI-zgycTgzUGU7mvPkKH43qO8Ua1-13tCUBKKa8VxcotZ67Mxm1QAvBGoDnTKwWMwghLzs6d6WViXQg6eWlJcpBA\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with RS256. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_rs256",
      "params": {
        "named": [
          {
            "description": "The RS256 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_rs384(\"\"\"-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs/ibN8r68pLMR6gRzg4S\n8v8l6Q7yi8qURjkEbcNeM1rkokC7xh0I4JVTwxYSVv/JIW8qJdyspl5NIfuAVi32\nWfKvSAs+NIs+DMsNPYw3yuQals4AX8hith1YDvYpr8SD44jxhz/DR9lYKZFGhXGB\n+7NqQ7vpTWp3BceLYocazWJgusZt7CgecIq57ycM5hjM93BvlrUJ8nQ1a46wfL/8\nCy4P0et70hzZrsjjN41KFhKY0iUwlyU41yEiDHvHDDsTMBxAZosWjSREGfJL6Mfp\nXOInTHs/Gg6DZMkbxjQu6L06EdJ+Q/NwglJdAXM7Zo9rNELqRig6DdvG5JesdMsO\n+QIDAQAB\n-----END PUBLIC KEY-----\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJSUzM4NCIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.orcXYBcjVE5DU7mvq4KKWFfNdXR4nEY_xupzWoETRpYmQZIozlZnM_nHxEk2dySvpXlAzVm7kgOPK2RFtGlOVaNRIa3x-pMMr-bhZTno4L8Hl4sYxOks3bWtjK7wql4uqUbqThSJB12psAXw2-S-I_FMngOPGIn4jDT9b802ottJSvTpXcy0-eKTjrV2PSkRRu-EYJh0CJZW55MNhqlt6kCGhAXfbhNazN3ASX-dmpd_JixyBKphrngr_zRA-FCn_Xf3QQDA-5INopb4Yp5QiJ7UxVqQEKI80X_JvJqz9WE1qiAw8pq5-xTen1t7zTP-HT1NbbD3kltcNa3G8acmNg\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with RS384. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_rs384",
      "params": {
        "named": [
          {
            "description": "The RS384 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.claims = this.signed.parse_jwt_rs512(\"\"\"-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs/ibN8r68pLMR6gRzg4S\n8v8l6Q7yi8qURjkEbcNeM1rkokC7xh0I4JVTwxYSVv/JIW8qJdyspl5NIfuAVi32\nWfKvSAs+NIs+DMsNPYw3yuQals4AX8hith1YDvYpr8SD44jxhz/DR9lYKZFGhXGB\n+7NqQ7vpTWp3BceLYocazWJgusZt7CgecIq57ycM5hjM93BvlrUJ8nQ1a46wfL/8\nCy4P0et70hzZrsjjN41KFhKY0iUwlyU41yEiDHvHDDsTMBxAZosWjSREGfJL6Mfp\nXOInTHs/Gg6DZMkbxjQu6L06EdJ+Q/NwglJdAXM7Zo9rNELqRig6DdvG5JesdMsO\n+QIDAQAB\n-----END PUBLIC KEY-----\"\"\")",
              "results": [
                [
                  "{\"signed\":\"eyJhbGciOiJSUzUxMiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.rsMp_X5HMrUqKnZJIxo27aAoscovRA6SSQYR9rq7pifIj0YHXxMyNyOBDGnvVALHKTi25VUGHpfNUW0VVMmae0A4t_ObNU6hVZHguWvetKZZq4FZpW1lgWHCMqgPGwT5_uOqwYCH6r8tJuZT3pqXeL0CY4putb1AN2w6CVp620nh3l8d3XWb4jaifycd_4CEVCqHuWDmohfug4VhmoVKlIXZkYoAQowgHlozATDssBSWdYtv107Wd2AzEoiXPu6e3pflsuXULlyqQnS4ELEKPYThFLafh1NqvZDPddqozcPZ-iODBW-xf3A4DYDdivnMYLrh73AZOGHexxu8ay6nDA\"}",
                  "{\"claims\":{\"iat\":1516239022,\"mood\":\"Disdainful\",\"sub\":\"1234567890\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a claims object from a JWT string encoded with RS512. This method does not validate JWT claims.",
      "impure": false,
      "name": "parse_jwt_rs512",
      "params": {
        "named": [
          {
            "description": "The RS512 secret that was used for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = content().decode(\"hex\").parse_msgpack()",
              "results": [
                [
                  "81a3666f6fa3626172",
                  "{\"foo\":\"bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root = this.encoded.decode(\"base64\").parse_msgpack()",
              "results": [
                [
                  "{\"encoded\":\"gaNmb2+jYmFy\"}",
                  "{\"foo\":\"bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Parses a https://msgpack.org/[MessagePack^] message into a structured document.",
      "impure": false,
      "name": "parse_msgpack",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = content().parse_parquet()",
              "results": [],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Decodes a https://parquet.apache.org/docs/[Parquet file^] into an array of objects, one for each row within the file.",
      "impure": false,
      "name": "parse_parquet",
      "params": {
        "named": [
          {
            "default": false,
            "description": "Deprecated: This parameter is no longer used.",
            "name": "byte_array_as_string",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to parse a string as a timestamp following a specified format and outputs a timestamp, which can then be fed into methods such as <<ts_format, `ts_format`>>.\n\nThe input format is defined by showing how the reference time, defined to be Mon Jan 2 15:04:05 -0700 MST 2006, would be displayed if it were the value. For an alternative way to specify formats check out the <<ts_strptime, `ts_strptime`>> method.",
      "impure": false,
      "name": "parse_timestamp",
      "params": {
        "named": [
          {
            "description": "The format of the target string.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Deprecated",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Attempts to parse a string as a timestamp following a specified strptime-compatible format and outputs a timestamp, which can then be fed into <<ts_format, `ts_format`>>.",
      "impure": false,
      "name": "parse_timestamp_strptime",
      "params": {
        "named": [
          {
            "description": "The format of the target string.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "deprecated"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo_url = this.foo_url.parse_url()",
              "results": [
                [
                  "{\"foo_url\":\"https://docs.redpanda.com/redpanda-connect/guides/bloblang/about/\"}",
                  "{\"foo_url\":{\"fragment\":\"\",\"host\":\"docs.redpanda.com\",\"opaque\":\"\",\"path\":\"/redpanda-connect/guides/bloblang/about/\",\"raw_fragment\":\"\",\"raw_path\":\"\",\"raw_query\":\"\",\"scheme\":\"https\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.username = this.url.parse_url().user.name | \"unknown\"",
              "results": [
                [
                  "{\"url\":\"amqp://foo:bar@127.0.0.1:5672/\"}",
                  "{\"username\":\"foo\"}"
                ],
                [
                  "{\"url\":\"redis://localhost:6379\"}",
                  "{\"username\":\"unknown\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to parse a URL from a string value, returning a structured result that describes the various facets of the URL. The fields returned within the structured result roughly follow https://pkg.go.dev/net/url#URL, and may be expanded in future in order to present more information.",
      "impure": false,
      "name": "parse_url",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.doc = this.doc.parse_xml()",
              "results": [
                [
                  "{\"doc\":\"<root><title>This is a title</title><content>This is some content</content></root>\"}",
                  "{\"doc\":{\"root\":{\"content\":\"This is some content\",\"title\":\"This is a title\"}}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.doc = this.doc.parse_xml(cast: false)",
              "results": [
                [
                  "{\"doc\":\"<root><title>This is a title</title><number id=99>123</number><bool>True</bool></root>\"}",
                  "{\"doc\":{\"root\":{\"bool\":\"True\",\"number\":{\"#text\":\"123\",\"-id\":\"99\"},\"title\":\"This is a title\"}}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.doc = this.doc.parse_xml(cast: true)",
              "results": [
                [
                  "{\"doc\":\"<root><title>This is a title</title><number id=99>123</number><bool>True</bool></root>\"}",
                  "{\"doc\":{\"root\":{\"bool\":true,\"number\":{\"#text\":123,\"-id\":99},\"title\":\"This is a title\"}}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nAttempts to parse a string as an XML document and returns a structured result, where elements appear as keys of an object according to the following rules:\n\n- If an element contains attributes they are parsed by prefixing a hyphen, `-`, to the attribute label.\n- If the element is a simple element and has attributes, the element value is given the key `#text`.\n- XML comments, directives, and process instructions are ignored.\n- When elements are repeated the resulting JSON value is an array.\n- If cast is true, try to cast values to numbers and booleans instead of returning strings.\n",
      "impure": false,
      "name": "parse_xml",
      "params": {
        "named": [
          {
            "default": false,
            "description": "whether to try to cast values that are numbers and booleans to the right type.",
            "is_optional": true,
            "name": "cast",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "bool"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Parsing",
          "Description": "Attempts to parse a string as a single YAML document and returns the result.",
          "Examples": [
            {
              "mapping": "root.doc = this.doc.parse_yaml()",
              "results": [
                [
                  "{\"doc\":\"foo: bar\"}",
                  "{\"doc\":{\"foo\":\"bar\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "parse_yaml",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Create a diff by comparing the current value with the given one. Wraps the github.com/r3labs/diff/v3 package. See its https://pkg.go.dev/github.com/r3labs/diff/v3[docs^] for more information.",
      "impure": false,
      "name": "patch",
      "params": {
        "named": [
          {
            "description": "The changelog to apply.",
            "name": "changelog",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "beta",
      "version": "4.25.0"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value * 10.pow(-2)",
              "results": [
                [
                  "{\"value\":2}",
                  "{\"new_value\":0.02}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.new_value = this.value.pow(-2)",
              "results": [
                [
                  "{\"value\":2}",
                  "{\"new_value\":0.25}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the number raised to the specified exponent.",
      "impure": false,
      "name": "pow",
      "params": {
        "named": [
          {
            "description": "The exponent you want to raise to the power of.",
            "name": "exponent",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "float"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Quotes a target string using escape sequences (`\\t`, `\\n`, `\\xFF`, `\\u0100`) for control characters and non-printable characters.",
          "Examples": [
            {
              "mapping": "root.quoted = this.thing.quote()",
              "results": [
                [
                  "{\"thing\":\"foo\\nbar\"}",
                  "{\"quoted\":\"\\\"foo\\\\nbar\\\"\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "quote",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Regular Expressions",
          "Description": "Returns an array containing all successive matches of a regular expression in a string.",
          "Examples": [
            {
              "mapping": "root.matches = this.value.re_find_all(\"a.\")",
              "results": [
                [
                  "{\"value\":\"paranormal\"}",
                  "{\"matches\":[\"ar\",\"an\",\"al\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "re_find_all",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Regular Expressions",
          "Description": "Returns an array of objects containing all matches of the regular expression and the matches of its subexpressions. The key of each match value is the name of the group when specified, otherwise it is the index of the matching group, starting with the expression as a whole at 0.",
          "Examples": [
            {
              "mapping": "root.matches = this.value.re_find_all_object(\"a(?P<foo>x*)b\")",
              "results": [
                [
                  "{\"value\":\"-axxb-ab-\"}",
                  "{\"matches\":[{\"0\":\"axxb\",\"foo\":\"xx\"},{\"0\":\"ab\",\"foo\":\"\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.matches = this.value.re_find_all_object(\"(?m)(?P<key>\\\\w+):\\\\s+(?P<value>\\\\w+)$\")",
              "results": [
                [
                  "{\"value\":\"option1: value1\\noption2: value2\\noption3: value3\"}",
                  "{\"matches\":[{\"0\":\"option1: value1\",\"key\":\"option1\",\"value\":\"value1\"},{\"0\":\"option2: value2\",\"key\":\"option2\",\"value\":\"value2\"},{\"0\":\"option3: value3\",\"key\":\"option3\",\"value\":\"value3\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "re_find_all_object",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Regular Expressions",
          "Description": "Returns an array of arrays containing all successive matches of the regular expression in a string and the matches, if any, of its subexpressions.",
          "Examples": [
            {
              "mapping": "root.matches = this.value.re_find_all_submatch(\"a(x*)b\")",
              "results": [
                [
                  "{\"value\":\"-axxb-ab-\"}",
                  "{\"matches\":[[\"axxb\",\"xx\"],[\"ab\",\"\"]]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "re_find_all_submatch",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Regular Expressions",
          "Description": "Returns an object containing the first match of the regular expression and the matches of its subexpressions. The key of each match value is the name of the group when specified, otherwise it is the index of the matching group, starting with the expression as a whole at 0.",
          "Examples": [
            {
              "mapping": "root.matches = this.value.re_find_object(\"a(?P<foo>x*)b\")",
              "results": [
                [
                  "{\"value\":\"-axxb-ab-\"}",
                  "{\"matches\":{\"0\":\"axxb\",\"foo\":\"xx\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.matches = this.value.re_find_object(\"(?P<key>\\\\w+):\\\\s+(?P<value>\\\\w+)\")",
              "results": [
                [
                  "{\"value\":\"option1: value1\"}",
                  "{\"matches\":{\"0\":\"option1: value1\",\"key\":\"option1\",\"value\":\"value1\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "re_find_object",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Regular Expressions",
          "Description": "Checks whether a regular expression matches against any part of a string and returns a boolean.",
          "Examples": [
            {
              "mapping": "root.matches = this.value.re_match(\"[0-9]\")",
              "results": [
                [
                  "{\"value\":\"there are 10 puppies\"}",
                  "{\"matches\":true}"
                ],
                [
                  "{\"value\":\"there are ten puppies\"}",
                  "{\"matches\":false}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "re_match",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "impure": false,
      "name": "re_replace",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "The value to replace with.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "hidden"
    },
    {
      "categories": [
        {
          "Category": "Regular Expressions",
          "Description": "Replaces all occurrences of the argument regular expression in a string with a value. Inside the value $ signs are interpreted as submatch expansions, e.g. `$1` represents the text of the first submatch.",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.re_replace_all(\"ADD ([0-9]+)\",\"+($1)\")",
              "results": [
                [
                  "{\"value\":\"foo ADD 70\"}",
                  "{\"new_value\":\"foo +(70)\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "re_replace_all",
      "params": {
        "named": [
          {
            "description": "The pattern to match against.",
            "name": "pattern",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "The value to replace with.",
            "name": "value",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "impure": false,
      "name": "replace",
      "params": {
        "named": [
          {
            "description": "A string to match against.",
            "name": "old",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "A string to replace with.",
            "name": "new",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "hidden"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Replaces all occurrences of the first argument in a target string with the second argument.",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.replace_all(\"foo\",\"dog\")",
              "results": [
                [
                  "{\"value\":\"The foo ate my homework\"}",
                  "{\"new_value\":\"The dog ate my homework\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "replace_all",
      "params": {
        "named": [
          {
            "description": "A string to match against.",
            "name": "old",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "A string to replace with.",
            "name": "new",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "For each pair of strings in an argument array, replaces all occurrences of the first item of the pair with the second. This is a more compact way of chaining a series of `replace_all` methods.",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.replace_all_many([\n  \"<b>\", \"&lt;b&gt;\",\n  \"</b>\", \"&lt;/b&gt;\",\n  \"<i>\", \"&lt;i&gt;\",\n  \"</i>\", \"&lt;/i&gt;\",\n])",
              "results": [
                [
                  "{\"value\":\"<i>Hello</i> <b>World</b>\"}",
                  "{\"new_value\":\"&lt;i&gt;Hello&lt;/i&gt; &lt;b&gt;World&lt;/b&gt;\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "replace_all_many",
      "params": {
        "named": [
          {
            "description": "An array of values, each even value will be replaced with the following odd value.",
            "name": "values",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "array"
          }
        ]
      },
      "status": "stable"
    },
    {
      "impure": false,
      "name": "replace_many",
      "params": {
        "named": [
          {
            "description": "An array of values, each even value will be replaced with the following odd value.",
            "name": "values",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "array"
          }
        ]
      },
      "status": "hidden"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Returns the target string in reverse order.",
          "Examples": [
            {
              "mapping": "root.reversed = this.thing.reverse()",
              "results": [
                [
                  "{\"thing\":\"backwards\"}",
                  "{\"reversed\":\"sdrawkcab\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root = content().reverse()",
              "results": [
                [
                  "{\"thing\":\"backwards\"}",
                  "}\"sdrawkcab\":\"gniht\"{"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "reverse",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.round()",
              "results": [
                [
                  "{\"value\":5.3}",
                  "{\"new_value\":5}"
                ],
                [
                  "{\"value\":5.9}",
                  "{\"new_value\":6}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Rounds numbers to the nearest integer, rounding half away from zero. If the resulting value fits within a 64-bit integer then that is returned, otherwise a new floating point number is returned.",
      "impure": false,
      "name": "round",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_es256(\"\"\"-----BEGIN EC PRIVATE KEY-----\n... signature data ...\n-----END EC PRIVATE KEY-----\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.-8LrOdkEiv_44ADWW08lpbq41ZmHCel58NMORPq1q4Dyw0zFhqDVLrRoSvCvuyyvgXAFb9IHfR-9MlJ_2ShA9A\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using ES256.",
      "impure": false,
      "name": "sign_jwt_es256",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_es384(\"\"\"-----BEGIN EC PRIVATE KEY-----\n... signature data ...\n-----END EC PRIVATE KEY-----\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJFUzM4NCIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIn0.8FmTKH08dl7dyxrNu0rmvhegiIBCy-O9cddGco2e9lpZtgv5mS5qHgPkgBC5eRw1d7SRJsHwHZeehzdqT5Ba7aZJIhz9ds0sn37YQ60L7jT0j2gxCzccrt4kECHnUnLw\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using ES384.",
      "impure": false,
      "name": "sign_jwt_es384",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_es512(\"\"\"-----BEGIN EC PRIVATE KEY-----\n... signature data ...\n-----END EC PRIVATE KEY-----\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJFUzUxMiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIn0.AQbEWymoRZxDJEJtKSFFG2k2VbDCTYSuBwAZyMqexCspr3If8aERTVGif8HXG3S7TzMBCCzxkcKr3eIU441l3DlpAMNfQbkcOlBqMvNBn-CX481WyKf3K5rFHQ-6wRonz05aIsWAxCDvAozI_9J0OWllxdQ2MBAuTPbPJ38OqXsYkCQs\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using ES512.",
      "impure": false,
      "name": "sign_jwt_es512",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.20.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_hs256(\"\"\"dont-tell-anyone\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIn0.hUl-nngPMY_3h9vveWJUPsCcO5PeL6k9hWLnMYeFbFQ\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using HS256.",
      "impure": false,
      "name": "sign_jwt_hs256",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.12.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_hs384(\"\"\"dont-tell-anyone\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJIUzM4NCIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIn0.zGYLr83aToon1efUNq-hw7XgT20lPvZb8sYei8x6S6mpHwb433SJdXJXx0Oio8AZ\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using HS384.",
      "impure": false,
      "name": "sign_jwt_hs384",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.12.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_hs512(\"\"\"dont-tell-anyone\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIn0.zBNR9o_6EDwXXKkpKLNJhG26j8Dc-mV-YahBwmEdCrmiWt5les8I9rgmNlWIowpq6Yxs4kLNAdFhqoRz3NXT3w\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using HS512.",
      "impure": false,
      "name": "sign_jwt_hs512",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.12.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_rs256(\"\"\"-----BEGIN RSA PRIVATE KEY-----\n... signature data ...\n-----END RSA PRIVATE KEY-----\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.b0lH3jEupZZ4zoaly4Y_GCvu94HH6UKdKY96zfGNsIkPZpQLHIkZ7jMWlLlNOAd8qXlsBGP_i8H2qCKI4zlWJBGyPZgxXDzNRPVrTDfFpn4t4nBcA1WK2-ntXP3ehQxsaHcQU8Z_nsogId7Pme5iJRnoHWEnWtbwz5DLSXL3ZZNnRdrHM9MdI7QSDz9mojKDCaMpGN9sG7Xl-tGdBp1XzXuUOzG8S03mtZ1IgVR1uiBL2N6oohHIAunk8DIAmNWI-zgycTgzUGU7mvPkKH43qO8Ua1-13tCUBKKa8VxcotZ67Mxm1QAvBGoDnTKwWMwghLzs6d6WViXQg6eWlJcpBA\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using RS256.",
      "impure": false,
      "name": "sign_jwt_rs256",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.18.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_rs384(\"\"\"-----BEGIN RSA PRIVATE KEY-----\n... signature data ...\n-----END RSA PRIVATE KEY-----\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJSUzM4NCIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.orcXYBcjVE5DU7mvq4KKWFfNdXR4nEY_xupzWoETRpYmQZIozlZnM_nHxEk2dySvpXlAzVm7kgOPK2RFtGlOVaNRIa3x-pMMr-bhZTno4L8Hl4sYxOks3bWtjK7wql4uqUbqThSJB12psAXw2-S-I_FMngOPGIn4jDT9b802ottJSvTpXcy0-eKTjrV2PSkRRu-EYJh0CJZW55MNhqlt6kCGhAXfbhNazN3ASX-dmpd_JixyBKphrngr_zRA-FCn_Xf3QQDA-5INopb4Yp5QiJ7UxVqQEKI80X_JvJqz9WE1qiAw8pq5-xTen1t7zTP-HT1NbbD3kltcNa3G8acmNg\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using RS384.",
      "impure": false,
      "name": "sign_jwt_rs384",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.18.0"
    },
    {
      "categories": [
        {
          "Category": "JSON Web Tokens",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.signed = this.claims.sign_jwt_rs512(\"\"\"-----BEGIN RSA PRIVATE KEY-----\n... signature data ...\n-----END RSA PRIVATE KEY-----\"\"\")",
              "results": [
                [
                  "{\"claims\":{\"sub\":\"user123\"}}",
                  "{\"signed\":\"eyJhbGciOiJSUzUxMiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MTYyMzkwMjIsIm1vb2QiOiJEaXNkYWluZnVsIiwic3ViIjoiMTIzNDU2Nzg5MCJ9.rsMp_X5HMrUqKnZJIxo27aAoscovRA6SSQYR9rq7pifIj0YHXxMyNyOBDGnvVALHKTi25VUGHpfNUW0VVMmae0A4t_ObNU6hVZHguWvetKZZq4FZpW1lgWHCMqgPGwT5_uOqwYCH6r8tJuZT3pqXeL0CY4putb1AN2w6CVp620nh3l8d3XWb4jaifycd_4CEVCqHuWDmohfug4VhmoVKlIXZkYoAQowgHlozATDssBSWdYtv107Wd2AzEoiXPu6e3pflsuXULlyqQnS4ELEKPYThFLafh1NqvZDPddqozcPZ-iODBW-xf3A4DYDdivnMYLrh73AZOGHexxu8ay6nDA\"}"
                ]
              ],
              "skip_testing": true,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Hash and sign an object representing JSON Web Token (JWT) claims using RS512.",
      "impure": false,
      "name": "sign_jwt_rs512",
      "params": {
        "named": [
          {
            "description": "The secret to use for signing the token.",
            "name": "signing_secret",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "v4.18.0"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = (this.value * (pi() / 180)).sin()",
              "results": [
                [
                  "{\"value\":45}",
                  "{\"new_value\":0.7071067811865475}"
                ],
                [
                  "{\"value\":0}",
                  "{\"new_value\":0}"
                ],
                [
                  "{\"value\":90}",
                  "{\"new_value\":1}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Calculates the sine of a given angle specified in radians.",
      "impure": false,
      "name": "sin",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Extract a slice from a string by specifying two indices, a low and high bound, which selects a half-open range that includes the first character, but excludes the last one. If the second index is omitted then it defaults to the length of the input sequence.",
          "Examples": [
            {
              "mapping": "root.beginning = this.value.slice(0, 2)\nroot.end = this.value.slice(4)",
              "results": [
                [
                  "{\"value\":\"foo bar\"}",
                  "{\"beginning\":\"fo\",\"end\":\"bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.last_chunk = this.value.slice(-4)\nroot.the_rest = this.value.slice(0, -4)",
              "results": [
                [
                  "{\"value\":\"foo bar\"}",
                  "{\"last_chunk\":\" bar\",\"the_rest\":\"foo\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "A negative low index can be used, indicating an offset from the end of the sequence. If the low index is greater than the length of the sequence then an empty result is returned."
            }
          ]
        },
        {
          "Category": "Object & Array Manipulation",
          "Description": "Extract a slice from an array by specifying two indices, a low and high bound, which selects a half-open range that includes the first element, but excludes the last one. If the second index is omitted then it defaults to the length of the input sequence.",
          "Examples": [
            {
              "mapping": "root.beginning = this.value.slice(0, 2)\nroot.end = this.value.slice(4)",
              "results": [
                [
                  "{\"value\":[\"foo\",\"bar\",\"baz\",\"buz\",\"bev\"]}",
                  "{\"beginning\":[\"foo\",\"bar\"],\"end\":[\"bev\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.last_chunk = this.value.slice(-2)\nroot.the_rest = this.value.slice(0, -2)",
              "results": [
                [
                  "{\"value\":[\"foo\",\"bar\",\"baz\",\"buz\",\"bev\"]}",
                  "{\"last_chunk\":[\"buz\",\"bev\"],\"the_rest\":[\"foo\",\"bar\",\"baz\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": "A negative low index can be used, indicating an offset from the end of the sequence. If the low index is greater than the length of the sequence then an empty result is returned."
            }
          ]
        }
      ],
      "impure": false,
      "name": "slice",
      "params": {
        "named": [
          {
            "description": "The low bound, which is the first element of the selection, or if negative selects from the end.",
            "name": "low",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          },
          {
            "description": "An optional high bound.",
            "is_optional": true,
            "name": "high",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.slug = this.value.slug()",
              "results": [
                [
                  "{\"value\":\"Gopher & Benthos\"}",
                  "{\"slug\":\"gopher-and-benthos\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Creates a slug from an English string"
            },
            {
              "mapping": "root.slug = this.value.slug(\"fr\")",
              "results": [
                [
                  "{\"value\":\"Gaufre & Poisson d'Eau Profonde\"}",
                  "{\"slug\":\"gaufre-et-poisson-deau-profonde\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Creates a slug from a French string"
            }
          ]
        }
      ],
      "description": "Creates a \"slug\" from a given string. Wraps the github.com/gosimple/slug package. See its https://pkg.go.dev/github.com/gosimple/slug[docs^] for more information.",
      "impure": false,
      "name": "slug",
      "params": {
        "named": [
          {
            "default": "en",
            "is_optional": true,
            "name": "lang",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta",
      "version": "4.2.0"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Attempts to sort the values of an array in increasing order. The type of all values must match in order for the ordering to succeed. Supports string and number values.",
          "Examples": [
            {
              "mapping": "root.sorted = this.foo.sort()",
              "results": [
                [
                  "{\"foo\":[\"bbb\",\"ccc\",\"aaa\"]}",
                  "{\"sorted\":[\"aaa\",\"bbb\",\"ccc\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.sorted = this.foo.sort(item -> item.left.v < item.right.v)",
              "results": [
                [
                  "{\"foo\":[{\"id\":\"foo\",\"v\":\"bbb\"},{\"id\":\"bar\",\"v\":\"ccc\"},{\"id\":\"baz\",\"v\":\"aaa\"}]}",
                  "{\"sorted\":[{\"id\":\"baz\",\"v\":\"aaa\"},{\"id\":\"foo\",\"v\":\"bbb\"},{\"id\":\"bar\",\"v\":\"ccc\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": "It's also possible to specify a mapping argument, which is provided an object context with fields `left` and `right`, the mapping must return a boolean indicating whether the `left` value is less than `right`. This allows you to sort arrays containing non-string or non-number values."
            }
          ]
        }
      ],
      "impure": false,
      "name": "sort",
      "params": {
        "named": [
          {
            "description": "An optional query that should explicitly compare elements `left` and `right` and provide a boolean result.",
            "is_optional": true,
            "name": "compare",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Attempts to sort the elements of an array, in increasing order, by a value emitted by an argument query applied to each element. The type of all values must match in order for the ordering to succeed. Supports string and number values.",
          "Examples": [
            {
              "mapping": "root.sorted = this.foo.sort_by(ele -> ele.id)",
              "results": [
                [
                  "{\"foo\":[{\"id\":\"bbb\",\"message\":\"bar\"},{\"id\":\"aaa\",\"message\":\"foo\"},{\"id\":\"ccc\",\"message\":\"baz\"}]}",
                  "{\"sorted\":[{\"id\":\"aaa\",\"message\":\"foo\"},{\"id\":\"bbb\",\"message\":\"bar\"},{\"id\":\"ccc\",\"message\":\"baz\"}]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "sort_by",
      "params": {
        "named": [
          {
            "description": "A query to apply to each element that yields a value used for sorting.",
            "name": "query",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Split a string value into an array of strings by splitting it on a string separator.",
          "Examples": [
            {
              "mapping": "root.new_value = this.value.split(\",\")",
              "results": [
                [
                  "{\"value\":\"foo,bar,baz\"}",
                  "{\"new_value\":[\"foo\",\"bar\",\"baz\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "split",
      "params": {
        "named": [
          {
            "description": "The delimiter to split with.",
            "name": "delimiter",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.locations = this.locations.map_each(loc -> {loc.state: [loc.name]}).squash()",
              "results": [
                [
                  "{\"locations\":[{\"name\":\"Seattle\",\"state\":\"WA\"},{\"name\":\"New York\",\"state\":\"NY\"},{\"name\":\"Bellevue\",\"state\":\"WA\"},{\"name\":\"Olympia\",\"state\":\"WA\"}]}",
                  "{\"locations\":{\"NY\":[\"New York\"],\"WA\":[\"Seattle\",\"Bellevue\",\"Olympia\"]}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Squashes an array of objects into a single object, where key collisions result in the values being merged (following similar rules as the `.merge()` method)",
      "impure": false,
      "name": "squash",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Marshal a value into a string. If the value is already a string it is unchanged.",
          "Examples": [
            {
              "mapping": "root.nested_json = this.string()",
              "results": [
                [
                  "{\"foo\":\"bar\"}",
                  "{\"nested_json\":\"{\\\"foo\\\":\\\"bar\\\"}\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.id = this.id.string()",
              "results": [
                [
                  "{\"id\":228930314431312345}",
                  "{\"id\":\"228930314431312345\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "string",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.stripped = this.value.strip_html()",
              "results": [
                [
                  "{\"value\":\"<p>the plain <strong>old text</strong></p>\"}",
                  "{\"stripped\":\"the plain old text\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.stripped = this.value.strip_html([\"article\"])",
              "results": [
                [
                  "{\"value\":\"<article><p>the plain <strong>old text</strong></p></article>\"}",
                  "{\"stripped\":\"<article>the plain old text</article>\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "It's also possible to provide an explicit list of element types to preserve in the output."
            }
          ]
        }
      ],
      "description": "Attempts to remove all HTML tags from a target string.",
      "impure": false,
      "name": "strip_html",
      "params": {
        "named": [
          {
            "description": "An optional array of element types to preserve in the output.",
            "is_optional": true,
            "name": "preserve",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "unknown"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Sum the numerical values of an array.",
          "Examples": [
            {
              "mapping": "root.sum = this.foo.sum()",
              "results": [
                [
                  "{\"foo\":[3,8,4]}",
                  "{\"sum\":15}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "sum",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.new_value = \"%f\".format((this.value * (pi() / 180)).tan())",
              "results": [
                [
                  "{\"value\":0}",
                  "{\"new_value\":\"0.000000\"}"
                ],
                [
                  "{\"value\":45}",
                  "{\"new_value\":\"1.000000\"}"
                ],
                [
                  "{\"value\":180}",
                  "{\"new_value\":\"-0.000000\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Calculates the tangent of a given angle specified in radians.",
      "impure": false,
      "name": "tan",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Attempt to parse a value into a timestamp. An optional argument can be provided, in which case if the value cannot be parsed into a timestamp the argument will be returned instead.",
          "Examples": [
            {
              "mapping": "root.foo = this.ts.timestamp()\nroot.bar = this.none.timestamp(1234567890.timestamp())",
              "results": [],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "timestamp",
      "params": {
        "named": [
          {
            "description": "An optional value to yield if the target cannot be parsed as a timestamp.",
            "is_optional": true,
            "name": "default",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "timestamp"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Remove all leading and trailing characters from a string that are contained within an argument cutset. If no arguments are provided then whitespace is removed.",
          "Examples": [
            {
              "mapping": "root.title = this.title.trim(\"!?\")\nroot.description = this.description.trim()",
              "results": [
                [
                  "{\"description\":\"  something happened and its amazing! \",\"title\":\"!!!watch out!?\"}",
                  "{\"description\":\"something happened and its amazing!\",\"title\":\"watch out\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "trim",
      "params": {
        "named": [
          {
            "description": "An optional string of characters to trim from the target value.",
            "is_optional": true,
            "name": "cutset",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Remove the provided leading prefix substring from a string. If the string does not have the prefix substring, it is returned unchanged.",
          "Examples": [
            {
              "mapping": "root.name = this.name.trim_prefix(\"foobar_\")\nroot.description = this.description.trim_prefix(\"foobar_\")",
              "results": [
                [
                  "{\"description\":\"unchanged\",\"name\":\"foobar_blobton\"}",
                  "{\"description\":\"unchanged\",\"name\":\"blobton\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "trim_prefix",
      "params": {
        "named": [
          {
            "description": "The leading prefix substring to trim from the string.",
            "name": "prefix",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "4.12.0"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Remove the provided trailing suffix substring from a string. If the string does not have the suffix substring, it is returned unchanged.",
          "Examples": [
            {
              "mapping": "root.name = this.name.trim_suffix(\"_foobar\")\nroot.description = this.description.trim_suffix(\"_foobar\")",
              "results": [
                [
                  "{\"description\":\"unchanged\",\"name\":\"blobton_foobar\"}",
                  "{\"description\":\"unchanged\",\"name\":\"blobton\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "trim_suffix",
      "params": {
        "named": [
          {
            "description": "The trailing suffix substring to trim from the string.",
            "name": "suffix",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable",
      "version": "4.12.0"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Parse parameter string as ISO 8601 period and add it to value with high precision for units larger than an hour.",
      "impure": false,
      "name": "ts_add_iso8601",
      "params": {
        "named": [
          {
            "description": "Duration in ISO 8601 format",
            "name": "duration",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.something_at = (this.created_at + 300).ts_format()",
              "results": [],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.something_at = (this.created_at + 300).ts_format(\"2006-Jan-02 15:04:05\")",
              "results": [],
              "skip_testing": false,
              "summary": "An optional string argument can be used in order to specify the output format of the timestamp. The format is defined by showing how the reference time, defined to be Mon Jan 2 15:04:05 -0700 MST 2006, would be displayed if it were the value."
            },
            {
              "mapping": "root.something_at = this.created_at.ts_format(format: \"2006-Jan-02 15:04:05\", tz: \"UTC\")",
              "results": [
                [
                  "{\"created_at\":1597405526}",
                  "{\"something_at\":\"2020-Aug-14 11:45:26\"}"
                ],
                [
                  "{\"created_at\":\"2020-08-14T11:50:26.371Z\"}",
                  "{\"something_at\":\"2020-Aug-14 11:50:26\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "A second optional string argument can also be used in order to specify a timezone, otherwise the timezone of the input string is used, or in the case of unix timestamps the local timezone is used."
            },
            {
              "mapping": "root.something_at = this.created_at.ts_format(\"2006-Jan-02 15:04:05.999999\", \"UTC\")",
              "results": [
                [
                  "{\"created_at\":1597405526.123456}",
                  "{\"something_at\":\"2020-Aug-14 11:45:26.123456\"}"
                ],
                [
                  "{\"created_at\":\"2020-08-14T11:50:26.371Z\"}",
                  "{\"something_at\":\"2020-Aug-14 11:50:26.371\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "And `ts_format` supports up to nanosecond precision with floating point timestamp values."
            }
          ]
        }
      ],
      "description": "Attempts to format a timestamp value as a string according to a specified format, or RFC 3339 by default. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format.\n\nThe output format is defined by showing how the reference time, defined to be Mon Jan 2 15:04:05 -0700 MST 2006, would be displayed if it were the value. For an alternative way to specify formats check out the <<ts_strftime, `ts_strftime`>> method.",
      "impure": false,
      "name": "ts_format",
      "params": {
        "named": [
          {
            "default": "2006-01-02T15:04:05.999999999Z07:00",
            "description": "The output format to use.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An optional timezone to use, otherwise the timezone of the input string is used, or in the case of unix timestamps the local timezone is used.",
            "is_optional": true,
            "name": "tz",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.doc.timestamp = this.doc.timestamp.ts_parse(\"2006-Jan-02\")",
              "results": [
                [
                  "{\"doc\":{\"timestamp\":\"2020-Aug-14\"}}",
                  "{\"doc\":{\"timestamp\":\"2020-08-14T00:00:00Z\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to parse a string as a timestamp following a specified format and outputs a timestamp, which can then be fed into methods such as <<ts_format, `ts_format`>>.\n\nThe input format is defined by showing how the reference time, defined to be Mon Jan 2 15:04:05 -0700 MST 2006, would be displayed if it were the value. For an alternative way to specify formats check out the <<ts_strptime, `ts_strptime`>> method.",
      "impure": false,
      "name": "ts_parse",
      "params": {
        "named": [
          {
            "description": "The format of the target string.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.created_at_hour = this.created_at.ts_round(\"1h\".parse_duration())",
              "results": [
                [
                  "{\"created_at\":\"2020-08-14T05:54:23Z\"}",
                  "{\"created_at_hour\":\"2020-08-14T06:00:00Z\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "Use the method `parse_duration` to convert a duration string into an integer argument."
            }
          ]
        }
      ],
      "description": "Returns the result of rounding a timestamp to the nearest multiple of the argument duration (nanoseconds). The rounding behavior for halfway values is to round up. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_round",
      "params": {
        "named": [
          {
            "description": "A duration measured in nanoseconds to round by.",
            "name": "duration",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "integer"
          }
        ]
      },
      "status": "beta",
      "version": "4.2.0"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.something_at = (this.created_at + 300).ts_strftime(\"%Y-%b-%d %H:%M:%S\")",
              "results": [],
              "skip_testing": false,
              "summary": "The format consists of zero or more conversion specifiers and ordinary characters (except `%`). All ordinary characters are copied to the output string without modification. Each conversion specification begins with `%` character followed by the character that determines the behavior of the specifier. Please refer to https://linux.die.net/man/3/strftime[man 3 strftime] for the list of format specifiers."
            },
            {
              "mapping": "root.something_at = this.created_at.ts_strftime(\"%Y-%b-%d %H:%M:%S\", \"UTC\")",
              "results": [
                [
                  "{\"created_at\":1597405526}",
                  "{\"something_at\":\"2020-Aug-14 11:45:26\"}"
                ],
                [
                  "{\"created_at\":\"2020-08-14T11:50:26.371Z\"}",
                  "{\"something_at\":\"2020-Aug-14 11:50:26\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "A second optional string argument can also be used in order to specify a timezone, otherwise the timezone of the input string is used, or in the case of unix timestamps the local timezone is used."
            },
            {
              "mapping": "root.something_at = this.created_at.ts_strftime(\"%Y-%b-%d %H:%M:%S.%f\", \"UTC\")",
              "results": [
                [
                  "{\"created_at\":1597405526}",
                  "{\"something_at\":\"2020-Aug-14 11:45:26.000000\"}"
                ],
                [
                  "{\"created_at\":\"2020-08-14T11:50:26.371Z\"}",
                  "{\"something_at\":\"2020-Aug-14 11:50:26.371000\"}"
                ]
              ],
              "skip_testing": false,
              "summary": "As an extension provided by the underlying formatting library, https://github.com/itchyny/timefmt-go[itchyny/timefmt-go], the `%f` directive is supported for zero-padded microseconds, which originates from Python. Note that E and O modifier characters are not supported."
            }
          ]
        }
      ],
      "description": "Attempts to format a timestamp value as a string according to a specified strftime-compatible format. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format.",
      "impure": false,
      "name": "ts_strftime",
      "params": {
        "named": [
          {
            "description": "The output format to use.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          },
          {
            "description": "An optional timezone to use, otherwise the timezone of the input string is used.",
            "is_optional": true,
            "name": "tz",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.doc.timestamp = this.doc.timestamp.ts_strptime(\"%Y-%b-%d\")",
              "results": [
                [
                  "{\"doc\":{\"timestamp\":\"2020-Aug-14\"}}",
                  "{\"doc\":{\"timestamp\":\"2020-08-14T00:00:00Z\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": "The format consists of zero or more conversion specifiers and ordinary characters (except `%`). All ordinary characters are copied to the output string without modification. Each conversion specification begins with a `%` character followed by the character that determines the behavior of the specifier. Please refer to https://linux.die.net/man/3/strptime[man 3 strptime] for the list of format specifiers."
            },
            {
              "mapping": "root.doc.timestamp = this.doc.timestamp.ts_strptime(\"%Y-%b-%d %H:%M:%S.%f\")",
              "results": [
                [
                  "{\"doc\":{\"timestamp\":\"2020-Aug-14 11:50:26.371000\"}}",
                  "{\"doc\":{\"timestamp\":\"2020-08-14T11:50:26.371Z\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": "As an extension provided by the underlying formatting library, https://github.com/itchyny/timefmt-go[itchyny/timefmt-go], the `%f` directive is supported for zero-padded microseconds, which originates from Python. Note that E and O modifier characters are not supported."
            }
          ]
        }
      ],
      "description": "Attempts to parse a string as a timestamp following a specified strptime-compatible format and outputs a timestamp, which can then be fed into <<ts_format, `ts_format`>>.",
      "impure": false,
      "name": "ts_strptime",
      "params": {
        "named": [
          {
            "description": "The format of the target string.",
            "name": "format",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.between = this.started_at.ts_sub(\"2020-08-14T05:54:23Z\").abs()",
              "results": [
                [
                  "{\"started_at\":\"2020-08-13T05:54:23Z\"}",
                  "{\"between\":86400000000000}"
                ]
              ],
              "skip_testing": false,
              "summary": "Use the `.abs()` method in order to calculate an absolute duration between two timestamps."
            }
          ]
        }
      ],
      "description": "Returns the difference in nanoseconds between the target timestamp (t1) and the timestamp provided as a parameter (t2). The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_sub",
      "params": {
        "named": [
          {
            "description": "The second timestamp to be subtracted from the method target.",
            "name": "t2",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "timestamp"
          }
        ]
      },
      "status": "beta",
      "version": "4.23.0"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": null
        }
      ],
      "description": "Parse parameter string as ISO 8601 period and subtract it from value with high precision for units larger than an hour.",
      "impure": false,
      "name": "ts_sub_iso8601",
      "params": {
        "named": [
          {
            "description": "Duration in ISO 8601 format",
            "name": "duration",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.created_at_utc = this.created_at.ts_tz(\"UTC\")",
              "results": [
                [
                  "{\"created_at\":\"2021-02-03T17:05:06+01:00\"}",
                  "{\"created_at_utc\":\"2021-02-03T16:05:06Z\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns the result of converting a timestamp to a specified timezone. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_tz",
      "params": {
        "named": [
          {
            "description": "The timezone to change to. If set to \"UTC\" then the timezone will be UTC. If set to \"Local\" then the local timezone will be used. Otherwise, the argument is taken to be a location name corresponding to a file in the IANA Time Zone database, such as \"America/New_York\".",
            "name": "tz",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta",
      "version": "4.3.0"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.created_at_unix = this.created_at.ts_unix()",
              "results": [
                [
                  "{\"created_at\":\"2009-11-10T23:00:00Z\"}",
                  "{\"created_at_unix\":1257894000}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_unix",
      "params": {},
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.created_at_unix = this.created_at.ts_unix_micro()",
              "results": [
                [
                  "{\"created_at\":\"2009-11-10T23:00:00Z\"}",
                  "{\"created_at_unix\":1257894000000000}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp with microsecond precision. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_unix_micro",
      "params": {},
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.created_at_unix = this.created_at.ts_unix_milli()",
              "results": [
                [
                  "{\"created_at\":\"2009-11-10T23:00:00Z\"}",
                  "{\"created_at_unix\":1257894000000}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp with millisecond precision. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_unix_milli",
      "params": {},
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Timestamp Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.created_at_unix = this.created_at.ts_unix_nano()",
              "results": [
                [
                  "{\"created_at\":\"2009-11-10T23:00:00Z\"}",
                  "{\"created_at_unix\":1257894000000000000}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Attempts to format a timestamp value as a unix timestamp with nanosecond precision. Timestamp values can either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in RFC 3339 format. The <<ts_parse, `ts_parse`>> method can be used in order to parse different timestamp formats.",
      "impure": false,
      "name": "ts_unix_nano",
      "params": {},
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Type Coercion",
          "Description": "Returns the type of a value as a string, providing one of the following values: `string`, `bytes`, `number`, `bool`, `timestamp`, `array`, `object` or `null`.",
          "Examples": [
            {
              "mapping": "root.bar_type = this.bar.type()\nroot.foo_type = this.foo.type()",
              "results": [
                [
                  "{\"bar\":10,\"foo\":\"is a string\"}",
                  "{\"bar_type\":\"number\",\"foo_type\":\"string\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.type = this.type()",
              "results": [
                [
                  "\"foobar\"",
                  "{\"type\":\"string\"}"
                ],
                [
                  "666",
                  "{\"type\":\"number\"}"
                ],
                [
                  "false",
                  "{\"type\":\"bool\"}"
                ],
                [
                  "[\"foo\", \"bar\"]",
                  "{\"type\":\"array\"}"
                ],
                [
                  "{\"foo\": \"bar\"}",
                  "{\"type\":\"object\"}"
                ],
                [
                  "null",
                  "{\"type\":\"null\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.type = content().type()",
              "results": [
                [
                  "foobar",
                  "{\"type\":\"bytes\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.type = this.ts_parse(\"2006-01-02\").type()",
              "results": [
                [
                  "\"2022-06-06\"",
                  "{\"type\":\"timestamp\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "type",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.uint16()\nroot.b = this.b.round().uint16()\nroot.c = this.c.uint16()\nroot.d = this.d.uint16().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":0}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.uint16()\n",
              "results": [
                [
                  "\"0xDE\"",
                  "222"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 16-bit unsigned integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 16-bit unsigned integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "uint16",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.uint32()\nroot.b = this.b.round().uint32()\nroot.c = this.c.uint32()\nroot.d = this.d.uint32().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":0}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.uint32()\n",
              "results": [
                [
                  "\"0xDEAD\"",
                  "57005"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 32-bit unsigned integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 32-bit unsigned integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "uint32",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.uint64()\nroot.b = this.b.round().uint64()\nroot.c = this.c.uint64()\nroot.d = this.d.uint64().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":0}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.uint64()\n",
              "results": [
                [
                  "\"0xDEADBEEF\"",
                  "3735928559"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 64-bit unsigned integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 64-bit unsigned integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "uint64",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Number Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "\nroot.a = this.a.uint8()\nroot.b = this.b.round().uint8()\nroot.c = this.c.uint8()\nroot.d = this.d.uint8().catch(0)\n",
              "results": [
                [
                  "{\"a\":12,\"b\":12.34,\"c\":\"12\",\"d\":-12}",
                  "{\"a\":12,\"b\":12,\"c\":12,\"d\":0}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "\nroot = this.uint8()\n",
              "results": [
                [
                  "\"0xD\"",
                  "13"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "\nConverts a numerical type into a 8-bit unsigned integer, this is for advanced use cases where a specific data type is needed for a given component (such as the ClickHouse SQL driver).\n\nIf the value is a string then an attempt will be made to parse it as a 8-bit unsigned integer. If the target value exceeds the capacity of an integer or contains decimal values then this method will throw an error. In order to convert a floating point number containing decimals first use <<round, `.round()`>> on the value. Please refer to the https://pkg.go.dev/strconv#ParseInt[`strconv.ParseInt` documentation] for details regarding the supported formats.",
      "impure": false,
      "name": "uint8",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Unescapes a string so that entities like `&lt;` become `<`. It unescapes a larger range of entities than `escape_html` escapes. For example, `&aacute;` unescapes to `á`, as does `&#225;` and `&xE1;`.",
          "Examples": [
            {
              "mapping": "root.unescaped = this.value.unescape_html()",
              "results": [
                [
                  "{\"value\":\"foo &amp; bar\"}",
                  "{\"unescaped\":\"foo & bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "unescape_html",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Expands escape sequences from a URL query string.",
          "Examples": [
            {
              "mapping": "root.unescaped = this.value.unescape_url_query()",
              "results": [
                [
                  "{\"value\":\"foo+%26+bar\"}",
                  "{\"unescaped\":\"foo & bar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "unescape_url_query",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.sentences = this.value.unicode_segments(\"sentence\")",
              "results": [
                [
                  "{\"value\":\"This is sentence 1.0. And this is sentence two.\"}",
                  "{\"sentences\":[\"This is sentence 1.0. \",\"And this is sentence two.\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Splits a string into different sentences"
            },
            {
              "mapping": "root.graphemes = this.value.unicode_segments(\"grapheme\")",
              "results": [
                [
                  "{\"value\":\"🐕‍🦺 🫠\"}",
                  "{\"graphemes\":[\"🐕‍🦺\",\" \",\"🫠\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Splits a string into different graphemes"
            },
            {
              "mapping": "root.words = this.value.unicode_segments(\"word\")",
              "results": [
                [
                  "{\"value\":\"Hello, world!\"}",
                  "{\"words\":[\"Hello\",\",\",\" \",\"world\",\"!\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": "Splits text into words"
            }
          ]
        }
      ],
      "description": "Splits text into segments from a given string based on the unicode text segmentation rules.",
      "impure": false,
      "name": "unicode_segments",
      "params": {
        "named": [
          {
            "name": "segmentation_type",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "beta"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Attempts to remove duplicate values from an array. The array may contain a combination of different value types, but numbers and strings are checked separately (`\"5\"` is a different element to `5`).",
          "Examples": [
            {
              "mapping": "root.uniques = this.foo.unique()",
              "results": [
                [
                  "{\"foo\":[\"a\",\"b\",\"a\",\"c\"]}",
                  "{\"uniques\":[\"a\",\"b\",\"c\"]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "unique",
      "params": {
        "named": [
          {
            "description": "An optional query that can be used in order to yield a value for each element to determine uniqueness.",
            "is_optional": true,
            "name": "emit",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "query expression"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Unquotes a target string, expanding any escape sequences (`\\t`, `\\n`, `\\xFF`, `\\u0100`) for control characters and non-printable characters.",
          "Examples": [
            {
              "mapping": "root.unquoted = this.thing.unquote()",
              "results": [
                [
                  "{\"thing\":\"\\\"foo\\\\nbar\\\"\"}",
                  "{\"unquoted\":\"foo\\nbar\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "unquote",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "String Manipulation",
          "Description": "Convert a string value into uppercase.",
          "Examples": [
            {
              "mapping": "root.foo = this.foo.uppercase()",
              "results": [
                [
                  "{\"foo\":\"hello world\"}",
                  "{\"foo\":\"HELLO WORLD\"}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "uppercase",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Encoding and Encryption",
          "Description": "\nReturns UUID version 5 for the given string.",
          "Examples": [
            {
              "mapping": "root.id = \"example\".uuid_v5()",
              "results": [],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.id = \"example\".uuid_v5(\"x500\")",
              "results": [],
              "skip_testing": false,
              "summary": ""
            },
            {
              "mapping": "root.id = \"example\".uuid_v5(\"77f836b7-9f61-46c0-851e-9b6ca3535e69\")",
              "results": [],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "uuid_v5",
      "params": {
        "named": [
          {
            "description": "An optional namespace name or UUID. It supports the `dns`, `url`, `oid` and `x500` predefined namespaces and any valid RFC-9562 UUID. If empty, the nil UUID will be used.",
            "is_optional": true,
            "name": "ns",
            "no_dynamic": false,
            "scalars_to_literal": false,
            "type": "string"
          }
        ]
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Returns the values of an object as an array. The order of the resulting array will be random.",
          "Examples": [
            {
              "mapping": "root.foo_vals = this.foo.values().sort()",
              "results": [
                [
                  "{\"foo\":{\"bar\":1,\"baz\":2}}",
                  "{\"foo_vals\":[1,2]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "values",
      "params": {},
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "SQL",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.embeddings = [1.2, 0.6, 0.9].vector()",
              "results": [],
              "skip_testing": false,
              "summary": "Create a vector from an array literal"
            },
            {
              "mapping": "root.embedding_vector = this.embedding_array.vector()",
              "results": [],
              "skip_testing": false,
              "summary": "Create a vector from an array"
            }
          ]
        }
      ],
      "description": "Creates a vector from a given array of floating point numbers.\n\nThis vector can be inserted into various SQL databases if they have support for embeddings vectors (for example `pgvector`).",
      "impure": false,
      "name": "vector",
      "params": {},
      "status": "beta",
      "version": "4.33.0"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root = this.with(\"inner.a\",\"inner.c\",\"d\")",
              "results": [
                [
                  "{\"inner\":{\"a\":\"first\",\"b\":\"second\",\"c\":\"third\"},\"d\":\"fourth\",\"e\":\"fifth\"}",
                  "{\"d\":\"fourth\",\"inner\":{\"a\":\"first\",\"c\":\"third\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Returns an object where all but one or more xref:configuration:field_paths.adoc[field path] arguments are removed. Each path specifies a specific field to be retained from the input object, allowing for nested fields.\n\nIf a key within a nested path does not exist then it is ignored.",
      "impure": false,
      "name": "with",
      "params": {
        "variadic": true
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "Returns an object where one or more xref:configuration:field_paths.adoc[field path] arguments are removed. Each path specifies a specific field to be deleted from the input object, allowing for nested fields.\n\nIf a key within a nested path does not exist or is not an object then it is not removed.",
          "Examples": [
            {
              "mapping": "root = this.without(\"inner.a\",\"inner.c\",\"d\")",
              "results": [
                [
                  "{\"inner\":{\"a\":\"first\",\"b\":\"second\",\"c\":\"third\"},\"d\":\"fourth\",\"e\":\"fifth\"}",
                  "{\"e\":\"fifth\",\"inner\":{\"b\":\"second\"}}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "impure": false,
      "name": "without",
      "params": {
        "variadic": true
      },
      "status": "stable"
    },
    {
      "categories": [
        {
          "Category": "Object & Array Manipulation",
          "Description": "",
          "Examples": [
            {
              "mapping": "root.foo = this.foo.zip(this.bar, this.baz)",
              "results": [
                [
                  "{\"foo\":[\"a\",\"b\",\"c\"],\"bar\":[1,2,3],\"baz\":[4,5,6]}",
                  "{\"foo\":[[\"a\",1,4],[\"b\",2,5],[\"c\",3,6]]}"
                ]
              ],
              "skip_testing": false,
              "summary": ""
            }
          ]
        }
      ],
      "description": "Zip an array value with one or more argument arrays. Each array must match in length.",
      "impure": false,
      "name": "zip",
      "params": {
        "variadic": true
      },
      "status": "stable"
    }
  ],
  "buffers": [
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": 524288000,
            "description": "The maximum buffer size (in bytes) to allow before applying backpressure upstream.",
            "kind": "scalar",
            "name": "limit",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to batch messages as they are flushed.",
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "Optionally configure a policy to flush buffered messages in batches.",
            "kind": "",
            "name": "batch_policy",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis buffer is appropriate when consuming messages from inputs that do not gracefully handle back pressure and where delivery guarantees aren't critical.\n\nThis buffer has a configurable limit, where consumption will be stopped with back pressure upstream if the total size of messages in the buffer reaches this amount. Since this calculation is only an estimate, and the real size of messages in RAM is always higher, it is recommended to set the limit significantly below the amount of RAM available.\n\n== Delivery guarantees\n\nThis buffer intentionally weakens the delivery guarantees of the pipeline and therefore should never be used in places where data loss is unacceptable.\n\n== Batching\n\nIt is possible to batch up messages sent from this buffer using a xref:configuration:batching.adoc#batch-policy[batch policy].",
      "name": "memory",
      "plugin": true,
      "status": "stable",
      "summary": "Stores consumed messages in memory and acknowledges them at the input level. During shutdown Redpanda Connect will make a best attempt at flushing all remaining messages before exiting cleanly.",
      "type": "buffer"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Selecting no buffer means the output layer is directly coupled with the input layer. This is the safest and lowest latency option since acknowledgements from at-least-once protocols can be propagated all the way from the output protocol to the input protocol.\n\nIf the output layer is hit with back pressure it will propagate all the way to the input layer, and further up the data stream. If you need to relieve your pipeline of this back pressure consider using a more robust buffering solution such as Kafka before resorting to alternatives.",
      "name": "none",
      "plugin": true,
      "status": "stable",
      "summary": "Do not buffer messages. This is the default and most resilient configuration.",
      "type": "buffer"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The path of the database file, which will be created if it does not already exist.",
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "description": "An optional list of processors to apply to messages before they are stored within the buffer. These processors are useful for compressing, archiving or otherwise reducing the data in size before it's stored on disk.",
            "is_optional": true,
            "kind": "array",
            "name": "pre_processors",
            "type": "processor"
          },
          {
            "description": "An optional list of processors to apply to messages after they are consumed from the buffer. These processors are useful for undoing any compression, archiving, etc that may have been done by your `pre_processors`.",
            "is_optional": true,
            "kind": "array",
            "name": "post_processors",
            "type": "processor"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nStored messages are then consumed as a stream from the database and deleted only once they are successfully sent at the output level. If the service is restarted Redpanda Connect will make a best attempt to finish delivering messages that are already read from the database, and when it starts again it will consume from the oldest message that has not yet been delivered.\n\n== Delivery guarantees\n\nMessages are not acknowledged at the input level until they have been added to the SQLite database, and they are not removed from the SQLite database until they have been successfully delivered. This means at-least-once delivery guarantees are preserved in cases where the service is shut down unexpectedly. However, since this process relies on interaction with the disk (wherever the SQLite DB is stored) these delivery guarantees are not resilient to disk corruption or loss.\n\n== Batching\n\nMessages that are logically batched at the point where they are added to the buffer will continue to be associated with that batch when they are consumed. This buffer is also more efficient when storing messages within batches, and therefore it is recommended to use batching at the input level in high-throughput use cases even if they are not required for processing.\n",
      "examples": [
        {
          "config": "\ninput:\n  batched:\n    child:\n      sql_select:\n        driver: postgres\n        dsn: postgres://foouser:foopass@localhost:5432/testdb?sslmode=disable\n        table: footable\n        columns: [ '*' ]\n    policy:\n      count: 100\n      period: 500ms\n\nbuffer:\n  sqlite:\n    path: ./foo.db\n    post_processors:\n      - split: {}\n",
          "summary": "Batching at the input level greatly increases the throughput of this buffer. If logical batches aren't needed for processing add a xref:components:processors/split.adoc[`split` processor] to the `post_processors`.",
          "title": "Batching for optimization"
        }
      ],
      "name": "sqlite",
      "plugin": true,
      "status": "stable",
      "summary": "Stores messages in an SQLite database and acknowledges them at the input level.",
      "type": "buffer"
    },
    {
      "categories": [
        "Windowing"
      ],
      "config": {
        "children": [
          {
            "bloblang": true,
            "default": "root = now()",
            "description": "\nA xref:guides:bloblang/about.adoc[Bloblang mapping] applied to each message during ingestion that provides the timestamp to use for allocating it a window. By default the function `now()` is used in order to generate a fresh timestamp at the time of ingestion (the processing time), whereas this mapping can instead extract a timestamp from the message itself (the event time).\n\nThe timestamp value assigned to `root` must either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in ISO 8601 format. If the mapping fails or provides an invalid result the message will be dropped (with logging to describe the problem).\n",
            "examples": [
              "root = this.created_at",
              "root = meta(\"kafka_timestamp_unix\").number()"
            ],
            "kind": "scalar",
            "name": "timestamp_mapping",
            "type": "string"
          },
          {
            "description": "A duration string describing the size of each window. By default windows are aligned to the zeroth minute and zeroth hour on the UTC clock, meaning windows of 1 hour duration will match the turn of each hour in the day, this can be adjusted with the `offset` field.",
            "examples": [
              "30s",
              "10m"
            ],
            "kind": "scalar",
            "name": "size",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional duration string describing by how much time the beginning of each window should be offset from the beginning of the previous, and therefore creates sliding windows instead of tumbling. When specified this duration must be smaller than the `size` of the window.",
            "examples": [
              "30s",
              "10m"
            ],
            "kind": "scalar",
            "name": "slide",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional duration string to offset the beginning of each window by, otherwise they are aligned to the zeroth minute and zeroth hour on the UTC clock. The offset cannot be a larger or equal measure to the window size or the slide.",
            "examples": [
              "-6h",
              "30m"
            ],
            "kind": "scalar",
            "name": "offset",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional duration string describing the length of time to wait after a window has ended before flushing it, allowing late arrivals to be included. Since this windowing buffer uses the system clock an allowed lateness can improve the matching of messages when using event time.",
            "examples": [
              "10s",
              "1m"
            ],
            "kind": "scalar",
            "name": "allowed_lateness",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nA window is a grouping of messages that fit within a discrete measure of time following the system clock. Messages are allocated to a window either by the processing time (the time at which they're ingested) or by the event time, and this is controlled via the <<timestamp_mapping, `timestamp_mapping` field>>.\n\nIn tumbling mode (default) the beginning of a window immediately follows the end of a prior window. When the buffer is initialized the first window to be created and populated is aligned against the zeroth minute of the zeroth hour of the day by default, and may therefore be open for a shorter period than the specified size.\n\nA window is flushed only once the system clock surpasses its scheduled end. If an <<allowed_lateness, `allowed_lateness`>> is specified then the window will not be flushed until the scheduled end plus that length of time.\n\nWhen a message is added to a window it has a metadata field `window_end_timestamp` added to it containing the timestamp of the end of the window as an RFC3339 string.\n\n== Sliding windows\n\nSliding windows begin from an offset of the prior windows' beginning rather than its end, and therefore messages may belong to multiple windows. In order to produce sliding windows specify a <<slide, `slide` duration>>.\n\n== Back pressure\n\nIf back pressure is applied to this buffer either due to output services being unavailable or resources being saturated, windows older than the current and last according to the system clock will be dropped in order to prevent unbounded resource usage. This means you should ensure that under the worst case scenario you have enough system memory to store two windows' worth of data at a given time (plus extra for redundancy and other services).\n\nIf messages could potentially arrive with event timestamps in the future (according to the system clock) then you should also factor in these extra messages in memory usage estimates.\n\n== Delivery guarantees\n\nThis buffer honours the transaction model within Redpanda Connect in order to ensure that messages are not acknowledged until they are either intentionally dropped or successfully delivered to outputs. However, since messages belonging to an expired window are intentionally dropped there are circumstances where not all messages entering the system will be delivered.\n\nWhen this buffer is configured with a slide duration it is possible for messages to belong to multiple windows, and therefore be delivered multiple times. In this case the first time the message is delivered it will be acked (or nacked) and subsequent deliveries of the same message will be a \"best attempt\".\n\nDuring graceful termination if the current window is partially populated with messages they will be nacked such that they are re-consumed the next time the service starts.\n",
      "examples": [
        {
          "config": "\nbuffer:\n  system_window:\n    timestamp_mapping: root = this.created_at\n    size: 1h\n\npipeline:\n  processors:\n    # Group messages of the window into batches of common traffic light IDs\n    - group_by_value:\n        value: '${! json(\"traffic_light\") }'\n\n    # Reduce each batch to a single message by deleting indexes > 0, and\n    # aggregate the car and passenger counts.\n    - mapping: |\n        root = if batch_index() == 0 {\n          {\n            \"traffic_light\": this.traffic_light,\n            \"created_at\": meta(\"window_end_timestamp\"),\n            \"total_cars\": json(\"registration_plate\").from_all().unique().length(),\n            \"passengers\": json(\"passengers\").from_all().sum(),\n          }\n        } else { deleted() }\n",
          "summary": "Given a stream of messages relating to cars passing through various traffic lights of the form:\n\n```json\n{\n  \"traffic_light\": \"cbf2eafc-806e-4067-9211-97be7e42cee3\",\n  \"created_at\": \"2021-08-07T09:49:35Z\",\n  \"registration_plate\": \"AB1C DEF\",\n  \"passengers\": 3\n}\n```\n\nWe can use a window buffer in order to create periodic messages summarizing the traffic for a period of time of this form:\n\n```json\n{\n  \"traffic_light\": \"cbf2eafc-806e-4067-9211-97be7e42cee3\",\n  \"created_at\": \"2021-08-07T10:00:00Z\",\n  \"total_cars\": 15,\n  \"passengers\": 43\n}\n```\n\nWith the following config:",
          "title": "Counting Passengers at Traffic"
        }
      ],
      "name": "system_window",
      "plugin": true,
      "status": "beta",
      "summary": "Chops a stream of messages into tumbling or sliding windows of fixed temporal size, following the system clock.",
      "type": "buffer",
      "version": "3.53.0"
    }
  ],
  "caches": [
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The table to store items in.",
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "The key of the table column to store item keys within.",
            "kind": "scalar",
            "name": "hash_key",
            "type": "string"
          },
          {
            "description": "The key of the table column to store item values within.",
            "kind": "scalar",
            "name": "data_key",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to use strongly consistent reads on Get commands.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "consistent_read",
            "type": "bool"
          },
          {
            "description": "An optional default TTL to set for items, calculated from the moment the item is cached. A `ttl_key` must be specified in order to set item TTLs.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string"
          },
          {
            "description": "The column key to place the TTL value within.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "ttl_key",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Determine time intervals and cut offs for retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "object"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "A prefix can be specified to allow multiple cache types to share a single DynamoDB table. An optional TTL duration (`ttl`) and field\n(`ttl_key`) can be specified if the backing table has TTL enabled.\n\nStrong read consistency can be enabled using the `consistent_read` configuration field.",
      "name": "aws_dynamodb",
      "plugin": true,
      "status": "stable",
      "summary": "Stores key/value pairs as a single document in a DynamoDB table. The key is stored as a string value and used as the table hash key. The value is stored as\na binary value using the `data_key` field name.",
      "type": "cache",
      "version": "3.36.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The S3 bucket to store items in.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "default": "application/octet-stream",
            "description": "The content type to set for each item.",
            "kind": "scalar",
            "name": "content_type",
            "type": "string"
          },
          {
            "default": false,
            "description": "Forces the client API to use path style URLs, which helps when connecting to custom endpoints.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "force_path_style_urls",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Determine time intervals and cut offs for retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "object"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "It is not possible to atomically upload S3 objects exclusively when the target does not already exist, therefore this cache is not suitable for deduplication.",
      "name": "aws_s3",
      "plugin": true,
      "status": "stable",
      "summary": "Stores each item in an S3 bucket as a file, where an item ID is the path of the item within the bucket.",
      "type": "cache",
      "version": "3.36.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "Couchbase connection string.",
            "examples": [
              "couchbase://localhost:11210"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "Username to connect to the cluster.",
            "is_optional": true,
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "description": "Password to connect to the cluster.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Couchbase bucket.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "description": "Bucket collection.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "description": "Bucket scope.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "scope",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "json",
                "JSONTranscoder implements the default transcoding behavior and applies JSON transcoding to all values. This will apply the following behavior to the value: binary ([]byte) -> error. default -> JSON value, JSON Flags."
              ],
              [
                "legacy",
                "LegacyTranscoder implements the behavior for a backward-compatible transcoder. This transcoder implements behavior matching that of gocb v1.This will apply the following behavior to the value: binary ([]byte) -> binary bytes, Binary expectedFlags. string -> string bytes, String expectedFlags. default -> JSON value, JSON expectedFlags."
              ],
              [
                "raw",
                "RawBinaryTranscoder implements passthrough behavior of raw binary data. This transcoder does not apply any serialization. This will apply the following behavior to the value: binary ([]byte) -> binary bytes, binary expectedFlags. default -> error."
              ],
              [
                "rawjson",
                "RawJSONTranscoder implements passthrough behavior of JSON data. This transcoder does not apply any serialization. It will forward data across the network without incurring unnecessary parsing costs. This will apply the following behavior to the value: binary ([]byte) -> JSON bytes, JSON expectedFlags. string -> JSON bytes, JSON expectedFlags. default -> error."
              ],
              [
                "rawstring",
                "RawStringTranscoder implements passthrough behavior of raw string data. This transcoder does not apply any serialization. This will apply the following behavior to the value: string -> string bytes, string expectedFlags. default -> error."
              ]
            ],
            "default": "legacy",
            "description": "Couchbase transcoder to use.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"json\": true,\n  \"legacy\": true,\n  \"raw\": true,\n  \"rawjson\": true,\n  \"rawstring\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transcoder",
            "type": "string"
          },
          {
            "default": "15s",
            "description": "Operation timeout.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "description": "An optional default TTL to set for items, calculated from the moment the item is cached.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "couchbase",
      "plugin": true,
      "status": "experimental",
      "summary": "Use a Couchbase instance as a cache.",
      "type": "cache",
      "version": "4.12.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The directory within which to store items.",
            "kind": "scalar",
            "name": "directory",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This type currently offers no form of item expiry or garbage collection, and is intended to be used for development and debugging purposes only.",
      "name": "file",
      "plugin": true,
      "status": "stable",
      "summary": "Stores each item in a directory as a file, where an item ID is the path relative to the configured directory.",
      "type": "cache"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The Google Cloud Storage bucket to store items in.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "description": "Optional field to explicitly set the Content-Type.",
            "is_optional": true,
            "kind": "scalar",
            "name": "content_type",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "It is not possible to atomically upload cloud storage objects exclusively when the target does not already exist, therefore this cache is not suitable for deduplication.",
      "name": "gcp_cloud_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Use a Google Cloud Storage bucket as a cache.",
      "type": "cache"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": 1000,
            "description": "The cache maximum capacity (number of entries)",
            "kind": "scalar",
            "name": "cap",
            "type": "int"
          },
          {
            "default": {},
            "description": "A table of key/value pairs that should be present in the cache on initialization. This can be used to create static lookup tables.",
            "examples": [
              {
                "Nickelback": "1995",
                "Spice Girls": "1994",
                "The Human League": "1977"
              }
            ],
            "kind": "map",
            "name": "init_values",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "arc",
                "is an adaptive replacement cache. It tracks recent evictions as well as recent usage in both the frequent and recent caches. Its computational overhead is comparable to two_queues, but the memory overhead is linear with the size of the cache. ARC has been patented by IBM."
              ],
              [
                "standard",
                "is a simple LRU cache. It is based on the LRU implementation in groupcache"
              ],
              [
                "two_queues",
                "tracks frequently used and recently used entries separately. This avoids a burst of accesses from taking out frequently used entries, at the cost of about 2x computational overhead and some extra bookkeeping."
              ]
            ],
            "default": "standard",
            "description": "the lru cache implementation",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"arc\": true,\n  \"standard\": true,\n  \"two_queues\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "algorithm",
            "type": "string"
          },
          {
            "default": 0.25,
            "description": "is the ratio of the two_queues cache dedicated to recently added entries that have only been accessed once.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "two_queues_recent_ratio",
            "type": "float"
          },
          {
            "default": 0.5,
            "description": "is the default ratio of ghost entries kept to track entries recently evicted on two_queues cache.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "two_queues_ghost_ratio",
            "type": "float"
          },
          {
            "default": false,
            "description": "If true, we do not lock on read/write events. The lru package is thread-safe, however the ADD operation is not atomic.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "optimistic",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This provides the lru package which implements a fixed-size thread safe LRU cache.\n\nIt uses the package https://github.com/hashicorp/golang-lru/v2[`lru`^]\n\nThe field init_values can be used to pre-populate the memory cache with any number of key/value pairs:\n\n```yaml\ncache_resources:\n  - label: foocache\n    lru:\n      cap: 1024\n      init_values:\n        foo: bar\n```\n\nThese values can be overridden during execution.",
      "name": "lru",
      "plugin": true,
      "status": "stable",
      "summary": "Stores key/value pairs in a lru in-memory cache. This cache is therefore reset every time the service restarts.",
      "type": "cache"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "A list of addresses of memcached servers to use.",
            "kind": "array",
            "name": "addresses",
            "type": "string"
          },
          {
            "description": "An optional string to prefix item keys with in order to prevent collisions with similar services.",
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "default": "300s",
            "description": "A default TTL to set for items, calculated from the moment the item is cached.",
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Determine time intervals and cut offs for retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "memcached",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to a cluster of memcached services, a prefix can be specified to allow multiple cache types to share a memcached cluster under different namespaces.",
      "type": "cache"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": "5m",
            "description": "The default TTL of each item. After this period an item will be eligible for removal during the next compaction.",
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string"
          },
          {
            "default": "60s",
            "description": "The period of time to wait before each compaction, at which point expired items are removed. This field can be set to an empty string in order to disable compactions/expiry entirely.",
            "kind": "scalar",
            "name": "compaction_interval",
            "type": "string"
          },
          {
            "default": {},
            "description": "A table of key/value pairs that should be present in the cache on initialization. This can be used to create static lookup tables.",
            "examples": [
              {
                "Nickelback": "1995",
                "Spice Girls": "1994",
                "The Human League": "1977"
              }
            ],
            "kind": "map",
            "name": "init_values",
            "type": "string"
          },
          {
            "default": 1,
            "description": "A number of logical shards to spread keys across, increasing the shards can have a performance benefit when processing a large number of keys.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "shards",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The compaction interval determines how often the cache is cleared of expired items, and this process is only triggered on writes to the cache. Access to the cache is blocked during this process.\n\nItem expiry can be disabled entirely by setting the `compaction_interval` to an empty string.\n\nThe field `init_values` can be used to prepopulate the memory cache with any number of key/value pairs which are exempt from TTLs:\n\n```yaml\ncache_resources:\n  - label: foocache\n    memory:\n      default_ttl: 60s\n      init_values:\n        foo: bar\n```\n\nThese values can be overridden during execution, at which point the configured TTL is respected as usual.",
      "name": "memory",
      "plugin": true,
      "status": "stable",
      "summary": "Stores key/value pairs in a map held in memory. This cache is therefore reset every time the service restarts. Each item in the cache has a TTL set from the moment it was last edited, after which it will be removed during the next compaction.",
      "type": "cache"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The URL of the target MongoDB server.",
            "examples": [
              "mongodb://localhost:27017"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target MongoDB database.",
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "default": "",
            "description": "The username to connect to the database.",
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "default": "",
            "description": "The password to connect to the database.",
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "The client application name.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "app_name",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target collection.",
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "description": "The field in the document that is used as the key.",
            "kind": "scalar",
            "name": "key_field",
            "type": "string"
          },
          {
            "description": "The field in the document that is used as the value.",
            "kind": "scalar",
            "name": "value_field",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "mongodb",
      "plugin": true,
      "status": "experimental",
      "summary": "Use a MongoDB instance as a cache.",
      "type": "cache",
      "version": "3.43.0"
    },
    {
      "categories": null,
      "config": {
        "kind": "array",
        "name": "",
        "type": "string"
      },
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - cache:\n              resource: leveled\n              operator: get\n              key: ${! json(\"key\") }\n          - catch:\n            - mapping: 'root = {\"err\":error()}'\n        result_map: 'root.result = this'\n\ncache_resources:\n  - label: leveled\n    multilevel: [ hot, cold ]\n\n  - label: hot\n    memory:\n      default_ttl: 60s\n\n  - label: cold\n    memcached:\n      addresses: [ TODO:11211 ]\n      default_ttl: 60s\n",
          "summary": "The multilevel cache is useful for reducing traffic against a remote cache by routing it through a local cache. In the following example requests will only go through to the memcached server if the local memory cache is missing the key.",
          "title": "Hot and cold cache"
        }
      ],
      "name": "multilevel",
      "plugin": true,
      "status": "stable",
      "summary": "Combines multiple caches as levels, performing read-through and write-through operations across them.",
      "type": "cache"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The name of the KV bucket.",
            "examples": [
              "my_kv_bucket"
            ],
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_kv",
      "plugin": true,
      "status": "experimental",
      "summary": "Cache key/values in a NATS key-value bucket.",
      "type": "cache",
      "version": "4.27.0"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "noop",
      "plugin": true,
      "status": "stable",
      "summary": "Noop is a cache that stores nothing, all gets returns not found. Why? Sometimes doing nothing is the braver option.",
      "type": "cache",
      "version": "4.27.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "An optional string to prefix item keys with in order to prevent collisions with similar services.",
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional default TTL to set for items, calculated from the moment the item is cached.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "500ms",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "1s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Determine time intervals and cut offs for retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "redis",
      "plugin": true,
      "status": "stable",
      "summary": "Use a Redis instance as a cache. The expiration can be set to zero or an empty string in order to set no expiration.",
      "type": "cache"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "The topic to store data in.",
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enables topics to be auto created if they do not exist when fetching their metadata.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "allow_auto_topic_creation",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nA cache that stores data in a Kafka topic.\n\nThis cache is useful for data that is written frequently and queried infreqently.\nReads of the cache require reading the entire topic partition, so if there is a need for frequent reads, it's recommended to put an in memory caching layer infront of this cache.\n\nTopics that are used as caches should be compacted so that reads are less expensive when they rescan the topic, as only the latest value is needed.\n\nThis cache does not support any special TTL mechanism, any TTL should be handled by the Kafka topic itself using data retention policies.\n",
      "name": "redpanda",
      "plugin": true,
      "status": "beta",
      "summary": "A Kafka cache using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "cache"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": "",
            "description": "A default TTL to set for items, calculated from the moment the item is cached. Set to an empty string or zero duration to disable TTLs.",
            "examples": [
              "5m",
              "60s"
            ],
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether retries should be enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Determines how and whether get attempts should be retried if the key is not found. Ristretto is a concurrent cache that does not immediately reflect writes, and so it can sometimes be useful to enable retries at the cost of speed in cases where the key is expected to exist.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "get_retries",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This cache is more efficient and appropriate for high-volume use cases than the standard memory cache. However, the add command is non-atomic, and therefore this cache is not suitable for deduplication.",
      "name": "ristretto",
      "plugin": true,
      "status": "stable",
      "summary": "Stores key/value pairs in a map held in the memory-bound https://github.com/dgraph-io/ristretto[Ristretto cache^].",
      "type": "cache"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The table to insert/read/delete cache items.",
            "examples": [
              "foo"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "The name of a column to be used for storing cache item keys. This column should support strings of arbitrary size.",
            "examples": [
              "foo"
            ],
            "kind": "scalar",
            "name": "key_column",
            "type": "string"
          },
          {
            "description": "The name of a column to be used for storing cache item values. This column should support strings of arbitrary size.",
            "examples": [
              "bar"
            ],
            "kind": "scalar",
            "name": "value_column",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to each insert query for a cache `set` operation. This should modify an insert statement into an upsert appropriate for the given SQL engine.",
            "examples": [
              "ON DUPLICATE KEY UPDATE bar=VALUES(bar)",
              "ON CONFLICT (foo) DO UPDATE SET bar=excluded.bar",
              "ON CONFLICT (foo) DO NOTHING"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "set_suffix",
            "type": "string"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nEach cache key/value pair will exist as a row within the specified table. Currently only the key and value columns are set, and therefore any other columns present within the target table must allow NULL values if this cache is going to be used for set and add operations.\n\nCache operations are translated into SQL statements as follows:\n\n== Get\n\nAll `get` operations are performed with a traditional `select` statement.\n\n== Delete\n\nAll `delete` operations are performed with a traditional `delete` statement.\n\n== Set\n\nThe `set` operation is performed with a traditional `insert` statement.\n\nThis will behave as an `add` operation by default, and so ideally needs to be adapted in order to provide updates instead of failing on collision\ts. Since different SQL engines implement upserts differently it is necessary to specify a `set_suffix` that modifies an `insert` statement in order to perform updates on conflict.\n\n== Add\n\nThe `add` operation is performed with a traditional `insert` statement.\n",
      "name": "sql",
      "plugin": true,
      "status": "experimental",
      "summary": "Uses an SQL database table as a destination for storing cache key/value items.",
      "type": "cache",
      "version": "4.26.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": 1024,
            "description": "The cache maximum capacity (number of entries)",
            "kind": "scalar",
            "name": "cap",
            "type": "int"
          },
          {
            "default": "5m0s",
            "description": "The cache ttl of each element",
            "kind": "scalar",
            "name": "default_ttl",
            "type": "string",
            "version": "4.21.0"
          },
          {
            "description": "Deprecated. Please use `default_ttl` field",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "ttl",
            "type": "string"
          },
          {
            "default": {},
            "description": "A table of key/value pairs that should be present in the cache on initialization. This can be used to create static lookup tables.",
            "examples": [
              {
                "Nickelback": "1995",
                "Spice Girls": "1994",
                "The Human League": "1977"
              }
            ],
            "kind": "map",
            "name": "init_values",
            "type": "string"
          },
          {
            "default": false,
            "description": "If true, we do not lock on read/write events. The ttlru package is thread-safe, however the ADD operation is not atomic.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "optimistic",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The cache ttlru provides a simple, goroutine safe, cache with a fixed number of entries. Each entry has a per-cache defined TTL.\n\nThis TTL is reset on both modification and access of the value. As a result, if the cache is full, and no items have expired, when adding a new item, the item with the soonest expiration will be evicted.\n\nIt uses the package https://github.com/hashicorp/golang-lru/v2/expirable[`expirable`^]\n\nThe field init_values can be used to pre-populate the memory cache with any number of key/value pairs:\n\n```yaml\ncache_resources:\n  - label: foocache\n    ttlru:\n      default_ttl: '5m'\n      cap: 1024\n      init_values:\n        foo: bar\n```\n\nThese values can be overridden during execution.",
      "name": "ttlru",
      "plugin": true,
      "status": "stable",
      "summary": "Stores key/value pairs in a ttlru in-memory cache. This cache is therefore reset every time the service restarts.",
      "type": "cache"
    }
  ],
  "config": [
    {
      "children": [
        {
          "default": true,
          "description": "Whether to enable to HTTP server.",
          "kind": "scalar",
          "name": "enabled",
          "type": "bool"
        },
        {
          "default": "0.0.0.0:4195",
          "description": "The address to bind to.",
          "kind": "scalar",
          "name": "address",
          "type": "string"
        },
        {
          "default": "/benthos",
          "description": "Specifies a general prefix for all endpoints, this can help isolate the service endpoints when using a reverse proxy with other shared services. All endpoints will still be registered at the root as well as behind the prefix, e.g. with a root_path set to `/foo` the endpoint `/version` will be accessible from both `/version` and `/foo/version`.",
          "kind": "scalar",
          "name": "root_path",
          "type": "string"
        },
        {
          "default": false,
          "description": "Whether to register a few extra endpoints that can be useful for debugging performance or behavioral problems.",
          "kind": "scalar",
          "name": "debug_endpoints",
          "type": "bool"
        },
        {
          "default": "",
          "description": "An optional certificate file for enabling TLS.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "cert_file",
          "type": "string"
        },
        {
          "default": "",
          "description": "An optional key file for enabling TLS.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "key_file",
          "type": "string"
        },
        {
          "children": [
            {
              "default": false,
              "description": "Whether to allow CORS requests.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "enabled",
              "type": "bool"
            },
            {
              "default": [],
              "description": "An explicit list of origins that are allowed for CORS requests.",
              "is_advanced": true,
              "kind": "array",
              "name": "allowed_origins",
              "type": "string"
            }
          ],
          "description": "Adds Cross-Origin Resource Sharing headers.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "cors",
          "type": "object",
          "version": "3.63.0"
        },
        {
          "children": [
            {
              "default": false,
              "description": "Enable basic authentication",
              "is_advanced": true,
              "kind": "scalar",
              "name": "enabled",
              "type": "bool"
            },
            {
              "default": "restricted",
              "description": "Custom realm name",
              "is_advanced": true,
              "kind": "scalar",
              "name": "realm",
              "type": "string"
            },
            {
              "default": "",
              "description": "Username required to authenticate.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "username",
              "type": "string"
            },
            {
              "default": "",
              "description": "Hashed password required to authenticate. (base64 encoded)",
              "is_advanced": true,
              "kind": "scalar",
              "name": "password_hash",
              "type": "string"
            },
            {
              "default": "sha256",
              "description": "Encryption algorithm used to generate `password_hash`.",
              "examples": [
                "md5",
                "sha256",
                "bcrypt",
                "scrypt"
              ],
              "is_advanced": true,
              "kind": "scalar",
              "name": "algorithm",
              "type": "string"
            },
            {
              "default": "",
              "description": "Salt for scrypt algorithm. (base64 encoded)",
              "is_advanced": true,
              "kind": "scalar",
              "name": "salt",
              "type": "string"
            }
          ],
          "description": "Allows you to enforce and customise basic authentication for requests to the HTTP server.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "basic_auth",
          "type": "object"
        }
      ],
      "description": "Configures the service-wide HTTP server.",
      "kind": "scalar",
      "name": "http",
      "type": "object"
    },
    {
      "default": {
        "stdin": {}
      },
      "description": "An input to source messages from.",
      "kind": "scalar",
      "name": "input",
      "type": "input"
    },
    {
      "default": {
        "none": {}
      },
      "description": "An optional buffer to store messages during transit.",
      "kind": "scalar",
      "name": "buffer",
      "type": "buffer"
    },
    {
      "children": [
        {
          "default": -1,
          "description": "The number of threads to execute processing pipelines across.",
          "kind": "scalar",
          "name": "threads",
          "type": "int"
        },
        {
          "default": [],
          "description": "A list of processors to apply to messages.",
          "kind": "array",
          "name": "processors",
          "type": "processor"
        }
      ],
      "description": "Describes optional processing pipelines used for mutating messages.",
      "kind": "scalar",
      "name": "pipeline",
      "type": "object"
    },
    {
      "default": {
        "stdout": {}
      },
      "description": "An output to sink messages to.",
      "kind": "scalar",
      "name": "output",
      "type": "output"
    },
    {
      "default": [],
      "description": "A list of input resources, each must have a unique label.",
      "is_advanced": true,
      "kind": "array",
      "name": "input_resources",
      "type": "input"
    },
    {
      "default": [],
      "description": "A list of processor resources, each must have a unique label.",
      "is_advanced": true,
      "kind": "array",
      "name": "processor_resources",
      "type": "processor"
    },
    {
      "default": [],
      "description": "A list of output resources, each must have a unique label.",
      "is_advanced": true,
      "kind": "array",
      "name": "output_resources",
      "type": "output"
    },
    {
      "default": [],
      "description": "A list of cache resources, each must have a unique label.",
      "is_advanced": true,
      "kind": "array",
      "name": "cache_resources",
      "type": "cache"
    },
    {
      "default": [],
      "description": "A list of rate limit resources, each must have a unique label.",
      "is_advanced": true,
      "kind": "array",
      "name": "rate_limit_resources",
      "type": "rate_limit"
    },
    {
      "children": [
        {
          "default": "INFO",
          "description": "Set the minimum severity level for emitting logs.",
          "kind": "scalar",
          "name": "level",
          "options": [
            "OFF",
            "FATAL",
            "ERROR",
            "WARN",
            "INFO",
            "DEBUG",
            "TRACE",
            "ALL",
            "NONE"
          ],
          "type": "string"
        },
        {
          "default": "logfmt",
          "description": "Set the format of emitted logs.",
          "kind": "scalar",
          "linter": "\nlet options = {\n  \"json\": true,\n  \"logfmt\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
          "name": "format",
          "options": [
            "json",
            "logfmt"
          ],
          "type": "string"
        },
        {
          "default": true,
          "description": "Whether to include timestamps in logs.",
          "kind": "scalar",
          "name": "add_timestamp",
          "type": "bool"
        },
        {
          "default": "level",
          "description": "The name of the level field added to logs when the `format` is `json`.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "level_name",
          "type": "string"
        },
        {
          "default": "time",
          "description": "The name of the timestamp field added to logs when `add_timestamp` is set to `true` and the `format` is `json`.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "timestamp_name",
          "type": "string"
        },
        {
          "default": "msg",
          "description": "The name of the message field added to logs when the `format` is `json`.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "message_name",
          "type": "string"
        },
        {
          "default": {
            "@service": "redpanda-connect"
          },
          "description": "A map of key/value pairs to add to each structured log.",
          "kind": "map",
          "name": "static_fields",
          "type": "string"
        },
        {
          "children": [
            {
              "default": "",
              "description": "The file path to write logs to, if the file does not exist it will be created. Leave this field empty or unset to disable file based logging.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "path",
              "type": "string"
            },
            {
              "default": false,
              "description": "Whether to rotate log files automatically.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "rotate",
              "type": "bool"
            },
            {
              "default": 0,
              "description": "The maximum number of days to retain old log files based on the timestamp encoded in their filename, after which they are deleted. Setting to zero disables this mechanism.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "rotate_max_age_days",
              "type": "int"
            }
          ],
          "description": "Experimental: Specify fields for optionally writing logs to a file.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "file",
          "type": "object"
        }
      ],
      "description": "Describes how operational logs should be emitted.",
      "kind": "scalar",
      "name": "logger",
      "type": "object"
    },
    {
      "default": {
        "mapping": "",
        "prometheus": {}
      },
      "description": "A mechanism for exporting metrics.",
      "kind": "scalar",
      "name": "metrics",
      "type": "metrics"
    },
    {
      "default": {
        "none": {}
      },
      "description": "A mechanism for exporting traces.",
      "kind": "scalar",
      "name": "tracer",
      "type": "tracer"
    },
    {
      "default": "0s",
      "description": "A period of time to wait for metrics and traces to be pulled or pushed from the process.",
      "kind": "scalar",
      "name": "shutdown_delay",
      "type": "string"
    },
    {
      "default": "20s",
      "description": "The maximum period of time to wait for a clean shutdown. If this time is exceeded Redpanda Connect will forcefully close.",
      "kind": "scalar",
      "name": "shutdown_timeout",
      "type": "string"
    },
    {
      "children": [
        {
          "description": "The name of the test, this should be unique and give a rough indication of what behavior is being tested.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "name",
          "type": "string"
        },
        {
          "description": "An optional map of environment variables to set for the duration of the test.",
          "is_advanced": true,
          "is_optional": true,
          "kind": "map",
          "name": "environment",
          "type": "string"
        },
        {
          "default": "/pipeline/processors",
          "description": "\nA [JSON Pointer][json-pointer] that identifies the specific processors which should be executed by the test. The target can either be a single processor or an array of processors. Alternatively a resource label can be used to identify a processor.\n\nIt is also possible to target processors in a separate file by prefixing the target with a path relative to the test file followed by a # symbol.\n",
          "examples": [
            "foo_processor",
            "/pipeline/processors/0",
            "target.yaml#/pipeline/processors",
            "target.yaml#/pipeline/processors"
          ],
          "is_advanced": true,
          "kind": "scalar",
          "name": "target_processors",
          "type": "string"
        },
        {
          "default": "",
          "description": "A file path relative to the test definition path of a Bloblang file to execute as an alternative to testing processors with the `target_processors` field. This allows you to define unit tests for Bloblang mappings directly.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "target_mapping",
          "type": "string"
        },
        {
          "description": "An optional map of processors to mock. Keys should contain either a label or a JSON pointer of a processor that should be mocked. Values should contain a processor definition, which will replace the mocked processor. Most of the time you'll want to use a [`mapping` processor][processors.mapping] here, and use it to create a result that emulates the target processor.",
          "examples": [
            {
              "get_foobar_api": {
                "mapping": "root = content().string() + \" this is some mock content\""
              }
            },
            {
              "/pipeline/processors/1": {
                "mapping": "root = content().string() + \" this is some mock content\""
              }
            }
          ],
          "is_advanced": true,
          "is_optional": true,
          "kind": "map",
          "name": "mocks",
          "type": "unknown"
        },
        {
          "children": [
            {
              "description": "The raw content of the input message.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "content",
              "type": "string"
            },
            {
              "description": "Sets the raw content of the message to a JSON document matching the structure of the value.",
              "examples": [
                {
                  "bar": [
                    "element1",
                    10
                  ],
                  "foo": "foo value"
                }
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "json_content",
              "type": "unknown"
            },
            {
              "description": "Sets the raw content of the message by reading a file. The path of the file should be relative to the path of the test file.",
              "examples": [
                "./foo/bar.txt"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "file_content",
              "type": "string"
            },
            {
              "description": "A map of metadata key/values to add to the input message.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "map",
              "name": "metadata",
              "type": "unknown"
            }
          ],
          "description": "Define a batch of messages to feed into your test, specify either an `input_batch` or a series of `input_batches`.",
          "is_advanced": true,
          "is_optional": true,
          "kind": "array",
          "name": "input_batch",
          "type": "object"
        },
        {
          "children": [
            {
              "description": "The raw content of the input message.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "content",
              "type": "string"
            },
            {
              "description": "Sets the raw content of the message to a JSON document matching the structure of the value.",
              "examples": [
                {
                  "bar": [
                    "element1",
                    10
                  ],
                  "foo": "foo value"
                }
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "json_content",
              "type": "unknown"
            },
            {
              "description": "Sets the raw content of the message by reading a file. The path of the file should be relative to the path of the test file.",
              "examples": [
                "./foo/bar.txt"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "file_content",
              "type": "string"
            },
            {
              "description": "A map of metadata key/values to add to the input message.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "map",
              "name": "metadata",
              "type": "unknown"
            }
          ],
          "description": "Define a series of batches of messages to feed into your test, specify either an `input_batch` or a series of `input_batches`.",
          "is_advanced": true,
          "is_optional": true,
          "kind": "2darray",
          "name": "input_batches",
          "type": "object"
        },
        {
          "children": [
            {
              "bloblang": true,
              "description": "Executes a Bloblang mapping on the output message, if the result is anything other than a boolean equalling `true` the test fails.",
              "examples": [
                "this.age > 10 && @foo.length() > 0"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "bloblang",
              "type": "string"
            },
            {
              "description": "Checks the full raw contents of a message against a value.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "content_equals",
              "type": "string"
            },
            {
              "description": "Checks whether the full raw contents of a message matches a regular expression (re2).",
              "examples": [
                "^foo [a-z]+ bar$"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "content_matches",
              "type": "string"
            },
            {
              "description": "Checks a map of metadata keys to values against the metadata stored in the message. If there is a value mismatch between a key of the condition versus the message metadata this condition will fail.",
              "examples": [
                {
                  "example_key": "example metadata value"
                }
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "map",
              "name": "metadata_equals",
              "type": "unknown"
            },
            {
              "description": "Checks that the contents of a message matches the contents of a file. The path of the file should be relative to the path of the test file.",
              "examples": [
                "./foo/bar.txt"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "file_equals",
              "type": "string"
            },
            {
              "description": "Checks that both the message and the file contents are valid JSON documents, and that they are structurally equivalent. Will ignore formatting and ordering differences. The path of the file should be relative to the path of the test file.",
              "examples": [
                "./foo/bar.json"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "file_json_equals",
              "type": "string"
            },
            {
              "description": "Checks that both the message and the condition are valid JSON documents, and that they are structurally equivalent. Will ignore formatting and ordering differences.",
              "examples": [
                {
                  "key": "value"
                }
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "json_equals",
              "type": "unknown"
            },
            {
              "description": "Checks that both the message and the condition are valid JSON documents, and that the message is a superset of the condition.",
              "examples": [
                {
                  "key": "value"
                }
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "json_contains",
              "type": "unknown"
            },
            {
              "description": "Checks that both the message and the file contents are valid JSON documents, and that the message is a superset of the condition. Will ignore formatting and ordering differences. The path of the file should be relative to the path of the test file.",
              "examples": [
                "./foo/bar.json"
              ],
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "file_json_contains",
              "type": "string"
            }
          ],
          "description": "List of output batches.",
          "is_advanced": true,
          "is_optional": true,
          "kind": "2darray",
          "name": "output_batches",
          "type": "object"
        }
      ],
      "description": "A list of one or more unit tests to execute.",
      "is_advanced": true,
      "is_optional": true,
      "kind": "array",
      "name": "tests",
      "type": "object"
    },
    {
      "children": [
        {
          "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
          "examples": [
            [
              "localhost:9092"
            ],
            [
              "foo:9092",
              "bar:9092"
            ],
            [
              "foo:9092,bar:9092"
            ]
          ],
          "kind": "array",
          "name": "seed_brokers",
          "type": "string"
        },
        {
          "default": "benthos",
          "description": "An identifier for the client connection.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "client_id",
          "type": "string"
        },
        {
          "children": [
            {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "enabled",
              "type": "bool"
            },
            {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "skip_cert_verify",
              "type": "bool"
            },
            {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "enable_renegotiation",
              "type": "bool",
              "version": "3.45.0"
            },
            {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "examples": [
                "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
              ],
              "is_advanced": true,
              "is_secret": true,
              "kind": "scalar",
              "name": "root_cas",
              "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
              "type": "string"
            },
            {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "examples": [
                "./root_cas.pem"
              ],
              "is_advanced": true,
              "kind": "scalar",
              "name": "root_cas_file",
              "type": "string"
            },
            {
              "children": [
                {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "is_advanced": true,
                  "kind": "scalar",
                  "name": "cert",
                  "type": "string"
                },
                {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "is_advanced": true,
                  "is_secret": true,
                  "kind": "scalar",
                  "name": "key",
                  "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                  "type": "string"
                },
                {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "is_advanced": true,
                  "kind": "scalar",
                  "name": "cert_file",
                  "type": "string"
                },
                {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "is_advanced": true,
                  "kind": "scalar",
                  "name": "key_file",
                  "type": "string"
                },
                {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "examples": [
                    "foo",
                    "${KEY_PASSWORD}"
                  ],
                  "is_advanced": true,
                  "is_secret": true,
                  "kind": "scalar",
                  "name": "password",
                  "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                  "type": "string"
                }
              ],
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "examples": [
                [
                  {
                    "cert": "foo",
                    "key": "bar"
                  }
                ],
                [
                  {
                    "cert_file": "./example.pem",
                    "key_file": "./example.key"
                  }
                ]
              ],
              "is_advanced": true,
              "kind": "array",
              "name": "client_certs",
              "type": "object"
            }
          ],
          "description": "Custom TLS settings can be used to override system defaults.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "tls",
          "type": "object"
        },
        {
          "children": [
            {
              "annotated_options": [
                [
                  "AWS_MSK_IAM",
                  "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                ],
                [
                  "OAUTHBEARER",
                  "OAuth Bearer based authentication."
                ],
                [
                  "PLAIN",
                  "Plain text authentication."
                ],
                [
                  "SCRAM-SHA-256",
                  "SCRAM based authentication as specified in RFC5802."
                ],
                [
                  "SCRAM-SHA-512",
                  "SCRAM based authentication as specified in RFC5802."
                ],
                [
                  "none",
                  "Disable sasl authentication"
                ]
              ],
              "description": "The SASL mechanism to use.",
              "is_advanced": true,
              "kind": "scalar",
              "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
              "name": "mechanism",
              "type": "string"
            },
            {
              "default": "",
              "description": "A username to provide for PLAIN or SCRAM-* authentication.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "username",
              "type": "string"
            },
            {
              "default": "",
              "description": "A password to provide for PLAIN or SCRAM-* authentication.",
              "is_advanced": true,
              "is_secret": true,
              "kind": "scalar",
              "name": "password",
              "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
              "type": "string"
            },
            {
              "default": "",
              "description": "The token to use for a single session's OAUTHBEARER authentication.",
              "is_advanced": true,
              "kind": "scalar",
              "name": "token",
              "type": "string"
            },
            {
              "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "map",
              "name": "extensions",
              "type": "string"
            },
            {
              "children": [
                {
                  "description": "The AWS region to target.",
                  "is_advanced": true,
                  "is_optional": true,
                  "kind": "scalar",
                  "name": "region",
                  "type": "string"
                },
                {
                  "description": "Allows you to specify a custom endpoint for the AWS API.",
                  "is_advanced": true,
                  "is_optional": true,
                  "kind": "scalar",
                  "name": "endpoint",
                  "type": "string"
                },
                {
                  "children": [
                    {
                      "description": "A profile from `~/.aws/credentials` to use.",
                      "is_advanced": true,
                      "is_optional": true,
                      "kind": "scalar",
                      "name": "profile",
                      "type": "string"
                    },
                    {
                      "description": "The ID of credentials to use.",
                      "is_advanced": true,
                      "is_optional": true,
                      "kind": "scalar",
                      "name": "id",
                      "type": "string"
                    },
                    {
                      "description": "The secret for the credentials being used.",
                      "is_advanced": true,
                      "is_optional": true,
                      "is_secret": true,
                      "kind": "scalar",
                      "name": "secret",
                      "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                      "type": "string"
                    },
                    {
                      "description": "The token for the credentials being used, required when using short term credentials.",
                      "is_advanced": true,
                      "is_optional": true,
                      "kind": "scalar",
                      "name": "token",
                      "type": "string"
                    },
                    {
                      "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                      "is_advanced": true,
                      "is_optional": true,
                      "kind": "scalar",
                      "name": "from_ec2_role",
                      "type": "bool",
                      "version": "4.2.0"
                    },
                    {
                      "description": "A role ARN to assume.",
                      "is_advanced": true,
                      "is_optional": true,
                      "kind": "scalar",
                      "name": "role",
                      "type": "string"
                    },
                    {
                      "description": "An external ID to provide when assuming a role.",
                      "is_advanced": true,
                      "is_optional": true,
                      "kind": "scalar",
                      "name": "role_external_id",
                      "type": "string"
                    }
                  ],
                  "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                  "is_advanced": true,
                  "is_optional": true,
                  "kind": "scalar",
                  "name": "credentials",
                  "type": "object"
                }
              ],
              "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
              "is_advanced": true,
              "is_optional": true,
              "kind": "scalar",
              "name": "aws",
              "type": "object"
            }
          ],
          "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
          "examples": [
            [
              {
                "mechanism": "SCRAM-SHA-512",
                "password": "bar",
                "username": "foo"
              }
            ]
          ],
          "is_advanced": true,
          "is_optional": true,
          "kind": "array",
          "name": "sasl",
          "type": "object"
        },
        {
          "default": "5m",
          "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "metadata_max_age",
          "type": "string"
        },
        {
          "default": "10s",
          "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "request_timeout_overhead",
          "type": "string"
        },
        {
          "default": "20s",
          "description": "The rough amount of time to allow connections to idle before they are closed.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "conn_idle_timeout",
          "type": "string"
        },
        {
          "default": "",
          "description": "An optional identifier for the pipeline, this will be present in logs and status updates sent to topics.",
          "kind": "scalar",
          "name": "pipeline_id",
          "type": "string"
        },
        {
          "default": "",
          "description": "A topic to send process logs to.",
          "examples": [
            "__redpanda.connect.logs"
          ],
          "kind": "scalar",
          "name": "logs_topic",
          "type": "string"
        },
        {
          "default": "info",
          "kind": "scalar",
          "linter": "\nlet options = {\n  \"debug\": true,\n  \"info\": true,\n  \"warn\": true,\n  \"error\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
          "name": "logs_level",
          "options": [
            "debug",
            "info",
            "warn",
            "error"
          ],
          "type": "string"
        },
        {
          "default": "",
          "description": "A topic to send status updates to.",
          "examples": [
            "__redpanda.connect.status"
          ],
          "kind": "scalar",
          "name": "status_topic",
          "type": "string"
        },
        {
          "default": "",
          "is_deprecated": true,
          "kind": "scalar",
          "name": "rack_id",
          "type": "string"
        },
        {
          "annotated_options": [
            [
              "least_backup",
              "Chooses the least backed up partition (the partition with the fewest amount of buffered records). Partitions are selected per batch."
            ],
            [
              "manual",
              "Manually select a partition for each message, requires the field `partition` to be specified."
            ],
            [
              "murmur2_hash",
              "Kafka's default hash algorithm that uses a 32-bit murmur2 hash of the key to compute which partition the record will be on."
            ],
            [
              "round_robin",
              "Round-robin's messages through all available partitions. This algorithm has lower throughput and causes higher CPU load on brokers, but can be useful if you want to ensure an even distribution of records to partitions."
            ]
          ],
          "description": "Override the default murmur2 hashing partitioner.",
          "is_advanced": true,
          "is_optional": true,
          "kind": "scalar",
          "linter": "\nlet options = {\n  \"least_backup\": true,\n  \"manual\": true,\n  \"murmur2_hash\": true,\n  \"round_robin\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
          "name": "partitioner",
          "type": "string"
        },
        {
          "default": true,
          "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "idempotent_write",
          "type": "bool"
        },
        {
          "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
          "is_advanced": true,
          "is_optional": true,
          "kind": "scalar",
          "linter": "\nlet options = {\n  \"lz4\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"none\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
          "name": "compression",
          "options": [
            "lz4",
            "snappy",
            "gzip",
            "none",
            "zstd"
          ],
          "type": "string"
        },
        {
          "default": true,
          "description": "Enables topics to be auto created if they do not exist when fetching their metadata.",
          "is_advanced": true,
          "kind": "scalar",
          "name": "allow_auto_topic_creation",
          "type": "bool"
        },
        {
          "default": "10s",
          "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
          "is_advanced": true,
          "kind": "scalar",
          "name": "timeout",
          "type": "string"
        },
        {
          "default": "1MiB",
          "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
          "examples": [
            "100MB",
            "50mib"
          ],
          "is_advanced": true,
          "kind": "scalar",
          "name": "max_message_bytes",
          "type": "string"
        },
        {
          "default": "100MiB",
          "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
          "examples": [
            "128MB",
            "50mib"
          ],
          "is_advanced": true,
          "kind": "scalar",
          "name": "broker_write_max_bytes",
          "type": "string"
        }
      ],
      "kind": "scalar",
      "name": "redpanda",
      "type": "object"
    }
  ],
  "inputs": [
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. The first URL to successfully establish a connection will be used until the connection is closed. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "amqp://guest:guest@127.0.0.1:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/,amqp://127.0.0.2:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/",
                "amqp://127.0.0.2:5672/"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string",
            "version": "3.58.0"
          },
          {
            "description": "An AMQP queue to consume from.",
            "kind": "scalar",
            "name": "queue",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to enable queue declaration.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": true,
                "description": "Whether the declared queue is durable.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "durable",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether the declared queue will auto-delete.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "auto_delete",
                "type": "bool"
              },
              {
                "description": "\nOptional arguments specific to the server's implementation of the queue that can be sent for queue types which require extra parameters.\n\n== Arguments\n\n- x-queue-type\n\nIs used to declare quorum and stream queues. Accepted values are: 'classic' (default), 'quorum', 'stream', 'drop-head', 'reject-publish' and 'reject-publish-dlx'.\n\n- x-max-length\n\nMaximum number of messages, is a non-negative integer value.\n\n- x-max-length-bytes\n\nMaximum number of messages, is a non-negative integer value.\n\n- x-overflow\n\nSets overflow behaviour. Possible values are: 'drop-head' (default), 'reject-publish', 'reject-publish-dlx'.\n\n- x-message-ttl\n\nTTL period in milliseconds. Must be a string representation of the number.\n\n- x-expires\n\nExpiration policy, describes the expiration period in milliseconds. Must be a positive integer.\n\n- x-max-age\n\nControls the retention of a stream. Must be a strin, valid units: (Y, M, D, h, m, s) e.g. '7D' for a week.\n\n- x-stream-max-segment-size-bytes\n\nControls the size of the segment files on disk (default 500000000). Must be a positive integer.\n\n- x-queue-version\n\ndeclares the Classic Queue version to use. Expects an integer, either 1 or 2.\n\n- x-consumer-timeout\n\nInteger specified in milliseconds.\n\n- x-single-active-consumer\n\nEnables Single Active Consumer, Expects a Boolean.\n\nSee https://github.com/rabbitmq/amqp091-go/blob/b3d409fe92c34bea04d8123a136384c85e8dc431/types.go#L282-L362 for more information on available arguments.",
                "examples": [
                  {
                    "x-max-length": 1000,
                    "x-max-length-bytes": 4096,
                    "x-queue-type": "quorum"
                  }
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "arguments",
                "type": "string"
              }
            ],
            "description": "Allows you to passively declare the target queue. If the queue already exists then the declaration passively verifies that they match the target fields.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "queue_declare",
            "type": "object"
          },
          {
            "children": [
              {
                "default": "",
                "description": "The exchange of the declared binding.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "exchange",
                "type": "string"
              },
              {
                "default": "",
                "description": "The key of the declared binding.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "key",
                "type": "string"
              }
            ],
            "description": "Allows you to passively declare bindings for the target queue.",
            "examples": [
              [
                {
                  "exchange": "foo",
                  "key": "bar"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "bindings_declare",
            "type": "object"
          },
          {
            "default": "",
            "description": "A consumer tag.",
            "kind": "scalar",
            "name": "consumer_tag",
            "type": "string"
          },
          {
            "default": false,
            "description": "Acknowledge messages automatically as they are consumed rather than waiting for acknowledgments from downstream. This can improve throughput and prevent the pipeline from blocking but at the cost of eliminating delivery guarantees.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auto_ack",
            "type": "bool"
          },
          {
            "default": [],
            "description": "A list of regular expression patterns whereby if a message that has failed to be delivered by Redpanda Connect has an error that matches it will be dropped (or delivered to a dead-letter queue if one exists). By default failed messages are nacked with requeue enabled.",
            "examples": [
              [
                "^reject me please:.+$"
              ]
            ],
            "is_advanced": true,
            "kind": "array",
            "name": "nack_reject_patterns",
            "type": "string",
            "version": "3.64.0"
          },
          {
            "default": 10,
            "description": "The maximum number of pending messages to have consumed at a time.",
            "kind": "scalar",
            "name": "prefetch_count",
            "type": "int"
          },
          {
            "default": 0,
            "description": "The maximum amount of pending messages measured in bytes to have consumed at a time.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "prefetch_size",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nTLS is automatic when connecting to an `amqps` URL, but custom settings can be enabled in the `tls` section.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- amqp_content_type\n- amqp_content_encoding\n- amqp_delivery_mode\n- amqp_priority\n- amqp_correlation_id\n- amqp_reply_to\n- amqp_expiration\n- amqp_message_id\n- amqp_timestamp\n- amqp_type\n- amqp_user_id\n- amqp_app_id\n- amqp_consumer_tag\n- amqp_delivery_tag\n- amqp_redelivered\n- amqp_exchange\n- amqp_routing_key\n- All existing message headers, including nested headers prefixed with the key of their respective parent.\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolations].",
      "name": "amqp_0_9",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to an AMQP (0.91) queue. AMQP is a messaging protocol used by various message brokers, including RabbitMQ.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A URL to connect to.",
            "examples": [
              "amqp://localhost:5672/",
              "amqps://guest:guest@localhost:5672/"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "A list of URLs to connect to. The first URL to successfully establish a connection will be used until the connection is closed. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "amqp://guest:guest@127.0.0.1:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/,amqp://127.0.0.2:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/",
                "amqp://127.0.0.2:5672/"
              ]
            ],
            "is_optional": true,
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string",
            "version": "4.23.0"
          },
          {
            "description": "The source address to consume from.",
            "examples": [
              "/foo",
              "queue:/bar",
              "topic:/baz"
            ],
            "kind": "scalar",
            "name": "source_address",
            "type": "string"
          },
          {
            "default": false,
            "description": "Experimental: Azure service bus specific option to renew lock if processing takes more then configured lock time",
            "is_advanced": true,
            "kind": "scalar",
            "name": "azure_renew_lock",
            "type": "bool",
            "version": "3.45.0"
          },
          {
            "default": false,
            "description": "Read additional message header fields into `amqp_*` metadata properties.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "read_header",
            "type": "bool",
            "version": "4.25.0"
          },
          {
            "default": 64,
            "description": "Specifies the maximum number of unacknowledged messages the sender can transmit. Once this limit is reached, no more messages will arrive until messages are acknowledged and settled.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this < 1 { [ \"credit must be at least 1\" ] }",
            "name": "credit",
            "type": "int",
            "version": "4.26.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "anonymous",
                    "Anonymous SASL authentication."
                  ],
                  [
                    "none",
                    "No SASL based authentication."
                  ],
                  [
                    "plain",
                    "Plain text SASL authentication."
                  ]
                ],
                "default": "none",
                "description": "The SASL authentication mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"anonymous\": true,\n  \"none\": true,\n  \"plain\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A SASL plain text username. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${USER}"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "user",
                "type": "string"
              },
              {
                "default": "",
                "description": "A SASL plain text password. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${PASSWORD}"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Enables SASL authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "sasl",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "\nroot = if this.url.or(\"\") == \"\" && this.urls.or([]).length() == 0 {\n  \"field 'urls' must be set\"\n}\n",
        "name": "",
        "type": "object"
      },
      "description": "== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- amqp_content_type\n- amqp_content_encoding\n- amqp_creation_time\n- All string typed message annotations\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\nBy setting `read_header` to `true`, additional message header properties will be added to each message:\n\n```text\n- amqp_durable\n- amqp_priority\n- amqp_ttl\n- amqp_first_acquirer\n- amqp_delivery_count\n```\n\n== Performance\n\nThis input benefits from receiving multiple messages in flight in parallel for improved performance.\nYou can tune the max number of in flight messages with the field `credit`.\n",
      "name": "amqp_1",
      "plugin": true,
      "status": "stable",
      "summary": "Reads messages from an AMQP (1.0) server.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "One or more Kinesis data streams to consume from. Streams can either be specified by their name or full ARN. Shards of a stream are automatically balanced across consumers by coordinating through the provided DynamoDB table. Multiple comma separated streams can be listed in a single element. Shards are automatically distributed across consumers of a stream by coordinating through the provided DynamoDB table. Alternatively, it's possible to specify an explicit shard to consume from with a colon after the stream name, e.g. `foo:0` would consume the shard `0` of the stream `foo`.",
            "examples": [
              [
                "foo",
                "arn:aws:kinesis:*:111122223333:stream/my-stream"
              ]
            ],
            "kind": "array",
            "name": "streams",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "The name of the table to access.",
                "kind": "scalar",
                "name": "table",
                "type": "string"
              },
              {
                "default": false,
                "description": "Whether, if the table does not exist, it should be created.",
                "kind": "scalar",
                "name": "create",
                "type": "bool"
              },
              {
                "default": "PAY_PER_REQUEST",
                "description": "When creating the table determines the billing mode.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"provisioned\": true,\n  \"pay_per_request\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "billing_mode",
                "options": [
                  "PROVISIONED",
                  "PAY_PER_REQUEST"
                ],
                "type": "string"
              },
              {
                "default": 0,
                "description": "Set the provisioned read capacity when creating the table with a `billing_mode` of `PROVISIONED`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "read_capacity_units",
                "type": "int"
              },
              {
                "default": 0,
                "description": "Set the provisioned write capacity when creating the table with a `billing_mode` of `PROVISIONED`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "write_capacity_units",
                "type": "int"
              },
              {
                "description": "The AWS region to target.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "region",
                "type": "string"
              },
              {
                "description": "Allows you to specify a custom endpoint for the AWS API.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "endpoint",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "A profile from `~/.aws/credentials` to use.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "profile",
                    "type": "string"
                  },
                  {
                    "description": "The ID of credentials to use.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "id",
                    "type": "string"
                  },
                  {
                    "description": "The secret for the credentials being used.",
                    "is_advanced": true,
                    "is_optional": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "secret",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "description": "The token for the credentials being used, required when using short term credentials.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "token",
                    "type": "string"
                  },
                  {
                    "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "from_ec2_role",
                    "type": "bool",
                    "version": "4.2.0"
                  },
                  {
                    "description": "A role ARN to assume.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "role",
                    "type": "string"
                  },
                  {
                    "description": "An external ID to provide when assuming a role.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "role_external_id",
                    "type": "string"
                  }
                ],
                "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "credentials",
                "type": "object"
              }
            ],
            "description": "Determines the table used for storing and accessing the latest consumed sequence for shards, and for coordinating balanced consumers of streams.",
            "kind": "scalar",
            "name": "dynamodb",
            "type": "object"
          },
          {
            "default": 1024,
            "description": "The maximum gap between the in flight sequence versus the latest acknowledged sequence at a given time. Increasing this limit enables parallel processing and batching at the output level to work on individual shards. Any given sequence will not be committed unless all messages under that offset are delivered in order to preserve at least once delivery guarantees.",
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": "5s",
            "description": "The period of time between each update to the checkpoint table.",
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": "2s",
            "description": "Determines how long beyond the next commit period a client will wait when stealing a shard for the current owner to store a checkpoint. A longer value increases the time taken to balance shards but reduces the likelihood of processing duplicate messages.",
            "kind": "scalar",
            "name": "steal_grace_period",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The period of time between each attempt to rebalance shards across clients.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rebalance_period",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The period of time after which a client that has failed to update a shard checkpoint is assumed to be inactive.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "lease_period",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether to consume from the oldest message when a sequence does not yet exist for the stream.",
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nConsumes messages from one or more Kinesis streams either by automatically balancing shards across other instances of this input, or by consuming shards listed explicitly. The latest message sequence consumed by this input is stored within a <<table-schema,DynamoDB table>>, which allows it to resume at the correct sequence of the shard during restarts. This table is also used for coordination across distributed inputs when shard balancing.\n\nRedpanda Connect will not store a consumed sequence unless it is acknowledged at the output level, which ensures at-least-once delivery guarantees.\n\n== Ordering\n\nBy default messages of a shard can be processed in parallel, up to a limit determined by the field `checkpoint_limit`. However, if strict ordered processing is required then this value must be set to 1 in order to process shard messages in lock-step. When doing so it is recommended that you perform batching at this component for performance as it will not be possible to batch lock-stepped messages at the output level.\n\n== Table schema\n\nIt's possible to configure Redpanda Connect to create the DynamoDB table required for coordination if it does not already exist. However, if you wish to create this yourself (recommended) then create a table with a string HASH key `StreamID` and a string RANGE key `ShardID`.\n\n== Batching\n\nUse the `batching` fields to configure an optional xref:configuration:batching.adoc#batch-policy[batching policy]. Each stream shard will be batched separately in order to ensure that acknowledgements aren't contaminated.\n",
      "name": "aws_kinesis",
      "plugin": true,
      "status": "stable",
      "summary": "Receive messages from one or more Kinesis streams.",
      "type": "input",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The bucket to consume from. If the field `sqs.url` is specified this field is optional.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional path prefix, if set only objects with the prefix are consumed when walking a bucket.",
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": false,
            "description": "Forces the client API to use path style URLs for downloading keys, which is often required when connecting to custom endpoints.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "force_path_style_urls",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to delete downloaded objects from the bucket once they are processed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_objects",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "to_the_end": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          },
          {
            "children": [
              {
                "default": "",
                "description": "An optional SQS URL to connect to. When specified this queue will control which objects are downloaded.",
                "kind": "scalar",
                "name": "url",
                "type": "string"
              },
              {
                "default": "",
                "description": "A custom endpoint to use when connecting to SQS.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "endpoint",
                "type": "string"
              },
              {
                "default": "Records.*.s3.object.key",
                "description": "A xref:configuration:field_paths.adoc[dot path] whereby object keys are found in SQS messages.",
                "kind": "scalar",
                "name": "key_path",
                "type": "string"
              },
              {
                "default": "Records.*.s3.bucket.name",
                "description": "A xref:configuration:field_paths.adoc[dot path] whereby the bucket name can be found in SQS messages.",
                "kind": "scalar",
                "name": "bucket_path",
                "type": "string"
              },
              {
                "default": "",
                "description": "A xref:configuration:field_paths.adoc[dot path] of a field to extract an enveloped JSON payload for further extracting the key and bucket from SQS messages. This is specifically useful when subscribing an SQS queue to an SNS topic that receives bucket events.",
                "examples": [
                  "Message"
                ],
                "kind": "scalar",
                "name": "envelope_path",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional period of time to wait from when a notification was originally sent to when the target key download is attempted.",
                "examples": [
                  "10s",
                  "5m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "delay_period",
                "type": "string"
              },
              {
                "default": 10,
                "description": "The maximum number of SQS messages to consume from each request.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_messages",
                "type": "int"
              },
              {
                "default": 0,
                "description": "Whether to set the wait time. Enabling this activates long-polling. Valid values: 0 to 20.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "wait_time_seconds",
                "type": "int"
              }
            ],
            "description": "Consume SQS messages in order to trigger key downloads.",
            "is_optional": true,
            "kind": "scalar",
            "name": "sqs",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Stream objects on upload with SQS\n\nA common pattern for consuming S3 objects is to emit upload notification events from the bucket either directly to an SQS queue, or to an SNS topic that is consumed by an SQS queue, and then have your consumer listen for events which prompt it to download the newly uploaded objects. More information about this pattern and how to set it up can be found at in the https://docs.aws.amazon.com/AmazonS3/latest/dev/ways-to-add-notification-config-to-bucket.html[Amazon S3 docs].\n\nRedpanda Connect is able to follow this pattern when you configure an `sqs.url`, where it consumes events from SQS and only downloads object keys received within those events. In order for this to work Redpanda Connect needs to know where within the event the key and bucket names can be found, specified as xref:configuration:field_paths.adoc[dot paths] with the fields `sqs.key_path` and `sqs.bucket_path`. The default values for these fields should already be correct when following the guide above.\n\nIf your notification events are being routed to SQS via an SNS topic then the events will be enveloped by SNS, in which case you also need to specify the field `sqs.envelope_path`, which in the case of SNS to SQS will usually be `Message`.\n\nWhen using SQS please make sure you have sensible values for `sqs.max_messages` and also the visibility timeout of the queue itself. When Redpanda Connect consumes an S3 object the SQS message that triggered it is not deleted until the S3 object has been sent onwards. This ensures at-least-once crash resiliency, but also means that if the S3 object takes longer to process than the visibility timeout of your queue then the same objects might be processed multiple times.\n\n== Download large files\n\nWhen downloading large files it's often necessary to process it in streamed parts in order to avoid loading the entire file in memory at a given time. In order to do this a <<scanner, `scanner`>> can be specified that determines how to break the input into smaller individual messages.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more  in xref:guides:cloud/aws.adoc[].\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- s3_key\n- s3_bucket\n- s3_last_modified_unix\n- s3_last_modified (RFC3339)\n- s3_content_type\n- s3_content_encoding\n- s3_version_id\n- All user defined metadata\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation]. Note that user defined metadata is case insensitive within AWS, and it is likely that the keys will be received in a capitalized form, if you wish to make them consistent you can map all metadata keys to lower or uppercase using a Bloblang mapping such as `meta = meta().map_each_key(key -> key.lowercase())`.",
      "name": "aws_s3",
      "plugin": true,
      "status": "stable",
      "summary": "Downloads objects within an Amazon S3 bucket, optionally filtered by a prefix, either by walking the items in the bucket or by streaming upload notifications in realtime.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The SQS URL to consume from.",
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether to delete the consumed message once it is acked. Disabling allows you to handle the deletion using a different mechanism.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_message",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether to set the visibility timeout of the consumed message to zero once it is nacked. Disabling honors the preset visibility timeout specified for the queue.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "reset_visibility",
            "type": "bool",
            "version": "3.58.0"
          },
          {
            "default": 10,
            "description": "The maximum number of messages to return on one poll. Valid values: 1 to 10.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_number_of_messages",
            "type": "int"
          },
          {
            "default": 1000,
            "description": "The maximum number of outstanding pending messages to be consumed at a given time.",
            "kind": "scalar",
            "name": "max_outstanding_messages",
            "type": "int"
          },
          {
            "default": 0,
            "description": "Whether to set the wait time. Enabling this activates long-polling. Valid values: 0 to 20.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "wait_time_seconds",
            "type": "int"
          },
          {
            "default": "30s",
            "description": "The time to process messages before needing to refresh the receipt handle. Messages will be eligible for refresh when half of the timeout has elapsed. This sets MessageVisibility for each received message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "message_timeout",
            "type": "string"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS\nservices. It's also possible to set them explicitly at the component level,\nallowing you to transfer data across accounts. You can find out more in\nxref:guides:cloud/aws.adoc[].\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- sqs_message_id\n- sqs_receipt_handle\n- sqs_approximate_receive_count\n- All message attributes\n\nYou can access these metadata fields using\nxref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "aws_sqs",
      "plugin": true,
      "status": "stable",
      "summary": "Consume messages from an AWS SQS URL.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The name of the container from which to download blobs.",
            "interpolated": true,
            "kind": "scalar",
            "name": "container",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional path prefix, if set only objects with the prefix are consumed.",
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "to_the_end": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          },
          {
            "default": false,
            "description": "Whether to delete downloaded objects from the blob once they are processed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_objects",
            "type": "bool"
          },
          {
            "description": "EXPERIMENTAL: An optional source of download targets, configured as a xref:components:inputs/about.adoc[regular Redpanda Connect input]. Each message yielded by this input should be a single structured object containing a field `name`, which represents the blob to be downloaded.",
            "examples": [
              {
                "mqtt": {
                  "topics": [
                    "some-topic"
                  ],
                  "urls": [
                    "example.westeurope-1.ts.eventgrid.azure.net:8883"
                  ]
                },
                "processors": [
                  {
                    "unarchive": {
                      "format": "json_array"
                    }
                  },
                  {
                    "mapping": "if this.eventType == \"Microsoft.Storage.BlobCreated\" {\n  root.name = this.data.url.parse_url().path.trim_prefix(\"/foocontainer/\")\n} else {\n  root = deleted()\n}"
                  }
                ]
              }
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "targets_input",
            "type": "input",
            "version": "4.27.0"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nSupports multiple authentication methods but only one of the following is required:\n\n- `storage_connection_string`\n- `storage_account` and `storage_access_key`\n- `storage_account` and `storage_sas_token`\n- `storage_account` to access via https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n\nIf multiple are set then the `storage_connection_string` is given priority.\n\nIf the `storage_connection_string` does not contain the `AccountName` parameter, please specify it in the\n`storage_account` field.\n\n== Download large files\n\nWhen downloading large files it's often necessary to process it in streamed parts in order to avoid loading the entire file in memory at a given time. In order to do this a <<scanner, `scanner`>> can be specified that determines how to break the input into smaller individual messages.\n\n== Stream new files\n\nBy default this input will consume all files found within the target container and will then gracefully terminate. This is referred to as a \"batch\" mode of operation. However, it's possible to instead configure a container as https://learn.microsoft.com/en-gb/azure/event-grid/event-schema-blob-storage[an Event Grid source^] and then use this as a <<targetsinput, `targets_input`>>, in which case new files are consumed as they're uploaded and Redpanda Connect will continue listening for and downloading files as they arrive. This is referred to as a \"streamed\" mode of operation.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- blob_storage_key\n- blob_storage_container\n- blob_storage_last_modified\n- blob_storage_last_modified_unix\n- blob_storage_content_type\n- blob_storage_content_encoding\n- All user defined metadata\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "azure_blob_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Downloads objects within an Azure Blob Storage container, optionally filtered by a prefix.",
      "type": "input",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Azure"
      ],
      "config": {
        "children": [
          {
            "description": "CosmosDB endpoint.",
            "examples": [
              "https://localhost:8081"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "description": "Account key.",
            "examples": [
              "C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw=="
            ],
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "account_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Connection string.",
            "examples": [
              "AccountEndpoint=https://localhost:8081/;AccountKey=C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==;"
            ],
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "connection_string",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Database.",
            "examples": [
              "testdb"
            ],
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "description": "Container.",
            "examples": [
              "testcontainer"
            ],
            "kind": "scalar",
            "name": "container",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a single partition key value or an array of partition key values of type string, integer or boolean. Currently, hierarchical partition keys are not supported so only one value may be provided.",
            "examples": [
              "root = \"blobfish\"",
              "root = 41",
              "root = true",
              "root = null",
              "root = now().ts_format(\"2006-01-02\")"
            ],
            "kind": "scalar",
            "name": "partition_keys_map",
            "type": "string"
          },
          {
            "description": "The query to execute",
            "examples": [
              "SELECT c.foo FROM testcontainer AS c WHERE c.bar = \"baz\" AND c.timestamp < @timestamp"
            ],
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that, for each message, creates a list of arguments to use with the query.",
            "examples": [
              "root = [\n  { \"Name\": \"@name\", \"Value\": \"benthos\" },\n]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "default": -1,
            "description": "The maximum number of messages that should be accumulated into each batch. Use '-1' specify dynamic page size.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this < -1 || this == 0 || this > 2147483647 { [ \"batch_count must be must be > 0 and smaller than 2147483647 or -1.\" ] }",
            "name": "batch_count",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "linter": "root = []\nlet hasEndpoint = this.endpoint.or(\"\") != \"\"\nlet hasConnectionString = this.connection_string.or(\"\") != \"\"\n\nroot.\"-\" = if !$hasEndpoint && !$hasConnectionString {\n  \"Either `endpoint` or `connection_string` must be set.\"\n}\n",
        "name": "",
        "type": "object"
      },
      "description": "\n== Cross-partition queries\n\nCross-partition queries are currently not supported by the underlying driver. For every query, the PartitionKey values must be known in advance and specified in the config. https://github.com/Azure/azure-sdk-for-go/issues/18578#issuecomment-1222510989[See details^].\n\n\n== Credentials\n\nYou can use one of the following authentication mechanisms:\n\n- Set the `endpoint` field and the `account_key` field\n- Set only the `endpoint` field to use https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n- Set the `connection_string` field\n\n\n== Metadata\n\nThis component adds the following metadata fields to each message:\n```\n- activity_id\n- request_charge\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n",
      "examples": [
        {
          "config": "\ninput:\n  azure_cosmosdb:\n    endpoint: http://localhost:8080\n    account_key: C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==\n    database: blobbase\n    container: blobfish\n    partition_keys_map: root = \"AbyssalPlain\"\n    query: SELECT * FROM blobfish AS b WHERE b.species = @species\n    args_mapping: |\n      root = [\n          { \"Name\": \"@species\", \"Value\": \"smooth-head\" },\n      ]\n",
          "summary": "Execute a parametrized SQL query to select documents from a container.",
          "title": "Query container"
        }
      ],
      "footnotes": "\n\n== CosmosDB emulator\n\nIf you wish to run the CosmosDB emulator that is referenced in the documentation https://learn.microsoft.com/en-us/azure/cosmos-db/linux-emulator[here^], the following Docker command should do the trick:\n\n```bash\n> docker run --rm -it -p 8081:8081 --name=cosmosdb -e AZURE_COSMOS_EMULATOR_PARTITION_COUNT=10 -e AZURE_COSMOS_EMULATOR_ENABLE_DATA_PERSISTENCE=false mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator\n```\n\nNote: `AZURE_COSMOS_EMULATOR_PARTITION_COUNT` controls the number of partitions that will be supported by the emulator. The bigger the value, the longer it takes for the container to start up.\n\nAdditionally, instead of installing the container self-signed certificate which is exposed via `https://localhost:8081/_explorer/emulator.pem`, you can run https://mitmproxy.org/[mitmproxy^] like so:\n\n```bash\n> mitmproxy -k --mode \"reverse:https://localhost:8081\"\n```\n\nThen you can access the CosmosDB UI via `http://localhost:8080/_explorer/index.html` and use `http://localhost:8080` as the CosmosDB endpoint.\n",
      "name": "azure_cosmosdb",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a SQL query against https://learn.microsoft.com/en-us/azure/cosmos-db/introduction[Azure CosmosDB^] and creates a batch of messages from each page of items.",
      "type": "input",
      "version": "v4.25.0"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The name of the source storage queue.",
            "examples": [
              "foo_queue",
              "${! env(\"MESSAGE_TYPE\").lowercase() }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "queue_name",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The timeout duration until a dequeued message gets visible again, 30s by default",
            "is_advanced": true,
            "kind": "scalar",
            "name": "dequeue_visibility_timeout",
            "type": "string",
            "version": "3.45.0"
          },
          {
            "default": 10,
            "description": "The maximum number of unprocessed messages to fetch at a given time.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": false,
            "description": "If set to `true` the queue is polled on each read request for information such as the queue message lag. These properties are added to consumed messages as metadata, but will also have a negative performance impact.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "track_properties",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nThis input adds the following metadata fields to each message:\n\n```\n- queue_storage_insertion_time\n- queue_storage_queue_name\n- queue_storage_message_lag (if 'track_properties' set to true)\n- All user defined queue metadata\n```\n\nOnly one authentication method is required, `storage_connection_string` or `storage_account` and `storage_access_key`. If both are set then the `storage_connection_string` is given priority.",
      "name": "azure_queue_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Dequeue objects from an Azure Storage Queue.",
      "type": "input",
      "version": "3.42.0"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The table to read messages from.",
            "examples": [
              "Foo"
            ],
            "kind": "scalar",
            "name": "table_name",
            "type": "string"
          },
          {
            "default": "",
            "description": "OData filter expression. Is not set all rows are returned. Valid operators are `eq, ne, gt, lt, ge and le`",
            "examples": [
              "PartitionKey eq 'foo' and RowKey gt '1000'"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "filter",
            "type": "string"
          },
          {
            "default": "",
            "description": "Select expression using OData notation. Limits the columns on each record to just those requested.",
            "examples": [
              "PartitionKey,RowKey,Foo,Bar,Timestamp"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "select",
            "type": "string"
          },
          {
            "default": 1000,
            "description": "Maximum number of records to return on each page.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "page_size",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nQueries an Azure Storage Account Table, optionally with multiple filters.\n== Metadata\nThis input adds the following metadata fields to each message:\n\n- table_storage_name\n- row_num\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "azure_table_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Queries an Azure Storage Account Table, optionally with multiple filters.",
      "type": "input",
      "version": "4.10.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The child input.",
            "kind": "scalar",
            "name": "child",
            "type": "input"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "policy",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Batching at the input level is sometimes useful for processing across micro-batches, and can also sometimes be a useful performance trick. However, most inputs are fine without it so unless you have a specific plan for batching this component is not worth using.",
      "name": "batched",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes data from a child input and applies a batching policy to the stream.",
      "type": "input",
      "version": "4.11.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "An address to connect to.",
            "examples": [
              "127.0.0.1:11300"
            ],
            "kind": "scalar",
            "name": "address",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "beanstalkd",
      "plugin": true,
      "status": "experimental",
      "summary": "Reads messages from a Beanstalkd queue.",
      "type": "input",
      "version": "4.7.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": 1,
            "description": "Whatever is specified within `inputs` will be created this many times.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "copies",
            "type": "int"
          },
          {
            "description": "A list of inputs to create.",
            "kind": "array",
            "name": "inputs",
            "type": "input"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nA broker type is configured with its own list of input configurations and a field to specify how many copies of the list of inputs should be created.\n\nAdding more input types allows you to combine streams from multiple sources into one. For example, reading from both RabbitMQ and Kafka:\n\n```yaml\ninput:\n  broker:\n    copies: 1\n    inputs:\n      - amqp_0_9:\n          urls:\n            - amqp://guest:guest@localhost:5672/\n          consumer_tag: benthos-consumer\n          queue: benthos-queue\n\n        # Optional list of input specific processing steps\n        processors:\n          - mapping: |\n              root.message = this\n              root.meta.link_count = this.links.length()\n              root.user.age = this.user.age.number()\n\n      - kafka:\n          addresses:\n            - localhost:9092\n          client_id: benthos_kafka_input\n          consumer_group: benthos_consumer_group\n          topics: [ benthos_stream:0 ]\n```\n\nIf the number of copies is greater than zero the list will be copied that number of times. For example, if your inputs were of type foo and bar, with 'copies' set to '2', you would end up with two 'foo' inputs and two 'bar' inputs.\n\n== Batching\n\nIt's possible to configure a xref:configuration:batching.adoc#batch-policy[batch policy] with a broker using the `batching` fields. When doing this the feeds from all child inputs are combined. Some inputs do not support broker based batching and specify this in their documentation.\n\n== Processors\n\nIt is possible to configure xref:components:processors/about.adoc[processors] at the broker level, where they will be applied to _all_ child inputs, as well as on the individual child inputs. If you have processors at both the broker level _and_ on child inputs then the broker processors will be applied _after_ the child nodes processors.",
      "name": "broker",
      "plugin": true,
      "status": "stable",
      "summary": "Allows you to combine multiple inputs into a single stream of data, where each input will be read in parallel.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of Cassandra nodes to connect to. Multiple comma separated addresses can be specified on a single line.",
            "examples": [
              [
                "localhost:9042"
              ],
              [
                "foo:9042",
                "bar:9042"
              ],
              [
                "foo:9042,bar:9042"
              ]
            ],
            "kind": "array",
            "name": "addresses",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use password authentication",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "The username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "The password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of Cassandra authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "password_authenticator",
            "type": "object"
          },
          {
            "default": false,
            "description": "If enabled the driver will not attempt to get host info from the system.peers table. This can speed up queries but will mean that data_centre, rack and token information will not be available.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "disable_initial_host_lookup",
            "type": "bool"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before giving up on a request.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          },
          {
            "default": "600ms",
            "description": "The client connection timeout.",
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The local DC to use, enables DC aware policy.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "local_dc",
                "type": "string"
              },
              {
                "description": "The local rack to use, requires local_dc to be set, enables rack aware policy.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "local_rack",
                "type": "string"
              }
            ],
            "description": "Optional host selection policy configurations. Highly recommended in deployments with multiple DCs. Host selection is always token aware if the token can be calculated from query. By default the underlying policy is round robin over all nodes. Users can specify a local DC and rack to use for the DC Aware & Rack Aware policies. ",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this.local_rack != \"\" && (!this.exists(\"local_dc\") || this.local_dc == \"\") { \"local_dc must be set if local_rack is set\" }",
            "name": "host_selection_policy",
            "type": "object"
          },
          {
            "description": "A query to execute.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\ninput:\n  cassandra:\n    addresses:\n      - 172.17.0.2\n    query:\n      'SELECT * FROM learn_cassandra.users_by_country'\n",
          "summary": "\nLet's presume that we have 3 Cassandra nodes, like in this tutorial by Sebastian Sigl from freeCodeCamp:\n\nhttps://www.freecodecamp.org/news/the-apache-cassandra-beginner-tutorial/\n\nThen if we want to select everything from the table users_by_country, we should use the configuration below.\nIf we specify the stdin output, the result will look like:\n\n```json\n{\"age\":23,\"country\":\"UK\",\"first_name\":\"Bob\",\"last_name\":\"Sandler\",\"user_email\":\"bob@email.com\"}\n```\n\nThis configuration also works for Scylla.\n",
          "title": "Minimal Select (Cassandra/Scylla)"
        }
      ],
      "name": "cassandra",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a find query and creates a message for each row received.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A Data Source Name to identify the target database.",
            "examples": [
              "postgres://user:password@example.com:26257/defaultdb?sslmode=require"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "CSV of tables to be included in the changefeed",
            "examples": [
              [
                "table1",
                "table2"
              ]
            ],
            "kind": "array",
            "name": "tables",
            "type": "string"
          },
          {
            "description": "A https://docs.redpanda.com/redpanda-connect/components/caches/about[cache resource^] to use for storing the current latest cursor that has been successfully delivered, this allows Redpanda Connect to continue from that cursor upon restart, rather than consume the entire state of the table.",
            "is_optional": true,
            "kind": "scalar",
            "name": "cursor_cache",
            "type": "string"
          },
          {
            "description": "A list of options to be included in the changefeed (WITH X, Y...).\n\nNOTE: Both the CURSOR option and UPDATED will be ignored from these options when a `cursor_cache` is specified, as they are set explicitly by Redpanda Connect in this case.",
            "examples": [
              [
                "virtual_columns=\"omitted\""
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "options",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This input will continue to listen to the changefeed until shutdown. A backfill of the full current state of the table will be delivered upon each run unless a cache is configured for storing cursor timestamps, as this is how Redpanda Connect keeps track as to which changes have been successfully delivered.\n\nNote: You must have `SET CLUSTER SETTING kv.rangefeed.enabled = true;` on your CRDB cluster, for more information refer to https://www.cockroachlabs.com/docs/stable/changefeed-examples?filters=core[the official CockroachDB documentation^].",
      "name": "cockroachdb_changefeed",
      "plugin": true,
      "status": "experimental",
      "summary": "Listens to a https://www.cockroachlabs.com/docs/stable/changefeed-examples[CockroachDB Core Changefeed^] and creates a message for each row received. Each message is a json object looking like: \n```json\n{\n\t\"primary_key\": \"[\\\"1a7ff641-3e3b-47ee-94fe-a0cadb56cd8f\\\", 2]\", // stringifed JSON array\n\t\"row\": \"{\\\"after\\\": {\\\"k\\\": \\\"1a7ff641-3e3b-47ee-94fe-a0cadb56cd8f\\\", \\\"v\\\": 2}, \\\"updated\\\": \\\"1637953249519902405.0000000000\\\"}\", // stringified JSON object\n\t\"table\": \"strm_2\"\n}\n```",
      "type": "input"
    },
    {
      "categories": [
        "Local"
      ],
      "config": {
        "children": [
          {
            "description": "A list of file paths to read from. Each file will be read sequentially until the list is exhausted, at which point the input will close. Glob patterns are supported, including super globs (double star).",
            "examples": [
              [
                "/tmp/foo.csv",
                "/tmp/bar/*.csv",
                "/tmp/data/**/*.csv"
              ]
            ],
            "kind": "array",
            "name": "paths",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether to reference the first row as a header row. If set to true the output structure for messages will be an object where field keys are determined by the header row. Otherwise, each message will consist of an array of values from the corresponding CSV row.",
            "kind": "scalar",
            "name": "parse_header_row",
            "type": "bool"
          },
          {
            "default": ",",
            "description": "The delimiter to use for splitting values in each record. It must be a single character.",
            "kind": "scalar",
            "name": "delimiter",
            "type": "string"
          },
          {
            "default": false,
            "description": "If set to `true`, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field.",
            "kind": "scalar",
            "name": "lazy_quotes",
            "type": "bool",
            "version": "4.1.0"
          },
          {
            "default": false,
            "description": "Whether to delete input files from the disk once they are fully consumed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_on_finish",
            "type": "bool"
          },
          {
            "default": 1,
            "description": "Optionally process records in batches. This can help to speed up the consumption of exceptionally large CSV files. When the end of the file is reached the remaining records are processed as a (potentially smaller) batch.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "batch_count",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis input offers more control over CSV parsing than the xref:components:inputs/file.adoc[`file` input].\n\nWhen parsing with a header row each line of the file will be consumed as a structured object, where the key names are determined from the header now. For example, the following CSV file:\n\n```csv\nfoo,bar,baz\nfirst foo,first bar,first baz\nsecond foo,second bar,second baz\n```\n\nWould produce the following messages:\n\n```json\n{\"foo\":\"first foo\",\"bar\":\"first bar\",\"baz\":\"first baz\"}\n{\"foo\":\"second foo\",\"bar\":\"second bar\",\"baz\":\"second baz\"}\n```\n\nIf, however, the field `parse_header_row` is set to `false` then arrays are produced instead, like follows:\n\n```json\n[\"first foo\",\"first bar\",\"first baz\"]\n[\"second foo\",\"second bar\",\"second baz\"]\n```\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- header\n- path\n- mod_time_unix\n- mod_time (RFC3339)\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\nNote: The `header` field is only set when `parse_header_row` is `true`.\n\n=== Output CSV column order\n\nWhen xref:guides:bloblang/advanced.adoc#creating-csv[creating CSV] from Redpanda Connect messages, the columns must be sorted lexicographically to make the output deterministic. Alternatively, when using the `csv` input, one can leverage the `header` metadata field to retrieve the column order:\n\n```yaml\ninput:\n  csv:\n    paths:\n      - ./foo.csv\n      - ./bar.csv\n    parse_header_row: true\n\n  processors:\n    - mapping: |\n        map escape_csv {\n          root = if this.re_match(\"[\\\"\\n,]+\") {\n            \"\\\"\" + this.replace_all(\"\\\"\", \"\\\"\\\"\") + \"\\\"\"\n          } else {\n            this\n          }\n        }\n\n        let header = if count(@path) == 1 {\n          @header.map_each(c -> c.apply(\"escape_csv\")).join(\",\") + \"\\n\"\n        } else { \"\" }\n\n        root = $header + @header.map_each(c -> this.get(c).string().apply(\"escape_csv\")).join(\",\")\n\noutput:\n  file:\n    path: ./output/${! @path.filepath_split().index(-1) }\n```\n",
      "footnotes": "This input is particularly useful when consuming CSV from files too large to parse entirely within memory. However, in cases where CSV is consumed from other input types it's also possible to parse them using the xref:guides:bloblang/methods.adoc#parse_csv[Bloblang `parse_csv` method].",
      "name": "csv",
      "plugin": true,
      "status": "stable",
      "summary": "Reads one or more CSV files as structured records following the format described in RFC 4180.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "Social"
      ],
      "config": {
        "children": [
          {
            "description": "A discord channel ID to consume messages from.",
            "kind": "scalar",
            "name": "channel_id",
            "type": "string"
          },
          {
            "description": "A bot token used for authentication.",
            "kind": "scalar",
            "name": "bot_token",
            "type": "string"
          },
          {
            "description": "A cache resource to use for performing unread message backfills, the ID of the last message received will be stored in this cache and used for subsequent requests.",
            "kind": "scalar",
            "name": "cache",
            "type": "string"
          },
          {
            "default": "last_message_id",
            "description": "The key identifier used when storing the ID of the last message received.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cache_key",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": "1m",
            "description": "The length of time (as a duration string) to wait between each poll for backlogged messages. This field can be set empty, in which case requests are made at the limit set by the rate limit. This field also supports cron expressions.",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "poll_period",
            "type": "string"
          },
          {
            "default": 100,
            "description": "The maximum number of messages to receive in a single request.",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "limit",
            "type": "int"
          },
          {
            "default": "An optional rate limit resource to restrict API requests with.",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This input works by authenticating as a bot using token based authentication. The ID of the newest message consumed and acked is stored in a cache in order to perform a backfill of unread messages each time the input is initialised. Ideally this cache should be persisted across restarts.",
      "name": "discord",
      "plugin": true,
      "status": "experimental",
      "summary": "Consumes messages posted in a Discord channel.",
      "type": "input"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": {},
            "description": "A map of inputs to statically create.",
            "kind": "map",
            "name": "inputs",
            "type": "input"
          },
          {
            "default": "",
            "description": "A path prefix for HTTP endpoints that are registered.",
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "footnotes": "\n== Endpoints\n\n=== GET `/inputs`\n\nReturns a JSON object detailing all dynamic inputs, providing information such as their current uptime and configuration.\n\n=== GET `/inputs/\\{id}`\n\nReturns the configuration of an input.\n\n=== POST `/inputs/\\{id}`\n\nCreates or updates an input with a configuration provided in the request body (in YAML or JSON format).\n\n=== DELETE `/inputs/\\{id}`\n\nStops and removes an input.\n\n=== GET `/inputs/\\{id}/uptime`\n\nReturns the uptime of an input as a duration string (of the form \"72h3m0.5s\"), or \"stopped\" in the case where the input has gracefully terminated.",
      "name": "dynamic",
      "plugin": true,
      "status": "stable",
      "summary": "A special broker type where the inputs are identified by unique labels and can be created, changed and removed during runtime via a REST HTTP interface.",
      "type": "input"
    },
    {
      "categories": [
        "Local"
      ],
      "config": {
        "children": [
          {
            "description": "A list of paths to consume sequentially. Glob patterns are supported, including super globs (double star).",
            "kind": "array",
            "name": "paths",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "lines": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          },
          {
            "default": false,
            "description": "Whether to delete input files from the disk once they are fully consumed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_on_finish",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- path\n- mod_time_unix\n- mod_time (RFC3339)\n```\n\nYou can access these metadata fields using\nxref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "examples": [
        {
          "config": "\ninput:\n  file:\n    paths: [ ./data/*.csv ]\n    scanner:\n      csv: {}\n",
          "summary": "If we wished to consume a directory of CSV files as structured documents we can use a glob pattern and the `csv` scanner:",
          "title": "Read a Bunch of CSVs"
        }
      ],
      "name": "file",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes data from files on disk, emitting messages according to a chosen codec.",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "default": "/",
            "description": "The endpoint path to listen for data delivery requests.",
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "200",
                "description": "Specify the status code to return with synchronous responses. This is a string value, which allows you to customize it based on resulting payloads and their metadata.",
                "examples": [
                  "${! json(\"status\") }",
                  "${! meta(\"status\") }"
                ],
                "interpolated": true,
                "is_advanced": true,
                "kind": "scalar",
                "name": "status",
                "type": "string"
              },
              {
                "default": {
                  "Content-Type": "application/octet-stream"
                },
                "description": "Specify headers to return with synchronous responses.",
                "interpolated": true,
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "Provide a list of explicit metadata key prefixes to match against.",
                    "examples": [
                      [
                        "foo_",
                        "bar_"
                      ],
                      [
                        "kafka_"
                      ],
                      [
                        "content-"
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "include_prefixes",
                    "type": "string"
                  },
                  {
                    "default": [],
                    "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                    "examples": [
                      [
                        ".*"
                      ],
                      [
                        "_timestamp_unix$"
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "include_patterns",
                    "type": "string"
                  }
                ],
                "description": "Specify criteria for which metadata values are added to the response as headers.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "metadata_headers",
                "type": "object"
              }
            ],
            "description": "Customize messages returned via xref:guides:sync_responses.adoc[synchronous responses].",
            "is_advanced": true,
            "kind": "scalar",
            "name": "sync_response",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe field `rate_limit` allows you to specify an optional xref:components:rate_limits/about.adoc[`rate_limit` resource], which will be applied to each HTTP request made and each websocket payload received.\n\nWhen the rate limit is breached HTTP requests will have a 429 response returned with a Retry-After header.\n\n== Responses\n\nIt's possible to return a response for each message received using xref:guides:sync_responses.adoc[synchronous responses]. When doing so you can customize headers with the `sync_response` field `headers`, which can also use xref:configuration:interpolation.adoc#bloblang-queries[function interpolation] in the value based on the response message contents.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- http_server_user_agent\n- http_server_request_path\n- http_server_verb\n- http_server_remote_ip\n- All headers (only first values are taken)\n- All query parameters\n- All path parameters\n- All cookies\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "gateway",
      "plugin": true,
      "status": "stable",
      "summary": "Receive messages delivered over HTTP.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "GCP"
      ],
      "config": {
        "children": [
          {
            "description": "GCP project where the query job will execute.",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Fully-qualified BigQuery table name to query.",
            "examples": [
              "bigquery-public-data.samples.shakespeare"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "A list of columns to query.",
            "kind": "array",
            "name": "columns",
            "type": "string"
          },
          {
            "description": "An optional where clause to add. Placeholder arguments are populated with the `args_mapping` field. Placeholders should always be question marks (`?`).",
            "examples": [
              "type = ? and created_at > ?",
              "user_id = ?"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "where",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": {},
            "description": "A list of labels to add to the query job.",
            "kind": "map",
            "name": "job_labels",
            "type": "string"
          },
          {
            "default": "",
            "description": "The priority with which to schedule the query.",
            "kind": "scalar",
            "name": "priority",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `where`.",
            "examples": [
              "root = [ \"article\", now().ts_format(\"2006-01-02\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "An optional prefix to prepend to the select query (before SELECT).",
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to the select query.",
            "is_optional": true,
            "kind": "scalar",
            "name": "suffix",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Once the rows from the query are exhausted, this input shuts down, allowing the pipeline to gracefully terminate (or the next input in a xref:components:inputs/sequence.adoc[sequence] to execute).",
      "examples": [
        {
          "config": "\ninput:\n  gcp_bigquery_select:\n    project: sample-project\n    table: bigquery-public-data.samples.shakespeare\n    columns:\n      - word\n      - sum(word_count) as total_count\n    where: length(word) >= ?\n    suffix: |\n      GROUP BY word\n      ORDER BY total_count DESC\n      LIMIT 10\n    args_mapping: |\n      root = [ 3 ]\n",
          "summary": "\nHere we query the public corpus of Shakespeare's works to generate a stream of the top 10 words that are 3 or more characters long:",
          "title": "Word counts"
        }
      ],
      "name": "gcp_bigquery_select",
      "plugin": true,
      "status": "beta",
      "summary": "Executes a `SELECT` query against BigQuery and creates a message for each row received.",
      "type": "input",
      "version": "3.63.0"
    },
    {
      "categories": [
        "Services",
        "GCP"
      ],
      "config": {
        "children": [
          {
            "description": "The name of the bucket from which to download objects.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional path prefix, if set only objects with the prefix are consumed.",
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "to_the_end": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          },
          {
            "default": false,
            "description": "Whether to delete downloaded objects from the bucket once they are processed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_objects",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```\n- gcs_key\n- gcs_bucket\n- gcs_last_modified\n- gcs_last_modified_unix\n- gcs_content_type\n- gcs_content_encoding\n- All user defined metadata\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n=== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to GCP services. You can find out more in xref:guides:cloud/gcp.adoc[].",
      "name": "gcp_cloud_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Downloads objects within a Google Cloud Storage bucket, optionally filtered by a prefix.",
      "type": "input",
      "version": "3.43.0"
    },
    {
      "categories": [
        "Services",
        "GCP"
      ],
      "config": {
        "children": [
          {
            "description": "The project ID of the target subscription.",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The target subscription ID.",
            "kind": "scalar",
            "name": "subscription",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional endpoint to override the default of `pubsub.googleapis.com:443`. This can be used to connect to a region specific pubsub endpoint. For a list of valid values, see https://cloud.google.com/pubsub/docs/reference/service_apis_overview#list_of_regional_endpoints[this document^].",
            "examples": [
              "us-central1-pubsub.googleapis.com:443",
              "us-west3-pubsub.googleapis.com:443"
            ],
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "default": false,
            "description": "Enable synchronous pull mode.",
            "kind": "scalar",
            "name": "sync",
            "type": "bool"
          },
          {
            "default": 1000,
            "description": "The maximum number of outstanding pending messages to be consumed at a given time.",
            "kind": "scalar",
            "name": "max_outstanding_messages",
            "type": "int"
          },
          {
            "default": 1000000000,
            "description": "The maximum number of outstanding pending messages to be consumed measured in bytes.",
            "kind": "scalar",
            "name": "max_outstanding_bytes",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to configure subscription or not.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "Defines the topic that the subscription should be vinculated to.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "topic",
                "type": "string"
              }
            ],
            "description": "Allows you to configure the input subscription and creates if it doesn't exist.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "create_subscription",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nFor information on how to set up credentials see https://cloud.google.com/docs/authentication/production[this guide^].\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- gcp_pubsub_publish_time_unix - The time at which the message was published to the topic.\n- gcp_pubsub_delivery_attempt - When dead lettering is enabled, this is set to the number of times PubSub has attempted to deliver a message.\n- gcp_pubsub_message_id - The unique identifier of the message.\n- gcp_pubsub_ordering_key - The ordering key of the message.\n- All message attributes\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n",
      "name": "gcp_pubsub",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes messages from a GCP Cloud Pub/Sub subscription.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "GCP"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "Base64 encoded GCP service account JSON credentials file for authentication. If not provided, Application Default Credentials (ADC) will be used.",
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials_json",
            "type": "string"
          },
          {
            "description": "GCP project ID containing the Spanner instance",
            "kind": "scalar",
            "name": "project_id",
            "type": "string"
          },
          {
            "description": "Spanner instance ID",
            "kind": "scalar",
            "name": "instance_id",
            "type": "string"
          },
          {
            "description": "Spanner database ID",
            "kind": "scalar",
            "name": "database_id",
            "type": "string"
          },
          {
            "description": "The name of the change stream to track, the stream must exist in the database. To create a change stream, see https://cloud.google.com/spanner/docs/change-streams/manage.",
            "kind": "scalar",
            "name": "stream_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "RFC3339 formatted inclusive timestamp to start reading from the change stream (default: current time)",
            "examples": [
              "2022-01-01T00:00:00Z"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "start_timestamp",
            "type": "string"
          },
          {
            "default": "",
            "description": "RFC3339 formatted exclusive timestamp to stop reading at (default: no end time)",
            "examples": [
              "2022-01-01T00:00:00Z"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "end_timestamp",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "Duration string for heartbeat interval",
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": "",
            "description": "The table to store metadata in (default: cdc_metadata_<stream_id>)",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata_table",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "Duration string for frequency of querying Spanner for minimum watermark.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "min_watermark_cache_ttl",
            "type": "string"
          },
          {
            "description": "List of modification types to process. If not specified, all modification types are processed. Allowed values: INSERT, UPDATE, DELETE",
            "examples": [
              [
                "INSERT",
                "UPDATE",
                "DELETE"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "allowed_mod_types",
            "type": "string"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nConsumes change records from a Google Cloud Spanner change stream. This input allows\nyou to track and process database changes in real-time, making it useful for data\nreplication, event-driven architectures, and maintaining derived data stores.\n\nThe input reads from a specified change stream within a Spanner database and converts\neach change record into a message. The message payload contains the change records in\nJSON format, and metadata is added with details about the Spanner instance, database,\nand stream.\n\nChange streams provide a way to track mutations to your Spanner database tables. For\nmore information about Spanner change streams, refer to the Google Cloud documentation:\nhttps://cloud.google.com/spanner/docs/change-streams\n",
      "name": "gcp_spanner_cdc",
      "plugin": true,
      "status": "beta",
      "summary": "Creates an input that consumes from a spanner change stream.",
      "type": "input",
      "version": "4.56.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang] mapping to use for generating messages.",
            "examples": [
              "root = \"hello world\"",
              "root = {\"test\":\"message\",\"id\":uuid_v4()}"
            ],
            "kind": "scalar",
            "name": "mapping",
            "type": "string"
          },
          {
            "default": "1s",
            "description": "The time interval at which messages should be generated, expressed either as a duration string or as a cron expression. If set to an empty string messages will be generated as fast as downstream services can process them. Cron expressions can specify a timezone by prefixing the expression with `TZ=<location name>`, where the location name corresponds to a file within the IANA Time Zone database.",
            "examples": [
              "5s",
              "1m",
              "1h",
              "@every 1s",
              "0,30 */2 * * * *",
              "TZ=Europe/London 30 3-6,20-23 * * *"
            ],
            "kind": "scalar",
            "name": "interval",
            "type": "string"
          },
          {
            "default": 0,
            "description": "An optional number of messages to generate, if set above 0 the specified number of messages is generated and then the input will shut down.",
            "kind": "scalar",
            "name": "count",
            "type": "int"
          },
          {
            "default": 1,
            "description": "The number of generated messages that should be accumulated into each batch flushed at the specified interval.",
            "kind": "scalar",
            "name": "batch_size",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\ninput:\n  generate:\n    interval: '@every 5m'\n    mapping: 'root = {}'\n  processors:\n    - sql_select:\n        driver: postgres\n        dsn: postgres://foouser:foopass@localhost:5432/testdb?sslmode=disable\n        table: foo\n        columns: [ \"*\" ]\n",
          "summary": "A common use case for the generate input is to trigger processors on a schedule so that the processors themselves can behave similarly to an input. The following configuration reads rows from a PostgreSQL table every 5 minutes.",
          "title": "Cron Scheduled Processing"
        },
        {
          "config": "\ninput:\n  generate:\n    count: 100\n    interval: \"\"\n    mapping: |\n      root = if random_int() % 2 == 0 {\n        {\n          \"type\": \"foo\",\n          \"foo\": \"is yummy\"\n        }\n      } else {\n        {\n          \"type\": \"bar\",\n          \"bar\": \"is gross\"\n        }\n      }\n",
          "summary": "The generate input can be used as a convenient way to generate test data. The following example generates 100 rows of structured data by setting an explicit count. The interval field is set to empty, which means data is generated as fast as the downstream components can consume it.",
          "title": "Generate 100 Rows"
        }
      ],
      "name": "generate",
      "plugin": true,
      "status": "stable",
      "summary": "Generates messages at a given interval using a xref:guides:bloblang/about.adoc[Bloblang] mapping executed without a context. This allows you to generate messages for testing your pipeline configs.",
      "type": "input",
      "version": "3.40.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the Git repository to clone.",
            "examples": [
              "https://github.com/username/repo.git"
            ],
            "kind": "scalar",
            "name": "repository_url",
            "type": "string"
          },
          {
            "default": "main",
            "description": "The branch to check out.",
            "kind": "scalar",
            "name": "branch",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "Duration between polling attempts",
            "examples": [
              "10s"
            ],
            "kind": "scalar",
            "name": "poll_interval",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of file patterns to include (e.g., '**/*.md', 'configs/*.yaml'). If empty, all files will be included. Supports glob patterns: *, /**/, ?, and character ranges [a-z]. Any character with a special meaning can be escaped with a backslash.",
            "is_optional": true,
            "kind": "array",
            "name": "include_patterns",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of file patterns to exclude (e.g., '.git/**', '**/*.png'). These patterns take precedence over include_patterns. Supports glob patterns: *, /**/, ?, and character ranges [a-z]. Any character with a special meaning can be escaped with a backslash.",
            "is_optional": true,
            "kind": "array",
            "name": "exclude_patterns",
            "type": "string"
          },
          {
            "default": 10485760,
            "description": "The maximum size of files to include in bytes. Files larger than this will be skipped. Set to 0 for no limit.",
            "kind": "scalar",
            "name": "max_file_size",
            "type": "int"
          },
          {
            "description": "A cache resource to store the last processed commit hash, allowing the input to resume from where it left off after a restart.",
            "is_optional": true,
            "kind": "scalar",
            "name": "checkpoint_cache",
            "type": "string"
          },
          {
            "default": "git_last_commit",
            "description": "The key to use when storing the last processed commit hash in the cache.",
            "is_optional": true,
            "kind": "scalar",
            "name": "checkpoint_key",
            "type": "string"
          },
          {
            "children": [
              {
                "children": [
                  {
                    "default": "",
                    "description": "Username for basic authentication",
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "username",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "Password for basic authentication",
                    "is_optional": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "Basic authentication credentials",
                "is_optional": true,
                "kind": "scalar",
                "name": "basic",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "Path to SSH private key file",
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "private_key_path",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "SSH private key content",
                    "is_optional": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "private_key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "Passphrase for the SSH private key",
                    "is_optional": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "passphrase",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "SSH key authentication",
                "is_optional": true,
                "kind": "scalar",
                "name": "ssh_key",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "Token value for token-based authentication",
                    "is_optional": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "value",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "Token-based authentication",
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "object"
              }
            ],
            "description": "Authentication options for the Git repository",
            "is_optional": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe git input clones the specified repository (or pulls updates if already cloned) and reads \nthe content of the specified file. It periodically polls the repository for new commits and emits \na message when changes are detected.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- git_file_path\n- git_file_size\n- git_file_mode\n- git_file_modified\n- git_commit\n- git_mime_type\n- git_is_binary\n- git_encoding (present if the file was base64 encoded)\n- git_deleted (only present if the file was deleted)\n\nYou can access these metadata fields using function interpolation.",
      "name": "git",
      "plugin": true,
      "status": "beta",
      "summary": "A Git input that clones (or pulls) a repository and reads the repository contents.",
      "type": "input",
      "version": "4.51.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of target host addresses to connect to.",
            "examples": [
              "localhost:9000"
            ],
            "kind": "array",
            "name": "hosts",
            "type": "string"
          },
          {
            "default": "",
            "description": "A user ID to connect as.",
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "description": "The directory to consume from.",
            "kind": "scalar",
            "name": "directory",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- hdfs_name\n- hdfs_path\n\nYou can access these metadata fields using\nxref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "hdfs",
      "plugin": true,
      "status": "stable",
      "summary": "Reads files from a HDFS directory, where each discrete file will be consumed as a single message payload.",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "The URL to connect to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "default": "GET",
            "description": "A verb to connect with",
            "examples": [
              "POST",
              "GET",
              "DELETE"
            ],
            "kind": "scalar",
            "name": "verb",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of headers to add to the request.",
            "examples": [
              {
                "Content-Type": "application/octet-stream",
                "traceparent": "${! tracing_span().traceparent }"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "headers",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Specify optional matching rules to determine which metadata keys should be added to the HTTP request as headers.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "",
            "description": "EXPERIMENTAL: Optionally set a level at which the request and response payload of each request made will be logged.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"trace\": true,\n  \"debug\": true,\n  \"info\": true,\n  \"warn\": true,\n  \"error\": true,\n  \"fatal\": true,\n  \"\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "dump_request_log_level",
            "options": [
              "TRACE",
              "DEBUG",
              "INFO",
              "WARN",
              "ERROR",
              "FATAL",
              ""
            ],
            "type": "string",
            "version": "4.12.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 2 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the token provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "client_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the client key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "client_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The URL of the token provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_url",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "default": [],
                "description": "A list of optional requested permissions.",
                "is_advanced": true,
                "kind": "array",
                "name": "scopes",
                "type": "string",
                "version": "3.45.0"
              },
              {
                "default": {},
                "description": "A list of optional endpoint parameters, values should be arrays of strings.",
                "examples": [
                  {
                    "bar": [
                      "woof"
                    ],
                    "foo": [
                      "meow",
                      "quack"
                    ]
                  }
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "linter": "\nroot = if this.type() == \"object\" {\n  this.values().map_each(ele -> if ele.type() != \"array\" {\n    \"field must be an object containing arrays of strings, got %s (%v)\".format(ele.format_json(no_indent: true), ele.type())\n  } else {\n    ele.map_each(str -> if str.type() != \"string\" {\n      \"field values must be strings, got %s (%v)\".format(str.format_json(no_indent: true), str.type())\n    } else { deleted() })\n  }).\n    flatten()\n}\n",
                "name": "endpoint_params",
                "type": "unknown",
                "version": "4.21.0"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 2 using the client credentials token flow.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth2",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Specify which response headers should be added to resulting messages as metadata. Header keys are lowercased before matching, so ensure that your patterns target lowercased versions of the header keys that you expect.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "extract_headers",
            "type": "object"
          },
          {
            "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
            "is_optional": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "A static timeout to apply to requests.",
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1s",
            "description": "The base period to wait between failed requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_period",
            "type": "string"
          },
          {
            "default": "300s",
            "description": "The maximum period to wait between failed requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retry_backoff",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of retry attempts to make.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether or not to transparently follow redirects, i.e. responses with 300-399 status codes. If disabled, the response message will contain the body, status, and headers from the redirect response and the processor will not make a request to the URL set in the Location header of the response.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "follow_redirects",
            "type": "bool"
          },
          {
            "default": [
              429
            ],
            "description": "A list of status codes whereby the request should be considered to have failed and retries should be attempted, but the period between them should be increased gradually.",
            "is_advanced": true,
            "kind": "array",
            "name": "backoff_on",
            "type": "int"
          },
          {
            "default": [],
            "description": "A list of status codes whereby the request should be considered to have failed but retries should not be attempted. This is useful for preventing wasted retries for requests that will never succeed. Note that with these status codes the _request_ is dropped, but _message_ that caused the request will not be dropped.",
            "is_advanced": true,
            "kind": "array",
            "name": "drop_on",
            "type": "int"
          },
          {
            "default": [],
            "description": "A list of status codes whereby the attempt should be considered successful, this is useful for dropping requests that return non-2XX codes indicating that the message has been dealt with, such as a 303 See Other or a 409 Conflict. All 2XX codes are considered successful unless they are present within `backoff_on` or `drop_on`, regardless of this field.",
            "is_advanced": true,
            "kind": "array",
            "name": "successful_on",
            "type": "int"
          },
          {
            "description": "An optional HTTP proxy URL.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "proxy_url",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether or not to disable disable HTTP/2",
            "is_advanced": true,
            "kind": "scalar",
            "name": "disable_http2",
            "type": "bool",
            "version": "4.44.0"
          },
          {
            "description": "An optional payload to deliver for each request.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "payload",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether empty payloads received from the target server should be dropped.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "drop_empty_bodies",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Enables streaming mode.",
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": true,
                "description": "Sets whether to re-establish the connection once it is lost.",
                "kind": "scalar",
                "name": "reconnect",
                "type": "bool"
              },
              {
                "annotated_options": [
                  [
                    "auto",
                    "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
                  ],
                  [
                    "all-bytes",
                    "Consume the entire file as a single binary message."
                  ],
                  [
                    "avro-ocf:marshaler=x",
                    "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
                  ],
                  [
                    "chunker:x",
                    "Consume the file in chunks of a given number of bytes."
                  ],
                  [
                    "csv",
                    "Consume structured rows as comma separated values, the first row must be a header row."
                  ],
                  [
                    "csv:x",
                    "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
                  ],
                  [
                    "csv-safe",
                    "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
                  ],
                  [
                    "csv-safe:x",
                    "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
                  ],
                  [
                    "delim:x",
                    "Consume the file in segments divided by a custom delimiter."
                  ],
                  [
                    "gzip",
                    "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
                  ],
                  [
                    "pgzip",
                    "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
                  ],
                  [
                    "lines",
                    "Consume the file in segments divided by linebreaks."
                  ],
                  [
                    "multipart",
                    "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
                  ],
                  [
                    "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                    "Consume the file in segments divided by regular expression."
                  ],
                  [
                    "skipbom",
                    "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
                  ],
                  [
                    "tar",
                    "Parse the file as a tar archive, and consume each file of the archive as a message."
                  ]
                ],
                "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
                "examples": [
                  "lines",
                  "delim:\t",
                  "delim:foobar",
                  "gzip/csv"
                ],
                "is_deprecated": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "codec",
                "type": "string"
              },
              {
                "default": 1000000,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "max_buffer",
                "type": "int"
              },
              {
                "default": {
                  "lines": {}
                },
                "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
                "is_optional": true,
                "kind": "scalar",
                "name": "scanner",
                "type": "scanner",
                "version": "4.25.0"
              }
            ],
            "description": "Allows you to set streaming mode, where requests are kept open and messages are processed line-by-line.",
            "is_optional": true,
            "kind": "scalar",
            "name": "stream",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe URL and header values of this type can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Streaming\n\nIf you enable streaming then Redpanda Connect will consume the body of the response as a continuous stream of data, breaking messages out following a chosen scanner. This allows you to consume APIs that provide long lived streamed data feeds (such as Twitter).\n\n== Pagination\n\nThis input supports interpolation functions in the `url` and `headers` fields where data from the previous successfully consumed message (if there was one) can be referenced. This can be used in order to support basic levels of pagination. However, in cases where pagination depends on logic it is recommended that you use an xref:components:processors/http.adoc[`http` processor] instead, often combined with a xref:components:inputs/generate.adoc[`generate` input] in order to schedule the processor.",
      "examples": [
        {
          "config": "\ninput:\n  http_client:\n    url: >-\n      https://api.example.com/search?query=allmyfoos&start_time=${! (\n        (timestamp_unix()-300).ts_format(\"2006-01-02T15:04:05Z\",\"UTC\").escape_url_query()\n      ) }${! (\"&next_token=\"+this.meta.next_token.not_null()) | \"\" }\n    verb: GET\n    rate_limit: foo_searches\n    oauth2:\n      enabled: true\n      token_url: https://api.example.com/oauth2/token\n      client_key: \"${EXAMPLE_KEY}\"\n      client_secret: \"${EXAMPLE_SECRET}\"\n\nrate_limit_resources:\n  - label: foo_searches\n    local:\n      count: 1\n      interval: 30s\n",
          "summary": "Interpolation functions within the `url` and `headers` fields can be used to reference the previously consumed message, which allows simple pagination.",
          "title": "Basic Pagination"
        }
      ],
      "name": "http_client",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to a server and continuously performs requests for a single message.",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "An alternative address to host from. If left empty the service wide address is used.",
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": "/post",
            "description": "The endpoint path to listen for POST requests.",
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": "/post/ws",
            "description": "The endpoint path to create websocket connections from.",
            "kind": "scalar",
            "name": "ws_path",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional message to deliver to fresh websocket connections.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ws_welcome_message",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional message to delivery to websocket connections that are rate limited.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ws_rate_limit_message",
            "type": "string"
          },
          {
            "default": [
              "POST"
            ],
            "description": "An array of verbs that are allowed for the `path` endpoint.",
            "kind": "array",
            "name": "allowed_verbs",
            "type": "string",
            "version": "3.33.0"
          },
          {
            "default": "5s",
            "description": "Timeout for requests. If a consumed messages takes longer than this to be delivered the connection is closed, but the message may still be delivered.",
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "default": "",
            "description": "Enable TLS by specifying a certificate and key file. Only valid with a custom `address`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cert_file",
            "type": "string"
          },
          {
            "default": "",
            "description": "Enable TLS by specifying a certificate and key file. Only valid with a custom `address`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "key_file",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to allow CORS requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": [],
                "description": "An explicit list of origins that are allowed for CORS requests.",
                "is_advanced": true,
                "kind": "array",
                "name": "allowed_origins",
                "type": "string"
              }
            ],
            "description": "Adds Cross-Origin Resource Sharing headers. Only valid with a custom `address`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cors",
            "type": "object",
            "version": "3.63.0"
          },
          {
            "children": [
              {
                "default": "200",
                "description": "Specify the status code to return with synchronous responses. This is a string value, which allows you to customize it based on resulting payloads and their metadata.",
                "examples": [
                  "${! json(\"status\") }",
                  "${! meta(\"status\") }"
                ],
                "interpolated": true,
                "is_advanced": true,
                "kind": "scalar",
                "name": "status",
                "type": "string"
              },
              {
                "default": {
                  "Content-Type": "application/octet-stream"
                },
                "description": "Specify headers to return with synchronous responses.",
                "interpolated": true,
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "Provide a list of explicit metadata key prefixes to match against.",
                    "examples": [
                      [
                        "foo_",
                        "bar_"
                      ],
                      [
                        "kafka_"
                      ],
                      [
                        "content-"
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "include_prefixes",
                    "type": "string"
                  },
                  {
                    "default": [],
                    "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                    "examples": [
                      [
                        ".*"
                      ],
                      [
                        "_timestamp_unix$"
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "include_patterns",
                    "type": "string"
                  }
                ],
                "description": "Specify criteria for which metadata values are added to the response as headers.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "metadata_headers",
                "type": "object"
              }
            ],
            "description": "Customize messages returned via xref:guides:sync_responses.adoc[synchronous responses].",
            "is_advanced": true,
            "kind": "scalar",
            "name": "sync_response",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIf the `address` config field is left blank the xref:components:http/about.adoc[service-wide HTTP server] will be used.\n\nThe field `rate_limit` allows you to specify an optional xref:components:rate_limits/about.adoc[`rate_limit` resource], which will be applied to each HTTP request made and each websocket payload received.\n\nWhen the rate limit is breached HTTP requests will have a 429 response returned with a Retry-After header. Websocket payloads will be dropped and an optional response payload will be sent as per `ws_rate_limit_message`.\n\n== Responses\n\nIt's possible to return a response for each message received using xref:guides:sync_responses.adoc[synchronous responses]. When doing so you can customize headers with the `sync_response` field `headers`, which can also use xref:configuration:interpolation.adoc#bloblang-queries[function interpolation] in the value based on the response message contents.\n\n== Endpoints\n\nThe following fields specify endpoints that are registered for sending messages, and support path parameters of the form `/\\{foo}`, which are added to ingested messages as metadata. A path ending in `/` will match against all extensions of that path:\n\n=== `path` (defaults to `/post`)\n\nThis endpoint expects POST requests where the entire request body is consumed as a single message.\n\nIf the request contains a multipart `content-type` header as per https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^] then the multiple parts are consumed as a batch of messages, where each body part is a message of the batch.\n\n=== `ws_path` (defaults to `/post/ws`)\n\nCreates a websocket connection, where payloads received on the socket are passed through the pipeline as a batch of one message.\n\n\n[CAUTION]\n.Endpoint caveats\n====\nComponents within a Redpanda Connect config will register their respective endpoints in a non-deterministic order. This means that establishing precedence of endpoints that are registered via multiple `http_server` inputs or outputs (either within brokers or from cohabiting streams) is not possible in a predictable way.\n\nThis ambiguity makes it difficult to ensure that paths which are both a subset of a path registered by a separate component, and end in a slash (`/`) and will therefore match against all extensions of that path, do not prevent the more specific path from matching against requests.\n\nIt is therefore recommended that you ensure paths of separate components do not collide unless they are explicitly non-competing.\n\nFor example, if you were to deploy two separate `http_server` inputs, one with a path `/foo/` and the other with a path `/foo/bar`, it would not be possible to ensure that the path `/foo/` does not swallow requests made to `/foo/bar`.\n====\n\nYou may specify an optional `ws_welcome_message`, which is a static payload to be sent to all clients once a websocket connection is first established.\n\nIt's also possible to specify a `ws_rate_limit_message`, which is a static payload to be sent to clients that have triggered the servers rate limit.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- http_server_user_agent\n- http_server_request_path\n- http_server_verb\n- http_server_remote_ip\n- All headers (only first values are taken)\n- All query parameters\n- All path parameters\n- All cookies\n```\n\nIf HTTPS is enabled, the following fields are added as well:\n```text\n- http_server_tls_version\n- http_server_tls_subject\n- http_server_tls_cipher_suite\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "examples": [
        {
          "config": "\ninput:\n  http_server:\n    path: /\n    allowed_verbs: [ GET, POST ]\n    sync_response:\n      headers:\n        Content-Type: application/json\n\n  processors:\n    - switch:\n      - check: '@http_server_request_path == \"/foo\"'\n        processors:\n          - mapping: |\n              root.title = \"You Got Fooed!\"\n              root.result = content().string().uppercase()\n\n      - check: '@http_server_request_path == \"/bar\"'\n        processors:\n          - mapping: 'root.title = \"Bar Is Slow\"'\n          - sleep: # Simulate a slow endpoint\n              duration: 1s\n",
          "summary": "This example shows an `http_server` input that captures all requests and processes them by switching on that path:",
          "title": "Path Switching"
        },
        {
          "config": "\ninput:\n  http_server:\n    path: /oauth2_test\n    allowed_verbs: [ GET, POST ]\n    sync_response:\n      headers:\n        Content-Type: application/json\n\n  processors:\n    - log:\n        message: \"Received request\"\n        level: INFO\n        fields_mapping: |\n          root = @\n          root.body = content().string()\n\n    - mapping: |\n        root.access_token = \"MTQ0NjJkZmQ5OTM2NDE1ZTZjNGZmZjI3\"\n        root.token_type = \"Bearer\"\n        root.expires_in = 3600\n\n    - sync_response: {}\n    - mapping: 'root = deleted()'\n",
          "summary": "This example shows an `http_server` input that mocks an OAuth 2.0 Client Credentials flow server at the endpoint `/oauth2_test`:",
          "title": "Mock OAuth 2.0 Server"
        }
      ],
      "name": "http_server",
      "plugin": true,
      "status": "stable",
      "summary": "Receive messages POSTed over HTTP(S). HTTP 2.0 is supported when using TLS, which is enabled when key and cert files are specified.",
      "type": "input"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nDirectly connect to an output within a Redpanda Connect process by referencing it by a chosen ID. This allows you to hook up isolated streams whilst running Redpanda Connect in xref:guides:streams_mode/about.adoc[streams mode], it is NOT recommended that you connect the inputs of a stream with an output of the same stream, as feedback loops can lead to deadlocks in your message flow.\n\nIt is possible to connect multiple inputs to the same inproc ID, resulting in messages dispatching in a round-robin fashion to connected inputs. However, only one output can assume an inproc ID, and will replace existing outputs if a collision occurs.",
      "name": "inproc",
      "plugin": true,
      "status": "stable",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "localhost:9041,localhost:9042"
              ],
              [
                "localhost:9041",
                "localhost:9042"
              ]
            ],
            "kind": "array",
            "name": "addresses",
            "type": "string"
          },
          {
            "description": "A list of topics to consume from. Multiple comma separated topics can be listed in a single element. Partitions are automatically distributed across consumers of a topic. Alternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive.",
            "examples": [
              [
                "foo",
                "bar"
              ],
              [
                "foo,bar"
              ],
              [
                "foo:0",
                "bar:1",
                "bar:3"
              ],
              [
                "foo:0,bar:1,bar:3"
              ],
              [
                "foo:0-5"
              ]
            ],
            "kind": "array",
            "name": "topics",
            "type": "string",
            "version": "3.33.0"
          },
          {
            "description": "The version of the Kafka protocol to use. This limits the capabilities used by the client and should ideally match the version of your brokers. Defaults to the oldest supported stable version.",
            "examples": [
              "2.1.0",
              "3.1.0"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "target_version",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication. NOTE: When using plain text auth it is extremely likely that you'll also need to <<tls-enabled, enable TLS>>."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "Authentication using the SCRAM-SHA-256 mechanism."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "Authentication using the SCRAM-SHA-512 mechanism."
                  ],
                  [
                    "none",
                    "Default, no SASL authentication."
                  ]
                ],
                "default": "none",
                "description": "The SASL authentication mechanism, if left empty SASL authentication is not used.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A PLAIN username. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${USER}"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "user",
                "type": "string"
              },
              {
                "default": "",
                "description": "A PLAIN password. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${PASSWORD}"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A static OAUTHBEARER access token",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "Instead of using a static `access_token` allows you to query a xref:components:caches/about.adoc[`cache`] resource to fetch OAUTHBEARER tokens from",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_cache",
                "type": "string"
              },
              {
                "default": "",
                "description": "Required when using a `token_cache`, the key to query the cache with for tokens.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_key",
                "type": "string"
              }
            ],
            "description": "Enables SASL authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "",
            "description": "An identifier for the consumer group of the connection. This field can be explicitly made empty in order to disable stored offsets for the consumed topic partitions.",
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "description": "When using consumer groups, an identifier for this specific input so that it can be identified over restarts of this process. This should be unique per input.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "instance_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "A rack identifier for this client.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": true,
            "description": "Determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset. The setting is applied when creating a new consumer group or the saved offset no longer exists.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages of the same topic and partition that can be processed at a given time. Increasing this limit enables parallel processing and batching at the output level to work on individual partitions. Any given offset will not be committed unless all messages under that offset are delivered in order to preserve at least once delivery guarantees.",
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int",
            "version": "3.33.0"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "EXPERIMENTAL: Specify a maximum period of time in which each message can be consumed and awaiting either acknowledgement or rejection before rejection is instead forced. This can be useful for avoiding situations where certain downstream components can result in blocked confirmation of delivery that exceeds SLAs.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timely_nacks_maximum_wait",
            "type": "string"
          },
          {
            "default": "1s",
            "description": "The period of time between each commit of the current partition offsets. Offsets are always committed during shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": "100ms",
            "description": "A maximum estimate for the time taken to process a message, this is used for tuning consumer group synchronization.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_processing_period",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] that attempts to extract an object containing tracing propagation information, which will then be used as the root tracing span for the message. The specification of the extracted fields must match the format used by the service wide tracer.",
            "examples": [
              "root = @",
              "root = this.meta.span"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "extract_tracing_map",
            "type": "string",
            "version": "3.45.0"
          },
          {
            "children": [
              {
                "default": "10s",
                "description": "A period after which a consumer of the group is kicked after no heartbeats.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "session_timeout",
                "type": "string"
              },
              {
                "default": "3s",
                "description": "A period in which heartbeats should be sent out.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "heartbeat_interval",
                "type": "string"
              },
              {
                "default": "60s",
                "description": "A period after which rebalancing is abandoned if unresolved.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "rebalance_timeout",
                "type": "string"
              }
            ],
            "description": "Tuning parameters for consumer group synchronization.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "group",
            "type": "object"
          },
          {
            "default": 256,
            "description": "The maximum number of unprocessed messages to fetch at a given time.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_buffer_cap",
            "type": "int"
          },
          {
            "default": false,
            "description": "Decode headers into lists to allow handling of multiple values with the same key",
            "is_advanced": true,
            "kind": "scalar",
            "name": "multi_header",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "is_advanced": true,
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nOffsets are managed within Kafka under the specified consumer group, and partitions for each topic are automatically balanced across members of the consumer group.\n\nThe Kafka input allows parallel processing of messages from different topic partitions, and messages of the same topic partition are processed with a maximum parallelism determined by the field <<checkpoint_limit,`checkpoint_limit`>>.\n\nIn order to enforce ordered processing of partition messages set the <checkpoint_limit,`checkpoint_limit`>> to `1` and this will force partitions to be processed in lock-step, where a message will only be processed once the prior message is delivered.\n\nBatching messages before processing can be enabled using the <<batching,`batching`>> field, and this batching is performed per-partition such that messages of a batch will always originate from the same partition. This batching mechanism is capable of creating batches of greater size than the <<checkpoint_limit,`checkpoint_limit`>>, in which case the next batch will only be created upon delivery of the current one.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- kafka_key\n- kafka_topic\n- kafka_partition\n- kafka_offset\n- kafka_lag\n- kafka_timestamp_ms\n- kafka_timestamp_unix\n- kafka_tombstone_message\n- All existing message headers (version 0.11+)\n\nThe field `kafka_lag` is the calculated difference between the high water mark offset of the partition at the time of ingestion and the current message offset.\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n== Ordering\n\nBy default messages of a topic partition can be processed in parallel, up to a limit determined by the field `checkpoint_limit`. However, if strict ordered processing is required then this value must be set to 1 in order to process shard messages in lock-step. When doing so it is recommended that you perform batching at this component for performance as it will not be possible to batch lock-stepped messages at the output level.\n\n== Troubleshooting\n\nIf you're seeing issues writing to or reading from Kafka with this component then it's worth trying out the newer xref:components:inputs/kafka_franz.adoc[`kafka_franz` input].\n\n- I'm seeing logs that report `Failed to connect to kafka: kafka: client has run out of available brokers to talk to (Is your cluster reachable?)`, but the brokers are definitely reachable.\n\nUnfortunately this error message will appear for a wide range of connection problems even when the broker endpoint can be reached. Double check your authentication configuration and also ensure that you have <<tlsenabled, enabled TLS>> if applicable.",
      "name": "kafka",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to Kafka brokers and consumes one or more topics.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "\nA list of topics to consume from. Multiple comma separated topics can be listed in a single element. When a `consumer_group` is specified partitions are automatically distributed across consumers of a topic, otherwise all partitions are consumed.\n\nAlternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive.\n\nFinally, it's also possible to specify an explicit offset to consume from by adding another colon after the partition, e.g. `foo:0:10` would consume the partition 0 of the topic foo starting from the offset 10. If the offset is not present (or remains unspecified) then the field `start_from_oldest` determines which offset to start from.",
            "examples": [
              [
                "foo",
                "bar"
              ],
              [
                "things.*"
              ],
              [
                "foo,bar"
              ],
              [
                "foo:0",
                "bar:1",
                "bar:3"
              ],
              [
                "foo:0,bar:1,bar:3"
              ],
              [
                "foo:0-5"
              ]
            ],
            "kind": "array",
            "name": "topics",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether listed topics should be interpreted as regular expression patterns for matching multiple topics. When enabled, the client will periodically refresh the list of matching topics based on the `metadata_max_age` interval. When topics are specified with explicit partitions this field must remain set to `false`.",
            "kind": "scalar",
            "name": "regexp_topics",
            "type": "bool"
          },
          {
            "default": "",
            "description": "A rack specifies where the client is physically located and changes fetch requests to consume from the closest replica as opposed to the leader replica.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "When using a consumer group, an instance ID specifies the groups static membership, which can prevent rebalances during reconnects. When using a instance ID the client does NOT leave the group when closing. To actually leave the group one must use an external admin command to leave the group on behalf of this instance ID. This ID must be unique per consumer within the group.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "instance_id",
            "type": "string"
          },
          {
            "default": "45s",
            "description": "When using a consumer group, `rebalance_timeout` sets how long group members are allowed to take when a rebalance has begun. This timeout is how long all members are allowed to complete work and commit offsets, minus the time it took to detect the rebalance (from a heartbeat).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rebalance_timeout",
            "type": "string"
          },
          {
            "default": "1m",
            "description": "When using a consumer group, `session_timeout` sets how long a member in hte group can go between heartbeats. If a member does not heartbeat in this timeout, the broker will remove the member from the group and initiate a rebalance.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "session_timeout",
            "type": "string"
          },
          {
            "default": "3s",
            "description": "When using a consumer group, `heartbeat_interval` sets how long a group member goes between heartbeats to Kafka. Kafka uses heartbeats to ensure that a group member's sesion stays active. This value should be no higher than 1/3rd of the `session_timeout`. This is equivalent to the Java heartbeat.interval.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset. The setting is applied when creating a new consumer group or the saved offset no longer exists.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "committed",
                "Prevents consuming a partition in a group if the partition has no prior commits. Corresponds to Kafka's `auto.offset.reset=none` option"
              ],
              [
                "earliest",
                "Start from the earliest offset. Corresponds to Kafka's `auto.offset.reset=earliest` option."
              ],
              [
                "latest",
                "Start from the latest offset. Corresponds to Kafka's `auto.offset.reset=latest` option."
              ]
            ],
            "default": "earliest",
            "description": "Sets the offset to start consuming from, or if OffsetOutOfRange is seen while fetching, to restart consuming from.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"committed\": true,\n  \"earliest\": true,\n  \"latest\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "start_offset",
            "type": "string"
          },
          {
            "default": "50MiB",
            "description": "Sets the maximum amount of bytes a broker will try to send during a fetch. Note that brokers may not obey this limit if it has records larger than this limit. This is the equivalent to the Java fetch.max.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "Sets the maximum amount of time a broker will wait for a fetch response to hit the minimum number of required bytes. This is the equivalent to the Java fetch.max.wait.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_wait",
            "type": "string"
          },
          {
            "default": "1B",
            "description": "Sets the minimum amount of bytes a broker will try to send during a fetch. This is the equivalent to the Java fetch.min.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_min_bytes",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "Sets the maximum amount of bytes that will be consumed for a single partition in a fetch request. Note that if a single batch is larger than this number, that batch will still be returned so the client can make progress. This is the equivalent to the Java fetch.max.partition.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_partition_bytes",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "read_committed",
                "If set, only committed transactional records are processed."
              ],
              [
                "read_uncommitted",
                "If set, then uncommitted records are processed."
              ]
            ],
            "default": "read_uncommitted",
            "description": "The transaction isolation level",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"read_committed\": true,\n  \"read_uncommitted\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transaction_isolation_level",
            "type": "string"
          },
          {
            "description": "An optional consumer group to consume as. When specified the partitions of specified topics are automatically distributed across consumers sharing a consumer group, and partition offsets are automatically committed and resumed under this name. Consumer groups are not supported when specifying explicit partitions to consume from in the `topics` field.",
            "is_optional": true,
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "default": 1024,
            "description": "Determines how many messages of the same partition can be processed in parallel before applying back pressure. When a message of a given offset is delivered to the output the offset is only allowed to be committed when all messages of prior offsets have also been delivered, this ensures at-least-once delivery guarantees. However, this mechanism also increases the likelihood of duplicates in the event of crashes or server faults, reducing the checkpoint limit will mitigate this.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int"
          },
          {
            "default": "5s",
            "description": "The period of time between each commit of the current partition offsets. Offsets are always committed during shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": false,
            "description": "Decode headers into lists to allow handling of multiple values with the same key",
            "is_advanced": true,
            "kind": "scalar",
            "name": "multi_header",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "Allows you to configure a xref:configuration:batching.adoc[batching policy] that applies to individual topic partitions in order to batch messages together before flushing them for processing. Batching can be beneficial for performance as well as useful for windowed processing, and doing so this way preserves the ordering of topic partitions.",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "is_advanced": true,
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": "5s",
            "description": "The period of time between each topic lag refresh cycle.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "topic_lag_refresh_period",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "EXPERIMENTAL: Specify a maximum period of time in which each message can be consumed and awaiting either acknowledgement or rejection before rejection is instead forced. This can be useful for avoiding situations where certain downstream components can result in blocked confirmation of delivery that exceeds SLAs.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timely_nacks_maximum_wait",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "\nlet has_topic_partitions = this.topics.any(t -> t.contains(\":\"))\n\nroot = [\n  if $has_topic_partitions {\n    if this.consumer_group.or(\"\") != \"\" {\n      \"this input does not support both a consumer group and explicit topic partitions\"\n    } else if this.regexp_topics {\n      \"this input does not support both regular expression topics and explicit topic partitions\"\n    }\n  } else {\n    if this.consumer_group.or(\"\") == \"\" {\n      \"a consumer group is mandatory when not using explicit topic partitions\"\n    }\n  },\n  # We don't have any way to distinguish between start_from_oldest set explicitly to true and not set at all, so we\n  # assume users will be OK if start_offset overwrites it silently\n  if this.start_from_oldest == false && this.start_offset == \"earliest\" {\n    \"start_from_oldest cannot be set to false when start_offset is set to earliest\"\n  }\n]\n",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen a consumer group is specified this input consumes one or more topics where partitions will automatically balance across any other connected clients with the same consumer group. When a consumer group is not specified topics can either be consumed in their entirety or with explicit partitions.\n\nThis input often out-performs the traditional `kafka` input as well as providing more useful logs and error messages.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- kafka_key\n- kafka_topic\n- kafka_partition\n- kafka_offset\n- kafka_lag\n- kafka_timestamp_ms\n- kafka_timestamp_unix\n- kafka_tombstone_message\n- All record headers\n```\n",
      "name": "kafka_franz",
      "plugin": true,
      "status": "beta",
      "summary": "A Kafka input using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "input",
      "version": "3.61.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target MongoDB server.",
            "examples": [
              "mongodb://localhost:27017"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target MongoDB database.",
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "default": "",
            "description": "The username to connect to the database.",
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "default": "",
            "description": "The password to connect to the database.",
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "The client application name.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "app_name",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The collection to select from.",
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "default": "find",
            "description": "The mongodb operation to perform.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"find\": true,\n  \"aggregate\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "options": [
              "find",
              "aggregate"
            ],
            "type": "string",
            "version": "4.2.0"
          },
          {
            "annotated_options": [
              [
                "canonical",
                "A string format that emphasizes type preservation at the expense of readability and interoperability. That is, conversion from canonical to BSON will generally preserve type information except in certain specific cases. "
              ],
              [
                "relaxed",
                "A string format that emphasizes readability and interoperability at the expense of type preservation.That is, conversion from relaxed format to BSON can lose type information."
              ]
            ],
            "default": "canonical",
            "description": "The json_marshal_mode setting is optional and controls the format of the output message.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"canonical\": true,\n  \"relaxed\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "json_marshal_mode",
            "type": "string",
            "version": "4.7.0"
          },
          {
            "bloblang": true,
            "description": "Bloblang expression describing MongoDB query.",
            "examples": [
              "\n  root.from = {\"$lte\": timestamp_unix()}\n  root.to = {\"$gte\": timestamp_unix()}\n"
            ],
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "A explicit number of documents to batch up before flushing them for processing. Must be greater than `0`. Operations: `find`, `aggregate`",
            "examples": [
              1000
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "batch_size",
            "type": "int",
            "version": "4.26.0"
          },
          {
            "description": "An object specifying fields to sort by, and the respective sort order (`1` ascending, `-1` descending). Note: The driver currently appears to support only one sorting key. Operations: `find`",
            "examples": [
              {
                "name": 1
              },
              {
                "age": -1
              }
            ],
            "is_optional": true,
            "kind": "map",
            "name": "sort",
            "type": "int",
            "version": "4.26.0"
          },
          {
            "description": "An explicit maximum number of documents to return. Operations: `find`",
            "is_optional": true,
            "kind": "scalar",
            "name": "limit",
            "type": "int",
            "version": "4.26.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Once the documents from the query are exhausted, this input shuts down, allowing the pipeline to gracefully terminate (or the next input in a xref:components:inputs/sequence.adoc[sequence] to execute).",
      "name": "mongodb",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a query and creates a message for each document received.",
      "type": "input",
      "version": "3.64.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The URL of the target MongoDB server.",
            "examples": [
              "mongodb://localhost:27017"
            ],
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "description": "The name of the target MongoDB database.",
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "default": "",
            "description": "The username to connect to the database.",
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "default": "",
            "description": "The password to connect to the database.",
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The collections to stream changes from.",
            "kind": "array",
            "name": "collections",
            "type": "string"
          },
          {
            "default": "mongodb_cdc_checkpoint",
            "description": "Checkpoint cache key name.",
            "kind": "scalar",
            "name": "checkpoint_key",
            "type": "string"
          },
          {
            "description": "Checkpoint cache name.",
            "kind": "scalar",
            "name": "checkpoint_cache",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The interval between writing checkpoints to the cache.",
            "kind": "scalar",
            "name": "checkpoint_interval",
            "type": "string"
          },
          {
            "default": 1000,
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int"
          },
          {
            "default": 1000,
            "description": "The batch size of documents for MongoDB to return.",
            "kind": "scalar",
            "name": "read_batch_size",
            "type": "int"
          },
          {
            "default": "1s",
            "description": "The maximum time MongoDB waits to fulfill `read_batch_size` on the change stream before returning documents.",
            "kind": "scalar",
            "name": "read_max_wait",
            "type": "string"
          },
          {
            "default": false,
            "description": "If to read initial snapshot before streaming changes.",
            "kind": "scalar",
            "name": "stream_snapshot",
            "type": "bool"
          },
          {
            "default": 1,
            "description": "Parallelism for snapshot phase.",
            "kind": "scalar",
            "linter": "match {\n  this < 1 => [\"field snapshot_parallelism must be greater or equal to 1.\"],\n}",
            "name": "snapshot_parallelism",
            "type": "int"
          },
          {
            "default": false,
            "description": "If true, determine parallel snapshot chunks using `$bucketAuto` instead of the `splitVector` command. This allows parallel collection reading in environments where privledged access to the MongoDB cluster is not allowed such as MongoDB Atlas.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "snapshot_auto_bucket_sharding",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "partial_update",
                "In this mode update operations only have a description of the update operation, which follows the following schema:\n      {\n        \"_id\": <document_id>,\n        \"operations\": [\n          # type == set means that the value was updated like so:\n          # root.foo.\"bar.baz\" = \"world\"\n          {\"path\": [\"foo\", \"bar.baz\"], \"type\": \"set\", \"value\":\"world\"},\n          # type == unset means that the value was deleted like so:\n          # root.qux = deleted()\n          {\"path\": [\"qux\"], \"type\": \"unset\", \"value\": null},\n          # type == truncatedArray means that the array at that path was truncated to value number of elements\n          # root.array = this.array.slice(2)\n          {\"path\": [\"array\"], \"type\": \"truncatedArray\", \"value\": 2}\n        ]\n      }\n      "
              ],
              [
                "pre_and_post_images",
                "Uses pre and post image collection to emit the full documents for update and delete operations. To use and configure this mode see the setup steps in the https://www.mongodb.com/docs/manual/changeStreams/#change-streams-with-document-pre--and-post-images[^MongoDB documentation]."
              ],
              [
                "update_lookup",
                "In this mode insert, replace and update operations have the full document emitted and deletes only have the _id field populated. Documents updates lookup the full document. This corresponds to the updateLookup option, see the https://www.mongodb.com/docs/manual/changeStreams/#std-label-change-streams-updateLookup[^MongoDB documentation] for more information."
              ]
            ],
            "default": "update_lookup",
            "description": "The mode in which to emit documents, specifically updates and deletes.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"partial_update\": true,\n  \"pre_and_post_images\": true,\n  \"update_lookup\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "document_mode",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "canonical",
                "A string format that emphasizes type preservation at the expense of readability and interoperability. That is, conversion from canonical to BSON will generally preserve type information except in certain specific cases. "
              ],
              [
                "relaxed",
                "A string format that emphasizes readability and interoperability at the expense of type preservation.That is, conversion from relaxed format to BSON can lose type information."
              ]
            ],
            "default": "canonical",
            "description": "The json_marshal_mode setting is optional and controls the format of the output message.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"canonical\": true,\n  \"relaxed\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "json_marshal_mode",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "The client application name.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "app_name",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Read from a MongoDB replica set using https://www.mongodb.com/docs/manual/changeStreams/[^Change Streams]. It's only possible to watch for changes when using a sharded MongoDB or a MongoDB cluster running as a replica set.\n\nBy default MongoDB does not propagate changes in all cases. In order to capture all changes (including deletes) in a MongoDB cluster one needs to enable pre and post image saving and the collection needs to also enable saving these pre and post images. For more information see https://www.mongodb.com/docs/manual/changeStreams/#change-streams-with-document-pre--and-post-images[^MongoDB documentation].\n\n== Metadata\n\nEach message omitted by this plugin has the following metadata:\n\n- operation: either \"create\", \"replace\", \"delete\" or \"update\" for changes streamed. Documents from the initial snapshot have the operation set to \"read\".\n- collection: the collection the document was written to.\n- operation_time: the oplog time for when this operation occurred.\n    ",
      "name": "mongodb_cdc",
      "plugin": true,
      "status": "experimental",
      "summary": "Streams changes from a MongoDB replica set.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. The format should be `scheme://host:port` where `scheme` is one of `tcp`, `ssl`, or `ws`, `host` is the ip-address (or hostname) and `port` is the port on which the broker is accepting connections. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "tcp://localhost:1883"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "",
            "description": "An identifier for the client connection.",
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "nanoid",
                "append a nanoid of length 21 characters"
              ]
            ],
            "description": "Append a dynamically generated suffix to the specified `client_id` on each run of the pipeline. This can be useful when clustering Redpanda Connect producers.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = []",
            "name": "dynamic_client_id_suffix",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The maximum amount of time to wait in order to establish a connection before the attempt is abandoned.",
            "examples": [
              "1s",
              "500ms"
            ],
            "kind": "scalar",
            "name": "connect_timeout",
            "type": "string",
            "version": "3.58.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to enable last will messages.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": 0,
                "description": "Set QoS for last will message. Valid values are: 0, 1, 2.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "qos",
                "type": "int"
              },
              {
                "default": false,
                "description": "Set retained for last will message.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "retained",
                "type": "bool"
              },
              {
                "default": "",
                "description": "Set topic for last will message.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "topic",
                "type": "string"
              },
              {
                "default": "",
                "description": "Set payload for last will message.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "payload",
                "type": "string"
              }
            ],
            "description": "Set last will message in case of Redpanda Connect failure",
            "is_advanced": true,
            "kind": "scalar",
            "name": "will",
            "type": "object"
          },
          {
            "default": "",
            "description": "A username to connect with.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "default": "",
            "description": "A password to connect with.",
            "is_advanced": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": 30,
            "description": "Max seconds of inactivity before a keepalive message is sent.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "keepalive",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "A list of topics to consume from.",
            "kind": "array",
            "name": "topics",
            "type": "string"
          },
          {
            "default": 1,
            "description": "The level of delivery guarantee to enforce. Has options 0, 1, 2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "qos",
            "type": "int"
          },
          {
            "default": true,
            "description": "Set whether the connection is non-persistent.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "clean_session",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- mqtt_duplicate\n- mqtt_qos\n- mqtt_retained\n- mqtt_topic\n- mqtt_message_id\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "mqtt",
      "plugin": true,
      "status": "stable",
      "summary": "Subscribe to topics on MQTT brokers.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "mariadb",
                "MariaDB flavored databases."
              ],
              [
                "mysql",
                "MySQL flavored databases."
              ]
            ],
            "default": "mysql",
            "description": "The type of MySQL database to connect to.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mariadb\": true,\n  \"mysql\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "flavor",
            "type": "string"
          },
          {
            "description": "The DSN of the MySQL database to connect to.",
            "examples": [
              "user:password@tcp(localhost:3306)/database"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "A list of tables to stream from the database.",
            "examples": [
              [
                "table1",
                "table2"
              ]
            ],
            "kind": "array",
            "linter": "root = if this.length() == 0 { [ \"field 'tables' must contain at least one table\" ] }",
            "name": "tables",
            "type": "string"
          },
          {
            "description": "A https://www.docs.redpanda.com/redpanda-connect/components/caches/about[cache resource^] to use for storing the current latest BinLog Position that has been successfully delivered, this allows Redpanda Connect to continue from that BinLog Position upon restart, rather than consume the entire state of the table.",
            "kind": "scalar",
            "name": "checkpoint_cache",
            "type": "string"
          },
          {
            "default": "mysql_binlog_position",
            "description": "The key to use to store the snapshot position in `checkpoint_cache`. An alternative key can be provided if multiple CDC inputs share the same cache.",
            "kind": "scalar",
            "name": "checkpoint_key",
            "type": "string"
          },
          {
            "default": 1000,
            "description": "The maximum number of rows to be streamed in a single batch when taking a snapshot.",
            "kind": "scalar",
            "name": "snapshot_max_batch_size",
            "type": "int"
          },
          {
            "description": "If set to true, the connector will query all the existing data as a part of snapshot process. Otherwise, it will start from the current binlog position.",
            "kind": "scalar",
            "name": "stream_snapshot",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages that can be processed at a given time. Increasing this limit enables parallel processing and batching at the output level. Any given BinLog Position will not be acknowledged unless all messages under that offset are delivered in order to preserve at least once delivery guarantees.",
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- operation\n- table\n- binlog_position\n",
      "name": "mysql_cdc",
      "plugin": true,
      "status": "beta",
      "summary": "Enables MySQL streaming for RedPanda Connect.",
      "type": "input",
      "version": "4.45.0"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to (or as). If an item of the list contains commas it will be expanded into multiple URLs.",
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether the URLs provided should be connected to, or bound as.",
            "kind": "scalar",
            "name": "bind",
            "type": "bool"
          },
          {
            "default": "PULL",
            "description": "The socket type to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"pull\": true,\n  \"sub\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "socket_type",
            "options": [
              "PULL",
              "SUB"
            ],
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": [],
            "description": "A list of subscription topic filters to use when consuming from a SUB socket. Specifying a single sub_filter of `''` will subscribe to everything.",
            "kind": "array",
            "name": "sub_filters",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period to wait until a poll is abandoned and reattempted.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "poll_timeout",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Currently only PULL and SUB sockets are supported.",
      "name": "nanomsg",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes messages via Nanomsg sockets (scalability protocols).",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "A subject to consume from. Supports wildcards for consuming multiple subjects. Either a subject or stream must be specified.",
            "examples": [
              "foo.bar.baz",
              "foo.*.baz",
              "foo.bar.*",
              "foo.>"
            ],
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "description": "An optional queue group to consume as.",
            "is_optional": true,
            "kind": "scalar",
            "name": "queue",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Control whether ACKS are sent as a reply to each message. When enabled, these replies are sent only once the data has been delivered to all outputs.",
            "kind": "scalar",
            "name": "send_ack",
            "type": "bool"
          },
          {
            "description": "An optional delay duration on redelivering a message when negatively acknowledged.",
            "examples": [
              "1m"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "nak_delay",
            "type": "string"
          },
          {
            "default": 500000,
            "description": "The maximum number of messages to pull at a time.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this < 0 { [\"prefetch count must be greater than or equal to zero\"] }",
            "name": "prefetch_count",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] that attempts to extract an object containing tracing propagation information, which will then be used as the root tracing span for the message. The specification of the extracted fields must match the format used by the service wide tracer.",
            "examples": [
              "root = @",
              "root = this.meta.span"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "extract_tracing_map",
            "type": "string",
            "version": "4.23.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- nats_subject\n- nats_reply_subject\n- All message headers (when supported by the connection)\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats",
      "plugin": true,
      "status": "stable",
      "summary": "Subscribe to a NATS subject.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "An optional queue group to consume as. Used to configure a push consumer.",
            "is_optional": true,
            "kind": "scalar",
            "name": "queue",
            "type": "string"
          },
          {
            "description": "A subject to consume from. Supports wildcards for consuming multiple subjects. Either a subject or stream must be specified.",
            "examples": [
              "foo.bar.baz",
              "foo.*.baz",
              "foo.bar.*",
              "foo.>"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "description": "Preserve the state of your consumer under a durable name. Used to configure a pull consumer.",
            "is_optional": true,
            "kind": "scalar",
            "name": "durable",
            "type": "string"
          },
          {
            "description": "A stream to consume from. Either a subject or stream must be specified.",
            "is_optional": true,
            "kind": "scalar",
            "name": "stream",
            "type": "string"
          },
          {
            "description": "Indicates that the subscription should use an existing consumer.",
            "is_optional": true,
            "kind": "scalar",
            "name": "bind",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "all",
                "Deliver all available messages."
              ],
              [
                "last",
                "Deliver starting with the last published messages."
              ],
              [
                "last_per_subject",
                "Deliver starting with the last published message per subject."
              ],
              [
                "new",
                "Deliver starting from now, not taking into account any previous messages."
              ]
            ],
            "default": "all",
            "description": "Determines which messages to deliver when consuming without a durable subscriber.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"all\": true,\n  \"last\": true,\n  \"last_per_subject\": true,\n  \"new\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "deliver",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The maximum amount of time NATS server should wait for an ack from consumer.",
            "examples": [
              "100ms",
              "5m"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "ack_wait",
            "type": "string"
          },
          {
            "default": 1024,
            "description": "The maximum number of outstanding acks to be allowed before consuming is halted.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_ack_pending",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] that attempts to extract an object containing tracing propagation information, which will then be used as the root tracing span for the message. The specification of the extracted fields must match the format used by the service wide tracer.",
            "examples": [
              "root = @",
              "root = this.meta.span"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "extract_tracing_map",
            "type": "string",
            "version": "4.23.0"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n\t\t\tthis.exists(\"queue\") && this.queue != \"\" && this.exists(\"durable\") && this.durable != \"\" => [ \"both 'queue' and 'durable' can't be set simultaneously\" ],\n\t\t\t}",
        "name": "",
        "type": "object"
      },
      "description": "\n== Consume mirrored streams\n\nIn the case where a stream being consumed is mirrored from a different JetStream domain the stream cannot be resolved from the subject name alone, and so the stream name as well as the subject (if applicable) must both be specified.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- nats_subject\n- nats_sequence_stream\n- nats_sequence_consumer\n- nats_num_delivered\n- nats_num_pending\n- nats_domain\n- nats_timestamp_unix_nano\n```\n\nYou can access these metadata fields using\nxref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_jetstream",
      "plugin": true,
      "status": "stable",
      "summary": "Reads messages from NATS JetStream subjects.",
      "type": "input",
      "version": "3.46.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The name of the KV bucket.",
            "examples": [
              "my_kv_bucket"
            ],
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "default": ">",
            "description": "Key to watch for updates, can include wildcards.",
            "examples": [
              "foo.bar.baz",
              "foo.*.baz",
              "foo.bar.*",
              "foo.>"
            ],
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Do not send delete markers as messages.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ignore_deletes",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Include all the history per key, not just the last one.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "include_history",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Retrieve only the metadata of the entry",
            "is_advanced": true,
            "kind": "scalar",
            "name": "meta_only",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n``` text\n- nats_kv_key\n- nats_kv_bucket\n- nats_kv_revision\n- nats_kv_delta\n- nats_kv_operation\n- nats_kv_created\n```\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_kv",
      "plugin": true,
      "status": "beta",
      "summary": "Watches for updates in a NATS key-value bucket.",
      "type": "input",
      "version": "4.12.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The ID of the cluster to consume from.",
            "kind": "scalar",
            "name": "cluster_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "A client ID to connect as.",
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "The queue to consume from.",
            "kind": "scalar",
            "name": "queue",
            "type": "string"
          },
          {
            "default": "",
            "description": "A subject to consume from.",
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "default": "",
            "description": "Preserve the state of your consumer under a durable name.",
            "kind": "scalar",
            "name": "durable_name",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether the subscription should be destroyed when this client disconnects.",
            "kind": "scalar",
            "name": "unsubscribe_on_close",
            "type": "bool"
          },
          {
            "default": true,
            "description": "If a position is not found for a queue, determines whether to consume from the oldest available message, otherwise messages are consumed from the latest.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "default": 1024,
            "description": "The maximum number of unprocessed messages to fetch at a given time.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_inflight",
            "type": "int"
          },
          {
            "default": "30s",
            "description": "An optional duration to specify at which a message that is yet to be acked will be automatically retried.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ack_wait",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] that attempts to extract an object containing tracing propagation information, which will then be used as the root tracing span for the message. The specification of the extracted fields must match the format used by the service wide tracer.",
            "examples": [
              "root = @",
              "root = this.meta.span"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "extract_tracing_map",
            "type": "string",
            "version": "4.23.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n[CAUTION]\n.Deprecation notice\n====\nThe NATS Streaming Server is being deprecated. Critical bug fixes and security fixes will be applied until June of 2023. NATS-enabled applications requiring persistence should use https://docs.nats.io/nats-concepts/jetstream[JetStream^].\n====\n\nTracking and persisting offsets through a durable name is also optional and works with or without a queue. If a durable name is not provided then subjects are consumed from the most recently published message.\n\nWhen a consumer closes its connection it unsubscribes, when all consumers of a durable queue do this the offsets are deleted. In order to avoid this you can stop the consumers from unsubscribing by setting the field `unsubscribe_on_close` to `false`.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- nats_stream_subject\n- nats_stream_sequence\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_stream",
      "plugin": true,
      "status": "stable",
      "summary": "Subscribe to a NATS Stream subject. Joining a queue is optional and allows multiple clients of a subject to consume using queue semantics.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of nsqd addresses to connect to.",
            "kind": "array",
            "name": "nsqd_tcp_addresses",
            "type": "string"
          },
          {
            "description": "A list of nsqlookupd addresses to connect to.",
            "kind": "array",
            "name": "lookupd_http_addresses",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The topic to consume from.",
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "description": "The channel to consume from.",
            "kind": "scalar",
            "name": "channel",
            "type": "string"
          },
          {
            "description": "A user agent to assume when connecting.",
            "is_optional": true,
            "kind": "scalar",
            "name": "user_agent",
            "type": "string"
          },
          {
            "default": 100,
            "description": "The maximum number of pending messages to consume at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": 5,
            "description": "The maximum number of attempts to successfully consume a messages.",
            "kind": "scalar",
            "name": "max_attempts",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- nsq_attempts\n- nsq_id\n- nsq_nsqd_address\n- nsq_timestamp\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n",
      "name": "nsq",
      "plugin": true,
      "status": "stable",
      "summary": "Subscribe to an NSQ instance topic and channel.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "children": [
              {
                "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
                "examples": [
                  [
                    "localhost:9092"
                  ],
                  [
                    "foo:9092",
                    "bar:9092"
                  ],
                  [
                    "foo:9092,bar:9092"
                  ]
                ],
                "is_optional": true,
                "kind": "array",
                "name": "seed_brokers",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether custom TLS settings are enabled.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": false,
                    "description": "Whether to skip server side certificate verification.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "skip_cert_verify",
                    "type": "bool"
                  },
                  {
                    "default": false,
                    "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enable_renegotiation",
                    "type": "bool",
                    "version": "3.45.0"
                  },
                  {
                    "default": "",
                    "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "root_cas",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "./root_cas.pem"
                    ],
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "root_cas_file",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "default": "",
                        "description": "A plain text certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text certificate key to use.",
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "key",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate key to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "key_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                        "examples": [
                          "foo",
                          "${KEY_PASSWORD}"
                        ],
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "password",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      }
                    ],
                    "default": [],
                    "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                    "examples": [
                      [
                        {
                          "cert": "foo",
                          "key": "bar"
                        }
                      ],
                      [
                        {
                          "cert_file": "./example.pem",
                          "key_file": "./example.key"
                        }
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "client_certs",
                    "type": "object"
                  }
                ],
                "description": "Custom TLS settings can be used to override system defaults.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "tls",
                "type": "object"
              },
              {
                "description": "\nA list of topics to consume from. Multiple comma separated topics can be listed in a single element. When a `consumer_group` is specified partitions are automatically distributed across consumers of a topic, otherwise all partitions are consumed.\n\nAlternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive.\n\nFinally, it's also possible to specify an explicit offset to consume from by adding another colon after the partition, e.g. `foo:0:10` would consume the partition 0 of the topic foo starting from the offset 10. If the offset is not present (or remains unspecified) then the field `start_from_oldest` determines which offset to start from.",
                "examples": [
                  [
                    "foo",
                    "bar"
                  ],
                  [
                    "things.*"
                  ],
                  [
                    "foo,bar"
                  ],
                  [
                    "foo:0",
                    "bar:1",
                    "bar:3"
                  ],
                  [
                    "foo:0,bar:1,bar:3"
                  ],
                  [
                    "foo:0-5"
                  ]
                ],
                "kind": "array",
                "name": "topics",
                "type": "string"
              },
              {
                "default": false,
                "description": "Whether listed topics should be interpreted as regular expression patterns for matching multiple topics. When enabled, the client will periodically refresh the list of matching topics based on the `metadata_max_age` interval. When topics are specified with explicit partitions this field must remain set to `false`.",
                "kind": "scalar",
                "name": "regexp_topics",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A rack specifies where the client is physically located and changes fetch requests to consume from the closest replica as opposed to the leader replica.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "rack_id",
                "type": "string"
              },
              {
                "default": "",
                "description": "When using a consumer group, an instance ID specifies the groups static membership, which can prevent rebalances during reconnects. When using a instance ID the client does NOT leave the group when closing. To actually leave the group one must use an external admin command to leave the group on behalf of this instance ID. This ID must be unique per consumer within the group.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "instance_id",
                "type": "string"
              },
              {
                "default": "45s",
                "description": "When using a consumer group, `rebalance_timeout` sets how long group members are allowed to take when a rebalance has begun. This timeout is how long all members are allowed to complete work and commit offsets, minus the time it took to detect the rebalance (from a heartbeat).",
                "is_advanced": true,
                "kind": "scalar",
                "name": "rebalance_timeout",
                "type": "string"
              },
              {
                "default": "1m",
                "description": "When using a consumer group, `session_timeout` sets how long a member in hte group can go between heartbeats. If a member does not heartbeat in this timeout, the broker will remove the member from the group and initiate a rebalance.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "session_timeout",
                "type": "string"
              },
              {
                "default": "3s",
                "description": "When using a consumer group, `heartbeat_interval` sets how long a group member goes between heartbeats to Kafka. Kafka uses heartbeats to ensure that a group member's sesion stays active. This value should be no higher than 1/3rd of the `session_timeout`. This is equivalent to the Java heartbeat.interval.ms setting.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "heartbeat_interval",
                "type": "string"
              },
              {
                "default": true,
                "description": "Determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset. The setting is applied when creating a new consumer group or the saved offset no longer exists.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "start_from_oldest",
                "type": "bool"
              },
              {
                "annotated_options": [
                  [
                    "committed",
                    "Prevents consuming a partition in a group if the partition has no prior commits. Corresponds to Kafka's `auto.offset.reset=none` option"
                  ],
                  [
                    "earliest",
                    "Start from the earliest offset. Corresponds to Kafka's `auto.offset.reset=earliest` option."
                  ],
                  [
                    "latest",
                    "Start from the latest offset. Corresponds to Kafka's `auto.offset.reset=latest` option."
                  ]
                ],
                "default": "earliest",
                "description": "Sets the offset to start consuming from, or if OffsetOutOfRange is seen while fetching, to restart consuming from.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"committed\": true,\n  \"earliest\": true,\n  \"latest\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "start_offset",
                "type": "string"
              },
              {
                "default": "50MiB",
                "description": "Sets the maximum amount of bytes a broker will try to send during a fetch. Note that brokers may not obey this limit if it has records larger than this limit. This is the equivalent to the Java fetch.max.bytes setting.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "fetch_max_bytes",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "Sets the maximum amount of time a broker will wait for a fetch response to hit the minimum number of required bytes. This is the equivalent to the Java fetch.max.wait.ms setting.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "fetch_max_wait",
                "type": "string"
              },
              {
                "default": "1B",
                "description": "Sets the minimum amount of bytes a broker will try to send during a fetch. This is the equivalent to the Java fetch.min.bytes setting.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "fetch_min_bytes",
                "type": "string"
              },
              {
                "default": "1MiB",
                "description": "Sets the maximum amount of bytes that will be consumed for a single partition in a fetch request. Note that if a single batch is larger than this number, that batch will still be returned so the client can make progress. This is the equivalent to the Java fetch.max.partition.bytes setting.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "fetch_max_partition_bytes",
                "type": "string"
              },
              {
                "annotated_options": [
                  [
                    "read_committed",
                    "If set, only committed transactional records are processed."
                  ],
                  [
                    "read_uncommitted",
                    "If set, then uncommitted records are processed."
                  ]
                ],
                "default": "read_uncommitted",
                "description": "The transaction isolation level",
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"read_committed\": true,\n  \"read_uncommitted\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "transaction_isolation_level",
                "type": "string"
              },
              {
                "description": "An optional consumer group to consume as. When specified the partitions of specified topics are automatically distributed across consumers sharing a consumer group, and partition offsets are automatically committed and resumed under this name. Consumer groups are not supported when specifying explicit partitions to consume from in the `topics` field.",
                "is_optional": true,
                "kind": "scalar",
                "name": "consumer_group",
                "type": "string"
              },
              {
                "default": 1024,
                "description": "Determines how many messages of the same partition can be processed in parallel before applying back pressure. When a message of a given offset is delivered to the output the offset is only allowed to be committed when all messages of prior offsets have also been delivered, this ensures at-least-once delivery guarantees. However, this mechanism also increases the likelihood of duplicates in the event of crashes or server faults, reducing the checkpoint limit will mitigate this.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "checkpoint_limit",
                "type": "int"
              },
              {
                "default": "5s",
                "description": "The period of time between each commit of the current partition offsets. Offsets are always committed during shutdown.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "commit_period",
                "type": "string"
              },
              {
                "default": false,
                "description": "Decode headers into lists to allow handling of multiple values with the same key",
                "is_advanced": true,
                "kind": "scalar",
                "name": "multi_header",
                "type": "bool"
              },
              {
                "children": [
                  {
                    "default": 0,
                    "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "count",
                    "type": "int"
                  },
                  {
                    "default": 0,
                    "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "byte_size",
                    "type": "int"
                  },
                  {
                    "default": "",
                    "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                    "examples": [
                      "1s",
                      "1m",
                      "500ms"
                    ],
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "period",
                    "type": "string"
                  },
                  {
                    "bloblang": true,
                    "default": "",
                    "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                    "examples": [
                      "this.type == \"end_of_transaction\""
                    ],
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "check",
                    "type": "string"
                  },
                  {
                    "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                    "examples": [
                      [
                        {
                          "archive": {
                            "format": "concatenate"
                          }
                        }
                      ],
                      [
                        {
                          "archive": {
                            "format": "lines"
                          }
                        }
                      ],
                      [
                        {
                          "archive": {
                            "format": "json_array"
                          }
                        }
                      ]
                    ],
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "array",
                    "name": "processors",
                    "type": "processor"
                  }
                ],
                "description": "Allows you to configure a xref:configuration:batching.adoc[batching policy] that applies to individual topic partitions in order to batch messages together before flushing them for processing. Batching can be beneficial for performance as well as useful for windowed processing, and doing so this way preserves the ordering of topic partitions.",
                "examples": [
                  {
                    "byte_size": 5000,
                    "count": 0,
                    "period": "1s"
                  },
                  {
                    "count": 10,
                    "period": "1s"
                  },
                  {
                    "check": "this.contains(\"END BATCH\")",
                    "count": 0,
                    "period": "1m"
                  }
                ],
                "is_advanced": true,
                "kind": "",
                "name": "batching",
                "type": "object"
              },
              {
                "default": "5s",
                "description": "The period of time between each topic lag refresh cycle.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "topic_lag_refresh_period",
                "type": "string"
              }
            ],
            "kind": "scalar",
            "linter": "\nlet has_topic_partitions = this.topics.any(t -> t.contains(\":\"))\n\nroot = [\n  if $has_topic_partitions {\n    if this.consumer_group.or(\"\") != \"\" {\n      \"this input does not support both a consumer group and explicit topic partitions\"\n    } else if this.regexp_topics {\n      \"this input does not support both regular expression topics and explicit topic partitions\"\n    }\n  } else {\n    if this.consumer_group.or(\"\") == \"\" {\n      \"a consumer group is mandatory when not using explicit topic partitions\"\n    }\n  },\n  # We don't have any way to distinguish between start_from_oldest set explicitly to true and not set at all, so we\n  # assume users will be OK if start_offset overwrites it silently\n  if this.start_from_oldest == false && this.start_offset == \"earliest\" {\n    \"start_from_oldest cannot be set to false when start_offset is set to earliest\"\n  }\n]\n",
            "name": "kafka",
            "type": "object"
          },
          {
            "default": false,
            "kind": "scalar",
            "name": "disable_content_encryption",
            "type": "bool"
          },
          {
            "is_optional": true,
            "kind": "scalar",
            "name": "enrollment_ticket",
            "type": "string"
          },
          {
            "is_optional": true,
            "kind": "scalar",
            "name": "identity_name",
            "type": "string"
          },
          {
            "default": "self",
            "kind": "scalar",
            "name": "allow",
            "type": "string"
          },
          {
            "default": "self",
            "kind": "scalar",
            "name": "route_to_kafka_outlet",
            "type": "string"
          },
          {
            "default": "self",
            "kind": "scalar",
            "name": "allow_producer",
            "type": "string"
          },
          {
            "is_optional": true,
            "kind": "scalar",
            "name": "relay",
            "type": "string"
          },
          {
            "default": "127.0.0.1:6262",
            "kind": "scalar",
            "name": "node_address",
            "type": "string"
          },
          {
            "default": [],
            "description": "The fields to encrypt in the kafka messages, assuming the record is a valid JSON map. By default, the whole record is encrypted.",
            "kind": "array",
            "name": "encrypted_fields",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "ockam_kafka",
      "plugin": true,
      "status": "experimental",
      "summary": "Ockam",
      "type": "input"
    },
    {
      "categories": [
        "Local"
      ],
      "config": {
        "children": [
          {
            "description": "A list of file paths to read from. Each file will be read sequentially until the list is exhausted, at which point the input will close. Glob patterns are supported, including super globs (double star).",
            "examples": [
              "/tmp/foo.parquet",
              "/tmp/bar/*.parquet",
              "/tmp/data/**/*.parquet"
            ],
            "kind": "array",
            "name": "paths",
            "type": "string"
          },
          {
            "default": 1,
            "description": "Optionally process records in batches. This can help to speed up the consumption of exceptionally large files. When the end of the file is reached the remaining records are processed as a (potentially smaller) batch.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "batch_count",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis input uses https://github.com/parquet-go/parquet-go[https://github.com/parquet-go/parquet-go^], which is itself experimental. Therefore changes could be made into how this processor functions outside of major version releases.\n\nBy default any BYTE_ARRAY or FIXED_LEN_BYTE_ARRAY value will be extracted as a byte slice (`[]byte`) unless the logical type is UTF8, in which case they are extracted as a string (`string`).\n\nWhen a value extracted as a byte slice exists within a document which is later JSON serialized by default it will be base 64 encoded into strings, which is the default for arbitrary data fields. It is possible to convert these binary values to strings (or other data types) using Bloblang transformations such as `root.foo = this.foo.string()` or `root.foo = this.foo.encode(\"hex\")`, etc.",
      "name": "parquet",
      "plugin": true,
      "status": "experimental",
      "summary": "Reads and decodes https://parquet.apache.org/docs/[Parquet files^] into a stream of structured messages.",
      "type": "input",
      "version": "4.8.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The Data Source Name for the PostgreSQL database in the form of `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]`. Please note that Postgres enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.",
            "examples": [
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "default": false,
            "description": "When set to true, empty messages with operation types BEGIN and COMMIT are generated for the beginning and end of each transaction. Messages with operation metadata set to \"begin\" or \"commit\" will have null message payloads.",
            "kind": "scalar",
            "name": "include_transaction_markers",
            "type": "bool"
          },
          {
            "default": false,
            "description": "When set to true, the plugin will first stream a snapshot of all existing data in the database before streaming changes. In order to use this the tables that are being snapshot MUST have a primary key set so that reading from the table can be parallelized.",
            "examples": [
              true
            ],
            "kind": "scalar",
            "name": "stream_snapshot",
            "type": "bool"
          },
          {
            "default": 1,
            "description": "Determines the fraction of available memory that can be used for streaming the snapshot. Values between 0 and 1 represent the percentage of memory to use. Lower values make initial streaming slower but help prevent out-of-memory errors.",
            "examples": [
              0.2
            ],
            "is_deprecated": true,
            "kind": "scalar",
            "name": "snapshot_memory_safety_factor",
            "type": "float"
          },
          {
            "default": 1000,
            "description": "The number of rows to fetch in each batch when querying the snapshot.",
            "examples": [
              10000
            ],
            "kind": "scalar",
            "name": "snapshot_batch_size",
            "type": "int"
          },
          {
            "description": "The PostgreSQL schema from which to replicate data.",
            "examples": [
              "public",
              "\"MyCaseSensitiveSchemaNeedingQuotes\""
            ],
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          },
          {
            "description": "A list of table names to include in the logical replication. Each table should be specified as a separate item.",
            "examples": [
              [
                "my_table_1",
                "\"MyCaseSensitiveTableNeedingQuotes\""
              ]
            ],
            "kind": "array",
            "name": "tables",
            "type": "string"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages that can be processed at a given time. Increasing this limit enables parallel processing and batching at the output level. Any given LSN will not be acknowledged unless all messages under that offset are delivered in order to preserve at least once delivery guarantees.",
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int"
          },
          {
            "default": false,
            "description": "If set to true, creates a temporary replication slot that is automatically dropped when the connection is closed.",
            "kind": "scalar",
            "name": "temporary_slot",
            "type": "bool"
          },
          {
            "description": "The name of the PostgreSQL logical replication slot to use. If not provided, a random name will be generated. You can create this slot manually before starting replication if desired.",
            "examples": [
              "my_test_slot"
            ],
            "kind": "scalar",
            "name": "slot_name",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "Specify the standby timeout before refreshing an idle connection.",
            "examples": [
              "30s"
            ],
            "kind": "scalar",
            "name": "pg_standby_timeout",
            "type": "string"
          },
          {
            "default": "3s",
            "description": "How often to report changes to the replication lag.",
            "examples": [
              "6s"
            ],
            "kind": "scalar",
            "name": "pg_wal_monitor_interval",
            "type": "string"
          },
          {
            "default": 1,
            "description": "Int specifies a number of tables that will be processed in parallel during the snapshot processing stage",
            "kind": "scalar",
            "name": "max_parallel_snapshot_tables",
            "type": "int"
          },
          {
            "default": null,
            "description": "The value to emit when there are unchanged TOAST values in the stream. This occurs for updates and deletes where REPLICA IDENTITY is not FULL.",
            "examples": [
              "__redpanda_connect_unchanged_toast_value__"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "unchanged_toast_value",
            "type": "unknown"
          },
          {
            "default": "1h",
            "description": "The interval at which to write heartbeat messages. Heartbeat messages are needed in scenarios when the subscribed tables are low frequency, but there are other high frequency tables writing. Due to the checkpointing mechanism for replication slots, not having new messages to acknowledge will prevent postgres from reclaiming the write ahead log, which can exhaust the local disk. Having heartbeats allows Redpanda Connect to safely acknowledge data periodically and move forward the committed point in the log so it can be reclaimed. Setting the duration to 0s will disable heartbeats entirely. Heartbeats are created by periodically writing logical messages to the write ahead log using `pg_logical_emit_message`.",
            "examples": [
              "0s",
              "24h"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Streams changes from a PostgreSQL database for Change Data Capture (CDC).\nAdditionally, if `stream_snapshot` is set to true, then the existing data in the database is also streamed too.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n- table (Name of the table that the message originated from)\n- operation (Type of operation that generated the message: \"read\", \"insert\", \"update\", or \"delete\". \"read\" is from messages that are read in the initial snapshot phase. This will also be \"begin\" and \"commit\" if `include_transaction_markers` is enabled)\n- lsn (the log sequence number in postgres)\n\t\t",
      "name": "pg_stream",
      "plugin": true,
      "status": "deprecated",
      "summary": "Streams changes from a PostgreSQL database using logical replication.",
      "type": "input",
      "version": "4.39.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The Data Source Name for the PostgreSQL database in the form of `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]`. Please note that Postgres enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.",
            "examples": [
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "default": false,
            "description": "When set to true, empty messages with operation types BEGIN and COMMIT are generated for the beginning and end of each transaction. Messages with operation metadata set to \"begin\" or \"commit\" will have null message payloads.",
            "kind": "scalar",
            "name": "include_transaction_markers",
            "type": "bool"
          },
          {
            "default": false,
            "description": "When set to true, the plugin will first stream a snapshot of all existing data in the database before streaming changes. In order to use this the tables that are being snapshot MUST have a primary key set so that reading from the table can be parallelized.",
            "examples": [
              true
            ],
            "kind": "scalar",
            "name": "stream_snapshot",
            "type": "bool"
          },
          {
            "default": 1,
            "description": "Determines the fraction of available memory that can be used for streaming the snapshot. Values between 0 and 1 represent the percentage of memory to use. Lower values make initial streaming slower but help prevent out-of-memory errors.",
            "examples": [
              0.2
            ],
            "is_deprecated": true,
            "kind": "scalar",
            "name": "snapshot_memory_safety_factor",
            "type": "float"
          },
          {
            "default": 1000,
            "description": "The number of rows to fetch in each batch when querying the snapshot.",
            "examples": [
              10000
            ],
            "kind": "scalar",
            "name": "snapshot_batch_size",
            "type": "int"
          },
          {
            "description": "The PostgreSQL schema from which to replicate data.",
            "examples": [
              "public",
              "\"MyCaseSensitiveSchemaNeedingQuotes\""
            ],
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          },
          {
            "description": "A list of table names to include in the logical replication. Each table should be specified as a separate item.",
            "examples": [
              [
                "my_table_1",
                "\"MyCaseSensitiveTableNeedingQuotes\""
              ]
            ],
            "kind": "array",
            "name": "tables",
            "type": "string"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages that can be processed at a given time. Increasing this limit enables parallel processing and batching at the output level. Any given LSN will not be acknowledged unless all messages under that offset are delivered in order to preserve at least once delivery guarantees.",
            "kind": "scalar",
            "name": "checkpoint_limit",
            "type": "int"
          },
          {
            "default": false,
            "description": "If set to true, creates a temporary replication slot that is automatically dropped when the connection is closed.",
            "kind": "scalar",
            "name": "temporary_slot",
            "type": "bool"
          },
          {
            "description": "The name of the PostgreSQL logical replication slot to use. If not provided, a random name will be generated. You can create this slot manually before starting replication if desired.",
            "examples": [
              "my_test_slot"
            ],
            "kind": "scalar",
            "name": "slot_name",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "Specify the standby timeout before refreshing an idle connection.",
            "examples": [
              "30s"
            ],
            "kind": "scalar",
            "name": "pg_standby_timeout",
            "type": "string"
          },
          {
            "default": "3s",
            "description": "How often to report changes to the replication lag.",
            "examples": [
              "6s"
            ],
            "kind": "scalar",
            "name": "pg_wal_monitor_interval",
            "type": "string"
          },
          {
            "default": 1,
            "description": "Int specifies a number of tables that will be processed in parallel during the snapshot processing stage",
            "kind": "scalar",
            "name": "max_parallel_snapshot_tables",
            "type": "int"
          },
          {
            "default": null,
            "description": "The value to emit when there are unchanged TOAST values in the stream. This occurs for updates and deletes where REPLICA IDENTITY is not FULL.",
            "examples": [
              "__redpanda_connect_unchanged_toast_value__"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "unchanged_toast_value",
            "type": "unknown"
          },
          {
            "default": "1h",
            "description": "The interval at which to write heartbeat messages. Heartbeat messages are needed in scenarios when the subscribed tables are low frequency, but there are other high frequency tables writing. Due to the checkpointing mechanism for replication slots, not having new messages to acknowledge will prevent postgres from reclaiming the write ahead log, which can exhaust the local disk. Having heartbeats allows Redpanda Connect to safely acknowledge data periodically and move forward the committed point in the log so it can be reclaimed. Setting the duration to 0s will disable heartbeats entirely. Heartbeats are created by periodically writing logical messages to the write ahead log using `pg_logical_emit_message`.",
            "examples": [
              "0s",
              "24h"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Streams changes from a PostgreSQL database for Change Data Capture (CDC).\nAdditionally, if `stream_snapshot` is set to true, then the existing data in the database is also streamed too.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n- table (Name of the table that the message originated from)\n- operation (Type of operation that generated the message: \"read\", \"insert\", \"update\", or \"delete\". \"read\" is from messages that are read in the initial snapshot phase. This will also be \"begin\" and \"commit\" if `include_transaction_markers` is enabled)\n- lsn (the log sequence number in postgres)\n\t\t",
      "name": "postgres_cdc",
      "plugin": true,
      "status": "beta",
      "summary": "Streams changes from a PostgreSQL database using logical replication.",
      "type": "input",
      "version": "4.39.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A URL to connect to.",
            "examples": [
              "pulsar://localhost:6650",
              "pulsar://pulsar.us-west.example.com:6650",
              "pulsar+ssl://pulsar.us-west.example.com:6651"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "A list of topics to subscribe to. This or topics_pattern must be set.",
            "is_optional": true,
            "kind": "array",
            "name": "topics",
            "type": "string"
          },
          {
            "description": "A regular expression matching the topics to subscribe to. This or topics must be set.",
            "is_optional": true,
            "kind": "scalar",
            "name": "topics_pattern",
            "type": "string"
          },
          {
            "description": "Specify the subscription name for this consumer.",
            "kind": "scalar",
            "name": "subscription_name",
            "type": "string"
          },
          {
            "default": "shared",
            "description": "Specify the subscription type for this consumer.\n\n> NOTE: Using a `key_shared` subscription type will __allow out-of-order delivery__ since nack-ing messages sets non-zero nack delivery delay - this can potentially cause consumers to stall. See https://pulsar.apache.org/docs/en/2.8.1/concepts-messaging/#negative-acknowledgement[Pulsar documentation^] and https://github.com/apache/pulsar/issues/12208[this Github issue^] for more details.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"shared\": true,\n  \"key_shared\": true,\n  \"failover\": true,\n  \"exclusive\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "subscription_type",
            "options": [
              "shared",
              "key_shared",
              "failover",
              "exclusive"
            ],
            "type": "string"
          },
          {
            "default": "latest",
            "description": "Specify the subscription initial position for this consumer.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"latest\": true,\n  \"earliest\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "subscription_initial_position",
            "options": [
              "latest",
              "earliest"
            ],
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              }
            ],
            "description": "Specify the path to a custom CA certificate to trust broker TLS service.",
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether OAuth2 is enabled.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "OAuth2 audience.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "audience",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "OAuth2 issuer URL.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "issuer_url",
                    "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "OAuth2 scope to request.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "scope",
                    "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path to a file containing a private key.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "private_key_file",
                    "type": "string"
                  }
                ],
                "description": "Parameters for Pulsar OAuth2 authentication.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "oauth2",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether Token Auth is enabled.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "Actual base64 encoded token.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "token",
                    "type": "string"
                  }
                ],
                "description": "Parameters for Pulsar Token authentication.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "object"
              }
            ],
            "description": "Optional configuration of Pulsar authentication methods.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object",
            "version": "3.60.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- pulsar_message_id\n- pulsar_key\n- pulsar_ordering_key\n- pulsar_event_time_unix\n- pulsar_publish_time_unix\n- pulsar_topic\n- pulsar_producer_name\n- pulsar_redelivery_count\n- All properties of the message\n```\n\nYou can access these metadata fields using\nxref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n",
      "name": "pulsar",
      "plugin": true,
      "status": "experimental",
      "summary": "Reads messages from an Apache Pulsar server.",
      "type": "input",
      "version": "3.43.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The child input to consume from.",
            "kind": "scalar",
            "name": "input",
            "type": "input"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether the input should now be closed.",
            "examples": [
              "this.type == \"foo\"",
              "count(\"messages\") >= 100"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "check",
            "type": "string"
          },
          {
            "description": "The maximum amount of time without receiving new messages after which the input is closed.",
            "examples": [
              "5s"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "idle_timeout",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether the input should be reopened if it closes itself before the condition has resolved to true.",
            "kind": "scalar",
            "name": "restart_input",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nMessages are read continuously while the query check returns false, when the query returns true the message that triggered the check is sent out and the input is closed. Use this to define inputs where the stream should end once a certain message appears.\n\nIf the idle timeout is configured, the input will be closed if no new messages arrive after that period of time. Use this field if you want to empty out and close an input that doesn't have a logical end.\n\nSometimes inputs close themselves. For example, when the `file` input type reaches the end of a file it will shut down. By default this type will also shut down. If you wish for the input type to be restarted every time it shuts down until the query check is met then set `restart_input` to `true`.\n\n== Metadata\n\nA metadata key `benthos_read_until` containing the value `final` is added to the first part of the message that triggers the input to stop.",
      "examples": [
        {
          "config": "\n# Only read 100 messages, and then exit.\ninput:\n  read_until:\n    check: count(\"messages\") >= 100\n    input:\n      kafka:\n        addresses: [ TODO ]\n        topics: [ foo, bar ]\n        consumer_group: foogroup\n",
          "summary": "A common reason to use this input is to consume only N messages from an input and then stop. This can easily be done with the xref:guides:bloblang/functions.adoc#count[`count` function]:",
          "title": "Consume N Messages"
        },
        {
          "config": "\n# Consumes all messages and exit when the last message was consumed 5s ago.\ninput:\n  read_until:\n    idle_timeout: 5s\n    input:\n      kafka:\n        addresses: [ TODO ]\n        topics: [ foo, bar ]\n        consumer_group: foogroup\n",
          "summary": "A common reason to use this input is a job that consumes all messages and exits once its empty:",
          "title": "Read from a kafka and close when empty"
        }
      ],
      "name": "read_until",
      "plugin": true,
      "status": "stable",
      "summary": "Reads messages from a child input until a consumed message passes a xref:guides:bloblang/about.adoc[Bloblang query], at which point the input closes. It is also possible to configure a timeout after which the input is closed if no new messages arrive in that period.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The key of a list to read from.",
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": 0,
            "description": "Optionally sets a limit on the number of messages that can be flowing through a Redpanda Connect stream pending acknowledgment from the input at any given time. Once a message has been either acknowledged or rejected (nacked) it is no longer considered pending. If the input produces logical batches then each batch is considered a single count against the maximum. **WARNING**: Batching policies at the output level will stall if this field limits the number of messages below the batching threshold. Zero (default) or lower implies no limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int",
            "version": "4.9.0"
          },
          {
            "default": "5s",
            "description": "The length of time to poll for new messages before reattempting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "blpop",
            "description": "The command used to pop elements from the Redis list",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"blpop\": true,\n  \"brpop\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "command",
            "options": [
              "blpop",
              "brpop"
            ],
            "type": "string",
            "version": "4.22.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "redis_list",
      "plugin": true,
      "status": "stable",
      "summary": "Pops messages from the beginning of a Redis list using the BLPop command.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "A list of channels to consume from.",
            "kind": "array",
            "name": "channels",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to use the PSUBSCRIBE command, allowing for glob-style patterns within target channel names.",
            "kind": "scalar",
            "name": "use_patterns",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIn order to subscribe to channels using the `PSUBSCRIBE` command set the field `use_patterns` to `true`, then you can include glob-style patterns in your channel names. For example:\n\n- `h?llo` subscribes to hello, hallo and hxllo\n- `h*llo` subscribes to hllo and heeeello\n- `h[ae]llo` subscribes to hello and hallo, but not hillo\n\nUse `\\` to escape special characters if you want to match them verbatim.",
      "name": "redis_pubsub",
      "plugin": true,
      "status": "stable",
      "summary": "Consume from a Redis publish/subscribe channel using either the SUBSCRIBE or PSUBSCRIBE commands.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": "",
            "description": "Iterates only elements matching the optional glob-style pattern. By default, it matches all elements.",
            "examples": [
              "*",
              "1*",
              "foo*",
              "foo",
              "*4*"
            ],
            "kind": "scalar",
            "name": "match",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Optionally, iterates only elements matching a blob-style pattern. For example:\n\n- `*foo*` iterates only keys which contain `foo` in it.\n- `foo*` iterates only keys starting with `foo`.\n\nThis input generates a message for each key value pair in the following format:\n\n```json\n{\"key\":\"foo\",\"value\":\"bar\"}\n```\n",
      "name": "redis_scan",
      "plugin": true,
      "status": "experimental",
      "summary": "Scans the set of keys in the current selected database and gets their values, using the Scan and Get commands.",
      "type": "input",
      "version": "4.27.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": "body",
            "description": "The field key to extract the raw message from. All other keys will be stored in the message as metadata.",
            "kind": "scalar",
            "name": "body_key",
            "type": "string"
          },
          {
            "description": "A list of streams to consume from.",
            "kind": "array",
            "name": "streams",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "default": 10,
            "description": "The maximum number of messages to consume from a single request.",
            "kind": "scalar",
            "name": "limit",
            "type": "int"
          },
          {
            "default": "",
            "description": "An identifier for the client connection.",
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "An identifier for the consumer group of the stream.",
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "default": true,
            "description": "Create subscribed streams if they do not exist (MKSTREAM option).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "create_streams",
            "type": "bool"
          },
          {
            "default": true,
            "description": "If an offset is not found for a stream, determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "default": "1s",
            "description": "The period of time between each commit of the current offset. Offsets are always committed during shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": "1s",
            "description": "The length of time to poll for new messages before reattempting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Redis stream entries are key/value pairs, as such it is necessary to specify the key that contains the body of the message. All other keys/value pairs are saved as metadata fields.",
      "name": "redis_streams",
      "plugin": true,
      "status": "stable",
      "summary": "Pulls messages from Redis (v5.0+) streams with the XREADGROUP command. The `client_id` should be unique for each consumer of a group.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "\nA list of topics to consume from. Multiple comma separated topics can be listed in a single element. When a `consumer_group` is specified partitions are automatically distributed across consumers of a topic, otherwise all partitions are consumed.\n\nAlternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive.\n\nFinally, it's also possible to specify an explicit offset to consume from by adding another colon after the partition, e.g. `foo:0:10` would consume the partition 0 of the topic foo starting from the offset 10. If the offset is not present (or remains unspecified) then the field `start_from_oldest` determines which offset to start from.",
            "examples": [
              [
                "foo",
                "bar"
              ],
              [
                "things.*"
              ],
              [
                "foo,bar"
              ],
              [
                "foo:0",
                "bar:1",
                "bar:3"
              ],
              [
                "foo:0,bar:1,bar:3"
              ],
              [
                "foo:0-5"
              ]
            ],
            "kind": "array",
            "name": "topics",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether listed topics should be interpreted as regular expression patterns for matching multiple topics. When enabled, the client will periodically refresh the list of matching topics based on the `metadata_max_age` interval. When topics are specified with explicit partitions this field must remain set to `false`.",
            "kind": "scalar",
            "name": "regexp_topics",
            "type": "bool"
          },
          {
            "default": "",
            "description": "A rack specifies where the client is physically located and changes fetch requests to consume from the closest replica as opposed to the leader replica.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "When using a consumer group, an instance ID specifies the groups static membership, which can prevent rebalances during reconnects. When using a instance ID the client does NOT leave the group when closing. To actually leave the group one must use an external admin command to leave the group on behalf of this instance ID. This ID must be unique per consumer within the group.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "instance_id",
            "type": "string"
          },
          {
            "default": "45s",
            "description": "When using a consumer group, `rebalance_timeout` sets how long group members are allowed to take when a rebalance has begun. This timeout is how long all members are allowed to complete work and commit offsets, minus the time it took to detect the rebalance (from a heartbeat).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rebalance_timeout",
            "type": "string"
          },
          {
            "default": "1m",
            "description": "When using a consumer group, `session_timeout` sets how long a member in hte group can go between heartbeats. If a member does not heartbeat in this timeout, the broker will remove the member from the group and initiate a rebalance.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "session_timeout",
            "type": "string"
          },
          {
            "default": "3s",
            "description": "When using a consumer group, `heartbeat_interval` sets how long a group member goes between heartbeats to Kafka. Kafka uses heartbeats to ensure that a group member's sesion stays active. This value should be no higher than 1/3rd of the `session_timeout`. This is equivalent to the Java heartbeat.interval.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset. The setting is applied when creating a new consumer group or the saved offset no longer exists.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "committed",
                "Prevents consuming a partition in a group if the partition has no prior commits. Corresponds to Kafka's `auto.offset.reset=none` option"
              ],
              [
                "earliest",
                "Start from the earliest offset. Corresponds to Kafka's `auto.offset.reset=earliest` option."
              ],
              [
                "latest",
                "Start from the latest offset. Corresponds to Kafka's `auto.offset.reset=latest` option."
              ]
            ],
            "default": "earliest",
            "description": "Sets the offset to start consuming from, or if OffsetOutOfRange is seen while fetching, to restart consuming from.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"committed\": true,\n  \"earliest\": true,\n  \"latest\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "start_offset",
            "type": "string"
          },
          {
            "default": "50MiB",
            "description": "Sets the maximum amount of bytes a broker will try to send during a fetch. Note that brokers may not obey this limit if it has records larger than this limit. This is the equivalent to the Java fetch.max.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "Sets the maximum amount of time a broker will wait for a fetch response to hit the minimum number of required bytes. This is the equivalent to the Java fetch.max.wait.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_wait",
            "type": "string"
          },
          {
            "default": "1B",
            "description": "Sets the minimum amount of bytes a broker will try to send during a fetch. This is the equivalent to the Java fetch.min.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_min_bytes",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "Sets the maximum amount of bytes that will be consumed for a single partition in a fetch request. Note that if a single batch is larger than this number, that batch will still be returned so the client can make progress. This is the equivalent to the Java fetch.max.partition.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_partition_bytes",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "read_committed",
                "If set, only committed transactional records are processed."
              ],
              [
                "read_uncommitted",
                "If set, then uncommitted records are processed."
              ]
            ],
            "default": "read_uncommitted",
            "description": "The transaction isolation level",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"read_committed\": true,\n  \"read_uncommitted\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transaction_isolation_level",
            "type": "string"
          },
          {
            "description": "An optional consumer group to consume as. When specified the partitions of specified topics are automatically distributed across consumers sharing a consumer group, and partition offsets are automatically committed and resumed under this name. Consumer groups are not supported when specifying explicit partitions to consume from in the `topics` field.",
            "is_optional": true,
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period of time between each commit of the current partition offsets. Offsets are always committed during shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": "1MB",
            "description": "A buffer size (in bytes) for each consumed partition, allowing records to be queued internally before flushing. Increasing this may improve throughput at the cost of higher memory utilisation. Note that each buffer can grow slightly beyond this value.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "partition_buffer_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period of time between each topic lag refresh cycle.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "topic_lag_refresh_period",
            "type": "string"
          },
          {
            "default": "32KB",
            "description": "The maximum size (in bytes) for each batch yielded by this input. When routed to a redpanda output without modification this would roughly translate to the batch.bytes config field of a traditional producer.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_yield_batch_bytes",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "EXPERIMENTAL: Specify a maximum period of time in which each message can be consumed and awaiting either acknowledgement or rejection before rejection is instead forced. This can be useful for avoiding situations where certain downstream components can result in blocked confirmation of delivery that exceeds SLAs.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timely_nacks_maximum_wait",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "\nlet has_topic_partitions = this.topics.any(t -> t.contains(\":\"))\n\nroot = [\n  if $has_topic_partitions {\n    if this.consumer_group.or(\"\") != \"\" {\n      \"this input does not support both a consumer group and explicit topic partitions\"\n    } else if this.regexp_topics {\n      \"this input does not support both regular expression topics and explicit topic partitions\"\n    }\n  } else {\n    if this.consumer_group.or(\"\") == \"\" {\n      \"a consumer group is mandatory when not using explicit topic partitions\"\n    }\n  },\n  # We don't have any way to distinguish between start_from_oldest set explicitly to true and not set at all, so we\n  # assume users will be OK if start_offset overwrites it silently\n  if this.start_from_oldest == false && this.start_offset == \"earliest\" {\n    \"start_from_oldest cannot be set to false when start_offset is set to earliest\"\n  }\n]\n",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen a consumer group is specified this input consumes one or more topics where partitions will automatically balance across any other connected clients with the same consumer group. When a consumer group is not specified topics can either be consumed in their entirety or with explicit partitions.\n\n== Delivery Guarantees\n\nWhen using consumer groups the offsets of \"delivered\" records will be committed automatically and continuously, and in the event of restarts these committed offsets will be used in order to resume from where the input left off. Redpanda Connect guarantees at least once delivery by ensuring that records are only considerd to be delivered when all configured outputs that the record is routed to have confirmed delivery.\n\n== Ordering\n\nIn order to preserve ordering of topic partitions, records consumed from each partition are processed and delivered in the order that they are received, and only one batch of records of a given partition will ever be processed at a time. This means that parallel processing can only occur when multiple topic partitions are being consumed, but ensures that data is processed in a sequential order as determined from the source partition.\n\nHowever, one way in which the order of records can be mixed is when delivery errors occur and error handling mechanisms kick in. Redpanda Connect always leans towards at least once delivery unless instructed otherwise, and this includes reattempting delivery of data when the ordering of that data can no longer be guaranteed.\n\nFor example, a batch of records may have been sent to an output broker and only a subset of records were delivered, in this case Redpanda Connect by default will reattempt to deliver the records that failed, even though these failed records may have come before records that were previously delivered successfully.\n\nIn order to avoid this scenario you must specify in your configuration an alternative way to handle delivery errors in the form of a xref:components:outputs/fallback.adoc[`fallback`] output. It is good practice to also disable the field `auto_retry_nacks` by setting it to `false` when you've added an explicit fallback output as this will improve the throughput of your pipeline. For example, the following config avoids ordering issues by specifying a fallback output into a DLQ topic, which is also retried indefinitely as a way to apply back pressure during connectivity issues:\n\n```yaml\noutput:\n  fallback:\n    - redpanda:\n        seed_brokers: [ localhost:9092 ]\n        topic: foo\n    - retry:\n        output:\n          redpanda:\n            seed_brokers: [ localhost:9092 ]\n            topic: foo_dlq\n```\n\n== Batching\n\nRecords are processed and delivered from each partition in batches as received from brokers. These batch sizes are therefore dynamically sized in order to optimise throughput, but can be tuned with the config fields `fetch_max_partition_bytes` and `fetch_max_bytes`. Batches can be further broken down using the xref:components:processors/split.adoc[`split`] processor.\n\n== Metrics\n\nEmits a `redpanda_lag` metric with `topic` and `partition` labels for each consumed topic.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- kafka_key\n- kafka_topic\n- kafka_partition\n- kafka_offset\n- kafka_lag\n- kafka_timestamp_ms\n- kafka_timestamp_unix\n- kafka_tombstone_message\n- All record headers\n```\n",
      "name": "redpanda",
      "plugin": true,
      "status": "beta",
      "summary": "A Kafka input using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "\nA list of topics to consume from. Multiple comma separated topics can be listed in a single element. When a `consumer_group` is specified partitions are automatically distributed across consumers of a topic, otherwise all partitions are consumed.\n\nAlternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive.\n\nFinally, it's also possible to specify an explicit offset to consume from by adding another colon after the partition, e.g. `foo:0:10` would consume the partition 0 of the topic foo starting from the offset 10. If the offset is not present (or remains unspecified) then the field `start_from_oldest` determines which offset to start from.",
            "examples": [
              [
                "foo",
                "bar"
              ],
              [
                "things.*"
              ],
              [
                "foo,bar"
              ],
              [
                "foo:0",
                "bar:1",
                "bar:3"
              ],
              [
                "foo:0,bar:1,bar:3"
              ],
              [
                "foo:0-5"
              ]
            ],
            "kind": "array",
            "name": "topics",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether listed topics should be interpreted as regular expression patterns for matching multiple topics. When enabled, the client will periodically refresh the list of matching topics based on the `metadata_max_age` interval. When topics are specified with explicit partitions this field must remain set to `false`.",
            "kind": "scalar",
            "name": "regexp_topics",
            "type": "bool"
          },
          {
            "default": "",
            "description": "A rack specifies where the client is physically located and changes fetch requests to consume from the closest replica as opposed to the leader replica.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "When using a consumer group, an instance ID specifies the groups static membership, which can prevent rebalances during reconnects. When using a instance ID the client does NOT leave the group when closing. To actually leave the group one must use an external admin command to leave the group on behalf of this instance ID. This ID must be unique per consumer within the group.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "instance_id",
            "type": "string"
          },
          {
            "default": "45s",
            "description": "When using a consumer group, `rebalance_timeout` sets how long group members are allowed to take when a rebalance has begun. This timeout is how long all members are allowed to complete work and commit offsets, minus the time it took to detect the rebalance (from a heartbeat).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rebalance_timeout",
            "type": "string"
          },
          {
            "default": "1m",
            "description": "When using a consumer group, `session_timeout` sets how long a member in hte group can go between heartbeats. If a member does not heartbeat in this timeout, the broker will remove the member from the group and initiate a rebalance.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "session_timeout",
            "type": "string"
          },
          {
            "default": "3s",
            "description": "When using a consumer group, `heartbeat_interval` sets how long a group member goes between heartbeats to Kafka. Kafka uses heartbeats to ensure that a group member's sesion stays active. This value should be no higher than 1/3rd of the `session_timeout`. This is equivalent to the Java heartbeat.interval.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset. The setting is applied when creating a new consumer group or the saved offset no longer exists.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "committed",
                "Prevents consuming a partition in a group if the partition has no prior commits. Corresponds to Kafka's `auto.offset.reset=none` option"
              ],
              [
                "earliest",
                "Start from the earliest offset. Corresponds to Kafka's `auto.offset.reset=earliest` option."
              ],
              [
                "latest",
                "Start from the latest offset. Corresponds to Kafka's `auto.offset.reset=latest` option."
              ]
            ],
            "default": "earliest",
            "description": "Sets the offset to start consuming from, or if OffsetOutOfRange is seen while fetching, to restart consuming from.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"committed\": true,\n  \"earliest\": true,\n  \"latest\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "start_offset",
            "type": "string"
          },
          {
            "default": "50MiB",
            "description": "Sets the maximum amount of bytes a broker will try to send during a fetch. Note that brokers may not obey this limit if it has records larger than this limit. This is the equivalent to the Java fetch.max.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "Sets the maximum amount of time a broker will wait for a fetch response to hit the minimum number of required bytes. This is the equivalent to the Java fetch.max.wait.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_wait",
            "type": "string"
          },
          {
            "default": "1B",
            "description": "Sets the minimum amount of bytes a broker will try to send during a fetch. This is the equivalent to the Java fetch.min.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_min_bytes",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "Sets the maximum amount of bytes that will be consumed for a single partition in a fetch request. Note that if a single batch is larger than this number, that batch will still be returned so the client can make progress. This is the equivalent to the Java fetch.max.partition.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_partition_bytes",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "read_committed",
                "If set, only committed transactional records are processed."
              ],
              [
                "read_uncommitted",
                "If set, then uncommitted records are processed."
              ]
            ],
            "default": "read_uncommitted",
            "description": "The transaction isolation level",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"read_committed\": true,\n  \"read_uncommitted\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transaction_isolation_level",
            "type": "string"
          },
          {
            "description": "An optional consumer group to consume as. When specified the partitions of specified topics are automatically distributed across consumers sharing a consumer group, and partition offsets are automatically committed and resumed under this name. Consumer groups are not supported when specifying explicit partitions to consume from in the `topics` field.",
            "is_optional": true,
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period of time between each commit of the current partition offsets. Offsets are always committed during shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": "1MB",
            "description": "A buffer size (in bytes) for each consumed partition, allowing records to be queued internally before flushing. Increasing this may improve throughput at the cost of higher memory utilisation. Note that each buffer can grow slightly beyond this value.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "partition_buffer_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period of time between each topic lag refresh cycle.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "topic_lag_refresh_period",
            "type": "string"
          },
          {
            "default": "32KB",
            "description": "The maximum size (in bytes) for each batch yielded by this input. When routed to a redpanda output without modification this would roughly translate to the batch.bytes config field of a traditional producer.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_yield_batch_bytes",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "EXPERIMENTAL: Specify a maximum period of time in which each message can be consumed and awaiting either acknowledgement or rejection before rejection is instead forced. This can be useful for avoiding situations where certain downstream components can result in blocked confirmation of delivery that exceeds SLAs.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timely_nacks_maximum_wait",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "\nlet has_topic_partitions = this.topics.any(t -> t.contains(\":\"))\n\nroot = [\n  if $has_topic_partitions {\n    if this.consumer_group.or(\"\") != \"\" {\n      \"this input does not support both a consumer group and explicit topic partitions\"\n    } else if this.regexp_topics {\n      \"this input does not support both regular expression topics and explicit topic partitions\"\n    }\n  } else {\n    if this.consumer_group.or(\"\") == \"\" {\n      \"a consumer group is mandatory when not using explicit topic partitions\"\n    }\n  },\n  # We don't have any way to distinguish between start_from_oldest set explicitly to true and not set at all, so we\n  # assume users will be OK if start_offset overwrites it silently\n  if this.start_from_oldest == false && this.start_offset == \"earliest\" {\n    \"start_from_oldest cannot be set to false when start_offset is set to earliest\"\n  }\n]\n",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen a consumer group is specified this input consumes one or more topics where partitions will automatically balance across any other connected clients with the same consumer group. When a consumer group is not specified topics can either be consumed in their entirety or with explicit partitions.\n\n== Delivery Guarantees\n\nWhen using consumer groups the offsets of \"delivered\" records will be committed automatically and continuously, and in the event of restarts these committed offsets will be used in order to resume from where the input left off. Redpanda Connect guarantees at least once delivery by ensuring that records are only considerd to be delivered when all configured outputs that the record is routed to have confirmed delivery.\n\n== Ordering\n\nIn order to preserve ordering of topic partitions, records consumed from each partition are processed and delivered in the order that they are received, and only one batch of records of a given partition will ever be processed at a time. This means that parallel processing can only occur when multiple topic partitions are being consumed, but ensures that data is processed in a sequential order as determined from the source partition.\n\nHowever, one way in which the order of records can be mixed is when delivery errors occur and error handling mechanisms kick in. Redpanda Connect always leans towards at least once delivery unless instructed otherwise, and this includes reattempting delivery of data when the ordering of that data can no longer be guaranteed.\n\nFor example, a batch of records may have been sent to an output broker and only a subset of records were delivered, in this case Redpanda Connect by default will reattempt to deliver the records that failed, even though these failed records may have come before records that were previously delivered successfully.\n\nIn order to avoid this scenario you must specify in your configuration an alternative way to handle delivery errors in the form of a xref:components:outputs/fallback.adoc[`fallback`] output. It is good practice to also disable the field `auto_retry_nacks` by setting it to `false` when you've added an explicit fallback output as this will improve the throughput of your pipeline. For example, the following config avoids ordering issues by specifying a fallback output into a DLQ topic, which is also retried indefinitely as a way to apply back pressure during connectivity issues:\n\n```yaml\noutput:\n  fallback:\n    - redpanda_common:\n        topic: foo\n    - retry:\n        output:\n          redpanda_common:\n            topic: foo_dlq\n```\n\n== Batching\n\nRecords are processed and delivered from each partition in batches as received from brokers. These batch sizes are therefore dynamically sized in order to optimise throughput, but can be tuned with the config fields `fetch_max_partition_bytes` and `fetch_max_bytes`. Batches can be further broken down using the xref:components:processors/split.adoc[`split`] processor.\n\n== Metrics\n\nEmits a `redpanda_lag` metric with `topic` and `partition` labels for each consumed topic.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- kafka_key\n- kafka_topic\n- kafka_partition\n- kafka_offset\n- kafka_lag\n- kafka_timestamp_ms\n- kafka_timestamp_unix\n- kafka_tombstone_message\n- All record headers\n```\n",
      "name": "redpanda_common",
      "plugin": true,
      "status": "beta",
      "summary": "Consumes data from a Redpanda (Kafka) broker, using credentials defined in a common top-level `redpanda` config block.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "\nA list of topics to consume from. Multiple comma separated topics can be listed in a single element. When a `consumer_group` is specified partitions are automatically distributed across consumers of a topic, otherwise all partitions are consumed.\n\nAlternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive.\n\nFinally, it's also possible to specify an explicit offset to consume from by adding another colon after the partition, e.g. `foo:0:10` would consume the partition 0 of the topic foo starting from the offset 10. If the offset is not present (or remains unspecified) then the field `start_from_oldest` determines which offset to start from.",
            "examples": [
              [
                "foo",
                "bar"
              ],
              [
                "things.*"
              ],
              [
                "foo,bar"
              ],
              [
                "foo:0",
                "bar:1",
                "bar:3"
              ],
              [
                "foo:0,bar:1,bar:3"
              ],
              [
                "foo:0-5"
              ]
            ],
            "kind": "array",
            "name": "topics",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether listed topics should be interpreted as regular expression patterns for matching multiple topics. When enabled, the client will periodically refresh the list of matching topics based on the `metadata_max_age` interval. When topics are specified with explicit partitions this field must remain set to `false`.",
            "kind": "scalar",
            "name": "regexp_topics",
            "type": "bool"
          },
          {
            "default": "",
            "description": "A rack specifies where the client is physically located and changes fetch requests to consume from the closest replica as opposed to the leader replica.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "When using a consumer group, an instance ID specifies the groups static membership, which can prevent rebalances during reconnects. When using a instance ID the client does NOT leave the group when closing. To actually leave the group one must use an external admin command to leave the group on behalf of this instance ID. This ID must be unique per consumer within the group.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "instance_id",
            "type": "string"
          },
          {
            "default": "45s",
            "description": "When using a consumer group, `rebalance_timeout` sets how long group members are allowed to take when a rebalance has begun. This timeout is how long all members are allowed to complete work and commit offsets, minus the time it took to detect the rebalance (from a heartbeat).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rebalance_timeout",
            "type": "string"
          },
          {
            "default": "1m",
            "description": "When using a consumer group, `session_timeout` sets how long a member in hte group can go between heartbeats. If a member does not heartbeat in this timeout, the broker will remove the member from the group and initiate a rebalance.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "session_timeout",
            "type": "string"
          },
          {
            "default": "3s",
            "description": "When using a consumer group, `heartbeat_interval` sets how long a group member goes between heartbeats to Kafka. Kafka uses heartbeats to ensure that a group member's sesion stays active. This value should be no higher than 1/3rd of the `session_timeout`. This is equivalent to the Java heartbeat.interval.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "heartbeat_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Determines whether to consume from the oldest available offset, otherwise messages are consumed from the latest offset. The setting is applied when creating a new consumer group or the saved offset no longer exists.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "start_from_oldest",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "committed",
                "Prevents consuming a partition in a group if the partition has no prior commits. Corresponds to Kafka's `auto.offset.reset=none` option"
              ],
              [
                "earliest",
                "Start from the earliest offset. Corresponds to Kafka's `auto.offset.reset=earliest` option."
              ],
              [
                "latest",
                "Start from the latest offset. Corresponds to Kafka's `auto.offset.reset=latest` option."
              ]
            ],
            "default": "earliest",
            "description": "Sets the offset to start consuming from, or if OffsetOutOfRange is seen while fetching, to restart consuming from.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"committed\": true,\n  \"earliest\": true,\n  \"latest\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "start_offset",
            "type": "string"
          },
          {
            "default": "50MiB",
            "description": "Sets the maximum amount of bytes a broker will try to send during a fetch. Note that brokers may not obey this limit if it has records larger than this limit. This is the equivalent to the Java fetch.max.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "Sets the maximum amount of time a broker will wait for a fetch response to hit the minimum number of required bytes. This is the equivalent to the Java fetch.max.wait.ms setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_wait",
            "type": "string"
          },
          {
            "default": "1B",
            "description": "Sets the minimum amount of bytes a broker will try to send during a fetch. This is the equivalent to the Java fetch.min.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_min_bytes",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "Sets the maximum amount of bytes that will be consumed for a single partition in a fetch request. Note that if a single batch is larger than this number, that batch will still be returned so the client can make progress. This is the equivalent to the Java fetch.max.partition.bytes setting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_max_partition_bytes",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "read_committed",
                "If set, only committed transactional records are processed."
              ],
              [
                "read_uncommitted",
                "If set, then uncommitted records are processed."
              ]
            ],
            "default": "read_uncommitted",
            "description": "The transaction isolation level",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"read_committed\": true,\n  \"read_uncommitted\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transaction_isolation_level",
            "type": "string"
          },
          {
            "description": "An optional consumer group to consume as. When specified the partitions of specified topics are automatically distributed across consumers sharing a consumer group, and partition offsets are automatically committed and resumed under this name. Consumer groups are not supported when specifying explicit partitions to consume from in the `topics` field.",
            "is_optional": true,
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period of time between each commit of the current partition offsets. Offsets are always committed during shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "default": "1MB",
            "description": "A buffer size (in bytes) for each consumed partition, allowing records to be queued internally before flushing. Increasing this may improve throughput at the cost of higher memory utilisation. Note that each buffer can grow slightly beyond this value.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "partition_buffer_bytes",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The period of time between each topic lag refresh cycle.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "topic_lag_refresh_period",
            "type": "string"
          },
          {
            "default": "32KB",
            "description": "The maximum size (in bytes) for each batch yielded by this input. When routed to a redpanda output without modification this would roughly translate to the batch.bytes config field of a traditional producer.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_yield_batch_bytes",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "EXPERIMENTAL: Specify a maximum period of time in which each message can be consumed and awaiting either acknowledgement or rejection before rejection is instead forced. This can be useful for avoiding situations where certain downstream components can result in blocked confirmation of delivery that exceeds SLAs.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timely_nacks_maximum_wait",
            "type": "string"
          },
          {
            "default": "redpanda_migrator_output",
            "description": "The label of the redpanda_migrator output in which the currently selected topics need to be created before attempting to read messages.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "output_resource",
            "type": "string"
          },
          {
            "default": true,
            "description": "Use the specified replication factor when creating topics.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "replication_factor_override",
            "type": "bool"
          },
          {
            "default": 3,
            "description": "Replication factor for created topics. This is only used when `replication_factor_override` is set to `true`.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "replication_factor",
            "type": "int"
          },
          {
            "default": false,
            "description": "Decode headers into lists to allow handling of multiple values with the same key",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "multi_header",
            "type": "bool"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages that should be accumulated into each batch.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "batch_size",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "\nlet has_topic_partitions = this.topics.any(t -> t.contains(\":\"))\n\nroot = [\n  if $has_topic_partitions {\n    if this.consumer_group.or(\"\") != \"\" {\n      \"this input does not support both a consumer group and explicit topic partitions\"\n    } else if this.regexp_topics {\n      \"this input does not support both regular expression topics and explicit topic partitions\"\n    }\n  } else {\n    if this.consumer_group.or(\"\") == \"\" {\n      \"a consumer group is mandatory when not using explicit topic partitions\"\n    }\n  },\n  # We don't have any way to distinguish between start_from_oldest set explicitly to true and not set at all, so we\n  # assume users will be OK if start_offset overwrites it silently\n  if this.start_from_oldest == false && this.start_offset == \"earliest\" {\n    \"start_from_oldest cannot be set to false when start_offset is set to earliest\"\n  }\n]\n",
        "name": "",
        "type": "object"
      },
      "description": "\nReads a batch of messages from a Kafka broker and waits for the output to acknowledge the writes before updating the Kafka consumer group offset.\n\nThis input should be used in combination with a `redpanda_migrator` output.\n\nWhen a consumer group is specified this input consumes one or more topics where partitions will automatically balance across any other connected clients with the same consumer group. When a consumer group is not specified topics can either be consumed in their entirety or with explicit partitions.\n\nIt provides the same delivery guarantees and ordering semantics as the `redpanda` input.\n\n== Metrics\n\nEmits a `redpanda_lag` metric with `topic` and `partition` labels for each consumed topic.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- kafka_key\n- kafka_topic\n- kafka_partition\n- kafka_offset\n- kafka_lag\n- kafka_timestamp_ms\n- kafka_timestamp_unix\n- kafka_tombstone_message\n- All record headers\n```\n",
      "name": "redpanda_migrator",
      "plugin": true,
      "status": "beta",
      "summary": "A Redpanda Migrator input using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "input",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The `redpanda_migrator` input configuration.\n",
            "kind": "map",
            "name": "redpanda_migrator",
            "type": "unknown"
          },
          {
            "description": "The `schema_registry` input configuration.\n",
            "kind": "map",
            "name": "schema_registry",
            "type": "unknown"
          },
          {
            "default": true,
            "description": "Migrate all schemas first before starting to migrate data.\n",
            "kind": "scalar",
            "name": "migrate_schemas_before_data",
            "type": "bool"
          },
          {
            "default": "15s",
            "description": "Duration between OffsetFetch polling attempts in redpanda_migrator_offsets input.\n",
            "kind": "scalar",
            "name": "consumer_group_offsets_poll_interval",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "All-in-one input which reads messages and schemas from a Kafka or Redpanda cluster. This input is meant to be used\ntogether with the `redpanda_migrator_bundle` output.\n",
      "name": "redpanda_migrator_bundle",
      "plugin": true,
      "status": "experimental",
      "summary": "Redpanda Migrator bundle input",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "\nA list of topics to consume from. Multiple comma separated topics can be listed in a single element. When a `consumer_group` is specified partitions are automatically distributed across consumers of a topic, otherwise all partitions are consumed.",
            "examples": [
              [
                "foo",
                "bar"
              ],
              [
                "things.*"
              ],
              [
                "foo,bar"
              ]
            ],
            "kind": "array",
            "linter": "if this.length() == 0 { [\"at least one topic must be specified\"] }",
            "name": "topics",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether listed topics should be interpreted as regular expression patterns for matching multiple topics.",
            "kind": "scalar",
            "name": "regexp_topics",
            "type": "bool"
          },
          {
            "default": "",
            "description": "A rack specifies where the client is physically located and changes fetch requests to consume from the closest replica as opposed to the leader replica.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": "15s",
            "description": "Duration between OffsetFetch polling attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "poll_interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "consumer_group",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "commit_period",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "partition_buffer_bytes",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "topic_lag_refresh_period",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_yield_batch_bytes",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis input reads consumer group updates via the `OffsetFetch` API and should be used in combination with the `redpanda_migrator_offsets` output.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- kafka_offset_topic\n- kafka_offset_group\n- kafka_offset_partition\n- kafka_offset_commit_timestamp\n- kafka_offset_metadata\n- kafka_is_high_watermark\n```\n",
      "name": "redpanda_migrator_offsets",
      "plugin": true,
      "status": "beta",
      "summary": "Redpanda Migrator consumer group offsets input using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "input",
      "version": "4.45.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "Resources allow you to tidy up deeply nested configs. For example, the config:\n\n```yaml\ninput:\n  broker:\n    inputs:\n      - kafka:\n          addresses: [ TODO ]\n          topics: [ foo ]\n          consumer_group: foogroup\n      - gcp_pubsub:\n          project: bar\n          subscription: baz\n```\n\nCould also be expressed as:\n\n```yaml\ninput:\n  broker:\n    inputs:\n      - resource: foo\n      - resource: bar\n\ninput_resources:\n  - label: foo\n    kafka:\n      addresses: [ TODO ]\n      topics: [ foo ]\n      consumer_group: foogroup\n\n  - label: bar\n    gcp_pubsub:\n      project: bar\n      subscription: baz\n```\n\nResources also allow you to reference a single input in multiple places, such as multiple streams mode configs, or multiple entries in a broker input. However, when a resource is referenced more than once the messages it produces are distributed across those references, so each message will only be directed to a single reference, not all of them.\n\nYou can find out more about resources in xref:configuration:resources.adoc[].",
      "name": "resource",
      "plugin": true,
      "status": "stable",
      "summary": "Resource is an input type that channels messages from a resource input, identified by its name.",
      "type": "input"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The base URL of the schema registry service.",
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "default": false,
            "description": "Include deleted entities.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "include_deleted",
            "type": "bool"
          },
          {
            "default": "",
            "description": "Include only subjects which match the regular expression filter. All subjects are selected when not set.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "subject_filter",
            "type": "string"
          },
          {
            "default": true,
            "description": "Fetch all schemas on connect and sort them by ID. Should be set to `true` when schema references are used.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fetch_in_order",
            "type": "bool",
            "version": "4.37.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- schema_registry_subject\n- schema_registry_subject_compatibility_level\n- schema_registry_version\n```\n\nYou can access these metadata fields using\nxref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n",
      "examples": [
        {
          "config": "\ninput:\n  schema_registry:\n    url: http://localhost:8081\n    include_deleted: true\n    subject_filter: ^foo.*\n",
          "summary": "Read all schemas (including deleted) from a Schema Registry instance which are associated with subjects matching the `^foo.*` filter.",
          "title": "Read schemas"
        }
      ],
      "name": "schema_registry",
      "plugin": true,
      "status": "beta",
      "summary": "Reads schemas from SchemaRegistry.",
      "type": "input",
      "version": "4.32.2"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "children": [
              {
                "default": "none",
                "description": "The type of join to perform. A `full-outer` ensures that all identifiers seen in any of the input sequences are sent, and is performed by consuming all input sequences before flushing the joined results. An `outer` join consumes all input sequences but only writes data joined from the last input in the sequence, similar to a left or right outer join. With an `outer` join if an identifier appears multiple times within the final sequence input it will be flushed each time it appears. `full-outter` and `outter` have been deprecated in favour of `full-outer` and `outer`.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"none\": true,\n  \"full-outer\": true,\n  \"outer\": true,\n  \"full-outter\": true,\n  \"outter\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "type",
                "options": [
                  "none",
                  "full-outer",
                  "outer",
                  "full-outter",
                  "outter"
                ],
                "type": "string"
              },
              {
                "default": "",
                "description": "A xref:configuration:field_paths.adoc[dot path] that points to a common field within messages of each fragmented data set and can be used to join them. Messages that are not structured or are missing this field will be dropped. This field must be set in order to enable joins.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "id_path",
                "type": "string"
              },
              {
                "default": 1,
                "description": "The total number of iterations (shards), increasing this number will increase the overall time taken to process the data, but reduces the memory used in the process. The real memory usage required is significantly higher than the real size of the data and therefore the number of iterations should be at least an order of magnitude higher than the available memory divided by the overall size of the dataset.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "iterations",
                "type": "int"
              },
              {
                "default": "array",
                "description": "The chosen strategy to use when a data join would otherwise result in a collision of field values. The strategy `array` means non-array colliding values are placed into an array and colliding arrays are merged. The strategy `replace` replaces old values with new values. The strategy `keep` keeps the old value.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"array\": true,\n  \"replace\": true,\n  \"keep\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "merge_strategy",
                "options": [
                  "array",
                  "replace",
                  "keep"
                ],
                "type": "string"
              }
            ],
            "description": "EXPERIMENTAL: Provides a way to perform outer joins of arbitrarily structured and unordered data resulting from the input sequence, even when the overall size of the data surpasses the memory available on the machine.\n\nWhen configured the sequence of inputs will be consumed one or more times according to the number of iterations, and when more than one iteration is specified each iteration will process an entirely different set of messages by sharding them by the ID field. Increasing the number of iterations reduces the memory consumption at the cost of needing to fully parse the data each time.\n\nEach message must be structured (JSON or otherwise processed into a structured form) and the fields will be aggregated with those of other messages sharing the ID. At the end of each iteration the joined messages are flushed downstream before the next iteration begins, hence keeping memory usage limited.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "sharded_join",
            "type": "object",
            "version": "3.40.0"
          },
          {
            "description": "An array of inputs to read from sequentially.",
            "kind": "array",
            "name": "inputs",
            "type": "input"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This input is useful for consuming from inputs that have an explicit end but must not be consumed in parallel.",
      "examples": [
        {
          "config": "\ninput:\n  sequence:\n    inputs:\n      - file:\n          paths: [ ./dataset.csv ]\n          scanner:\n            csv: {}\n      - generate:\n          count: 1\n          mapping: 'root = {\"status\":\"finished\"}'\n",
          "summary": "A common use case for sequence might be to generate a message at the end of our main input. With the following config once the records within `./dataset.csv` are exhausted our final payload `{\"status\":\"finished\"}` will be routed through the pipeline.",
          "title": "End of Stream Message"
        },
        {
          "config": "\ninput:\n  sequence:\n    sharded_join:\n      type: full-outer\n      id_path: uuid\n      merge_strategy: array\n    inputs:\n      - file:\n          paths:\n            - ./hobbies.csv\n            - ./main.csv\n          scanner:\n            csv: {}\n",
          "summary": "Redpanda Connect can be used to join unordered data from fragmented datasets in memory by specifying a common identifier field and a number of sharded iterations. For example, given two CSV files, the first called \"main.csv\", which contains rows of user data:\n\n```csv\nuuid,name,age\nAAA,Melanie,34\nBBB,Emma,28\nCCC,Geri,45\n```\n\nAnd the second called \"hobbies.csv\" that, for each user, contains zero or more rows of hobbies:\n\n```csv\nuuid,hobby\nCCC,pokemon go\nAAA,rowing\nAAA,golf\n```\n\nWe can parse and join this data into a single dataset:\n\n```json\n{\"uuid\":\"AAA\",\"name\":\"Melanie\",\"age\":34,\"hobbies\":[\"rowing\",\"golf\"]}\n{\"uuid\":\"BBB\",\"name\":\"Emma\",\"age\":28}\n{\"uuid\":\"CCC\",\"name\":\"Geri\",\"age\":45,\"hobbies\":[\"pokemon go\"]}\n```\n\nWith the following config:",
          "title": "Joining Data (Simple)"
        },
        {
          "config": "\ninput:\n  sequence:\n    sharded_join:\n      type: full-outer\n      id_path: uuid\n      iterations: 10\n      merge_strategy: array\n    inputs:\n      - file:\n          paths: [ ./main.csv ]\n          scanner:\n            csv: {}\n      - file:\n          paths: [ ./hobbies.ndjson ]\n          scanner:\n            lines: {}\n        processors:\n          - mapping: |\n              root.uuid = this.document.uuid\n              root.hobbies = this.document.hobbies.map_each(this.type)\n",
          "summary": "In this example we are able to join unordered and fragmented data from a combination of CSV files and newline-delimited JSON documents by specifying multiple sequence inputs with their own processors for extracting the structured data.\n\nThe first file \"main.csv\" contains straight forward CSV data:\n\n```csv\nuuid,name,age\nAAA,Melanie,34\nBBB,Emma,28\nCCC,Geri,45\n```\n\nAnd the second file called \"hobbies.ndjson\" contains JSON documents, one per line, that associate an identifier with an array of hobbies. However, these data objects are in a nested format:\n\n```json\n{\"document\":{\"uuid\":\"CCC\",\"hobbies\":[{\"type\":\"pokemon go\"}]}}\n{\"document\":{\"uuid\":\"AAA\",\"hobbies\":[{\"type\":\"rowing\"},{\"type\":\"golf\"}]}}\n```\n\nAnd so we will want to map these into a flattened structure before the join, and then we will end up with a single dataset that looks like this:\n\n```json\n{\"uuid\":\"AAA\",\"name\":\"Melanie\",\"age\":34,\"hobbies\":[\"rowing\",\"golf\"]}\n{\"uuid\":\"BBB\",\"name\":\"Emma\",\"age\":28}\n{\"uuid\":\"CCC\",\"name\":\"Geri\",\"age\":45,\"hobbies\":[\"pokemon go\"]}\n```\n\nWith the following config:",
          "title": "Joining Data (Advanced)"
        }
      ],
      "name": "sequence",
      "plugin": true,
      "status": "stable",
      "summary": "Reads messages from a sequence of child inputs, starting with the first and once that input gracefully terminates starts consuming from the next, and so on.",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "The address of the server to connect to.",
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The connection timeout to use when connecting to the target server.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "connection_timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "The username to authenticate with the SFTP server.",
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "The password for the specified username to connect to the SFTP server.",
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The path to the SFTP server's public key file, used for host key verification.",
                "is_optional": true,
                "kind": "scalar",
                "name": "host_public_key_file",
                "type": "string"
              },
              {
                "description": "The raw contents of the SFTP server's public key, used for host key verification.",
                "is_optional": true,
                "kind": "scalar",
                "name": "host_public_key",
                "type": "string"
              },
              {
                "description": "The path to the private key file, used for authenticating the username.",
                "is_optional": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "description": "The raw contents of the private key, used for authenticating the username.",
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "private_key",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "Optional passphrase for decrypting the private key, if it's encrypted.",
                "is_secret": true,
                "kind": "scalar",
                "name": "private_key_pass",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "The credentials to use to log into the target server.",
            "kind": "scalar",
            "linter": "\nroot = match {\n  this.exists(\"host_public_key\") && this.exists(\"host_public_key_file\") => \"both host_public_key and host_public_key_file can't be set simultaneously\"\n  this.exists(\"private_key\") && this.exists(\"private_key_file\") => \"both private_key and private_key_file can't be set simultaneously\"\n}",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": 10,
            "description": "The maximum number of SFTP sessions.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_sftp_sessions",
            "type": "int"
          },
          {
            "description": "A list of paths to consume sequentially. Glob patterns are supported.",
            "kind": "array",
            "name": "paths",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "to_the_end": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          },
          {
            "default": false,
            "description": "Whether to delete files from the server once they are processed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "delete_on_finish",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether file watching is enabled.",
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "1s",
                "description": "The minimum period of time since a file was last updated before attempting to consume it. Increasing this period decreases the likelihood that a file will be consumed whilst it is still being written to.",
                "examples": [
                  "10s",
                  "1m",
                  "10m"
                ],
                "kind": "scalar",
                "name": "minimum_age",
                "type": "string"
              },
              {
                "default": "1s",
                "description": "The interval between each attempt to scan the target paths for new files.",
                "examples": [
                  "100ms",
                  "1s"
                ],
                "kind": "scalar",
                "name": "poll_interval",
                "type": "string"
              },
              {
                "default": "",
                "description": "A xref:components:caches/about.adoc[cache resource] for storing the paths of files already consumed.",
                "kind": "scalar",
                "name": "cache",
                "type": "string"
              }
            ],
            "description": "An experimental mode whereby the input will periodically scan the target paths for new files and consume them, when all files are consumed the input will continue polling for new files.",
            "kind": "scalar",
            "name": "watcher",
            "type": "object",
            "version": "3.42.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- sftp_path\n- sftp_mod_time\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].",
      "name": "sftp",
      "plugin": true,
      "status": "beta",
      "summary": "Consumes files from an SFTP server.",
      "type": "input",
      "version": "3.39.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The Slack App token to use.",
            "kind": "scalar",
            "linter": "\n        root = if !this.has_prefix(\"xapp-\") { [ \"field must start with xapp-\" ] }\n      ",
            "name": "app_token",
            "type": "string"
          },
          {
            "description": "The Slack Bot User OAuth token to use.",
            "kind": "scalar",
            "linter": "\n        root = if !this.has_prefix(\"xoxb-\") { [ \"field must start with xoxb-\" ] }\n      ",
            "name": "bot_token",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Connects to Slack using https://api.slack.com/apis/socket-mode[^Socket Mode]. This allows for receiving events, interactions and slash commands. Each message emitted from this input has a @type metadata of the event type \"events_api\", \"interactions\" or \"slash_commands\".",
      "examples": [
        {
          "config": "\ninput:\n  slack:\n    app_token: \"${APP_TOKEN:xapp-demo}\"\n    bot_token: \"${BOT_TOKEN:xoxb-demo}\"\npipeline:\n  processors:\n    - mutation: |\n        # ignore hidden or non message events\n        if this.event.type != \"message\" || (this.event.hidden | false) {\n          root = deleted()\n        }\n        # Don't respond to our own messages\n        if this.authorizations.any(auth -> auth.user_id == this.event.user) {\n          root = deleted()\n        }\noutput:\n  slack_post:\n    bot_token: \"${BOT_TOKEN:xoxb-demo}\"\n    channel_id: \"${!this.event.channel}\"\n    thread_ts: \"${!this.event.ts}\"\n    text: \"ECHO: ${!this.event.text}\"\n    ",
          "summary": "A slackbot that echo messages from other users",
          "title": "Echo Slackbot"
        }
      ],
      "name": "slack",
      "plugin": true,
      "status": "experimental",
      "type": "input"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The Slack Bot User OAuth token to use.",
            "kind": "scalar",
            "linter": "\n        root = if !this.has_prefix(\"xoxb-\") { [ \"field must start with xoxb-\" ] }\n      ",
            "name": "bot_token",
            "type": "string"
          },
          {
            "default": "",
            "description": "The team ID to filter by",
            "kind": "scalar",
            "name": "team_id",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Reads all users in a slack organization (optionally filtered by a team ID).",
      "name": "slack_users",
      "plugin": true,
      "status": "experimental",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "A network type to assume (unix|tcp).",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"unix\": true,\n  \"tcp\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "network",
            "options": [
              "unix",
              "tcp"
            ],
            "type": "string"
          },
          {
            "description": "The address to connect to.",
            "examples": [
              "/tmp/benthos.sock",
              "127.0.0.1:6000"
            ],
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a string which will be sent upstream before the downstream data flow starts.",
            "examples": [
              "root = \"username,password\""
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "open_message_mapping",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "lines": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "socket",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to a tcp or unix socket and consumes a continuous stream of messages.",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "A network type to accept.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"unix\": true,\n  \"tcp\": true,\n  \"udp\": true,\n  \"tls\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "network",
            "options": [
              "unix",
              "tcp",
              "udp",
              "tls"
            ],
            "type": "string"
          },
          {
            "description": "The address to listen from.",
            "examples": [
              "/tmp/benthos.sock",
              "0.0.0.0:6000"
            ],
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "description": "An optional xref:components:caches/about.adoc[`cache`] within which this input should write it's bound address once known. The key of the cache item containing the address will be the label of the component suffixed with `_address` (e.g. `foo_address`), or `socket_server_address` when a label has not been provided. This is useful in situations where the address is dynamically allocated by the server (`127.0.0.1:0`) and you want to store the allocated address somewhere for reference by other systems and components.",
            "is_optional": true,
            "kind": "scalar",
            "name": "address_cache",
            "type": "string",
            "version": "4.25.0"
          },
          {
            "children": [
              {
                "description": "PEM encoded certificate for use with TLS.",
                "is_optional": true,
                "kind": "scalar",
                "name": "cert_file",
                "type": "string"
              },
              {
                "description": "PEM encoded private key for use with TLS.",
                "is_optional": true,
                "kind": "scalar",
                "name": "key_file",
                "type": "string"
              },
              {
                "default": false,
                "description": "Whether to generate self signed certificates.",
                "kind": "scalar",
                "name": "self_signed",
                "type": "bool"
              },
              {
                "annotated_options": [
                  [
                    "no",
                    "client certificate is not requested nor required."
                  ],
                  [
                    "request",
                    "will request client certificate, not require it."
                  ],
                  [
                    "require_any",
                    "will accept any client certificate, even if not valid."
                  ],
                  [
                    "require_valid",
                    "requires a valid client certificate."
                  ],
                  [
                    "verify_if_given",
                    "will verify a certificate, if one is sent by the client."
                  ]
                ],
                "default": "no",
                "description": "How client authentication is handled.",
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"no\": true,\n  \"request\": true,\n  \"require_any\": true,\n  \"require_valid\": true,\n  \"verify_if_given\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "client_auth",
                "type": "string",
                "version": "4.44.1"
              }
            ],
            "description": "TLS specific configuration, valid when the `network` is set to `tls`.",
            "is_optional": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "lines": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "socket_server",
      "plugin": true,
      "status": "stable",
      "summary": "Creates a server that receives a stream of messages over a TCP, UDP or Unix socket.",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "SpiceDB"
      ],
      "config": {
        "children": [
          {
            "description": "The SpiceDB endpoint.",
            "examples": [
              "grpc.authzed.com:443"
            ],
            "kind": "scalar",
            "name": "endpoint",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "",
            "description": "The SpiceDB Bearer token used to authenticate against the SpiceDB instance.",
            "examples": [
              "t_your_token_here_1234567deadbeef"
            ],
            "is_secret": true,
            "kind": "scalar",
            "name": "bearer_token",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "4MB",
            "description": "Maximum message size in bytes the SpiceDB client can receive.",
            "examples": [
              "100MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_receive_message_bytes",
            "type": "string"
          },
          {
            "description": "A cache resource to use for performing unread message backfills, the ID of the last message received will be stored in this cache and used for subsequent requests.",
            "kind": "scalar",
            "name": "cache",
            "type": "string"
          },
          {
            "default": "authzed.com/spicedb/watch/last_zed_token",
            "description": "The key identifier used when storing the ID of the last message received.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cache_key",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe SpiceDB input allows you to consume messages from the Watch API of a SpiceDB instance.\nThis input is useful for applications that need to react to changes in the data managed by SpiceDB in real-time.\n\n== Credentials\n\nYou need to provide the endpoint of your SpiceDB instance and a Bearer token for authentication.\n\n== Cache\n\nThe zed token of the newest update consumed and acked is stored in a cache in order to start reading from it each time the input is initialised.\nIdeally this cache should be persisted across restarts.\n",
      "name": "spicedb_watch",
      "plugin": true,
      "status": "stable",
      "summary": "Consume messages from the Watch API from SpiceDB.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "Full HTTP Search API endpoint URL.",
            "examples": [
              "https://foobar.splunkcloud.com/services/search/v2/jobs/export"
            ],
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "description": "Splunk account user.",
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "description": "Splunk account password.",
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Splunk search query.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "splunk",
      "plugin": true,
      "status": "beta",
      "summary": "Consumes messages from Splunk.",
      "type": "input",
      "version": "4.30.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
            "examples": [
              "SELECT * FROM footable WHERE user_id = $1;"
            ],
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Once the rows from the query are exhausted this input shuts down, allowing the pipeline to gracefully terminate (or the next input in a xref:components:inputs/sequence.adoc[sequence] to execute).",
      "examples": [
        {
          "config": "\ninput:\n  sql_raw:\n    driver: postgres\n    dsn: postgres://foouser:foopass@localhost:5432/testdb?sslmode=disable\n    query: \"SELECT name, count(*) FROM person WHERE last_updated < $1 GROUP BY name;\"\n    args_mapping: |\n      root = [\n        now().ts_unix() - 3600\n      ]\n",
          "summary": "\nHere we preform an aggregate over a list of names in a table that are less than 3600 seconds old.",
          "title": "Consumes an SQL table using a query as an input."
        }
      ],
      "name": "sql_raw",
      "plugin": true,
      "status": "beta",
      "summary": "Executes a select query and creates a message for each row received.",
      "type": "input",
      "version": "4.10.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The table to select from.",
            "examples": [
              "foo"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "A list of columns to select.",
            "examples": [
              [
                "*"
              ],
              [
                "foo",
                "bar",
                "baz"
              ]
            ],
            "kind": "array",
            "name": "columns",
            "type": "string"
          },
          {
            "description": "An optional where clause to add. Placeholder arguments are populated with the `args_mapping` field. Placeholders should always be question marks, and will automatically be converted to dollar syntax when the postgres or clickhouse drivers are used.",
            "examples": [
              "type = ? and created_at > ?",
              "user_id = ?"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "where",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `where`.",
            "examples": [
              "root = [ \"article\", now().ts_format(\"2006-01-02\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "An optional prefix to prepend to the select query (before SELECT).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to the select query.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "suffix",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Once the rows from the query are exhausted this input shuts down, allowing the pipeline to gracefully terminate (or the next input in a xref:components:inputs/sequence.adoc[sequence] to execute).",
      "examples": [
        {
          "config": "\ninput:\n  sql_select:\n    driver: postgres\n    dsn: postgres://foouser:foopass@localhost:5432/testdb?sslmode=disable\n    table: footable\n    columns: [ '*' ]\n    where: created_at >= ?\n    args_mapping: |\n      root = [\n        now().ts_unix() - 3600\n      ]\n",
          "summary": "\nHere we define a pipeline that will consume all rows from a table created within the last hour by comparing the unix timestamp stored in the row column \"created_at\":",
          "title": "Consume a Table (PostgreSQL)"
        }
      ],
      "name": "sql_select",
      "plugin": true,
      "status": "beta",
      "summary": "Executes a select query and creates a message for each row received.",
      "type": "input",
      "version": "3.59.0"
    },
    {
      "categories": [
        "Local"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "auto",
                "EXPERIMENTAL: Attempts to derive a codec for each file based on information such as the extension. For example, a .tar.gz file would be consumed with the `gzip/tar` codec. Defaults to all-bytes."
              ],
              [
                "all-bytes",
                "Consume the entire file as a single binary message."
              ],
              [
                "avro-ocf:marshaler=x",
                "EXPERIMENTAL: Consume a stream of Avro OCF datum. The `marshaler` parameter is optional and has the options: `goavro` (default), `json`. Use `goavro` if OCF contains logical types."
              ],
              [
                "chunker:x",
                "Consume the file in chunks of a given number of bytes."
              ],
              [
                "csv",
                "Consume structured rows as comma separated values, the first row must be a header row."
              ],
              [
                "csv:x",
                "Consume structured rows as values separated by a custom delimiter, the first row must be a header row. The custom delimiter must be a single character, e.g. the codec `\"csv:\\t\"` would consume a tab delimited file."
              ],
              [
                "csv-safe",
                "Consume structured rows like `csv`, but sends messages with empty maps on failure to parse. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "csv-safe:x",
                "Consume structured rows like `csv:x` as values separated by a custom delimiter, but sends messages with empty maps on failure to parse. The custom delimiter must be a single character, e.g. the codec `\"csv-safe:\\t\"` would consume a tab delimited file. Includes row number and parsing errors (if any) in the message's metadata."
              ],
              [
                "delim:x",
                "Consume the file in segments divided by a custom delimiter."
              ],
              [
                "gzip",
                "Decompress a gzip file, this codec should precede another codec, e.g. `gzip/all-bytes`, `gzip/tar`, `gzip/csv`, etc."
              ],
              [
                "pgzip",
                "Decompress a gzip file in parallel, this codec should precede another codec, e.g. `pgzip/all-bytes`, `pgzip/tar`, `pgzip/csv`, etc."
              ],
              [
                "lines",
                "Consume the file in segments divided by linebreaks."
              ],
              [
                "multipart",
                "Consumes the output of another codec and batches messages together. A batch ends when an empty message is consumed. For example, the codec `lines/multipart` could be used to consume multipart messages where an empty line indicates the end of each batch."
              ],
              [
                "regex:(?m)^\\d\\d:\\d\\d:\\d\\d",
                "Consume the file in segments divided by regular expression."
              ],
              [
                "skipbom",
                "Skip one or more byte order marks for each opened reader, this codec should precede another codec, e.g. `skipbom/csv`, etc."
              ],
              [
                "tar",
                "Parse the file as a tar archive, and consume each file of the archive as a message."
              ]
            ],
            "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar",
              "gzip/csv"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 1000000,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": {
              "lines": {}
            },
            "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
            "is_optional": true,
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner",
            "version": "4.25.0"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "stdin",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes data piped to stdin, chopping it into individual messages according to the specified scanner.",
      "type": "input"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The command to execute as a subprocess.",
            "examples": [
              "cat",
              "sed",
              "awk"
            ],
            "kind": "scalar",
            "name": "name",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of arguments to provide the command.",
            "kind": "array",
            "name": "args",
            "type": "string"
          },
          {
            "default": "lines",
            "description": "The way in which messages should be consumed from the subprocess.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lines\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "codec",
            "options": [
              "lines"
            ],
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether the command should be re-executed each time the subprocess ends.",
            "kind": "scalar",
            "name": "restart_on_exit",
            "type": "bool"
          },
          {
            "default": 65536,
            "description": "The maximum expected size of an individual message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nMessages are consumed according to a specified codec. The command is executed once and if it terminates the input also closes down gracefully. Alternatively, the field `restart_on_close` can be set to `true` in order to have Redpanda Connect re-execute the command each time it stops.\n\nThe field `max_buffer` defines the maximum message size able to be read from the subprocess. This value should be set significantly above the real expected maximum message size.\n\nThe execution environment of the subprocess is the same as the Redpanda Connect instance, including environment variables and the current working directory.",
      "name": "subprocess",
      "plugin": true,
      "status": "beta",
      "summary": "Executes a command, runs it as a subprocess, and consumes messages from it over stdout.",
      "type": "input"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The query to run",
            "examples": [
              "select * from iot",
              "select count(*) from table(iot)"
            ],
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": "tcp://localhost:8463",
            "description": "The url should always include schema and host.",
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "ID of the workspace. Required when reads from Timeplus Enterprise.",
            "is_optional": true,
            "kind": "scalar",
            "name": "workspace",
            "type": "string"
          },
          {
            "description": "The API key. Required when reads from Timeplus Enterprise Cloud",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "apikey",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The username. Required when reads from Timeplus Enterprise (self-hosted) or Timeplusd",
            "is_optional": true,
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "description": "The password. Required when reads from Timeplus Enterprise (self-hosted) or Timeplusd",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis input can execute a query on Timeplus Enterprise Cloud, Timeplus Enterprise (self-hosted) or Timeplusd. A structured message will be created\nfrom each row received.\n\nIf it is a streaming query, this input will keep running until the query is terminated. If it is a table query, this input will shut down once the rows from the query are exhausted.",
      "examples": [
        {
          "config": "\ninput:\n  timeplus:\n    url: https://us-west-2.timeplus.cloud\n    workspace: my_workspace_id\n    query: select * from iot\n    apikey: <Your API Key>",
          "summary": "You will need to create API Key on Timeplus Enterprise Cloud Web console first and then set the `apikey` field.",
          "title": "From Timeplus Enterprise Cloud via HTTP"
        },
        {
          "config": "\ninput:\n  timeplus:\n    url: http://localhost:8000\n    workspace: my_workspace_id\n    query: select * from iot\n    username: username\n    password: pw",
          "summary": "For self-housted Timeplus Enterprise, you will need to specify the username and password as well as the URL of the App server",
          "title": "From Timeplus Enterprise (self-hosted) via HTTP"
        },
        {
          "config": "\ninput:\n  timeplus:\n    url: tcp://localhost:8463\n    query: select * from iot\n    username: timeplus\n    password: timeplus",
          "summary": "Make sure the the schema of url is tcp",
          "title": "From Timeplus Enterprise (self-hosted) via TCP"
        }
      ],
      "name": "timeplus",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a query on Timeplus Enterprise and creates a message from each row received",
      "type": "input"
    },
    {
      "categories": [
        "Services",
        "Social"
      ],
      "config": {
        "children": [
          {
            "description": "A search expression to use.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": [],
            "description": "An optional list of additional fields to obtain for each tweet, by default only the fields `id` and `text` are returned. For more info refer to the https://developer.twitter.com/en/docs/twitter-api/fields[twitter API docs^].",
            "kind": "array",
            "name": "tweet_fields",
            "type": "string"
          },
          {
            "default": "1m",
            "description": "The length of time (as a duration string) to wait between each search request. This field can be set empty, in which case requests are made at the limit set by the rate limit. This field also supports cron expressions.",
            "kind": "scalar",
            "name": "poll_period",
            "type": "string"
          },
          {
            "default": "5m",
            "description": "A duration string indicating the maximum age of tweets to acquire when starting a search.",
            "kind": "scalar",
            "name": "backfill_period",
            "type": "string"
          },
          {
            "description": "A cache resource to use for request pagination.",
            "kind": "scalar",
            "name": "cache",
            "type": "string"
          },
          {
            "default": "last_tweet_id",
            "description": "The key identifier used when storing the ID of the last tweet received.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cache_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional rate limit resource to restrict API requests with.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "description": "An API key for OAuth 2.0 authentication. It is recommended that you populate this field using xref:configuration:interpolation.adoc[environment variables].",
            "kind": "scalar",
            "name": "api_key",
            "type": "string"
          },
          {
            "description": "An API secret for OAuth 2.0 authentication. It is recommended that you populate this field using xref:configuration:interpolation.adoc[environment variables].",
            "kind": "scalar",
            "name": "api_secret",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Continuously polls the https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent[Twitter recent search V2 API^] for tweets that match a given search query.\n\nEach tweet received is emitted as a JSON object message, with a field `id` and `text` by default. Extra fields https://developer.twitter.com/en/docs/twitter-api/fields[can be obtained from the search API^] when listed with the `tweet_fields` field.\n\nIn order to paginate requests that are made the ID of the latest received tweet is stored in a xref:components:caches/about.adoc[cache resource], which is then used by subsequent requests to ensure only tweets after it are consumed. It is recommended that the cache you use is persistent so that Redpanda Connect can resume searches at the correct place on a restart.\n\nAuthentication is done using OAuth 2.0 credentials which can be generated within the https://developer.twitter.com[Twitter developer portal^].\n",
      "name": "twitter_search",
      "plugin": true,
      "status": "experimental",
      "summary": "Consumes tweets matching a given search using the Twitter recent search V2 API.",
      "type": "input"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "The URL to connect to.",
            "examples": [
              "ws://localhost:4195/get/ws"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "An optional HTTP proxy URL.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "proxy_url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "An optional message to send to the server upon connection.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "open_message",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "binary",
                "Binary data open_message."
              ],
              [
                "text",
                "Text data open_message. The text message payload is interpreted as UTF-8 encoded text data."
              ]
            ],
            "default": "binary",
            "description": "An optional flag to indicate the data type of open_message.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"binary\": true,\n  \"text\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "open_message_type",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
            "kind": "scalar",
            "name": "auto_replay_nacks",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "description": "An optional limit to the number of consecutive retry attempts that will be made before abandoning the connection altogether and gracefully terminating the input. When all inputs terminate in this way the service (or stream) will shut down. If set to zero connections will never be reattempted upon a failure. If set below zero this field is ignored (effectively unset).",
                "examples": [
                  -1,
                  10
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "max_retries",
                "type": "int"
              }
            ],
            "description": "Customise how websocket connection attempts are made.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "connection",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "It is possible to configure an `open_message`, which when set to a non-empty string will be sent to the websocket server each time a connection is first established.",
      "name": "websocket",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to a websocket server and continuously receives messages.",
      "type": "input"
    }
  ],
  "metrics": [
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": "Benthos",
            "description": "The namespace used to distinguish metrics from other services.",
            "kind": "scalar",
            "name": "namespace",
            "type": "string"
          },
          {
            "default": "100ms",
            "description": "The period of time between PutMetricData requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "flush_period",
            "type": "string"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Timing metrics\n\nThe smallest timing unit that CloudWatch supports is microseconds, therefore timing metrics are automatically downgraded to microseconds (by dividing delta values by 1000). This conversion will also apply to custom timing metrics produced with a `metric` processor.\n\n== Billing\n\nAWS bills per metric series exported, it is therefore STRONGLY recommended that you reduce the metrics that are exposed with a `mapping` like this:\n\n```yaml\nmetrics:\n  mapping: |\n    if ![\n      \"input_received\",\n      \"input_latency\",\n      \"output_sent\",\n    ].contains(this) { deleted() }\n  aws_cloudwatch:\n    namespace: Foo\n```",
      "name": "aws_cloudwatch",
      "plugin": true,
      "status": "stable",
      "summary": "Send metrics to AWS CloudWatch using the PutMetricData endpoint.",
      "type": "metrics",
      "version": "3.36.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "A URL of the format `[https|http|udp]://host:port` to the InfluxDB host.",
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the database to use.",
            "kind": "scalar",
            "name": "db",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": "",
            "description": "A username (when applicable).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "default": "",
            "description": "A password (when applicable).",
            "is_advanced": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "A duration string indicating how often to poll and collect runtime metrics. Leave empty to disable this metric",
                "examples": [
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "runtime",
                "type": "string"
              },
              {
                "default": "",
                "description": "A duration string indicating how often to poll and collect GC metrics. Leave empty to disable this metric.",
                "examples": [
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "debug_gc",
                "type": "string"
              }
            ],
            "description": "Optional additional metrics to collect, enabling these metrics may have some performance implications as it acquires a global semaphore and does `stoptheworld()`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "include",
            "type": "object"
          },
          {
            "default": "1m",
            "description": "A duration string indicating how often metrics should be flushed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "interval",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "A duration string indicating how often to ping the host.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ping_interval",
            "type": "string"
          },
          {
            "default": "s",
            "description": "[ns|us|ms|s] timestamp precision passed to write api.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "precision",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "How long to wait for response for both ping and writing metrics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": {},
            "description": "Global tags added to each metric.",
            "examples": [
              {
                "hostname": "localhost",
                "zone": "danger"
              }
            ],
            "is_advanced": true,
            "kind": "map",
            "name": "tags",
            "type": "string"
          },
          {
            "description": "Sets the retention policy for each write.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "retention_policy",
            "type": "string"
          },
          {
            "description": "[any|one|quorum|all] sets write consistency when available.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "write_consistency",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "See https://docs.influxdata.com/influxdb/v1.8/tools/api/#write-http-endpoint for further details on the write API.",
      "name": "influxdb",
      "plugin": true,
      "status": "beta",
      "summary": "Send metrics to InfluxDB 1.x using the `/write` endpoint.",
      "type": "metrics",
      "version": "3.36.0"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This metrics type is useful for debugging as it provides a human readable format that you can parse with tools such as `jq`",
      "name": "json_api",
      "plugin": true,
      "status": "stable",
      "summary": "Serves metrics as JSON object with the service wide HTTP service at the endpoints `/stats` and `/metrics`.",
      "type": "metrics"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "An optional period of time to continuously print all metrics.",
            "is_optional": true,
            "kind": "scalar",
            "name": "push_interval",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether counters and timing metrics should be reset to 0 each time metrics are printed.",
            "kind": "scalar",
            "name": "flush_metrics",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nPrints each metric produced by Redpanda Connect as a log event (level `info` by default) during shutdown, and optionally on an interval.\n\nThis metrics type is useful for debugging pipelines when you only have access to the logger output and not the service-wide server. Otherwise it's recommended that you use either the `prometheus` or `json_api`types.",
      "name": "logger",
      "plugin": true,
      "status": "beta",
      "summary": "Prints aggregated metrics through the logger.",
      "type": "metrics"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "none",
      "plugin": true,
      "status": "stable",
      "summary": "Disable metrics entirely.",
      "type": "metrics"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether to export timing metrics as a histogram, if `false` a summary is used instead. When exporting histogram timings the delta values are converted from nanoseconds into seconds in order to better fit within bucket definitions. For more information on histograms and summaries refer to: https://prometheus.io/docs/practices/histograms/.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "use_histogram_timing",
            "type": "bool",
            "version": "3.63.0"
          },
          {
            "default": [],
            "description": "Timing metrics histogram buckets (in seconds). If left empty defaults to DefBuckets (https://pkg.go.dev/github.com/prometheus/client_golang/prometheus#pkg-variables). Applicable when `use_histogram_timing` is set to `true`.",
            "is_advanced": true,
            "kind": "array",
            "name": "histogram_buckets",
            "type": "float",
            "version": "3.63.0"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "Quantile value.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "quantile",
                "type": "float"
              },
              {
                "default": 0,
                "description": "Permissible margin of error for quantile calculations. Precise calculations in a streaming context (without prior knowledge of the full dataset) can be resource-intensive. To balance accuracy with computational efficiency, an error margin is introduced. For instance, if the 90th quantile (`0.9`) is determined to be `100ms` with a 1% error margin (`0.01`), the true value will fall within the `[99ms, 101ms]` range.)",
                "is_advanced": true,
                "kind": "scalar",
                "name": "error",
                "type": "float"
              }
            ],
            "default": [
              {
                "error": 0.05,
                "quantile": 0.5
              },
              {
                "error": 0.01,
                "quantile": 0.9
              },
              {
                "error": 0.001,
                "quantile": 0.99
              }
            ],
            "description": "A list of timing metrics summary buckets (as quantiles). Applicable when `use_histogram_timing` is set to `false`.",
            "examples": [
              [
                {
                  "error": 0.05,
                  "quantile": 0.5
                },
                {
                  "error": 0.01,
                  "quantile": 0.9
                },
                {
                  "error": 0.001,
                  "quantile": 0.99
                }
              ]
            ],
            "is_advanced": true,
            "kind": "array",
            "name": "summary_quantiles_objectives",
            "type": "object",
            "version": "4.23.0"
          },
          {
            "default": false,
            "description": "Whether to export process metrics such as CPU and memory usage in addition to Redpanda Connect metrics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "add_process_metrics",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to export Go runtime metrics such as GC pauses in addition to Redpanda Connect metrics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "add_go_metrics",
            "type": "bool"
          },
          {
            "description": "An optional <<push-gateway, Push Gateway URL>> to push metrics to.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "push_url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The period of time between each push when sending metrics to a Push Gateway.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "push_interval",
            "type": "string"
          },
          {
            "default": "benthos_push",
            "description": "An identifier for push jobs.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "push_job_name",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "The Basic Authentication username.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "The Basic Authentication password.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "The Basic Authentication credentials.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "push_basic_auth",
            "type": "object"
          },
          {
            "default": "",
            "description": "An optional file path to write all prometheus metrics on service shutdown.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "file_output_path",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "footnotes": "\n== Push gateway\n\nThe field `push_url` is optional and when set will trigger a push of metrics to a https://prometheus.io/docs/instrumenting/pushing/[Prometheus Push Gateway^] once Redpanda Connect shuts down. It is also possible to specify a `push_interval` which results in periodic pushes.\n\nThe Push Gateway is useful for when Redpanda Connect instances are short lived. Do not include the \"/metrics/jobs/...\" path in the push URL.\n\nIf the Push Gateway requires HTTP Basic Authentication it can be configured with `push_basic_auth`.",
      "name": "prometheus",
      "plugin": true,
      "status": "stable",
      "summary": "Host endpoints (`/metrics` and `/stats`) for Prometheus scraping.",
      "type": "metrics"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The address to send metrics to.",
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": "100ms",
            "description": "The time interval between metrics flushes.",
            "kind": "scalar",
            "name": "flush_period",
            "type": "string"
          },
          {
            "default": "none",
            "description": "Metrics tagging is supported in a variety of formats.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"none\": true,\n  \"datadog\": true,\n  \"influxdb\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "tag_format",
            "options": [
              "none",
              "datadog",
              "influxdb"
            ],
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "statsd",
      "plugin": true,
      "status": "stable",
      "summary": "Pushes metrics using the https://github.com/statsd/statsd[StatsD protocol^]. Supported tagging formats are 'none', 'datadog' and 'influxdb'.",
      "type": "metrics"
    }
  ],
  "outputs": [
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. The first URL to successfully establish a connection will be used until the connection is closed. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "amqp://guest:guest@127.0.0.1:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/,amqp://127.0.0.2:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/",
                "amqp://127.0.0.2:5672/"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string",
            "version": "3.58.0"
          },
          {
            "description": "An AMQP exchange to publish to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "exchange",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to declare the exchange.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "direct",
                "description": "The type of the exchange.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"direct\": true,\n  \"fanout\": true,\n  \"topic\": true,\n  \"headers\": true,\n  \"x-custom\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "type",
                "options": [
                  "direct",
                  "fanout",
                  "topic",
                  "headers",
                  "x-custom"
                ],
                "type": "string"
              },
              {
                "default": true,
                "description": "Whether the exchange should be durable.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "durable",
                "type": "bool"
              },
              {
                "description": "Optional arguments specific to the server's implementation of the exchange that can be sent for exchange types which require extra parameters.",
                "examples": [
                  {
                    "alternate-exchange": "my-ae"
                  }
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "arguments",
                "type": "string"
              }
            ],
            "description": "Optionally declare the target exchange (passive).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "exchange_declare",
            "type": "object"
          },
          {
            "default": "",
            "description": "The binding key to set for each message.",
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": "",
            "description": "The type property to set for each message.",
            "interpolated": true,
            "kind": "scalar",
            "name": "type",
            "type": "string"
          },
          {
            "default": "application/octet-stream",
            "description": "The content type attribute to set for each message.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_type",
            "type": "string"
          },
          {
            "default": "",
            "description": "The content encoding attribute to set for each message.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_encoding",
            "type": "string"
          },
          {
            "default": "",
            "description": "Set the correlation ID of each message with a dynamic interpolated expression.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "correlation_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "Carries response queue name - set with a dynamic interpolated expression.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "reply_to",
            "type": "string"
          },
          {
            "default": "",
            "description": "Set the per-message TTL",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "expiration",
            "type": "string"
          },
          {
            "default": "",
            "description": "Set the message ID of each message with a dynamic interpolated expression.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "message_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "Set the user ID to the name of the publisher.  If this property is set by a publisher, its value must be equal to the name of the user used to open the connection.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "user_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "Set the application ID of each message with a dynamic interpolated expression.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "app_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are attached to messages as headers.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "",
            "description": "Set the priority of each message with a dynamic interpolated expression.",
            "examples": [
              "0",
              "${! meta(\"amqp_priority\") }",
              "${! json(\"doc.priority\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "priority",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": false,
            "description": "Whether message delivery should be persistent (transient by default).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "persistent",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to set the mandatory flag on published messages. When set if a published message is routed to zero queues it is returned.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "mandatory",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to set the immediate flag on published messages. When set if there are no ready consumers of a queue then the message is dropped instead of waiting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "immediate",
            "type": "bool"
          },
          {
            "default": "",
            "description": "The maximum period to wait before abandoning it and reattempting. If not set, wait indefinitely.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The metadata from each message are delivered as headers.\n\nIt's possible for this output type to create the target exchange by setting `exchange_declare.enabled` to `true`, if the exchange already exists then the declaration passively verifies that the settings match.\n\nTLS is automatic when connecting to an `amqps` URL, but custom settings can be enabled in the `tls` section.\n\nThe fields 'key', 'exchange' and 'type' can be dynamically set using xref:configuration:interpolation.adoc#bloblang-queries[function interpolations].",
      "name": "amqp_0_9",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to an AMQP (0.91) exchange. AMQP is a messaging protocol used by various message brokers, including RabbitMQ.Connects to an AMQP (0.91) queue. AMQP is a messaging protocol used by various message brokers, including RabbitMQ.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A URL to connect to.",
            "examples": [
              "amqp://localhost:5672/",
              "amqps://guest:guest@localhost:5672/"
            ],
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "A list of URLs to connect to. The first URL to successfully establish a connection will be used until the connection is closed. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "amqp://guest:guest@127.0.0.1:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/,amqp://127.0.0.2:5672/"
              ],
              [
                "amqp://127.0.0.1:5672/",
                "amqp://127.0.0.2:5672/"
              ]
            ],
            "is_optional": true,
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string",
            "version": "4.23.0"
          },
          {
            "description": "The target address to write to.",
            "examples": [
              "/foo",
              "queue:/bar",
              "topic:/baz"
            ],
            "kind": "scalar",
            "name": "target_address",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "An optional Bloblang mapping that can be defined in order to set the `application-properties` on output messages.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "application_properties_map",
            "type": "string"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "anonymous",
                    "Anonymous SASL authentication."
                  ],
                  [
                    "none",
                    "No SASL based authentication."
                  ],
                  [
                    "plain",
                    "Plain text SASL authentication."
                  ]
                ],
                "default": "none",
                "description": "The SASL authentication mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"anonymous\": true,\n  \"none\": true,\n  \"plain\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A SASL plain text username. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${USER}"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "user",
                "type": "string"
              },
              {
                "default": "",
                "description": "A SASL plain text password. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${PASSWORD}"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Enables SASL authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "sasl",
            "type": "object"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are attached to messages as headers.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "opaque_binary",
            "description": "Specify the message body content type. The option `string` will transfer the message as an AMQP value of type string. Consider choosing the option `string` if your intention is to transfer UTF-8 string messages (like JSON messages) to the destination.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"opaque_binary\": true,\n  \"string\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "content_type",
            "options": [
              "opaque_binary",
              "string"
            ],
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "\nroot = if this.url.or(\"\") == \"\" && this.urls.or([]).length() == 0 {\n  \"field 'urls' must be set\"\n}\n",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nMessage metadata is added to each AMQP message as string annotations. In order to control which metadata keys are added use the `metadata` config field.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "amqp_1",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to an AMQP (1.0) server.",
      "type": "output"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The table to store messages in.",
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of column keys to string values to store.",
            "examples": [
              {
                "full_content": "${!content()}",
                "id": "${!json(\"id\")}",
                "title": "${!json(\"body.title\")}",
                "topic": "${!meta(\"kafka_topic\")}"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "string_columns",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of column keys to xref:configuration:field_paths.adoc[field paths] pointing to value data within messages.",
            "examples": [
              {
                "user": "path.to.user",
                "whole_document": "."
              },
              {
                "": "."
              }
            ],
            "kind": "map",
            "name": "json_map_columns",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional TTL to set for items, calculated from the moment the message is sent.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ttl",
            "type": "string"
          },
          {
            "default": "",
            "description": "The column key to place the TTL value within.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ttl_key",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe field `string_columns` is a map of column names to string values, where the values are xref:configuration:interpolation.adoc#bloblang-queries[function interpolated] per message of a batch. This allows you to populate string columns of an item by extracting fields within the document payload or metadata like follows:\n\n```yml\nstring_columns:\n  id: ${!json(\"id\")}\n  title: ${!json(\"body.title\")}\n  topic: ${!meta(\"kafka_topic\")}\n  full_content: ${!content()}\n```\n\nThe field `json_map_columns` is a map of column names to json paths, where the xref:configuration:field_paths.adoc[dot path] is extracted from each document and converted into a map value. Both an empty path and the path `.` are interpreted as the root of the document. This allows you to populate map columns of an item like follows:\n\n```yml\njson_map_columns:\n  user: path.to.user\n  whole_document: .\n```\n\nA column name can be empty:\n\n```yml\njson_map_columns:\n  \"\": .\n```\n\nIn which case the top level document fields will be written at the root of the item, potentially overwriting previously defined column values. If a path is not found within a document the column will not be populated.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].\n",
      "name": "aws_dynamodb",
      "plugin": true,
      "status": "stable",
      "summary": "Inserts items into a DynamoDB table.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The stream to publish messages to. Streams can either be specified by their name or full ARN.",
            "examples": [
              "foo",
              "arn:aws:kinesis:*:111122223333:stream/my-stream"
            ],
            "kind": "scalar",
            "name": "stream",
            "type": "string"
          },
          {
            "description": "A required key for partitioning messages.",
            "interpolated": true,
            "kind": "scalar",
            "name": "partition_key",
            "type": "string"
          },
          {
            "description": "A optional hash key for partitioning messages.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "hash_key",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": 0,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nBoth the `partition_key`(required) and `hash_key` (optional) fields can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages the interpolations are performed per message part.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "aws_kinesis",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to a Kinesis stream.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The stream to publish messages to.",
            "kind": "scalar",
            "name": "stream",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": 0,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].\n",
      "name": "aws_kinesis_firehose",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to a Kinesis Firehose delivery stream.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The bucket to upload messages to.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
            "description": "The path of each message to upload.",
            "examples": [
              "${!counter()}-${!timestamp_unix_nano()}.txt",
              "${!meta(\"kafka_key\")}.json",
              "${!json(\"doc.namespace\")}/${!json(\"doc.id\")}.json"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": {},
            "description": "Key/value pairs to store with the object as tags.",
            "examples": [
              {
                "Key1": "Value1",
                "Timestamp": "${!meta(\"Timestamp\")}"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "tags",
            "type": "string"
          },
          {
            "default": "application/octet-stream",
            "description": "The content type to set for each object.",
            "interpolated": true,
            "kind": "scalar",
            "name": "content_type",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional content encoding to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_encoding",
            "type": "string"
          },
          {
            "default": "",
            "description": "The cache control to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "cache_control",
            "type": "string"
          },
          {
            "default": "",
            "description": "The content disposition to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_disposition",
            "type": "string"
          },
          {
            "default": "",
            "description": "The content language to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_language",
            "type": "string"
          },
          {
            "default": "",
            "description": "The content MD5 to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_md5",
            "type": "string"
          },
          {
            "default": "",
            "description": "The website redirect location to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "website_redirect_location",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are attached to objects as headers.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "STANDARD",
            "description": "The storage class to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"standard\": true,\n  \"reduced_redundancy\": true,\n  \"glacier\": true,\n  \"standard_ia\": true,\n  \"onezone_ia\": true,\n  \"intelligent_tiering\": true,\n  \"deep_archive\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "storage_class",
            "options": [
              "STANDARD",
              "REDUCED_REDUNDANCY",
              "GLACIER",
              "STANDARD_IA",
              "ONEZONE_IA",
              "INTELLIGENT_TIERING",
              "DEEP_ARCHIVE"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional server side encryption key.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "kms_key_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "The algorithm used to create the checksum for each object.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"crc32\": true,\n  \"crc32c\": true,\n  \"sha1\": true,\n  \"sha256\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "checksum_algorithm",
            "options": [
              "CRC32",
              "CRC32C",
              "SHA1",
              "SHA256"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional server side encryption algorithm.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "server_side_encryption",
            "type": "string",
            "version": "3.63.0"
          },
          {
            "default": false,
            "description": "Forces the client API to use path style URLs, which helps when connecting to custom endpoints.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "force_path_style_urls",
            "type": "bool"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": "5s",
            "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "private",
            "description": "The object canned ACL value.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"private\": true,\n  \"public-read\": true,\n  \"public-read-write\": true,\n  \"authenticated-read\": true,\n  \"aws-exec-read\": true,\n  \"bucket-owner-read\": true,\n  \"bucket-owner-full-control\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "object_canned_acl",
            "options": [
              "private",
              "public-read",
              "public-read-write",
              "authenticated-read",
              "aws-exec-read",
              "bucket-owner-read",
              "bucket-owner-full-control"
            ],
            "type": "string"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIn order to have a different path for each object you should use function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries], which are calculated per message of a batch.\n\n== Metadata\n\nMetadata fields on messages will be sent as headers, in order to mutate these values (or remove them) check out the xref:configuration:metadata.adoc[metadata docs].\n\n== Tags\n\nThe tags field allows you to specify key/value pairs to attach to objects as tags, where the values support xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]:\n\n```yaml\noutput:\n  aws_s3:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.tar.gz\n    tags:\n      Key1: Value1\n      Timestamp: ${!meta(\"Timestamp\")}\n```\n\n=== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Batching\n\nIt's common to want to upload messages to S3 as batched archives, the easiest way to do this is to batch your messages at the output level and join the batch of messages with an xref:components:processors/archive.adoc[`archive`] and/or xref:components:processors/compress.adoc[`compress`] processor.\n\nFor example, if we wished to upload messages as a .tar.gz archive of documents we could achieve that with the following config:\n\n```yaml\noutput:\n  aws_s3:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.tar.gz\n    batching:\n      count: 100\n      period: 10s\n      processors:\n        - archive:\n            format: tar\n        - compress:\n            algorithm: gzip\n```\n\nAlternatively, if we wished to upload JSON documents as a single large document containing an array of objects we can do that with:\n\n```yaml\noutput:\n  aws_s3:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.json\n    batching:\n      count: 100\n      processors:\n        - archive:\n            format: json_array\n```\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "aws_s3",
      "plugin": true,
      "status": "stable",
      "summary": "Sends message parts as objects to an Amazon S3 bucket. Each object is uploaded with the path specified with the `path` field.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The topic to publish to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic_arn",
            "type": "string"
          },
          {
            "description": "An optional group ID to set for messages.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "message_group_id",
            "type": "string",
            "version": "3.60.0"
          },
          {
            "description": "An optional deduplication ID to set for messages.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "message_deduplication_id",
            "type": "string",
            "version": "3.60.0"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are sent as headers.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object",
            "version": "3.60.0"
          },
          {
            "default": "5s",
            "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "aws_sns",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to an AWS SNS topic.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "AWS"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target SQS queue.",
            "interpolated": true,
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "description": "An optional group ID to set for messages.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "message_group_id",
            "type": "string"
          },
          {
            "description": "An optional deduplication ID to set for messages.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "message_deduplication_id",
            "type": "string"
          },
          {
            "description": "An optional delay time in seconds for message. Value between 0 and 900",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "delay_seconds",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are sent as headers.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 10,
            "description": "Customize the maximum number of records delivered in a single SQS request. This value must be greater than 0 but no greater than 10.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "if this <= 0 || this > 10 { \"this field must be >0 and <=10\" } ",
            "name": "max_records_per_request",
            "type": "int"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": 0,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nMetadata values are sent along with the payload as attributes with the data type String. If the number of metadata values in a message exceeds the message attribute limit (10) then the top ten keys ordered alphabetically will be selected.\n\nThe fields `message_group_id`, `message_deduplication_id` and `delay_seconds` can be set dynamically using xref:configuration:interpolation.adoc#bloblang-queries[function interpolations], which are resolved individually for each message of a batch.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "aws_sqs",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to an SQS queue.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The container for uploading the messages to.",
            "examples": [
              "messages-${!timestamp(\"2006\")}"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "container",
            "type": "string"
          },
          {
            "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
            "description": "The path of each message to upload.",
            "examples": [
              "${!counter()}-${!timestamp_unix_nano()}.json",
              "${!meta(\"kafka_key\")}.json",
              "${!json(\"doc.namespace\")}/${!json(\"doc.id\")}.json"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": "BLOCK",
            "description": "Block and Append blobs are comprized of blocks, and each blob can support up to 50,000 blocks. The default value is `+\"`BLOCK`\"+`.`",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"block\": true,\n  \"append\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "blob_type",
            "options": [
              "BLOCK",
              "APPEND"
            ],
            "type": "string"
          },
          {
            "default": "PRIVATE",
            "description": "The container's public access level. The default value is `PRIVATE`.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"private\": true,\n  \"blob\": true,\n  \"container\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "public_access_level",
            "options": [
              "PRIVATE",
              "BLOB",
              "CONTAINER"
            ],
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nIn order to have a different path for each object you should use function\ninterpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are\ncalculated per message of a batch.\n\nSupports multiple authentication methods but only one of the following is required:\n\n- `storage_connection_string`\n- `storage_account` and `storage_access_key`\n- `storage_account` and `storage_sas_token`\n- `storage_account` to access via https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n\nIf multiple are set then the `storage_connection_string` is given priority.\n\nIf the `storage_connection_string` does not contain the `AccountName` parameter, please specify it in the\n`storage_account` field.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "azure_blob_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Sends message parts as objects to an Azure Blob Storage Account container. Each object is uploaded with the filename specified with the `container` field.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Azure"
      ],
      "config": {
        "children": [
          {
            "description": "CosmosDB endpoint.",
            "examples": [
              "https://localhost:8081"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "description": "Account key.",
            "examples": [
              "C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw=="
            ],
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "account_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Connection string.",
            "examples": [
              "AccountEndpoint=https://localhost:8081/;AccountKey=C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==;"
            ],
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "connection_string",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Database.",
            "examples": [
              "testdb"
            ],
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "description": "Container.",
            "examples": [
              "testcontainer"
            ],
            "kind": "scalar",
            "name": "container",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a single partition key value or an array of partition key values of type string, integer or boolean. Currently, hierarchical partition keys are not supported so only one value may be provided.",
            "examples": [
              "root = \"blobfish\"",
              "root = 41",
              "root = true",
              "root = null",
              "root = json(\"blobfish\").depth"
            ],
            "kind": "scalar",
            "name": "partition_keys_map",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "Create",
                "Create operation."
              ],
              [
                "Delete",
                "Delete operation."
              ],
              [
                "Patch",
                "Patch operation."
              ],
              [
                "Replace",
                "Replace operation."
              ],
              [
                "Upsert",
                "Upsert operation."
              ]
            ],
            "default": "Create",
            "description": "Operation.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"create\": true,\n  \"delete\": true,\n  \"patch\": true,\n  \"replace\": true,\n  \"upsert\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "type": "string"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "Add",
                    "Add patch operation."
                  ],
                  [
                    "Increment",
                    "Increment patch operation."
                  ],
                  [
                    "Remove",
                    "Remove patch operation."
                  ],
                  [
                    "Replace",
                    "Replace patch operation."
                  ],
                  [
                    "Set",
                    "Set patch operation."
                  ]
                ],
                "default": "Add",
                "description": "Operation.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"add\": true,\n  \"increment\": true,\n  \"remove\": true,\n  \"replace\": true,\n  \"set\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "operation",
                "type": "string"
              },
              {
                "description": "Path.",
                "examples": [
                  "/foo/bar/baz"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "path",
                "type": "string"
              },
              {
                "bloblang": true,
                "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a value of any type that is supported by CosmosDB.",
                "examples": [
                  "root = \"blobfish\"",
                  "root = 41",
                  "root = true",
                  "root = json(\"blobfish\").depth",
                  "root = [1, 2, 3]"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "value_map",
                "type": "string"
              }
            ],
            "description": "Patch operations to be performed when `operation: Patch` .",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "patch_operations",
            "type": "object"
          },
          {
            "description": "Patch operation condition.",
            "examples": [
              "from c where not is_defined(c.blobfish)"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "patch_condition",
            "type": "string"
          },
          {
            "default": true,
            "description": "Automatically set the item `id` field to a random UUID v4. If the `id` field is already set, then it will not be overwritten. Setting this to `false` can improve performance, since the messages will not have to be parsed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auto_id",
            "type": "bool"
          },
          {
            "description": "ID of item to replace or delete. Only used by the Replace and Delete operations",
            "examples": [
              "${! json(\"id\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "item_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "root = []\nlet hasEndpoint = this.endpoint.or(\"\") != \"\"\nlet hasConnectionString = this.connection_string.or(\"\") != \"\"\n\nroot.\"-\" = if !$hasEndpoint && !$hasConnectionString {\n  \"Either `endpoint` or `connection_string` must be set.\"\n}\n\nlet hasItemID = this.item_id.or(\"\") != \"\"\nlet hasPatchOperations = this.patch_operations.length().or(0) > 0\nlet hasPatchCondition = this.patch_condition.or(\"\") != \"\"\n\nroot.\"-\" = if !$hasItemID && (this.operation == \"Replace\" || this.operation == \"Delete\" || this.operation == \"Read\" || this.operation == \"Patch\") {\n  \"The `item_id` field must be set for Replace, Delete, Read and Patch operations.\"\n}\n\nroot.\"-\" = if this.operation == \"Patch\" && !$hasPatchOperations {\n  \"At least one `patch_operations` must be set when `operation: Patch`.\"\n}\n\nroot.\"-\" = if $hasPatchCondition && (!$hasPatchOperations || this.operation != \"Patch\") {\n  \"The `patch_condition`  field only applies to `Patch` operations and it requires one or more `patch_operations`.\"\n}\n\nroot.\"-\" = if this.operation == \"Patch\" && this.patch_operations.any(o -> o.operation != \"Remove\" && o.value_map.or(\"\") == \"\") {\n  \"The `patch_operations` `value_map` field must be set when `operation` is not `Remove`.\"\n}\n\nroot.\"-\" = if this.operation == \"Patch\" && this.patch_operations.any(o -> o.operation == \"Remove\" && o.value_map.or(\"\") != \"\") {\n  \"The `patch_operations` `value_map` field must not be set when `operation` is `Remove`.\"\n}\n",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen creating documents, each message must have the `id` property (case-sensitive) set (or use `auto_id: true`). It is the unique name that identifies the document, that is, no two documents share the same `id` within a logical partition. The `id` field must not exceed 255 characters. https://learn.microsoft.com/en-us/rest/api/cosmos-db/documents[See details^].\n\nThe `partition_keys` field must resolve to the same value(s) across the entire message batch.\n\n\n== Credentials\n\nYou can use one of the following authentication mechanisms:\n\n- Set the `endpoint` field and the `account_key` field\n- Set only the `endpoint` field to use https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n- Set the `connection_string` field\n\n\n== Batching\n\nCosmosDB limits the maximum batch size to 100 messages and the payload must not exceed 2MB (https://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits#per-request-limits[details here^]).\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\noutput:\n  azure_cosmosdb:\n    endpoint: http://localhost:8080\n    account_key: C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==\n    database: blobbase\n    container: blobfish\n    partition_keys_map: root = json(\"habitat\")\n    operation: Create\n",
          "summary": "Create new documents in the `blobfish` container with partition key `/habitat`.",
          "title": "Create documents"
        },
        {
          "config": "\noutput:\n  azure_cosmosdb:\n    endpoint: http://localhost:8080\n    account_key: C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==\n    database: testdb\n    container: blobfish\n    partition_keys_map: root = json(\"habitat\")\n    item_id: ${! json(\"id\") }\n    operation: Patch\n    patch_operations:\n      # Add a new /diet field\n      - operation: Add\n        path: /diet\n        value_map: root = json(\"diet\")\n      # Remove the first location from the /locations array field\n      - operation: Remove\n        path: /locations/0\n      # Add new location at the end of the /locations array field\n      - operation: Add\n        path: /locations/-\n        value_map: root = \"Challenger Deep\"\n",
          "summary": "Execute the Patch operation on documents from the `blobfish` container.",
          "title": "Patch documents"
        }
      ],
      "footnotes": "\n\n== CosmosDB emulator\n\nIf you wish to run the CosmosDB emulator that is referenced in the documentation https://learn.microsoft.com/en-us/azure/cosmos-db/linux-emulator[here^], the following Docker command should do the trick:\n\n```bash\n> docker run --rm -it -p 8081:8081 --name=cosmosdb -e AZURE_COSMOS_EMULATOR_PARTITION_COUNT=10 -e AZURE_COSMOS_EMULATOR_ENABLE_DATA_PERSISTENCE=false mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator\n```\n\nNote: `AZURE_COSMOS_EMULATOR_PARTITION_COUNT` controls the number of partitions that will be supported by the emulator. The bigger the value, the longer it takes for the container to start up.\n\nAdditionally, instead of installing the container self-signed certificate which is exposed via `https://localhost:8081/_explorer/emulator.pem`, you can run https://mitmproxy.org/[mitmproxy^] like so:\n\n```bash\n> mitmproxy -k --mode \"reverse:https://localhost:8081\"\n```\n\nThen you can access the CosmosDB UI via `http://localhost:8080/_explorer/index.html` and use `http://localhost:8080` as the CosmosDB endpoint.\n",
      "name": "azure_cosmosdb",
      "plugin": true,
      "status": "experimental",
      "summary": "Creates or updates messages as JSON documents in https://learn.microsoft.com/en-us/azure/cosmos-db/introduction[Azure CosmosDB^].",
      "type": "output",
      "version": "v4.25.0"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The data lake storage filesystem name for uploading the messages to.",
            "examples": [
              "messages-${!timestamp(\"2006\")}"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "filesystem",
            "type": "string"
          },
          {
            "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
            "description": "The path of each message to upload within the filesystem.",
            "examples": [
              "${!counter()}-${!timestamp_unix_nano()}.json",
              "${!meta(\"kafka_key\")}.json",
              "${!json(\"doc.namespace\")}/${!json(\"doc.id\")}.json"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nIn order to have a different path for each file you should use function\ninterpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are\ncalculated per message of a batch.\n\nSupports multiple authentication methods but only one of the following is required:\n\n- `storage_connection_string`\n- `storage_account` and `storage_access_key`\n- `storage_account` and `storage_sas_token`\n- `storage_account` to access via https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n\nIf multiple are set then the `storage_connection_string` is given priority.\n\nIf the `storage_connection_string` does not contain the `AccountName` parameter, please specify it in the\n`storage_account` field.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "azure_data_lake_gen2",
      "plugin": true,
      "status": "beta",
      "summary": "Sends message parts as files to an Azure Data Lake Gen2 filesystem. Each file is uploaded with the filename specified with the `path` field.",
      "type": "output",
      "version": "4.38.0"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The name of the target Queue Storage queue.",
            "interpolated": true,
            "kind": "scalar",
            "name": "queue_name",
            "type": "string"
          },
          {
            "default": "",
            "description": "The TTL of each individual message as a duration string. Defaults to 0, meaning no retention period is set",
            "examples": [
              "60s",
              "5m",
              "36h"
            ],
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "ttl",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nOnly one authentication method is required, `storage_connection_string` or `storage_account` and `storage_access_key`. If both are set then the `storage_connection_string` is given priority.\n\nIn order to set the `queue_name` you can use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are calculated per message of a batch.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "azure_queue_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Sends messages to an Azure Storage Queue.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services",
        "Azure"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_account",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
            "kind": "scalar",
            "name": "storage_access_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
            "kind": "scalar",
            "name": "storage_connection_string",
            "type": "string"
          },
          {
            "default": "",
            "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
            "kind": "scalar",
            "name": "storage_sas_token",
            "type": "string"
          },
          {
            "description": "The table to store messages into.",
            "examples": [
              "${! meta(\"kafka_topic\") }",
              "${! json(\"table\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "table_name",
            "type": "string"
          },
          {
            "default": "",
            "description": "The partition key.",
            "examples": [
              "${! json(\"date\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "partition_key",
            "type": "string"
          },
          {
            "default": "",
            "description": "The row key.",
            "examples": [
              "${! json(\"device\")}-${!uuid_v4() }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "row_key",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of properties to store into the table.",
            "interpolated": true,
            "kind": "map",
            "name": "properties",
            "type": "string"
          },
          {
            "default": "",
            "description": "Type of insert operation. Valid options are `INSERT`, `INSERT_MERGE` and `INSERT_REPLACE`",
            "examples": [
              "${! json(\"operation\") }",
              "${! meta(\"operation\") }",
              "INSERT"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"insert\": true,\n  \"insert_merge\": true,\n  \"insert_replace\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "insert_type",
            "options": [
              "INSERT",
              "INSERT_MERGE",
              "INSERT_REPLACE"
            ],
            "type": "string"
          },
          {
            "default": "INSERT",
            "description": "Type of transaction operation.",
            "examples": [
              "${! json(\"operation\") }",
              "${! meta(\"operation\") }",
              "INSERT"
            ],
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"insert\": true,\n  \"insert_merge\": true,\n  \"insert_replace\": true,\n  \"update_merge\": true,\n  \"update_replace\": true,\n  \"delete\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transaction_type",
            "options": [
              "INSERT",
              "INSERT_MERGE",
              "INSERT_REPLACE",
              "UPDATE_MERGE",
              "UPDATE_REPLACE",
              "DELETE"
            ],
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": "5s",
            "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.storage_connection_string != \"\" && !this.storage_connection_string.contains(\"AccountName=\")  && !this.storage_connection_string.contains(\"UseDevelopmentStorage=true;\") && this.storage_account == \"\" { [ \"storage_account must be set if storage_connection_string does not contain the \\\"AccountName\\\" parameter\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "\nOnly one authentication method is required, `storage_connection_string` or `storage_account` and `storage_access_key`. If both are set then the `storage_connection_string` is given priority.\n\nIn order to set the `table_name`,  `partition_key` and `row_key` you can use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are calculated per message of a batch.\n\nIf the `properties` are not set in the config, all the `json` fields are marshalled and stored in the table, which will be created if it does not exist.\n\nThe `object` and `array` fields are marshaled as strings. e.g.:\n\nThe JSON message:\n\n```json\n{\n  \"foo\": 55,\n  \"bar\": {\n    \"baz\": \"a\",\n    \"bez\": \"b\"\n  },\n  \"diz\": [\"a\", \"b\"]\n}\n```\n\nWill store in the table the following properties:\n\n```yml\nfoo: '55'\nbar: '{ \"baz\": \"a\", \"bez\": \"b\" }'\ndiz: '[\"a\", \"b\"]'\n```\n\nIt's also possible to use function interpolations to get or transform the properties values, e.g.:\n\n```yml\nproperties:\n  device: '${! json(\"device\") }'\n  timestamp: '${! json(\"timestamp\") }'\n```\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "azure_table_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Stores messages in an Azure Table Storage table.",
      "type": "output",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "An address to connect to.",
            "examples": [
              "127.0.0.1:11300"
            ],
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "beanstalkd",
      "plugin": true,
      "status": "experimental",
      "summary": "Write messages to a Beanstalkd queue.",
      "type": "output",
      "version": "4.7.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": 1,
            "description": "The number of copies of each configured output to spawn.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "copies",
            "type": "int"
          },
          {
            "default": "fan_out",
            "description": "The brokering pattern to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"fan_out\": true,\n  \"fan_out_fail_fast\": true,\n  \"fan_out_sequential\": true,\n  \"fan_out_sequential_fail_fast\": true,\n  \"round_robin\": true,\n  \"greedy\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "pattern",
            "options": [
              "fan_out",
              "fan_out_fail_fast",
              "fan_out_sequential",
              "fan_out_sequential_fail_fast",
              "round_robin",
              "greedy"
            ],
            "type": "string"
          },
          {
            "description": "A list of child outputs to broker.",
            "kind": "array",
            "name": "outputs",
            "type": "output"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nxref:components:processors/about.adoc[Processors] can be listed to apply across individual outputs or all outputs:\n\n```yaml\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n      - resource: foo\n      - resource: bar\n        # Processors only applied to messages sent to bar.\n        processors:\n          - resource: bar_processor\n\n  # Processors applied to messages sent to all brokered outputs.\n  processors:\n    - resource: general_processor\n```",
      "footnotes": "\n== Patterns\n\nThe broker pattern determines the way in which messages are allocated and can be chosen from the following:\n\n=== `fan_out`\n\nWith the fan out pattern all outputs will be sent every message that passes through Redpanda Connect in parallel.\n\nIf an output applies back pressure it will block all subsequent messages, and if an output fails to send a message it will be retried continuously until completion or service shut down. This mechanism is in place in order to prevent one bad output from causing a larger retry loop that results in a good output from receiving unbounded message duplicates.\n\nSometimes it is useful to disable the back pressure or retries of certain fan out outputs and instead drop messages that have failed or were blocked. In this case you can wrap outputs with a xref:components:outputs/drop_on.adoc[`drop_on` output].\n\n=== `fan_out_fail_fast`\n\nThe same as the `fan_out` pattern, except that output failures will not be automatically retried. This pattern should be used with caution as busy retry loops could result in unlimited duplicates being introduced into the non-failure outputs.\n\n=== `fan_out_sequential`\n\nSimilar to the fan out pattern except outputs are written to sequentially, meaning an output is only written to once the preceding output has confirmed receipt of the same message.\n\nIf an output applies back pressure it will block all subsequent messages, and if an output fails to send a message it will be retried continuously until completion or service shut down. This mechanism is in place in order to prevent one bad output from causing a larger retry loop that results in a good output from receiving unbounded message duplicates.\n\n=== `fan_out_sequential_fail_fast`\n\nThe same as the `fan_out_sequential` pattern, except that output failures will not be automatically retried. This pattern should be used with caution as busy retry loops could result in unlimited duplicates being introduced into the non-failure outputs.\n\n=== `round_robin`\n\nWith the round robin pattern each message will be assigned a single output following their order. If an output applies back pressure it will block all subsequent messages. If an output fails to send a message then the message will be re-attempted with the next input, and so on.\n\n=== `greedy`\n\nThe greedy pattern results in higher output throughput at the cost of potentially disproportionate message allocations to those outputs. Each message is sent to a single output, which is determined by allowing outputs to claim messages as soon as they are able to process them. This results in certain faster outputs potentially processing more messages at the cost of slower outputs.",
      "name": "broker",
      "plugin": true,
      "status": "stable",
      "summary": "Allows you to route messages to multiple child outputs using a range of brokering <<patterns>>.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The target cache to store messages in.",
            "kind": "scalar",
            "name": "target",
            "type": "string"
          },
          {
            "default": "${!count(\"items\")}-${!timestamp_unix_nano()}",
            "description": "The key to store messages by, function interpolation should be used in order to derive a unique key for each message.",
            "examples": [
              "${!count(\"items\")}-${!timestamp_unix_nano()}",
              "${!json(\"doc.id\")}",
              "${!meta(\"kafka_key\")}"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "The TTL of each individual item as a duration string. After this period an item will be eligible for removal during the next compaction. Not all caches support per-key TTLs, and those that do not will fall back to their generally configured TTL setting.",
            "examples": [
              "60s",
              "5m",
              "36h"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "ttl",
            "type": "string",
            "version": "3.33.0"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Caches are configured as xref:components:caches/about.adoc[resources], where there's a wide variety to choose from.\n\n:cache-support: aws_dynamodb=certified, aws_s3=certified, file=certified, memcached=certified, memory=certified, nats_kv=certified, redis=certified, ristretto=certified, couchbase=community, mongodb=community, sql=community, multilevel=community, ttlru=community, gcp_cloud_storage=community, lru=community, noop=community\n\nThe `target` field must reference a configured cache resource label like follows:\n\n```yaml\noutput:\n  cache:\n    target: foo\n    key: ${!json(\"document.id\")}\n\ncache_resources:\n  - label: foo\n    memcached:\n      addresses:\n        - localhost:11211\n      default_ttl: 60s\n```\n\nIn order to create a unique `key` value per item you should use function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "cache",
      "plugin": true,
      "status": "stable",
      "summary": "Stores each message in a xref:components:caches/about.adoc[cache].",
      "type": "output"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "A list of Cassandra nodes to connect to. Multiple comma separated addresses can be specified on a single line.",
            "examples": [
              [
                "localhost:9042"
              ],
              [
                "foo:9042",
                "bar:9042"
              ],
              [
                "foo:9042,bar:9042"
              ]
            ],
            "kind": "array",
            "name": "addresses",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use password authentication",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "The username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "The password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of Cassandra authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "password_authenticator",
            "type": "object"
          },
          {
            "default": false,
            "description": "If enabled the driver will not attempt to get host info from the system.peers table. This can speed up queries but will mean that data_centre, rack and token information will not be available.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "disable_initial_host_lookup",
            "type": "bool"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before giving up on a request.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          },
          {
            "default": "600ms",
            "description": "The client connection timeout.",
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The local DC to use, enables DC aware policy.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "local_dc",
                "type": "string"
              },
              {
                "description": "The local rack to use, requires local_dc to be set, enables rack aware policy.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "local_rack",
                "type": "string"
              }
            ],
            "description": "Optional host selection policy configurations. Highly recommended in deployments with multiple DCs. Host selection is always token aware if the token can be calculated from query. By default the underlying policy is round robin over all nodes. Users can specify a local DC and rack to use for the DC Aware & Rack Aware policies. ",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this.local_rack != \"\" && (!this.exists(\"local_dc\") || this.local_dc == \"\") { \"local_dc must be set if local_rack is set\" }",
            "name": "host_selection_policy",
            "type": "object"
          },
          {
            "description": "A query to execute for each message.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that can be used to provide arguments to Cassandra queries. The result of the query must be an array containing a matching number of elements to the query arguments.",
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string",
            "version": "3.55.0"
          },
          {
            "default": "QUORUM",
            "description": "The consistency level to use.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"any\": true,\n  \"one\": true,\n  \"two\": true,\n  \"three\": true,\n  \"quorum\": true,\n  \"all\": true,\n  \"local_quorum\": true,\n  \"each_quorum\": true,\n  \"local_one\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "consistency",
            "options": [
              "ANY",
              "ONE",
              "TWO",
              "THREE",
              "QUORUM",
              "ALL",
              "LOCAL_QUORUM",
              "EACH_QUORUM",
              "LOCAL_ONE"
            ],
            "type": "string"
          },
          {
            "default": true,
            "description": "If enabled the driver will perform a logged batch. Disabling this prompts unlogged batches to be used instead, which are less efficient but necessary for alternative storages that do not support logged batches.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "logged_batch",
            "type": "bool"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nQuery arguments can be set using a bloblang array for the fields using the `args_mapping` field.\n\nWhen populating timestamp columns the value must either be a string in ISO 8601 format (2006-01-02T15:04:05Z07:00), or an integer representing unix time in seconds.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\noutput:\n  cassandra:\n    addresses:\n      - localhost:9042\n    query: 'INSERT INTO foo.bar (id, content, created_at) VALUES (?, ?, ?)'\n    args_mapping: |\n      root = [\n        this.id,\n        this.content,\n        this.timestamp\n      ]\n    batching:\n      count: 500\n      period: 1s\n",
          "summary": "If we were to create a table with some basic columns with `CREATE TABLE foo.bar (id int primary key, content text, created_at timestamp);`, and were processing JSON documents of the form `{\"id\":\"342354354\",\"content\":\"hello world\",\"timestamp\":1605219406}` using logged batches, we could populate our table with the following config:",
          "title": "Basic Inserts"
        },
        {
          "config": "\noutput:\n  cassandra:\n    addresses:\n      - localhost:9042\n    query: 'INSERT INTO foospace.footable JSON ?'\n    args_mapping: 'root = [ this ]'\n    batching:\n      count: 500\n      period: 1s\n",
          "summary": "The following example inserts JSON documents into the table `footable` of the keyspace `foospace` using INSERT JSON (https://cassandra.apache.org/doc/latest/cql/json.html#insert-json).",
          "title": "Insert JSON Documents"
        }
      ],
      "name": "cassandra",
      "plugin": true,
      "status": "beta",
      "summary": "Runs a query against a Cassandra database for each message in order to insert data.",
      "type": "output"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "Couchbase connection string.",
            "examples": [
              "couchbase://localhost:11210"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "Username to connect to the cluster.",
            "is_optional": true,
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "description": "Password to connect to the cluster.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Couchbase bucket.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "description": "Bucket collection.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "description": "Bucket scope.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "scope",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "json",
                "JSONTranscoder implements the default transcoding behavior and applies JSON transcoding to all values. This will apply the following behavior to the value: binary ([]byte) -> error. default -> JSON value, JSON Flags."
              ],
              [
                "legacy",
                "LegacyTranscoder implements the behavior for a backward-compatible transcoder. This transcoder implements behavior matching that of gocb v1.This will apply the following behavior to the value: binary ([]byte) -> binary bytes, Binary expectedFlags. string -> string bytes, String expectedFlags. default -> JSON value, JSON expectedFlags."
              ],
              [
                "raw",
                "RawBinaryTranscoder implements passthrough behavior of raw binary data. This transcoder does not apply any serialization. This will apply the following behavior to the value: binary ([]byte) -> binary bytes, binary expectedFlags. default -> error."
              ],
              [
                "rawjson",
                "RawJSONTranscoder implements passthrough behavior of JSON data. This transcoder does not apply any serialization. It will forward data across the network without incurring unnecessary parsing costs. This will apply the following behavior to the value: binary ([]byte) -> JSON bytes, JSON expectedFlags. string -> JSON bytes, JSON expectedFlags. default -> error."
              ],
              [
                "rawstring",
                "RawStringTranscoder implements passthrough behavior of raw string data. This transcoder does not apply any serialization. This will apply the following behavior to the value: string -> string bytes, string expectedFlags. default -> error."
              ]
            ],
            "default": "legacy",
            "description": "Couchbase transcoder to use.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"json\": true,\n  \"legacy\": true,\n  \"raw\": true,\n  \"rawjson\": true,\n  \"rawstring\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transcoder",
            "type": "string"
          },
          {
            "default": "15s",
            "description": "Operation timeout.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "description": "Document id.",
            "examples": [
              "${! json(\"id\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "id",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "Document content.",
            "is_optional": true,
            "kind": "scalar",
            "name": "content",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "insert",
                "insert a new document."
              ],
              [
                "remove",
                "delete a document."
              ],
              [
                "replace",
                "replace the contents of a document."
              ],
              [
                "upsert",
                "creates a new document if it does not exist, if it does exist then it updates it."
              ]
            ],
            "default": "upsert",
            "description": "Couchbase operation to perform.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"insert\": true,\n  \"remove\": true,\n  \"replace\": true,\n  \"upsert\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "root = if ((this.operation == \"insert\" || this.operation == \"replace\" || this.operation == \"upsert\") && !this.exists(\"content\")) { [ \"content must be set for insert, replace and upsert operations.\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "When inserting, replacing or upserting documents, each must have the `content` property set.\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "couchbase",
      "plugin": true,
      "status": "experimental",
      "summary": "Performs operations against Couchbase for each message, allowing you to store or delete data.",
      "type": "output",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The connection URI to connect to.\nSee https://neo4j.com/docs/go-manual/current/connect-advanced/[Neo4j's documentation^] for more information. ",
            "examples": [
              "neo4j://demo.neo4jlabs.com",
              "neo4j+s://aura.databases.neo4j.io",
              "neo4j+ssc://self-signed.demo.neo4jlabs.com",
              "bolt://127.0.0.1:7687",
              "bolt+s://core.db.server:7687",
              "bolt+ssc://10.0.0.43"
            ],
            "kind": "scalar",
            "name": "uri",
            "type": "string"
          },
          {
            "description": "The cypher expression to execute against the graph database.",
            "examples": [
              "MERGE (p:Person {name: $name})",
              "MATCH (o:Organization {id: $orgId})\nMATCH (p:Person {name: $name})\nMERGE (p)-[:WORKS_FOR]->(o)"
            ],
            "kind": "scalar",
            "name": "cypher",
            "type": "string"
          },
          {
            "default": "",
            "description": "Set the target database for which expressions are evaluated against.",
            "kind": "scalar",
            "name": "database_name",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The mapping from the message to the data that is passed in as parameters to the cypher expression. Must be an object. By default the entire payload is used.",
            "examples": [
              "root.name = this.displayName",
              "root = {\"orgId\": this.org.id, \"name\": this.user.name}"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The realm for authentication challenges.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "realm",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The cypher output type writes a batch of messages to any graph database that supports the Neo4j or Bolt protocols.",
      "examples": [
        {
          "config": "\noutput:\n  cypher:\n    uri: neo4j+s://example.databases.neo4j.io\n    cypher: |\n      MERGE (product:Product {id: $id})\n        ON CREATE SET product.name = $product,\n                       product.title = $title,\n                       product.description = $description,\n    args_mapping: |\n      root = {}\n      root.id = this.product.id \n      root.product = this.product.summary.name\n      root.title = this.product.summary.displayName\n      root.description = this.product.fullDescription\n    basic_auth:\n      enabled: true\n      username: \"${NEO4J_USER}\"\n      password: \"${NEO4J_PASSWORD}\"\n",
          "summary": "This is an example of how to write to Neo4j Aura",
          "title": "Write to Neo4j Aura"
        }
      ],
      "name": "cypher",
      "plugin": true,
      "status": "experimental",
      "type": "output",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Services",
        "Social"
      ],
      "config": {
        "children": [
          {
            "description": "A discord channel ID to write messages to.",
            "kind": "scalar",
            "name": "channel_id",
            "type": "string"
          },
          {
            "description": "A bot token used for authentication.",
            "kind": "scalar",
            "name": "bot_token",
            "type": "string"
          },
          {
            "default": "An optional rate limit resource to restrict API requests with.",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis output POSTs messages to the `/channels/\\{channel_id}/messages` Discord API endpoint authenticated as a bot using token based authentication.\n\nIf the format of a message is a JSON object matching the https://discord.com/developers/docs/resources/channel#message-object[Discord API message type^] then it is sent directly, otherwise an object matching the API type is created with the content of the message added as a string.\n",
      "name": "discord",
      "plugin": true,
      "status": "experimental",
      "summary": "Writes messages to a Discord channel.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "drop",
      "plugin": true,
      "status": "stable",
      "summary": "Drops all messages.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether messages should be dropped when the child output returns an error of any type. For example, this could be when an `http_client` output gets a 4XX response code. In order to instead drop only on specific error patterns use the `error_matches` field instead.",
            "kind": "scalar",
            "name": "error",
            "type": "bool"
          },
          {
            "description": "A list of regular expressions (re2) where if the child output returns an error that matches any part of any of these patterns the message will be dropped.",
            "examples": [
              [
                "and that was really bad$"
              ],
              [
                "roughly [0-9]+ issues occurred"
              ]
            ],
            "is_optional": true,
            "kind": "array",
            "name": "error_patterns",
            "type": "string",
            "version": "4.27.0"
          },
          {
            "description": "An optional duration string that determines the maximum length of time to wait for a given message to be accepted by the child output before the message should be dropped instead. The most common reason for an output to block is when waiting for a lost connection to be re-established. Once a message has been dropped due to back pressure all subsequent messages are dropped immediately until the output is ready to process them again. Note that if `error` is set to `false` and this field is specified then messages dropped due to back pressure will return an error response (are nacked or reattempted).",
            "examples": [
              "30s",
              "1m"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "back_pressure",
            "type": "string"
          },
          {
            "description": "A child output to wrap with this drop mechanism.",
            "kind": "scalar",
            "name": "output",
            "type": "output"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Regular Redpanda Connect outputs will apply back pressure when downstream services aren't accessible, and Redpanda Connect retries (or nacks) all messages that fail to be delivered. However, in some circumstances, or for certain output types, we instead might want to relax these mechanisms, which is when this output becomes useful.",
      "examples": [
        {
          "config": "\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n      - kafka:\n          addresses: [ foobar:6379 ]\n          topic: foo\n      - drop_on:\n          error: true\n          output:\n            http_client:\n              url: http://example.com/foo/messages\n              verb: POST\n",
          "summary": "In this example we have a fan_out broker, where we guarantee delivery to our Kafka output, but drop messages if they fail our secondary HTTP client output.",
          "title": "Dropping failed HTTP requests"
        },
        {
          "config": "\noutput:\n  drop_on:\n    back_pressure: 10s\n    output:\n      websocket:\n        url: ws://example.com/foo/messages\n",
          "summary": "Most outputs that attempt to establish and long-lived connection will apply back-pressure when the connection is lost. The following example has a websocket output where if it takes longer than 10 seconds to establish a connection, or recover a lost one, pending messages are dropped.",
          "title": "Dropping from outputs that cannot connect"
        }
      ],
      "name": "drop_on",
      "plugin": true,
      "status": "stable",
      "summary": "Attempts to write messages to a child output and if the write fails for one of a list of configurable reasons the message is dropped (acked) instead of being reattempted (or nacked).",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": {},
            "description": "A map of outputs to statically create.",
            "kind": "map",
            "name": "outputs",
            "type": "output"
          },
          {
            "default": "",
            "description": "A path prefix for HTTP endpoints that are registered.",
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The broker pattern used is always `fan_out`, meaning each message will be delivered to each dynamic output.",
      "footnotes": "\n== Endpoints\n\n=== GET `/outputs`\n\nReturns a JSON object detailing all dynamic outputs, providing information such as their current uptime and configuration.\n\n=== GET `/outputs/\\{id}`\n\nReturns the configuration of an output.\n\n=== POST `/outputs/\\{id}`\n\nCreates or updates an output with a configuration provided in the request body (in YAML or JSON format).\n\n=== DELETE `/outputs/\\{id}`\n\nStops and removes an output.\n\n=== GET `/outputs/\\{id}/uptime`\n\nReturns the uptime of an output as a duration string (of the form \"72h3m0.5s\").",
      "name": "dynamic",
      "plugin": true,
      "status": "stable",
      "summary": "A special broker type where the outputs are identified by unique labels and can be created, changed and removed during runtime via a REST API.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "http://localhost:9200"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The index to place messages.",
            "interpolated": true,
            "kind": "scalar",
            "name": "index",
            "type": "string"
          },
          {
            "description": "The action to take on the document. This field must resolve to one of the following action types: `index`, `update`, `delete`, `create` or `upsert`. See the `Updating Documents` example for more on how the `update` action works and the `Create Documents` and `Upserting Documents` examples for how to use the `create` and `upsert` actions respectively.",
            "interpolated": true,
            "kind": "scalar",
            "name": "action",
            "type": "string"
          },
          {
            "description": "The ID for indexed messages. Interpolation should be used in order to create a unique ID for each message.",
            "examples": [
              "${!counter()}-${!timestamp_unix()}"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "id",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional pipeline id to preprocess incoming documents.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "pipeline",
            "type": "string"
          },
          {
            "default": "",
            "description": "The routing key to use for the document.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "routing",
            "type": "string"
          },
          {
            "default": 0,
            "description": "Specify how many times should an update operation be retried when a conflict occurs",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_on_conflict",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nBoth the `id` and `index` fields can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\n# Partial document update\noutput:\n  processors:\n    - mapping: |\n        meta id = this.id\n        # Performs a partial update ont he document.\n        root.doc = this\n  elasticsearch_v8:\n    urls: [localhost:9200]\n    index: foo\n    id: ${! @id }\n    action: update\n\n# Scripted update\noutput:\n  processors:\n    - mapping: |\n        meta id = this.id\n        # Increments the field \"counter\" by 1.\n        root.script.source = \"ctx._source.counter += 1\"\n  elasticsearch_v8:\n    urls: [localhost:9200]\n    index: foo\n    id: ${! @id }\n    action: update\n\n# Upsert\noutput:\n  processors:\n    - mapping: |\n        meta id = this.id\n        # If the product with the ID exists, its price will be updated to 100.\n        # If the product does not exist, a new document with ID 1 and a price\n        # of 50 will be inserted.\n        root.doc.product_price = 50\n        root.upsert.product_price = 100\n  elasticsearch_v8:\n    urls: [localhost:9200]\n    index: foo\n    id: ${! @id }\n    action: update\n",
          "summary": "When updating documents, the request body should contain a combination of a `doc`, `upsert`, and/or `script` fields at the top level, this should be done via mapping processors. `doc` updates using a partial document, `script` performs an update using a scripting language such as the built in Painless language, and `upsert` updates an existing document or inserts a new one if it doesn’t exist. For more information on the structures and behaviors of these fields, please see the https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html[Elasticsearch Update API^]",
          "title": "Updating Documents"
        },
        {
          "config": "\ninput:\n  redpanda:\n    seed_brokers: [localhost:19092]\n    topics: [\"things\"]\n    consumer_group: \"rpcn3\"\n  processors:\n    - mapping: |\n        meta id = this.id\n        root = this\noutput:\n  elasticsearch_v8:\n    urls: ['http://localhost:9200']\n    index: \"things\"\n    action: \"index\"\n    id: ${! meta(\"id\") }\n",
          "summary": "Here we read messages from a Redpanda cluster and write them to an Elasticsearch index using a field from the message as the ID for the Elasticsearch document.",
          "title": "Indexing documents from Redpanda"
        },
        {
          "config": "\ninput:\n  aws_s3:\n    bucket: \"my-cool-bucket\"\n    prefix: \"bug-facts/\"\n    scanner:\n      to_the_end: {}\noutput:\n  elasticsearch_v8:\n    urls: ['http://localhost:9200']\n    index: \"cool-bug-facts\"\n    action: \"index\"\n    id: ${! meta(\"s3_key\") }\n",
          "summary": "Here we read messages from a AWS S3 bucket and write them to an Elasticsearch index using the S3 key as the ID for the Elasticsearch document.",
          "title": "Indexing documents from S3"
        },
        {
          "config": "\noutput:\n  elasticsearch_v8:\n    urls: [localhost:9200]\n    index: foo\n    id: ${! json(\"id\") }\n    action: create\n",
          "summary": "When using the `create` action, a new document will be created if the document ID does not already exist. If the document ID already exists, the operation will fail.",
          "title": "Create Documents"
        },
        {
          "config": "\noutput:\n  processors:\n    - mapping: |\n        meta id = this.id\n        root = this.doc\n  elasticsearch_v8:\n    urls: [localhost:9200]\n    index: foo\n    id: ${! @id }\n    action: upsert\n",
          "summary": "When using the `upsert` action, if the document ID already exists, it will be updated. If the document ID does not exist, a new document will be inserted. The request body should contain the document to be indexed.",
          "title": "Upserting Documents"
        }
      ],
      "name": "elasticsearch_v8",
      "plugin": true,
      "status": "stable",
      "summary": "Publishes messages into an Elasticsearch index. If the index does not exist then it is created with a dynamic mapping.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": [],
        "kind": "array",
        "name": "",
        "type": "output"
      },
      "description": "\nThis pattern is useful for triggering events in the case where certain output targets have broken. For example, if you had an output type `http_client` but wished to reroute messages whenever the endpoint becomes unreachable you could use this pattern:\n\n```yaml\noutput:\n  fallback:\n    - http_client:\n        url: http://foo:4195/post/might/become/unreachable\n        retries: 3\n        retry_period: 1s\n    - http_client:\n        url: http://bar:4196/somewhere/else\n        retries: 3\n        retry_period: 1s\n      processors:\n        - mapping: 'root = \"failed to send this message to foo: \" + content()'\n    - file:\n        path: /usr/local/benthos/everything_failed.jsonl\n```\n\n== Metadata\n\nWhen a given output fails the message routed to the following output will have a metadata value named `fallback_error` containing a string error message outlining the cause of the failure. The content of this string will depend on the particular output and can be used to enrich the message or provide information used to broker the data to an appropriate output using something like a `switch` output.\n\n== Batching\n\nWhen an output within a fallback sequence uses batching, like so:\n\n```yaml\noutput:\n  fallback:\n    - aws_dynamodb:\n        table: foo\n        string_columns:\n          id: ${!json(\"id\")}\n          content: ${!content()}\n        batching:\n          count: 10\n          period: 1s\n    - file:\n        path: /usr/local/benthos/failed_stuff.jsonl\n```\n\nRedpanda Connect makes a best attempt at inferring which specific messages of the batch failed, and only propagates those individual messages to the next fallback tier.\n\nHowever, depending on the output and the error returned it is sometimes not possible to determine the individual messages that failed, in which case the whole batch is passed to the next tier in order to preserve at-least-once delivery guarantees.",
      "name": "fallback",
      "plugin": true,
      "status": "stable",
      "summary": "Attempts to send each message to a child output, starting from the first output on the list. If an output attempt fails then the next output in the list is attempted, and so on.",
      "type": "output",
      "version": "3.58.0"
    },
    {
      "categories": [
        "Local"
      ],
      "config": {
        "children": [
          {
            "description": "The file to write to, if the file does not yet exist it will be created.",
            "examples": [
              "/tmp/data.txt",
              "/tmp/${! timestamp_unix() }.txt",
              "/tmp/${! json(\"document.id\") }.json"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string",
            "version": "3.33.0"
          },
          {
            "annotated_options": [
              [
                "all-bytes",
                "Only applicable to file based outputs. Writes each message to a file in full, if the file already exists the old content is deleted."
              ],
              [
                "append",
                "Append each message to the output stream without any delimiter or special encoding."
              ],
              [
                "lines",
                "Append each message to the output stream followed by a line break."
              ],
              [
                "delim:x",
                "Append each message to the output stream followed by a custom delimiter."
              ]
            ],
            "default": "lines",
            "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar"
            ],
            "kind": "scalar",
            "name": "codec",
            "type": "string",
            "version": "3.33.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Messages can be written to different files by using xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the path field. However, only one file is ever open at a given time, and therefore when the path changes the previously open file is closed.",
      "name": "file",
      "plugin": true,
      "status": "stable",
      "summary": "Writes messages to files on disk based on a chosen codec.",
      "type": "output"
    },
    {
      "categories": [
        "GCP",
        "Services"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "The project ID of the dataset to insert data to. If not set, it will be inferred from the credentials or read from the GOOGLE_CLOUD_PROJECT environment variable.",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "default": "",
            "description": "The project ID in which jobs will be exectuted. If not set, project will be used.",
            "kind": "scalar",
            "name": "job_project",
            "type": "string"
          },
          {
            "description": "The BigQuery Dataset ID.",
            "kind": "scalar",
            "name": "dataset",
            "type": "string"
          },
          {
            "description": "The table to insert messages to.",
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "default": "NEWLINE_DELIMITED_JSON",
            "description": "The format of each incoming message.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"newline_delimited_json\": true,\n  \"csv\": true,\n  \"parquet\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "format",
            "options": [
              "NEWLINE_DELIMITED_JSON",
              "CSV",
              "PARQUET"
            ],
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of message batches to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": "WRITE_APPEND",
            "description": "Specifies how existing data in a destination table is treated.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"write_append\": true,\n  \"write_empty\": true,\n  \"write_truncate\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "write_disposition",
            "options": [
              "WRITE_APPEND",
              "WRITE_EMPTY",
              "WRITE_TRUNCATE"
            ],
            "type": "string"
          },
          {
            "default": "CREATE_IF_NEEDED",
            "description": "Specifies the circumstances under which destination table will be created. If CREATE_IF_NEEDED is used the GCP BigQuery will create the table if it does not already exist and tables are created atomically on successful completion of a job. The CREATE_NEVER option ensures the table must already exist and will not be automatically created.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"create_if_needed\": true,\n  \"create_never\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "create_disposition",
            "options": [
              "CREATE_IF_NEEDED",
              "CREATE_NEVER"
            ],
            "type": "string"
          },
          {
            "default": false,
            "description": "Causes values not matching the schema to be tolerated. Unknown values are ignored. For CSV this ignores extra values at the end of a line. For JSON this ignores named values that do not match any column name. If this field is set to false (the default value), records containing unknown values are treated as bad records. The max_bad_records field can be used to customize how bad records are handled.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ignore_unknown_values",
            "type": "bool"
          },
          {
            "default": 0,
            "description": "The maximum number of bad records that will be ignored when reading data.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_bad_records",
            "type": "int"
          },
          {
            "default": false,
            "description": "Indicates if we should automatically infer the options and schema for CSV and JSON sources. If the table doesn't exist and this field is set to `false` the output may not be able to insert data and will throw insertion error. Be careful using this field since it delegates to the GCP BigQuery service the schema detection and values like `\"no\"` may be treated as booleans for the CSV format.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auto_detect",
            "type": "bool"
          },
          {
            "default": {},
            "description": "A list of labels to add to the load job.",
            "kind": "map",
            "name": "job_labels",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "A list of values to use as header for each batch of messages. If not specified the first line of each message will be used as header.",
                "kind": "array",
                "name": "header",
                "type": "string"
              },
              {
                "default": ",",
                "description": "The separator for fields in a CSV file, used when reading or exporting data.",
                "kind": "scalar",
                "name": "field_delimiter",
                "type": "string"
              },
              {
                "default": false,
                "description": "Causes missing trailing optional columns to be tolerated when reading CSV data. Missing values are treated as nulls.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "allow_jagged_rows",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Sets whether quoted data sections containing newlines are allowed when reading CSV data.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "allow_quoted_newlines",
                "type": "bool"
              },
              {
                "default": "UTF-8",
                "description": "Encoding is the character encoding of data to be read.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"utf-8\": true,\n  \"iso-8859-1\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "encoding",
                "options": [
                  "UTF-8",
                  "ISO-8859-1"
                ],
                "type": "string"
              },
              {
                "default": 1,
                "description": "The number of rows at the top of a CSV file that BigQuery will skip when reading data. The default value is 1 since Redpanda Connect will add the specified header in the first line of each batch sent to BigQuery.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_leading_rows",
                "type": "int"
              }
            ],
            "description": "Specify how CSV data should be interpretted.",
            "kind": "scalar",
            "name": "csv",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to GCP services. You can find out more in xref:guides:cloud/gcp.adoc[].\n\n== Format\n\nThis output currently supports only CSV, NEWLINE_DELIMITED_JSON and PARQUET, formats. Learn more about how to use GCP BigQuery with them here:\n\n- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json[`NEWLINE_DELIMITED_JSON`^]\n- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv[`CSV`^]\n- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet[`PARQUET`^]\n\nEach message may contain multiple elements separated by newlines. For example a single message containing:\n\n```json\n{\"key\": \"1\"}\n{\"key\": \"2\"}\n```\n\nIs equivalent to two separate messages:\n\n```json\n{\"key\": \"1\"}\n```\n\nAnd:\n\n```json\n{\"key\": \"2\"}\n```\n\nThe same is true for the CSV format.\n\n=== CSV\n\nFor the CSV format when the field `csv.header` is specified a header row will be inserted as the first line of each message batch. If this field is not provided then the first message of each message batch must include a header line.\n\n=== Parquet\n\nFor parquet, the data can be encoded using the `parquet_encode` processor and each message that is sent to the output must be a full parquet message.\n\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "gcp_bigquery",
      "plugin": true,
      "status": "beta",
      "summary": "Sends messages as new rows to a Google Cloud BigQuery table.",
      "type": "output",
      "version": "3.55.0"
    },
    {
      "categories": [
        "Services",
        "GCP"
      ],
      "config": {
        "children": [
          {
            "description": "The bucket to upload messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
            "description": "The path of each message to upload.",
            "examples": [
              "${!counter()}-${!timestamp_unix_nano()}.txt",
              "${!meta(\"kafka_key\")}.json",
              "${!json(\"doc.namespace\")}/${!json(\"doc.id\")}.json"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": "application/octet-stream",
            "description": "The content type to set for each object.",
            "interpolated": true,
            "kind": "scalar",
            "name": "content_type",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional content encoding to set for each object.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "content_encoding",
            "type": "string"
          },
          {
            "default": "overwrite",
            "description": "Determines how file path collisions should be dealt with. Options are \"overwrite\", which replaces the existing file with the new one, \"append\", which appends the message bytes to the original file, \"error-if-exists\", which returns an error and rejects the message if the file exists, and \"ignore\", does not modify the original file and drops the message.",
            "interpolated": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"overwrite\": true,\n  \"append\": true,\n  \"error-if-exists\": true,\n  \"ignore\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "collision_mode",
            "options": [
              "overwrite",
              "append",
              "error-if-exists",
              "ignore"
            ],
            "type": "string",
            "version": "3.53.0"
          },
          {
            "default": 16777216,
            "description": "An optional chunk size which controls the maximum number of bytes of the object that the Writer will attempt to send to the server in a single request. If ChunkSize is set to zero, chunking will be disabled.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "chunk_size",
            "type": "int"
          },
          {
            "default": "3s",
            "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
            "examples": [
              "1s",
              "500ms"
            ],
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "interpolated": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of message batches to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIn order to have a different path for each object you should use function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries], which are calculated per message of a batch.\n\n== Metadata\n\nMetadata fields on messages will be sent as headers, in order to mutate these values (or remove them) check out the xref:configuration:metadata.adoc[metadata docs].\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to GCP services. You can find out more in xref:guides:cloud/gcp.adoc[].\n\n== Batching\n\nIt's common to want to upload messages to Google Cloud Storage as batched archives, the easiest way to do this is to batch your messages at the output level and join the batch of messages with an xref:components:processors/archive.adoc[`archive`] and/or xref:components:processors/compress.adoc[`compress`] processor.\n\nFor example, if we wished to upload messages as a .tar.gz archive of documents we could achieve that with the following config:\n\n```yaml\noutput:\n  gcp_cloud_storage:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.tar.gz\n    batching:\n      count: 100\n      period: 10s\n      processors:\n        - archive:\n            format: tar\n        - compress:\n            algorithm: gzip\n```\n\nAlternatively, if we wished to upload JSON documents as a single large document containing an array of objects we can do that with:\n\n```yaml\noutput:\n  gcp_cloud_storage:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.json\n    batching:\n      count: 100\n      processors:\n        - archive:\n            format: json_array\n```\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "gcp_cloud_storage",
      "plugin": true,
      "status": "beta",
      "summary": "Sends message parts as objects to a Google Cloud Storage bucket. Each object is uploaded with the path specified with the `path` field.",
      "type": "output",
      "version": "3.43.0"
    },
    {
      "categories": [
        "Services",
        "GCP"
      ],
      "config": {
        "children": [
          {
            "description": "The project ID of the topic to publish to.",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The topic to publish to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional endpoint to override the default of `pubsub.googleapis.com:443`. This can be used to connect to a region specific pubsub endpoint. For a list of valid values, see https://cloud.google.com/pubsub/docs/reference/service_apis_overview#list_of_regional_endpoints[this document^].",
            "examples": [
              "us-central1-pubsub.googleapis.com:443",
              "us-west3-pubsub.googleapis.com:443"
            ],
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "description": "The ordering key to use for publishing messages.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "ordering_key",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increasing this may improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": 100,
            "description": "Publish a pubsub buffer when it has this many messages",
            "kind": "scalar",
            "name": "count_threshold",
            "type": "int"
          },
          {
            "default": "10ms",
            "description": "Publish a non-empty pubsub buffer after this delay has passed.",
            "kind": "scalar",
            "name": "delay_threshold",
            "type": "string"
          },
          {
            "default": 1000000,
            "description": "Publish a batch when its size in bytes reaches this value.",
            "kind": "scalar",
            "name": "byte_threshold",
            "type": "int"
          },
          {
            "default": "1m0s",
            "description": "The maximum length of time to wait before abandoning a publish attempt for a message.",
            "examples": [
              "10s",
              "5m",
              "60m"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "publish_timeout",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether to validate the existence of the topic before publishing. If set to false and the topic does not exist, messages will be lost.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "validate_topic",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are sent as attributes, all are sent by default.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "children": [
              {
                "default": -1,
                "description": "Maximum size of buffered messages to be published. If less than or equal to zero, this is disabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_outstanding_bytes",
                "type": "int"
              },
              {
                "default": 1000,
                "description": "Maximum number of buffered messages to be published. If less than or equal to zero, this is disabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_outstanding_messages",
                "type": "int"
              },
              {
                "default": "block",
                "description": "Configures the behavior when trying to publish additional messages while the flow controller is full. The available options are block (default), ignore (disable), and signal_error (publish results will return an error).",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"ignore\": true,\n  \"block\": true,\n  \"signal_error\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "limit_exceeded_behavior",
                "options": [
                  "ignore",
                  "block",
                  "signal_error"
                ],
                "type": "string"
              }
            ],
            "description": "For a given topic, configures the PubSub client's internal buffer for messages to be published.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "flow_control",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "Configures a batching policy on this output. While the PubSub client maintains its own internal buffering mechanism, preparing larger batches of messages can further trade-off some latency for throughput.",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nFor information on how to set up credentials, see https://cloud.google.com/docs/authentication/production[this guide^].\n\n== Troubleshooting\n\nIf you're consistently seeing `Failed to send message to gcp_pubsub: context deadline exceeded` error logs without any further information it is possible that you are encountering https://github.com/benthosdev/benthos/issues/1042, which occurs when metadata values contain characters that are not valid utf-8. This can frequently occur when consuming from Kafka as the key metadata field may be populated with an arbitrary binary value, but this issue is not exclusive to Kafka.\n\nIf you are blocked by this issue then a work around is to delete either the specific problematic keys:\n\n```yaml\npipeline:\n  processors:\n    - mapping: |\n        meta kafka_key = deleted()\n```\n\nOr delete all keys with:\n\n```yaml\npipeline:\n  processors:\n    - mapping: meta = deleted()\n```",
      "name": "gcp_pubsub",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to a GCP Cloud Pub/Sub topic. xref:configuration:metadata.adoc[Metadata] from messages are sent as attributes.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of target host addresses to connect to.",
            "examples": [
              "localhost:9000"
            ],
            "kind": "array",
            "name": "hosts",
            "type": "string"
          },
          {
            "default": "",
            "description": "A user ID to connect as.",
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "description": "A directory to store message files within. If the directory does not exist it will be created.",
            "interpolated": true,
            "kind": "scalar",
            "name": "directory",
            "type": "string"
          },
          {
            "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
            "description": "The path to upload messages as, interpolation functions should be used in order to generate unique file paths.",
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Each file is written with the path specified with the 'path' field, in order to have a different path for each object you should use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "hdfs",
      "plugin": true,
      "status": "stable",
      "summary": "Sends message parts as files to a HDFS directory.",
      "type": "output"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "The URL to connect to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "default": "POST",
            "description": "A verb to connect with",
            "examples": [
              "POST",
              "GET",
              "DELETE"
            ],
            "kind": "scalar",
            "name": "verb",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of headers to add to the request.",
            "examples": [
              {
                "Content-Type": "application/octet-stream",
                "traceparent": "${! tracing_span().traceparent }"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "headers",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Specify optional matching rules to determine which metadata keys should be added to the HTTP request as headers.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "",
            "description": "EXPERIMENTAL: Optionally set a level at which the request and response payload of each request made will be logged.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"trace\": true,\n  \"debug\": true,\n  \"info\": true,\n  \"warn\": true,\n  \"error\": true,\n  \"fatal\": true,\n  \"\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "dump_request_log_level",
            "options": [
              "TRACE",
              "DEBUG",
              "INFO",
              "WARN",
              "ERROR",
              "FATAL",
              ""
            ],
            "type": "string",
            "version": "4.12.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 2 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the token provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "client_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the client key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "client_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The URL of the token provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_url",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "default": [],
                "description": "A list of optional requested permissions.",
                "is_advanced": true,
                "kind": "array",
                "name": "scopes",
                "type": "string",
                "version": "3.45.0"
              },
              {
                "default": {},
                "description": "A list of optional endpoint parameters, values should be arrays of strings.",
                "examples": [
                  {
                    "bar": [
                      "woof"
                    ],
                    "foo": [
                      "meow",
                      "quack"
                    ]
                  }
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "linter": "\nroot = if this.type() == \"object\" {\n  this.values().map_each(ele -> if ele.type() != \"array\" {\n    \"field must be an object containing arrays of strings, got %s (%v)\".format(ele.format_json(no_indent: true), ele.type())\n  } else {\n    ele.map_each(str -> if str.type() != \"string\" {\n      \"field values must be strings, got %s (%v)\".format(str.format_json(no_indent: true), str.type())\n    } else { deleted() })\n  }).\n    flatten()\n}\n",
                "name": "endpoint_params",
                "type": "unknown",
                "version": "4.21.0"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 2 using the client credentials token flow.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth2",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Specify which response headers should be added to resulting synchronous response messages as metadata. Header keys are lowercased before matching, so ensure that your patterns target lowercased versions of the header keys that you expect. This field is not applicable unless `propagate_response` is set to `true`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "extract_headers",
            "type": "object"
          },
          {
            "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
            "is_optional": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "A static timeout to apply to requests.",
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1s",
            "description": "The base period to wait between failed requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_period",
            "type": "string"
          },
          {
            "default": "300s",
            "description": "The maximum period to wait between failed requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retry_backoff",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of retry attempts to make.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether or not to transparently follow redirects, i.e. responses with 300-399 status codes. If disabled, the response message will contain the body, status, and headers from the redirect response and the processor will not make a request to the URL set in the Location header of the response.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "follow_redirects",
            "type": "bool"
          },
          {
            "default": [
              429
            ],
            "description": "A list of status codes whereby the request should be considered to have failed and retries should be attempted, but the period between them should be increased gradually.",
            "is_advanced": true,
            "kind": "array",
            "name": "backoff_on",
            "type": "int"
          },
          {
            "default": [],
            "description": "A list of status codes whereby the request should be considered to have failed but retries should not be attempted. This is useful for preventing wasted retries for requests that will never succeed. Note that with these status codes the _request_ is dropped, but _message_ that caused the request will not be dropped.",
            "is_advanced": true,
            "kind": "array",
            "name": "drop_on",
            "type": "int"
          },
          {
            "default": [],
            "description": "A list of status codes whereby the attempt should be considered successful, this is useful for dropping requests that return non-2XX codes indicating that the message has been dealt with, such as a 303 See Other or a 409 Conflict. All 2XX codes are considered successful unless they are present within `backoff_on` or `drop_on`, regardless of this field.",
            "is_advanced": true,
            "kind": "array",
            "name": "successful_on",
            "type": "int"
          },
          {
            "description": "An optional HTTP proxy URL.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "proxy_url",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether or not to disable disable HTTP/2",
            "is_advanced": true,
            "kind": "scalar",
            "name": "disable_http2",
            "type": "bool",
            "version": "4.44.0"
          },
          {
            "default": false,
            "description": "Send message batches as a single request using https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. If disabled messages in batches will be sent as individual requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "batch_as_multipart",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether responses from the server should be xref:guides:sync_responses.adoc[propagated back] to the input.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "propagate_response",
            "type": "bool"
          },
          {
            "default": 64,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "children": [
              {
                "default": "",
                "description": "The content type of the individual message part.",
                "examples": [
                  "application/bin"
                ],
                "interpolated": true,
                "is_advanced": true,
                "kind": "scalar",
                "name": "content_type",
                "type": "string"
              },
              {
                "default": "",
                "description": "The content disposition of the individual message part.",
                "examples": [
                  "form-data; name=\"bin\"; filename='${! @AttachmentName }"
                ],
                "interpolated": true,
                "is_advanced": true,
                "kind": "scalar",
                "name": "content_disposition",
                "type": "string"
              },
              {
                "default": "",
                "description": "The body of the individual message part.",
                "examples": [
                  "${! this.data.part1 }"
                ],
                "interpolated": true,
                "is_advanced": true,
                "kind": "scalar",
                "name": "body",
                "type": "string"
              }
            ],
            "default": [],
            "description": "EXPERIMENTAL: Create explicit multipart HTTP requests by specifying an array of parts to add to the request, each part specified consists of content headers and a data field that can be populated dynamically. If this field is populated it will override the default request creation behavior.",
            "is_advanced": true,
            "kind": "array",
            "name": "multipart",
            "type": "object",
            "version": "3.63.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen the number of retries expires the output will reject the message, the behavior after this will depend on the pipeline but usually this simply means the send is attempted again until successful whilst applying back pressure.\n\nThe URL and header values of this type can be dynamically set using function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].\n\nThe body of the HTTP request is the raw contents of the message payload. If the message has multiple parts (is a batch) the request will be sent according to https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. This behavior can be disabled by setting the field <<batch_as_multipart, `batch_as_multipart`>> to `false`.\n\n== Propagate responses\n\nIt's possible to propagate the response from each HTTP request back to the input source by setting `propagate_response` to `true`. Only inputs that support xref:guides:sync_responses.adoc[synchronous responses] are able to make use of these propagated responses.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "http_client",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to an HTTP server.",
      "type": "output"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "An alternative address to host from. If left empty the service wide address is used.",
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": "/get",
            "description": "The path from which discrete messages can be consumed.",
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": "/get/stream",
            "description": "The path from which a continuous stream of messages can be consumed.",
            "kind": "scalar",
            "name": "stream_path",
            "type": "string"
          },
          {
            "default": "/get/ws",
            "description": "The path from which websocket connections can be established.",
            "kind": "scalar",
            "name": "ws_path",
            "type": "string"
          },
          {
            "default": [
              "GET"
            ],
            "description": "An array of verbs that are allowed for the `path` and `stream_path` HTTP endpoint.",
            "kind": "array",
            "name": "allowed_verbs",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The maximum time to wait before a blocking, inactive connection is dropped (only applies to the `path` endpoint).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "",
            "description": "Enable TLS by specifying a certificate and key file. Only valid with a custom `address`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cert_file",
            "type": "string"
          },
          {
            "default": "",
            "description": "Enable TLS by specifying a certificate and key file. Only valid with a custom `address`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "key_file",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to allow CORS requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": [],
                "description": "An explicit list of origins that are allowed for CORS requests.",
                "is_advanced": true,
                "kind": "array",
                "name": "allowed_origins",
                "type": "string"
              }
            ],
            "description": "Adds Cross-Origin Resource Sharing headers. Only valid with a custom `address`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "cors",
            "type": "object",
            "version": "3.63.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Sets up an HTTP server that will send messages over HTTP(S) GET requests. If the `address` config field is left blank the xref:components:http/about.adoc[service-wide HTTP server] will be used.\n\nThree endpoints will be registered at the paths specified by the fields `path`, `stream_path` and `ws_path`. Which allow you to consume a single message batch, a continuous stream of line delimited messages, or a websocket of messages for each request respectively.\n\nWhen messages are batched the `path` endpoint encodes the batch according to https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. This behavior can be overridden by xref:configuration:batching.adoc#post-batch-processing[archiving your batches].\n\nPlease note, messages are considered delivered as soon as the data is written to the client. There is no concept of at least once delivery on this output.\n\n\n[CAUTION]\n.Endpoint caveats\n====\nComponents within a Redpanda Connect config will register their respective endpoints in a non-deterministic order. This means that establishing precedence of endpoints that are registered via multiple `http_server` inputs or outputs (either within brokers or from cohabiting streams) is not possible in a predictable way.\n\nThis ambiguity makes it difficult to ensure that paths which are both a subset of a path registered by a separate component, and end in a slash (`/`) and will therefore match against all extensions of that path, do not prevent the more specific path from matching against requests.\n\nIt is therefore recommended that you ensure paths of separate components do not collide unless they are explicitly non-competing.\n\nFor example, if you were to deploy two separate `http_server` inputs, one with a path `/foo/` and the other with a path `/foo/bar`, it would not be possible to ensure that the path `/foo/` does not swallow requests made to `/foo/bar`.\n====\n",
      "name": "http_server",
      "plugin": true,
      "status": "stable",
      "summary": "Sets up an HTTP server that will send messages over HTTP(S) GET requests. HTTP 2.0 is supported when using TLS, which is enabled when key and cert files are specified.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nSends data directly to Redpanda Connect inputs by connecting to a unique ID. This allows you to hook up isolated streams whilst running Redpanda Connect in xref:guides:streams_mode/about.adoc[streams mode], it is NOT recommended that you connect the inputs of a stream with an output of the same stream, as feedback loops can lead to deadlocks in your message flow.\n\nIt is possible to connect multiple inputs to the same inproc ID, resulting in messages dispatching in a round-robin fashion to connected inputs. However, only one output can assume an inproc ID, and will replace existing outputs if a collision occurs.",
      "name": "inproc",
      "plugin": true,
      "status": "stable",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "localhost:9041,localhost:9042"
              ],
              [
                "localhost:9041",
                "localhost:9042"
              ]
            ],
            "kind": "array",
            "name": "addresses",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication. NOTE: When using plain text auth it is extremely likely that you'll also need to <<tls-enabled, enable TLS>>."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "Authentication using the SCRAM-SHA-256 mechanism."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "Authentication using the SCRAM-SHA-512 mechanism."
                  ],
                  [
                    "none",
                    "Default, no SASL authentication."
                  ]
                ],
                "default": "none",
                "description": "The SASL authentication mechanism, if left empty SASL authentication is not used.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A PLAIN username. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${USER}"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "user",
                "type": "string"
              },
              {
                "default": "",
                "description": "A PLAIN password. It is recommended that you use environment variables to populate this field.",
                "examples": [
                  "${PASSWORD}"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A static OAUTHBEARER access token",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "Instead of using a static `access_token` allows you to query a xref:components:caches/about.adoc[`cache`] resource to fetch OAUTHBEARER tokens from",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_cache",
                "type": "string"
              },
              {
                "default": "",
                "description": "Required when using a `token_cache`, the key to query the cache with for tokens.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_key",
                "type": "string"
              }
            ],
            "description": "Enables SASL authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "sasl",
            "type": "object"
          },
          {
            "description": "The topic to publish messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "description": "The version of the Kafka protocol to use. This limits the capabilities used by the client and should ideally match the version of your brokers. Defaults to the oldest supported stable version.",
            "examples": [
              "2.1.0",
              "3.1.0"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "target_version",
            "type": "string"
          },
          {
            "default": "",
            "description": "A rack identifier for this client.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "The key to publish messages with.",
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": "fnv1a_hash",
            "description": "The partitioning algorithm to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"fnv1a_hash\": true,\n  \"murmur2_hash\": true,\n  \"random\": true,\n  \"round_robin\": true,\n  \"manual\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "partitioner",
            "options": [
              "fnv1a_hash",
              "murmur2_hash",
              "random",
              "round_robin",
              "manual"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "The manually-specified partition to publish messages to, relevant only when the field `partitioner` is set to `manual`. Must be able to parse as a 32-bit integer.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "partition",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to enable custom topic creation.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": -1,
                "description": "The number of partitions to create for new topics. Leave at -1 to use the broker configured default. Must be >= 1.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "partitions",
                "type": "int"
              },
              {
                "default": -1,
                "description": "The replication factor to use for new topics. Leave at -1 to use the broker configured default. Must be an odd number, and less then or equal to the number of brokers.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "replication_factor",
                "type": "int"
              }
            ],
            "description": "If enabled, topics will be created with the specified number of partitions and replication factor if they do not already exist.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "custom_topic_creation",
            "type": "object"
          },
          {
            "default": "none",
            "description": "The compression algorithm to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"none\": true,\n  \"snappy\": true,\n  \"lz4\": true,\n  \"gzip\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "compression",
            "options": [
              "none",
              "snappy",
              "lz4",
              "gzip",
              "zstd"
            ],
            "type": "string"
          },
          {
            "description": "An optional map of static headers that should be added to messages in addition to metadata.",
            "examples": [
              {
                "first-static-header": "value-1",
                "second-static-header": "value-2"
              }
            ],
            "is_optional": true,
            "kind": "map",
            "name": "static_headers",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are sent with messages as headers.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
            "examples": [
              "meta = @.merge(this)",
              "root.meta.span = this"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "inject_tracing_map",
            "type": "string",
            "version": "3.45.0"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": false,
            "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "idempotent_write",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Ensure that messages have been copied across all replicas before acknowledging receipt.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "ack_replicas",
            "type": "bool"
          },
          {
            "default": 1000000,
            "description": "The maximum size in bytes of messages sent to the target topic.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_msg_bytes",
            "type": "int"
          },
          {
            "default": "5s",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": false,
            "description": "When enabled forces an entire batch of messages to be retried if any individual message fails on a send, otherwise only the individual messages that failed are retried. Disabling this helps to reduce message duplicates during intermittent errors, but also makes it impossible to guarantee strict ordering of messages.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_as_batch",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 0,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "3s",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "10s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted. Setting this value to a zeroed duration (such as `0s`) will result in unbounded retries.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          },
          {
            "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix() }",
              "${! metadata(\"kafka_timestamp_unix\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix_milli() }",
              "${! metadata(\"kafka_timestamp_ms\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp_ms",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe config field `ack_replicas` determines whether we wait for acknowledgement from all replicas or just a single broker.\n\nBoth the `key` and `topic` fields can be dynamically set using function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].\n\nxref:configuration:metadata.adoc[Metadata] will be added to each message sent as headers (version 0.11+), but can be restricted using the field <<metadata, `metadata`>>.\n\n== Strict ordering and retries\n\nWhen strict ordering is required for messages written to topic partitions it is important to ensure that both the field `max_in_flight` is set to `1` and that the field `retry_as_batch` is set to `true`.\n\nYou must also ensure that failed batches are never rerouted back to the same output. This can be done by setting the field `max_retries` to `0` and `backoff.max_elapsed_time` to empty, which will apply back pressure indefinitely until the batch is sent successfully.\n\nHowever, this also means that manual intervention will eventually be required in cases where the batch cannot be sent due to configuration problems such as an incorrect `max_msg_bytes` estimate. A less strict but automated alternative would be to route failed batches to a dead letter queue using a xref:components:outputs/fallback.adoc[`fallback` broker], but this would allow subsequent batches to be delivered in the meantime whilst those failed batches are dealt with.\n\n== Troubleshooting\n\nIf you're seeing issues writing to or reading from Kafka with this component then it's worth trying out the newer xref:components:outputs/kafka_franz.adoc[`kafka_franz` output].\n\n- I'm seeing logs that report `Failed to connect to kafka: kafka: client has run out of available brokers to talk to (Is your cluster reachable?)`, but the brokers are definitely reachable.\n\nUnfortunately this error message will appear for a wide range of connection problems even when the broker endpoint can be reached. Double check your authentication configuration and also ensure that you have <<tlsenabled, enabled TLS>> if applicable.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "kafka",
      "plugin": true,
      "status": "stable",
      "summary": "The kafka output type writes a batch of messages to Kafka brokers and waits for acknowledgement before propagating it back to the input.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "A topic to write messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "description": "An optional key to populate for each message.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
            "examples": [
              "${! meta(\"partition\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "partition",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix() }",
              "${! metadata(\"kafka_timestamp_unix\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix_milli() }",
              "${! metadata(\"kafka_timestamp_ms\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp_ms",
            "type": "string"
          },
          {
            "default": 10,
            "description": "The maximum number of batches to be sending in parallel at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "least_backup",
                "Chooses the least backed up partition (the partition with the fewest amount of buffered records). Partitions are selected per batch."
              ],
              [
                "manual",
                "Manually select a partition for each message, requires the field `partition` to be specified."
              ],
              [
                "murmur2_hash",
                "Kafka's default hash algorithm that uses a 32-bit murmur2 hash of the key to compute which partition the record will be on."
              ],
              [
                "round_robin",
                "Round-robin's messages through all available partitions. This algorithm has lower throughput and causes higher CPU load on brokers, but can be useful if you want to ensure an even distribution of records to partitions."
              ]
            ],
            "description": "Override the default murmur2 hashing partitioner.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"least_backup\": true,\n  \"manual\": true,\n  \"murmur2_hash\": true,\n  \"round_robin\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "partitioner",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "idempotent_write",
            "type": "bool"
          },
          {
            "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lz4\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"none\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "compression",
            "options": [
              "lz4",
              "snappy",
              "gzip",
              "none",
              "zstd"
            ],
            "type": "string"
          },
          {
            "default": true,
            "description": "Enables topics to be auto created if they do not exist when fetching their metadata.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "allow_auto_topic_creation",
            "type": "bool"
          },
          {
            "default": "10s",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
            "examples": [
              "100MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_message_bytes",
            "type": "string"
          },
          {
            "default": "100MiB",
            "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
            "examples": [
              "128MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "broker_write_max_bytes",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  this.partitioner == \"manual\" && this.partition.or(\"\") == \"\" => \"a partition must be specified when the partitioner is set to manual\"\n  this.partitioner != \"manual\" && this.partition.or(\"\") != \"\" => \"a partition cannot be specified unless the partitioner is set to manual\"\n  this.timestamp.or(\"\") != \"\" && this.timestamp_ms.or(\"\") != \"\" => \"both timestamp and timestamp_ms cannot be specified simultaneously\"\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nWrites a batch of messages to Kafka brokers and waits for acknowledgement before propagating it back to the input.\n\nThis output often out-performs the traditional `kafka` output as well as providing more useful logs and error messages.\n",
      "name": "kafka_franz",
      "plugin": true,
      "status": "beta",
      "summary": "A Kafka output using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "output",
      "version": "3.61.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target MongoDB server.",
            "examples": [
              "mongodb://localhost:27017"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target MongoDB database.",
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "default": "",
            "description": "The username to connect to the database.",
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "default": "",
            "description": "The password to connect to the database.",
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "The client application name.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "app_name",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target collection.",
            "interpolated": true,
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "default": "update-one",
            "description": "The mongodb operation to perform.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"insert-one\": true,\n  \"delete-one\": true,\n  \"delete-many\": true,\n  \"replace-one\": true,\n  \"update-one\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "options": [
              "insert-one",
              "delete-one",
              "delete-many",
              "replace-one",
              "update-one"
            ],
            "type": "string"
          },
          {
            "children": [
              {
                "default": "majority",
                "description": "W requests acknowledgement that write operations propagate to the specified number of mongodb instances. Can be the string \"majority\" to wait for a calculated majority of nodes to acknowledge the write operation, or an integer value specifying an minimum number of nodes to acknowledge the operation, or a string specifying the name of a custom write concern configured in the cluster.",
                "kind": "scalar",
                "name": "w",
                "type": "string"
              },
              {
                "default": false,
                "description": "J requests acknowledgement from MongoDB that write operations are written to the journal.",
                "kind": "scalar",
                "name": "j",
                "type": "bool"
              },
              {
                "default": "",
                "description": "The write concern timeout.",
                "kind": "scalar",
                "name": "w_timeout",
                "type": "string"
              }
            ],
            "description": "The write concern settings for the mongo connection.",
            "kind": "scalar",
            "name": "write_concern",
            "type": "object"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A bloblang map representing a document to store within MongoDB, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The document map is required for the operations insert-one, replace-one, update-one and aggregate.",
            "examples": [
              "root.a = this.foo\nroot.b = this.bar"
            ],
            "kind": "scalar",
            "name": "document_map",
            "type": "string"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A bloblang map representing a filter for a MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The filter map is required for all operations except insert-one. It is used to find the document(s) for the operation. For example in a delete-one case, the filter map should have the fields required to locate the document to delete.",
            "examples": [
              "root.a = this.foo\nroot.b = this.bar"
            ],
            "kind": "scalar",
            "name": "filter_map",
            "type": "string"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A bloblang map representing the hint for the MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. This map is optional and is used with all operations except insert-one. It is used to improve performance of finding the documents in the mongodb.",
            "examples": [
              "root.a = this.foo\nroot.b = this.bar"
            ],
            "kind": "scalar",
            "name": "hint_map",
            "type": "string"
          },
          {
            "default": false,
            "description": "The upsert setting is optional and only applies for update-one and replace-one operations. If the filter specified in filter_map matches, the document is updated or replaced accordingly, otherwise it is created.",
            "kind": "scalar",
            "name": "upsert",
            "type": "bool",
            "version": "3.60.0"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "mongodb",
      "plugin": true,
      "status": "experimental",
      "summary": "Inserts items into a MongoDB collection.",
      "type": "output",
      "version": "3.43.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. The format should be `scheme://host:port` where `scheme` is one of `tcp`, `ssl`, or `ws`, `host` is the ip-address (or hostname) and `port` is the port on which the broker is accepting connections. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "tcp://localhost:1883"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "",
            "description": "An identifier for the client connection.",
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "nanoid",
                "append a nanoid of length 21 characters"
              ]
            ],
            "description": "Append a dynamically generated suffix to the specified `client_id` on each run of the pipeline. This can be useful when clustering Redpanda Connect producers.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = []",
            "name": "dynamic_client_id_suffix",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The maximum amount of time to wait in order to establish a connection before the attempt is abandoned.",
            "examples": [
              "1s",
              "500ms"
            ],
            "kind": "scalar",
            "name": "connect_timeout",
            "type": "string",
            "version": "3.58.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to enable last will messages.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": 0,
                "description": "Set QoS for last will message. Valid values are: 0, 1, 2.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "qos",
                "type": "int"
              },
              {
                "default": false,
                "description": "Set retained for last will message.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "retained",
                "type": "bool"
              },
              {
                "default": "",
                "description": "Set topic for last will message.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "topic",
                "type": "string"
              },
              {
                "default": "",
                "description": "Set payload for last will message.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "payload",
                "type": "string"
              }
            ],
            "description": "Set last will message in case of Redpanda Connect failure",
            "is_advanced": true,
            "kind": "scalar",
            "name": "will",
            "type": "object"
          },
          {
            "default": "",
            "description": "A username to connect with.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "default": "",
            "description": "A password to connect with.",
            "is_advanced": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": 30,
            "description": "Max seconds of inactivity before a keepalive message is sent.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "keepalive",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The topic to publish messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "default": 1,
            "description": "The QoS value to set for each message. Has options 0, 1, 2.",
            "kind": "scalar",
            "name": "qos",
            "type": "int"
          },
          {
            "default": "3s",
            "description": "The maximum amount of time to wait to write data before the attempt is abandoned.",
            "examples": [
              "1s",
              "500ms"
            ],
            "kind": "scalar",
            "name": "write_timeout",
            "type": "string",
            "version": "3.58.0"
          },
          {
            "default": false,
            "description": "Set message as retained on the topic.",
            "kind": "scalar",
            "name": "retained",
            "type": "bool"
          },
          {
            "description": "Override the value of `retained` with an interpolable value, this allows it to be dynamically set based on message contents. The value must resolve to either `true` or `false`.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "retained_interpolated",
            "type": "string",
            "version": "3.59.0"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe `topic` field can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "mqtt",
      "plugin": true,
      "status": "stable",
      "summary": "Pushes messages to an MQTT broker.",
      "type": "output"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "kind": "array",
            "name": "urls",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether the URLs listed should be bind (otherwise they are connected to).",
            "kind": "scalar",
            "name": "bind",
            "type": "bool"
          },
          {
            "default": "PUSH",
            "description": "The socket type to send with.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"push\": true,\n  \"pub\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "socket_type",
            "options": [
              "PUSH",
              "PUB"
            ],
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The maximum period of time to wait for a message to send before the request is abandoned and reattempted.",
            "kind": "scalar",
            "name": "poll_timeout",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Currently only PUSH and PUB sockets are supported.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "nanomsg",
      "plugin": true,
      "status": "stable",
      "summary": "Send messages over a Nanomsg socket.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The subject to publish to.",
            "examples": [
              "foo.bar.baz"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "default": {},
            "description": "Explicit message headers to add to messages.",
            "examples": [
              {
                "Content-Type": "application/json",
                "Timestamp": "${!meta(\"Timestamp\")}"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "headers",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
            "examples": [
              "meta = @.merge(this)",
              "root.meta.span = this"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "inject_tracing_map",
            "type": "string",
            "version": "4.23.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This output will interpolate functions within the subject field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats",
      "plugin": true,
      "status": "stable",
      "summary": "Publish to an NATS subject.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "A subject to write to.",
            "examples": [
              "foo.bar.baz",
              "${! meta(\"kafka_topic\") }",
              "foo.${! json(\"meta.type\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "default": {},
            "description": "Explicit message headers to add to messages.",
            "examples": [
              {
                "Content-Type": "application/json",
                "Timestamp": "${!meta(\"Timestamp\")}"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "headers",
            "type": "string",
            "version": "4.1.0"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
            "examples": [
              "meta = @.merge(this)",
              "root.meta.span = this"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "inject_tracing_map",
            "type": "string",
            "version": "4.23.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_jetstream",
      "plugin": true,
      "status": "stable",
      "summary": "Write messages to a NATS JetStream subject.",
      "type": "output",
      "version": "3.46.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The name of the KV bucket.",
            "examples": [
              "my_kv_bucket"
            ],
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "description": "The key for each message.",
            "examples": [
              "foo",
              "foo.bar.baz",
              "foo.${! json(\"meta.type\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": 1024,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe field `key` supports\nxref:configuration:interpolation.adoc#bloblang-queries[interpolation functions], allowing\nyou to create a unique key for each message.\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_kv",
      "plugin": true,
      "status": "beta",
      "summary": "Put messages in a NATS key-value bucket.",
      "type": "output",
      "version": "4.12.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The cluster ID to publish to.",
            "kind": "scalar",
            "name": "cluster_id",
            "type": "string"
          },
          {
            "description": "The subject to publish to.",
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "default": "",
            "description": "The client ID to connect with.",
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          },
          {
            "bloblang": true,
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
            "examples": [
              "meta = @.merge(this)",
              "root.meta.span = this"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "inject_tracing_map",
            "type": "string",
            "version": "4.23.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n[CAUTION]\n.Deprecation notice\n====\nThe NATS Streaming Server is being deprecated. Critical bug fixes and security fixes will be applied until June of 2023. NATS-enabled applications requiring persistence should use https://docs.nats.io/nats-concepts/jetstream[JetStream^].\n====\n\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "nats_stream",
      "plugin": true,
      "status": "stable",
      "summary": "Publish to a NATS Stream subject.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The address of the target NSQD server.",
            "kind": "scalar",
            "name": "nsqd_tcp_address",
            "type": "string"
          },
          {
            "description": "The topic to publish to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "description": "A user agent to assume when connecting.",
            "is_optional": true,
            "kind": "scalar",
            "name": "user_agent",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The `topic` field can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "nsq",
      "plugin": true,
      "status": "stable",
      "summary": "Publish to an NSQ topic.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "children": [
              {
                "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
                "examples": [
                  [
                    "localhost:9092"
                  ],
                  [
                    "foo:9092",
                    "bar:9092"
                  ],
                  [
                    "foo:9092,bar:9092"
                  ]
                ],
                "is_optional": true,
                "kind": "array",
                "name": "seed_brokers",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether custom TLS settings are enabled.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": false,
                    "description": "Whether to skip server side certificate verification.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "skip_cert_verify",
                    "type": "bool"
                  },
                  {
                    "default": false,
                    "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enable_renegotiation",
                    "type": "bool",
                    "version": "3.45.0"
                  },
                  {
                    "default": "",
                    "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "root_cas",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "./root_cas.pem"
                    ],
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "root_cas_file",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "default": "",
                        "description": "A plain text certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text certificate key to use.",
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "key",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate key to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "key_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                        "examples": [
                          "foo",
                          "${KEY_PASSWORD}"
                        ],
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "password",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      }
                    ],
                    "default": [],
                    "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                    "examples": [
                      [
                        {
                          "cert": "foo",
                          "key": "bar"
                        }
                      ],
                      [
                        {
                          "cert_file": "./example.pem",
                          "key_file": "./example.key"
                        }
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "client_certs",
                    "type": "object"
                  }
                ],
                "description": "Custom TLS settings can be used to override system defaults.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "tls",
                "type": "object"
              },
              {
                "default": 10,
                "description": "The maximum number of batches to be sending in parallel at any given time.",
                "kind": "scalar",
                "name": "max_in_flight",
                "type": "int"
              },
              {
                "children": [
                  {
                    "default": 0,
                    "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                    "kind": "scalar",
                    "name": "count",
                    "type": "int"
                  },
                  {
                    "default": 0,
                    "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                    "kind": "scalar",
                    "name": "byte_size",
                    "type": "int"
                  },
                  {
                    "default": "",
                    "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                    "examples": [
                      "1s",
                      "1m",
                      "500ms"
                    ],
                    "kind": "scalar",
                    "name": "period",
                    "type": "string"
                  },
                  {
                    "bloblang": true,
                    "default": "",
                    "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                    "examples": [
                      "this.type == \"end_of_transaction\""
                    ],
                    "kind": "scalar",
                    "name": "check",
                    "type": "string"
                  },
                  {
                    "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                    "examples": [
                      [
                        {
                          "archive": {
                            "format": "concatenate"
                          }
                        }
                      ],
                      [
                        {
                          "archive": {
                            "format": "lines"
                          }
                        }
                      ],
                      [
                        {
                          "archive": {
                            "format": "json_array"
                          }
                        }
                      ]
                    ],
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "array",
                    "name": "processors",
                    "type": "processor"
                  }
                ],
                "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
                "examples": [
                  {
                    "byte_size": 5000,
                    "count": 0,
                    "period": "1s"
                  },
                  {
                    "count": 10,
                    "period": "1s"
                  },
                  {
                    "check": "this.contains(\"END BATCH\")",
                    "count": 0,
                    "period": "1m"
                  }
                ],
                "kind": "",
                "name": "batching",
                "type": "object"
              },
              {
                "annotated_options": [
                  [
                    "least_backup",
                    "Chooses the least backed up partition (the partition with the fewest amount of buffered records). Partitions are selected per batch."
                  ],
                  [
                    "manual",
                    "Manually select a partition for each message, requires the field `partition` to be specified."
                  ],
                  [
                    "murmur2_hash",
                    "Kafka's default hash algorithm that uses a 32-bit murmur2 hash of the key to compute which partition the record will be on."
                  ],
                  [
                    "round_robin",
                    "Round-robin's messages through all available partitions. This algorithm has lower throughput and causes higher CPU load on brokers, but can be useful if you want to ensure an even distribution of records to partitions."
                  ]
                ],
                "description": "Override the default murmur2 hashing partitioner.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"least_backup\": true,\n  \"manual\": true,\n  \"murmur2_hash\": true,\n  \"round_robin\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "partitioner",
                "type": "string"
              },
              {
                "default": true,
                "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "idempotent_write",
                "type": "bool"
              },
              {
                "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"lz4\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"none\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "compression",
                "options": [
                  "lz4",
                  "snappy",
                  "gzip",
                  "none",
                  "zstd"
                ],
                "type": "string"
              },
              {
                "default": true,
                "description": "Enables topics to be auto created if they do not exist when fetching their metadata.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "allow_auto_topic_creation",
                "type": "bool"
              },
              {
                "default": "10s",
                "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
                "is_advanced": true,
                "kind": "scalar",
                "name": "timeout",
                "type": "string"
              },
              {
                "default": "1MiB",
                "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
                "examples": [
                  "100MB",
                  "50mib"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_message_bytes",
                "type": "string"
              },
              {
                "default": "100MiB",
                "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
                "examples": [
                  "128MB",
                  "50mib"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "broker_write_max_bytes",
                "type": "string"
              },
              {
                "description": "A topic to write messages to.",
                "interpolated": true,
                "kind": "scalar",
                "name": "topic",
                "type": "string"
              },
              {
                "description": "An optional key to populate for each message.",
                "interpolated": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "key",
                "type": "string"
              },
              {
                "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
                "examples": [
                  "${! meta(\"partition\") }"
                ],
                "interpolated": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "partition",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "Provide a list of explicit metadata key prefixes to match against.",
                    "examples": [
                      [
                        "foo_",
                        "bar_"
                      ],
                      [
                        "kafka_"
                      ],
                      [
                        "content-"
                      ]
                    ],
                    "kind": "array",
                    "name": "include_prefixes",
                    "type": "string"
                  },
                  {
                    "default": [],
                    "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                    "examples": [
                      [
                        ".*"
                      ],
                      [
                        "_timestamp_unix$"
                      ]
                    ],
                    "kind": "array",
                    "name": "include_patterns",
                    "type": "string"
                  }
                ],
                "description": "Determine which (if any) metadata values should be added to messages as headers.",
                "is_optional": true,
                "kind": "scalar",
                "name": "metadata",
                "type": "object"
              },
              {
                "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
                "examples": [
                  "${! timestamp_unix() }",
                  "${! metadata(\"kafka_timestamp_unix\") }"
                ],
                "interpolated": true,
                "is_advanced": true,
                "is_deprecated": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "timestamp",
                "type": "string"
              },
              {
                "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
                "examples": [
                  "${! timestamp_unix_milli() }",
                  "${! metadata(\"kafka_timestamp_ms\") }"
                ],
                "interpolated": true,
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "timestamp_ms",
                "type": "string"
              }
            ],
            "kind": "scalar",
            "name": "kafka",
            "type": "object"
          },
          {
            "default": false,
            "kind": "scalar",
            "name": "disable_content_encryption",
            "type": "bool"
          },
          {
            "is_optional": true,
            "kind": "scalar",
            "name": "enrollment_ticket",
            "type": "string"
          },
          {
            "is_optional": true,
            "kind": "scalar",
            "name": "identity_name",
            "type": "string"
          },
          {
            "default": "self",
            "is_optional": true,
            "kind": "scalar",
            "name": "allow",
            "type": "string"
          },
          {
            "default": "self",
            "kind": "scalar",
            "name": "route_to_kafka_outlet",
            "type": "string"
          },
          {
            "default": "self",
            "kind": "scalar",
            "name": "allow_consumer",
            "type": "string"
          },
          {
            "default": "/ip4/127.0.0.1/tcp/6262",
            "kind": "scalar",
            "name": "route_to_consumer",
            "type": "string"
          },
          {
            "default": [],
            "description": "The fields to encrypt in the kafka messages, assuming the record is a valid JSON map. By default, the whole record is encrypted.",
            "kind": "array",
            "name": "encrypted_fields",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "ockam_kafka",
      "plugin": true,
      "status": "experimental",
      "summary": "Ockam",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "http://localhost:9200"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The index to place messages.",
            "interpolated": true,
            "kind": "scalar",
            "name": "index",
            "type": "string"
          },
          {
            "description": "The action to take on the document. This field must resolve to one of the following action types: `index`, `update` or `delete`.",
            "interpolated": true,
            "kind": "scalar",
            "name": "action",
            "type": "string"
          },
          {
            "description": "The ID for indexed messages. Interpolation should be used in order to create a unique ID for each message.",
            "examples": [
              "${!counter()}-${!timestamp_unix()}"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "id",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional pipeline id to preprocess incoming documents.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "pipeline",
            "type": "string"
          },
          {
            "default": "",
            "description": "The routing key to use for the document.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "routing",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to connect to Amazon Elastic Service.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "description": "The AWS region to target.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "region",
                "type": "string"
              },
              {
                "description": "Allows you to specify a custom endpoint for the AWS API.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "endpoint",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "A profile from `~/.aws/credentials` to use.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "profile",
                    "type": "string"
                  },
                  {
                    "description": "The ID of credentials to use.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "id",
                    "type": "string"
                  },
                  {
                    "description": "The secret for the credentials being used.",
                    "is_advanced": true,
                    "is_optional": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "secret",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "description": "The token for the credentials being used, required when using short term credentials.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "token",
                    "type": "string"
                  },
                  {
                    "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "from_ec2_role",
                    "type": "bool",
                    "version": "4.2.0"
                  },
                  {
                    "description": "A role ARN to assume.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "role",
                    "type": "string"
                  },
                  {
                    "description": "An external ID to provide when assuming a role.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "role_external_id",
                    "type": "string"
                  }
                ],
                "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "credentials",
                "type": "object"
              }
            ],
            "description": "Enables and customises connectivity to Amazon Elastic Service.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "aws",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nBoth the `id` and `index` fields can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\noutput:\n  processors:\n    - mapping: |\n        meta id = this.id\n        root.doc = this\n  opensearch:\n    urls: [ TODO ]\n    index: foo\n    id: ${! @id }\n    action: update\n",
          "summary": "When https://opensearch.org/docs/latest/api-reference/document-apis/update-document/[updating documents^] the request body should contain a combination of a `doc`, `upsert`, and/or `script` fields at the top level, this should be done via mapping processors.",
          "title": "Updating Documents"
        }
      ],
      "name": "opensearch",
      "plugin": true,
      "status": "stable",
      "summary": "Publishes messages into an Elasticsearch index. If the index does not exist then it is created with a dynamic mapping.",
      "type": "output"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "The host for the Pinecone index.",
            "kind": "scalar",
            "linter": "root = if this.has_prefix(\"https://\") { [\"host field must be a FQDN not a URL (remove the https:// prefix)\"] }",
            "name": "host",
            "type": "string"
          },
          {
            "description": "The Pinecone api key.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "upsert-vectors",
            "description": "The operation to perform against the Pinecone index.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"update-vector\": true,\n  \"upsert-vectors\": true,\n  \"delete-vectors\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "options": [
              "update-vector",
              "upsert-vectors",
              "delete-vectors"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "The namespace to write to - writes to the default namespace by default.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "namespace",
            "type": "string"
          },
          {
            "description": "The ID for the index entry in Pinecone.",
            "interpolated": true,
            "kind": "scalar",
            "name": "id",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The mapping to extract out the vector from the document. The result must be a floating point array. Required if not a delete operation.",
            "examples": [
              "root = this.embeddings_vector",
              "root = [1.2, 0.5, 0.76]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "vector_mapping",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional mapping of message to metadata in the Pinecone index entry.",
            "examples": [
              "root = @",
              "root = metadata()",
              "root = {\"summary\": this.summary, \"foo\": this.other_field}"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata_mapping",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "pinecone",
      "plugin": true,
      "status": "experimental",
      "summary": "Inserts items into a Pinecone index.",
      "type": "output",
      "version": "4.31.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A URL to connect to.",
            "examples": [
              "pulsar://localhost:6650",
              "pulsar://pulsar.us-west.example.com:6650",
              "pulsar+ssl://pulsar.us-west.example.com:6651"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The topic to publish to.",
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              }
            ],
            "description": "Specify the path to a custom CA certificate to trust broker TLS service.",
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": "",
            "description": "The key to publish messages with.",
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": "",
            "description": "The ordering key to publish messages with.",
            "interpolated": true,
            "kind": "scalar",
            "name": "ordering_key",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether OAuth2 is enabled.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "OAuth2 audience.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "audience",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "OAuth2 issuer URL.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "issuer_url",
                    "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "OAuth2 scope to request.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "scope",
                    "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path to a file containing a private key.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "private_key_file",
                    "type": "string"
                  }
                ],
                "description": "Parameters for Pulsar OAuth2 authentication.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "oauth2",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether Token Auth is enabled.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "Actual base64 encoded token.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "token",
                    "type": "string"
                  }
                ],
                "description": "Parameters for Pulsar Token authentication.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "object"
              }
            ],
            "description": "Optional configuration of Pulsar authentication methods.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object",
            "version": "3.60.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "pulsar",
      "plugin": true,
      "status": "experimental",
      "summary": "Write messages to an Apache Pulsar server.",
      "type": "output",
      "version": "3.43.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "maximum batch size is 10 (limit of the pusher library)",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "Pusher channel to publish to. Interpolation functions can also be used",
            "examples": [
              "my_channel",
              "${!json(\"id\")}"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "channel",
            "type": "string"
          },
          {
            "description": "Event to publish to",
            "kind": "scalar",
            "name": "event",
            "type": "string"
          },
          {
            "description": "Pusher app id",
            "kind": "scalar",
            "name": "appId",
            "type": "string"
          },
          {
            "description": "Pusher key",
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "Pusher secret",
            "kind": "scalar",
            "name": "secret",
            "type": "string"
          },
          {
            "description": "Pusher cluster",
            "kind": "scalar",
            "name": "cluster",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enable SSL encryption",
            "kind": "scalar",
            "name": "secure",
            "type": "bool"
          },
          {
            "default": 1,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "pusher",
      "plugin": true,
      "status": "experimental",
      "summary": "Output for publishing messages to Pusher API (https://pusher.com)",
      "type": "output",
      "version": "4.3.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "description": "The gRPC host of the Qdrant server.",
            "examples": [
              "localhost:6334",
              "xyz-example.eu-central.aws.cloud.qdrant.io:6334"
            ],
            "kind": "scalar",
            "name": "grpc_host",
            "type": "string"
          },
          {
            "default": "",
            "description": "The Qdrant API token for authentication. Defaults to an empty string.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_token",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "TLS(HTTPS) config to use when connecting",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The name of the collection in Qdrant.",
            "interpolated": true,
            "kind": "scalar",
            "name": "collection_name",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The ID of the point to insert. Can be a UUID string or positive integer.",
            "examples": [
              "root = \"dc88c126-679f-49f5-ab85-04b77e8c2791\"",
              "root = 832"
            ],
            "kind": "scalar",
            "name": "id",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The mapping to extract the vector from the document.",
            "examples": [
              "root = {\"dense_vector\": [0.352,0.532,0.754],\"sparse_vector\": {\"indices\": [23,325,532],\"values\": [0.352,0.532,0.532]}, \"multi_vector\": [[0.352,0.532],[0.352,0.532]]}",
              "root = [1.2, 0.5, 0.76]",
              "root = this.vector",
              "root = [[0.352,0.532,0.532,0.234],[0.352,0.532,0.532,0.234]]",
              "root = {\"some_sparse\": {\"indices\":[23,325,532],\"values\":[0.352,0.532,0.532]}}",
              "root = {\"some_multi\": [[0.352,0.532,0.532,0.234],[0.352,0.532,0.532,0.234]]}",
              "root = {\"some_dense\": [0.352,0.532,0.532,0.234]}"
            ],
            "kind": "scalar",
            "name": "vector_mapping",
            "type": "string"
          },
          {
            "bloblang": true,
            "default": "root = {}",
            "description": "An optional mapping of message to payload associated with the point.",
            "examples": [
              "root = {\"field\": this.value, \"field_2\": 987}",
              "root = metadata()"
            ],
            "kind": "scalar",
            "name": "payload_mapping",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "qdrant",
      "plugin": true,
      "status": "experimental",
      "summary": "Adds items to a https://qdrant.tech/[Qdrant^] collection",
      "type": "output",
      "version": "4.33.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "Address of the QuestDB server's HTTP port (excluding protocol)",
            "examples": [
              "localhost:9000"
            ],
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "description": "Username for HTTP basic auth",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "username",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Password for HTTP basic auth",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Bearer token for HTTP auth (takes precedence over basic auth username & password)",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "token",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The time to continue retrying after a failed HTTP request. The interval between retries is an exponential backoff starting at 10ms and doubling after each failed attempt up to a maximum of 1 second.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "retry_timeout",
            "type": "string"
          },
          {
            "description": "The time to wait for a response from the server. This is in addition to the calculation derived from the request_min_throughput parameter.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "request_timeout",
            "type": "string"
          },
          {
            "description": "Minimum expected throughput in bytes per second for HTTP requests. If the throughput is lower than this value, the connection will time out. This is used to calculate an additional timeout on top of request_timeout. This is useful for large requests. You can set this value to 0 to disable this logic.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "request_min_throughput",
            "type": "int"
          },
          {
            "description": "Destination table",
            "examples": [
              "trades"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "Name of the designated timestamp field",
            "is_optional": true,
            "kind": "scalar",
            "name": "designated_timestamp_field",
            "type": "string"
          },
          {
            "default": "auto",
            "description": "Designated timestamp field units",
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if [\"nanos\",\"micros\",\"millis\",\"seconds\",\"auto\"].contains(this) != true { [ \"valid options are \\\"nanos\\\", \\\"micros\\\", \\\"millis\\\", \\\"seconds\\\", \\\"auto\\\"\" ] }",
            "name": "designated_timestamp_unit",
            "type": "string"
          },
          {
            "description": "String fields with textual timestamps",
            "is_optional": true,
            "kind": "array",
            "name": "timestamp_string_fields",
            "type": "string"
          },
          {
            "default": "Jan _2 15:04:05.000000Z0700",
            "description": "Timestamp format, used when parsing timestamp string fields. Specified in golang's time.Parse layout",
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp_string_format",
            "type": "string"
          },
          {
            "description": "Columns that should be the SYMBOL type (string values default to STRING)",
            "is_optional": true,
            "kind": "array",
            "name": "symbols",
            "type": "string"
          },
          {
            "description": "Columns that should be double type, (int is default)",
            "is_optional": true,
            "kind": "array",
            "name": "doubles",
            "type": "string"
          },
          {
            "default": false,
            "description": "Mark a message as errored if it is empty after field validation",
            "is_optional": true,
            "kind": "scalar",
            "name": "error_on_empty_messages",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Important: We recommend that the dedupe feature is enabled on the QuestDB server. Please visit https://questdb.io/docs/ for more information about deploying, configuring, and using QuestDB.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "questdb",
      "plugin": true,
      "status": "experimental",
      "summary": "Pushes messages to a QuestDB table",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The key for each message, function interpolations should be used to create a unique key per message.",
            "examples": [
              "${! @.kafka_key }",
              "${! this.doc.id }",
              "${! counter() }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether all metadata fields of messages should be walked and added to the list of hash fields to set.",
            "kind": "scalar",
            "name": "walk_metadata",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to walk each message as a JSON object and add each key/value pair to the list of hash fields to set.",
            "kind": "scalar",
            "name": "walk_json_object",
            "type": "bool"
          },
          {
            "default": {},
            "description": "A map of key/value pairs to set as hash fields.",
            "interpolated": true,
            "kind": "map",
            "name": "fields",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe field `key` supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions], allowing you to create a unique key for each message.\n\nThe field `fields` allows you to specify an explicit map of field names to interpolated values, also evaluated per message of a batch:\n\n```yaml\noutput:\n  redis_hash:\n    url: tcp://localhost:6379\n    key: ${!json(\"id\")}\n    fields:\n      topic: ${!meta(\"kafka_topic\")}\n      partition: ${!meta(\"kafka_partition\")}\n      content: ${!json(\"document.text\")}\n```\n\nIf the field `walk_metadata` is set to `true` then Redpanda Connect will walk all metadata fields of messages and add them to the list of hash fields to set.\n\nIf the field `walk_json_object` is set to `true` then Redpanda Connect will walk each message as a JSON object, extracting keys and the string representation of their value and adds them to the list of hash fields to set.\n\nThe order of hash field extraction is as follows:\n\n1. Metadata (if enabled)\n2. JSON object (if enabled)\n3. Explicit fields\n\nWhere latter stages will overwrite matching field names of a former stage.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "redis_hash",
      "plugin": true,
      "status": "stable",
      "summary": "Sets Redis hash objects using the HMSET command.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The key for each message, function interpolations can be optionally used to create a unique key per message.",
            "examples": [
              "some_list",
              "${! @.kafka_key }",
              "${! this.doc.id }",
              "${! counter() }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": "rpush",
            "description": "The command used to push elements to the Redis list",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"rpush\": true,\n  \"lpush\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "command",
            "options": [
              "rpush",
              "lpush"
            ],
            "type": "string",
            "version": "4.22.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The field `key` supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions], allowing you to create a unique key for each message.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "redis_list",
      "plugin": true,
      "status": "stable",
      "summary": "Pushes messages onto the end of a Redis list (which is created if it doesn't already exist) using the RPUSH command.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The channel to publish messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "channel",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis output will interpolate functions within the channel field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "redis_pubsub",
      "plugin": true,
      "status": "stable",
      "summary": "Publishes messages through the Redis PubSub model. It is not possible to guarantee that messages have been received.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The stream to add messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "stream",
            "type": "string"
          },
          {
            "default": "body",
            "description": "A key to set the raw body of the message to.",
            "kind": "scalar",
            "name": "body_key",
            "type": "string"
          },
          {
            "default": 0,
            "description": "When greater than zero enforces a rough cap on the length of the target stream.",
            "kind": "scalar",
            "name": "max_length",
            "type": "int"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
                "kind": "array",
                "name": "exclude_prefixes",
                "type": "string"
              }
            ],
            "description": "Specify criteria for which metadata values are included in the message body.",
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIt's possible to specify a maximum length of the target stream by setting it to a value greater than 0, in which case this cap is applied only when Redis is able to remove a whole macro node, for efficiency.\n\nRedis stream entries are key/value pairs, as such it is necessary to specify the key to be set to the body of the message. All metadata fields of the message will also be set as key/value pairs, if there is a key collision between a metadata item and the body then the body takes precedence.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "redis_streams",
      "plugin": true,
      "status": "stable",
      "summary": "Pushes messages to a Redis (v5.0+) Stream (which is created if it doesn't already exist) using the XADD command.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "A topic to write messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "description": "An optional key to populate for each message.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
            "examples": [
              "${! meta(\"partition\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "partition",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix() }",
              "${! metadata(\"kafka_timestamp_unix\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix_milli() }",
              "${! metadata(\"kafka_timestamp_ms\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp_ms",
            "type": "string"
          },
          {
            "default": 256,
            "description": "The maximum number of batches to be sending in parallel at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "annotated_options": [
              [
                "least_backup",
                "Chooses the least backed up partition (the partition with the fewest amount of buffered records). Partitions are selected per batch."
              ],
              [
                "manual",
                "Manually select a partition for each message, requires the field `partition` to be specified."
              ],
              [
                "murmur2_hash",
                "Kafka's default hash algorithm that uses a 32-bit murmur2 hash of the key to compute which partition the record will be on."
              ],
              [
                "round_robin",
                "Round-robin's messages through all available partitions. This algorithm has lower throughput and causes higher CPU load on brokers, but can be useful if you want to ensure an even distribution of records to partitions."
              ]
            ],
            "description": "Override the default murmur2 hashing partitioner.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"least_backup\": true,\n  \"manual\": true,\n  \"murmur2_hash\": true,\n  \"round_robin\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "partitioner",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "idempotent_write",
            "type": "bool"
          },
          {
            "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lz4\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"none\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "compression",
            "options": [
              "lz4",
              "snappy",
              "gzip",
              "none",
              "zstd"
            ],
            "type": "string"
          },
          {
            "default": true,
            "description": "Enables topics to be auto created if they do not exist when fetching their metadata.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "allow_auto_topic_creation",
            "type": "bool"
          },
          {
            "default": "10s",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
            "examples": [
              "100MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_message_bytes",
            "type": "string"
          },
          {
            "default": "100MiB",
            "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
            "examples": [
              "128MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "broker_write_max_bytes",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  this.partitioner == \"manual\" && this.partition.or(\"\") == \"\" => \"a partition must be specified when the partitioner is set to manual\"\n  this.partitioner != \"manual\" && this.partition.or(\"\") != \"\" => \"a partition cannot be specified unless the partitioner is set to manual\"\n  this.timestamp.or(\"\") != \"\" && this.timestamp_ms.or(\"\") != \"\" => \"both timestamp and timestamp_ms cannot be specified simultaneously\"\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nWrites a batch of messages to Kafka brokers and waits for acknowledgement before propagating it back to the input.\n",
      "name": "redpanda",
      "plugin": true,
      "status": "beta",
      "summary": "A Kafka output using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A topic to write messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "description": "An optional key to populate for each message.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
            "examples": [
              "${! meta(\"partition\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "partition",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix() }",
              "${! metadata(\"kafka_timestamp_unix\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix_milli() }",
              "${! metadata(\"kafka_timestamp_ms\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp_ms",
            "type": "string"
          },
          {
            "default": 10,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  this.partitioner == \"manual\" && this.partition.or(\"\") == \"\" => \"a partition must be specified when the partitioner is set to manual\"\n  this.partitioner != \"manual\" && this.partition.or(\"\") != \"\" => \"a partition cannot be specified unless the partitioner is set to manual\"\n  this.timestamp.or(\"\") != \"\" && this.timestamp_ms.or(\"\") != \"\" => \"both timestamp and timestamp_ms cannot be specified simultaneously\"\n}",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\ninput:\n  generate:\n    interval: 1s\n    mapping: 'root.name = fake(\"name\")'\n\npipeline:\n  processors:\n    - mutation: |\n        root.id = uuid_v4()\n        root.loud_name = this.name.uppercase()\n\noutput:\n  redpanda_common:\n    topic: bar\n    key: ${! @id }\n\nredpanda:\n  seed_brokers: [ \"127.0.0.1:9092\" ]\n  tls:\n    enabled: true\n  sasl:\n    - mechanism: SCRAM-SHA-512\n      password: bar\n      username: foo\n",
          "summary": "Data is generated and written to a topic bar, targetting the cluster configured within the redpanda block at the bottom. This is useful as it allows us to configure TLS and SASL only once for potentially multiple inputs and outputs.",
          "title": "Simple Output"
        }
      ],
      "name": "redpanda_common",
      "plugin": true,
      "status": "beta",
      "summary": "Sends data to a Redpanda (Kafka) broker, using credentials defined in a common top-level `redpanda` config block.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "description": "A topic to write messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "topic",
            "type": "string"
          },
          {
            "description": "An optional key to populate for each message.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
            "examples": [
              "${! meta(\"partition\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "partition",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix() }",
              "${! metadata(\"kafka_timestamp_unix\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix_milli() }",
              "${! metadata(\"kafka_timestamp_ms\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp_ms",
            "type": "string"
          },
          {
            "default": "",
            "description": "The topic prefix.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "topic_prefix",
            "type": "string"
          },
          {
            "default": 256,
            "description": "The maximum number of batches to be sending in parallel at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": "redpanda_migrator_input",
            "description": "The label of the redpanda_migrator input from which to read the configurations for topics and ACLs which need to be created.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "input_resource",
            "type": "string"
          },
          {
            "default": true,
            "description": "Use the specified replication factor when creating topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "replication_factor_override",
            "type": "bool"
          },
          {
            "default": 3,
            "description": "Replication factor for created topics. This is only used when `replication_factor_override` is set to `true`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "replication_factor",
            "type": "int"
          },
          {
            "default": false,
            "description": "Translate schema IDs.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "translate_schema_ids",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Set this to `true` when using Serverless clusters in Redpanda Cloud.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "is_serverless",
            "type": "bool"
          },
          {
            "default": "schema_registry_output",
            "description": "The label of the schema_registry output to use for fetching schema IDs.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "schema_registry_output_resource",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "rack_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "is_deprecated": true,
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "is_deprecated": true,
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "is_deprecated": true,
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "is_deprecated": true,
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_deprecated": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "is_deprecated": true,
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "annotated_options": [
              [
                "least_backup",
                "Chooses the least backed up partition (the partition with the fewest amount of buffered records). Partitions are selected per batch."
              ],
              [
                "manual",
                "Manually select a partition for each message, requires the field `partition` to be specified."
              ],
              [
                "murmur2_hash",
                "Kafka's default hash algorithm that uses a 32-bit murmur2 hash of the key to compute which partition the record will be on."
              ],
              [
                "round_robin",
                "Round-robin's messages through all available partitions. This algorithm has lower throughput and causes higher CPU load on brokers, but can be useful if you want to ensure an even distribution of records to partitions."
              ]
            ],
            "description": "Override the default murmur2 hashing partitioner.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"least_backup\": true,\n  \"manual\": true,\n  \"murmur2_hash\": true,\n  \"round_robin\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "partitioner",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "idempotent_write",
            "type": "bool"
          },
          {
            "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lz4\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"none\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "compression",
            "options": [
              "lz4",
              "snappy",
              "gzip",
              "none",
              "zstd"
            ],
            "type": "string"
          },
          {
            "default": true,
            "description": "Enables topics to be auto created if they do not exist when fetching their metadata.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "allow_auto_topic_creation",
            "type": "bool"
          },
          {
            "default": "10s",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
            "examples": [
              "100MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_message_bytes",
            "type": "string"
          },
          {
            "default": "100MiB",
            "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
            "examples": [
              "128MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "broker_write_max_bytes",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  this.partitioner == \"manual\" && this.partition.or(\"\") == \"\" => \"a partition must be specified when the partitioner is set to manual\"\n  this.partitioner != \"manual\" && this.partition.or(\"\") != \"\" => \"a partition cannot be specified unless the partitioner is set to manual\"\n  this.timestamp.or(\"\") != \"\" && this.timestamp_ms.or(\"\") != \"\" => \"both timestamp and timestamp_ms cannot be specified simultaneously\"\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nWrites a batch of messages to a Kafka broker and waits for acknowledgement before propagating it back to the input.\n\nThis output should be used in combination with a `redpanda_migrator` input identified by the label specified in\n`input_resource` which it can query for topic and ACL configurations. Once connected, the output will attempt to\ncreate all topics which the input consumes from along with their ACLs.\n\nIf the configured broker does not contain the current message topic, this output attempts to create it along with its\nACLs.\n\nACL migration adheres to the following principles:\n\n- `ALLOW WRITE` ACLs for topics are not migrated\n- `ALLOW ALL` ACLs for topics are downgraded to `ALLOW READ`\n- Only topic ACLs are migrated, group ACLs are not migrated\n",
      "examples": [
        {
          "config": "\noutput:\n  redpanda_migrator:\n    seed_brokers: [ \"127.0.0.1:9093\" ]\n    topic: ${! metadata(\"kafka_topic\").or(throw(\"missing kafka_topic metadata\")) }\n    key: ${! metadata(\"kafka_key\") }\n    partitioner: manual\n    partition: ${! metadata(\"kafka_partition\").or(throw(\"missing kafka_partition metadata\")) }\n    timestamp_ms: ${! metadata(\"kafka_timestamp_ms\").or(timestamp_unix_milli()) }\n    input_resource: redpanda_migrator_input\n    max_in_flight: 1\n",
          "summary": "Writes messages to the configured broker and creates topics and topic ACLs if they don't exist. It also ensures that the message order is preserved.",
          "title": "Transfer data"
        }
      ],
      "name": "redpanda_migrator",
      "plugin": true,
      "status": "beta",
      "summary": "A Redpanda Migrator output using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "output",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The `redpanda_migrator` output configuration.\n",
            "kind": "map",
            "name": "redpanda_migrator",
            "type": "unknown"
          },
          {
            "description": "The `schema_registry` output configuration. The `subject` field must be left empty.\n",
            "kind": "map",
            "name": "schema_registry",
            "type": "unknown"
          },
          {
            "default": false,
            "description": "Allow the target Schema Registry instance to allocate different schema IDs for migrated schemas. This is useful\nwhen it already contains some schemas which differ from the ones being migrated.\n",
            "kind": "scalar",
            "name": "translate_schema_ids",
            "type": "bool"
          },
          {
            "default": "",
            "description": "Specify the redpanda_migrator_bundle input label if one is assigned to it.\n",
            "kind": "scalar",
            "name": "input_bundle_label",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "All-in-one output which writes messages and schemas to a Kafka or Redpanda cluster. This output is meant to be used\ntogether with the `redpanda_migrator_bundle` input.\n",
      "name": "redpanda_migrator_bundle",
      "plugin": true,
      "status": "experimental",
      "summary": "Redpanda Migrator bundle output",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
            "examples": [
              [
                "localhost:9092"
              ],
              [
                "foo:9092",
                "bar:9092"
              ],
              [
                "foo:9092,bar:9092"
              ]
            ],
            "kind": "array",
            "name": "seed_brokers",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "An identifier for the client connection.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_id",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "AWS_MSK_IAM",
                    "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' java library."
                  ],
                  [
                    "OAUTHBEARER",
                    "OAuth Bearer based authentication."
                  ],
                  [
                    "PLAIN",
                    "Plain text authentication."
                  ],
                  [
                    "SCRAM-SHA-256",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "SCRAM-SHA-512",
                    "SCRAM based authentication as specified in RFC5802."
                  ],
                  [
                    "none",
                    "Disable sasl authentication"
                  ]
                ],
                "description": "The SASL mechanism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"aws_msk_iam\": true,\n  \"oauthbearer\": true,\n  \"plain\": true,\n  \"scram-sha-256\": true,\n  \"scram-sha-512\": true,\n  \"none\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "mechanism",
                "type": "string"
              },
              {
                "default": "",
                "description": "A username to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to provide for PLAIN or SCRAM-* authentication.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The token to use for a single session's OAUTHBEARER authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "name": "extensions",
                "type": "string"
              },
              {
                "children": [
                  {
                    "description": "The AWS region to target.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "region",
                    "type": "string"
                  },
                  {
                    "description": "Allows you to specify a custom endpoint for the AWS API.",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "endpoint",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "A profile from `~/.aws/credentials` to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "profile",
                        "type": "string"
                      },
                      {
                        "description": "The ID of credentials to use.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "id",
                        "type": "string"
                      },
                      {
                        "description": "The secret for the credentials being used.",
                        "is_advanced": true,
                        "is_optional": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "secret",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "description": "The token for the credentials being used, required when using short term credentials.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "token",
                        "type": "string"
                      },
                      {
                        "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "from_ec2_role",
                        "type": "bool",
                        "version": "4.2.0"
                      },
                      {
                        "description": "A role ARN to assume.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role",
                        "type": "string"
                      },
                      {
                        "description": "An external ID to provide when assuming a role.",
                        "is_advanced": true,
                        "is_optional": true,
                        "kind": "scalar",
                        "name": "role_external_id",
                        "type": "string"
                      }
                    ],
                    "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                    "is_advanced": true,
                    "is_optional": true,
                    "kind": "scalar",
                    "name": "credentials",
                    "type": "object"
                  }
                ],
                "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "aws",
                "type": "object"
              }
            ],
            "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "examples": [
              [
                {
                  "mechanism": "SCRAM-SHA-512",
                  "password": "bar",
                  "username": "foo"
                }
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "sasl",
            "type": "object"
          },
          {
            "default": "5m",
            "description": "The maximum age of metadata before it is refreshed. This interval also controls how frequently regex topic patterns are re-evaluated to discover new matching topics.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "metadata_max_age",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The request time overhead. Uses the given time as overhead while deadlining requests. Roughly equivalent to request.timeout.ms, but grants additional time to requests that have timeout fields.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "request_timeout_overhead",
            "type": "string"
          },
          {
            "default": "20s",
            "description": "The rough amount of time to allow connections to idle before they are closed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "conn_idle_timeout",
            "type": "string"
          },
          {
            "default": "${! @kafka_offset_topic }",
            "description": "Kafka offset topic.",
            "interpolated": true,
            "kind": "scalar",
            "name": "offset_topic",
            "type": "string"
          },
          {
            "default": "",
            "description": "Kafka offset topic prefix.",
            "interpolated": true,
            "is_advanced": true,
            "kind": "scalar",
            "name": "offset_topic_prefix",
            "type": "string"
          },
          {
            "default": "${! @kafka_offset_group }",
            "description": "Kafka offset group.",
            "interpolated": true,
            "kind": "scalar",
            "name": "offset_group",
            "type": "string"
          },
          {
            "default": "${! @kafka_offset_partition }",
            "description": "Kafka offset partition.",
            "interpolated": true,
            "kind": "scalar",
            "name": "offset_partition",
            "type": "string"
          },
          {
            "default": "${! @kafka_offset_commit_timestamp }",
            "description": "Kafka offset commit timestamp.",
            "interpolated": true,
            "kind": "scalar",
            "name": "offset_commit_timestamp",
            "type": "string"
          },
          {
            "default": "${! @kafka_offset_metadata }",
            "description": "Kafka offset metadata value.",
            "interpolated": true,
            "kind": "scalar",
            "name": "offset_metadata",
            "type": "string"
          },
          {
            "default": "${! @kafka_is_high_watermark }",
            "description": "Indicates if the update represents the high watermark of the Kafka topic partition.",
            "interpolated": true,
            "kind": "scalar",
            "name": "is_high_watermark",
            "type": "string"
          },
          {
            "default": "${! @kafka_key }",
            "description": "Kafka key.",
            "interpolated": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "kafka_key",
            "type": "string"
          },
          {
            "default": 1,
            "description": "The maximum number of batches to be sending in parallel at any given time.",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "default": "10s",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1MiB",
            "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
            "examples": [
              "100MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_message_bytes",
            "type": "string"
          },
          {
            "default": "100MiB",
            "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
            "examples": [
              "128MB",
              "50mib"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "broker_write_max_bytes",
            "type": "string"
          },
          {
            "default": 0,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This output should be used in combination with the `redpanda_migrator_offsets` input",
      "name": "redpanda_migrator_offsets",
      "plugin": true,
      "status": "beta",
      "summary": "Redpanda Migrator consumer group offsets output using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "type": "output",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nThe routing of messages after this output depends on the type of input it came from. For inputs that support propagating nacks upstream such as AMQP or NATS the message will be nacked. However, for inputs that are sequential such as files or Kafka the messages will simply be reprocessed from scratch.\n\nTo learn when this output could be useful, see [the <<examples>>.",
      "examples": [
        {
          "config": "\noutput:\n  switch:\n    retry_until_success: false\n    cases:\n      - check: '!errored()'\n        output:\n          amqp_1:\n            urls: [ amqps://guest:guest@localhost:5672/ ]\n            target_address: queue:/the_foos\n\n      - output:\n          reject: \"processing failed due to: ${! error() }\"\n",
          "summary": "\nThis input is particularly useful for routing messages that have failed during processing, where instead of routing them to some sort of dead letter queue we wish to push the error upstream. We can do this with a switch broker:",
          "title": "Rejecting Failed Messages"
        }
      ],
      "name": "reject",
      "plugin": true,
      "status": "stable",
      "summary": "Rejects all messages, treating them as though the output destination failed to publish them.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "kind": "scalar",
        "name": "",
        "type": "output"
      },
      "description": "\nThe routing of messages rejected by this output depends on the type of input it came from. For inputs that support propagating nacks upstream such as AMQP or NATS the message will be nacked. However, for inputs that are sequential such as files or Kafka the messages will simply be reprocessed from scratch.",
      "examples": [
        {
          "config": "\ninput:\n  nats_jetstream:\n    urls: [ nats://127.0.0.1:4222 ]\n    subject: foos.pending\n\npipeline:\n  processors:\n    - mutation: 'root.age = this.fuzzy.age.int64()'\n\noutput:\n  reject_errored:\n    nats_jetstream:\n      urls: [ nats://127.0.0.1:4222 ]\n      subject: foos.processed\n",
          "summary": "\nThe most straight forward use case for this output type is to nack messages that have failed their processing steps. In this example our mapping might fail, in which case the messages that failed are rejected and will be nacked by our input:",
          "title": "Rejecting Failed Messages"
        },
        {
          "config": "\npipeline:\n  processors:\n    - mutation: 'root.age = this.fuzzy.age.int64()'\n\noutput:\n  fallback:\n    - reject_errored:\n        http_client:\n          url: http://foo:4195/post/might/become/unreachable\n          retries: 3\n          retry_period: 1s\n    - http_client:\n        url: http://bar:4196/somewhere/else\n        retries: 3\n        retry_period: 1s\n",
          "summary": "\nAnother use case for this output is to send failed messages straight into a dead-letter queue. You use it within a xref:components:outputs/fallback.adoc[fallback output] that allows you to specify where these failed messages should go to next.",
          "title": "DLQing Failed Messages"
        }
      ],
      "name": "reject_errored",
      "plugin": true,
      "status": "stable",
      "summary": "Rejects messages that have failed their processing steps, resulting in nack behavior at the input level, otherwise sends them to a child output.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "Resources allow you to tidy up deeply nested configs. For example, the config:\n\n```yaml\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n    - kafka:\n        addresses: [ TODO ]\n        topic: foo\n    - gcp_pubsub:\n        project: bar\n        topic: baz\n```\n\nCould also be expressed as:\n\n```yaml\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n    - resource: foo\n    - resource: bar\n\noutput_resources:\n  - label: foo\n    kafka:\n      addresses: [ TODO ]\n      topic: foo\n\n  - label: bar\n    gcp_pubsub:\n      project: bar\n      topic: baz\n```\n\nYou can find out more about resources in xref:configuration:resources.adoc[]",
      "name": "resource",
      "plugin": true,
      "status": "stable",
      "summary": "Resource is an output type that channels messages to a resource output, identified by its name.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": 0,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "500ms",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "3s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "0s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          },
          {
            "description": "A child output.",
            "kind": "scalar",
            "name": "output",
            "type": "output"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nAll messages in Redpanda Connect are always retried on an output error, but this would usually involve propagating the error back to the source of the message, whereby it would be reprocessed before reaching the output layer once again.\n\nThis output type is useful whenever we wish to avoid reprocessing a message on the event of a failed send. We might, for example, have a deduplication processor that we want to avoid reapplying to the same message more than once in the pipeline.\n\nRather than retrying the same output you may wish to retry the send using a different output target (a dead letter queue). In which case you should instead use the xref:components:outputs/fallback.adoc[`fallback`] output type.",
      "name": "retry",
      "plugin": true,
      "status": "stable",
      "summary": "Attempts to write messages to a child output and if the write fails for any reason the message is retried either until success or, if the retries or max elapsed time fields are non-zero, either is reached.",
      "type": "output"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The base URL of the schema registry service.",
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "description": "Subject.",
            "interpolated": true,
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "description": "The compatibility level for the subject. Can be one of BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "subject_compatibility_level",
            "type": "string"
          },
          {
            "default": true,
            "description": "Backfill schema references and previous versions.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "backfill_dependencies",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Translate schema IDs.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "translate_ids",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Normalize schemas.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "normalize",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Remove metadata from schemas.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "remove_metadata",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Remove rule set from schemas.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "remove_rule_set",
            "type": "bool"
          },
          {
            "default": "schema_registry_input",
            "description": "The label of the schema_registry input from which to read source schemas.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "input_resource",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "examples": [
        {
          "config": "\noutput:\n  fallback:\n    - schema_registry:\n        url: http://localhost:8082\n        subject: ${! @schema_registry_subject }\n        subject_compatibility_level: ${! @schema_registry_subject_compatibility_level }\n    - switch:\n        cases:\n          - check: '@fallback_error == \"request returned status: 422\"'\n            output:\n              drop: {}\n              processors:\n                - log:\n                    message: |\n                      Subject '${! @schema_registry_subject }' version ${! @schema_registry_version } already has schema: ${! content() }\n          - output:\n              reject: ${! @fallback_error }\n",
          "summary": "Write schemas to a Schema Registry instance and log errors for schemas which already exist.",
          "title": "Write schemas"
        }
      ],
      "name": "schema_registry",
      "plugin": true,
      "status": "beta",
      "summary": "Publishes schemas to SchemaRegistry.",
      "type": "output",
      "version": "4.32.2"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "The address of the server to connect to.",
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "default": "30s",
            "description": "The connection timeout to use when connecting to the target server.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "connection_timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "default": "",
                "description": "The username to authenticate with the SFTP server.",
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "The password for the specified username to connect to the SFTP server.",
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The path to the SFTP server's public key file, used for host key verification.",
                "is_optional": true,
                "kind": "scalar",
                "name": "host_public_key_file",
                "type": "string"
              },
              {
                "description": "The raw contents of the SFTP server's public key, used for host key verification.",
                "is_optional": true,
                "kind": "scalar",
                "name": "host_public_key",
                "type": "string"
              },
              {
                "description": "The path to the private key file, used for authenticating the username.",
                "is_optional": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "description": "The raw contents of the private key, used for authenticating the username.",
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "private_key",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "Optional passphrase for decrypting the private key, if it's encrypted.",
                "is_secret": true,
                "kind": "scalar",
                "name": "private_key_pass",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "The credentials to use to log into the target server.",
            "kind": "scalar",
            "linter": "\nroot = match {\n  this.exists(\"host_public_key\") && this.exists(\"host_public_key_file\") => \"both host_public_key and host_public_key_file can't be set simultaneously\"\n  this.exists(\"private_key\") && this.exists(\"private_key_file\") => \"both private_key and private_key_file can't be set simultaneously\"\n}",
            "name": "credentials",
            "type": "object"
          },
          {
            "description": "The file to save the messages to on the server.",
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "all-bytes",
                "Only applicable to file based outputs. Writes each message to a file in full, if the file already exists the old content is deleted."
              ],
              [
                "append",
                "Append each message to the output stream without any delimiter or special encoding."
              ],
              [
                "delim:x",
                "Append each message to the output stream followed by a custom delimiter."
              ],
              [
                "lines",
                "Append each message to the output stream followed by a line break."
              ]
            ],
            "default": "all-bytes",
            "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar"
            ],
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "In order to have a different path for each object you should use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "name": "sftp",
      "plugin": true,
      "status": "beta",
      "summary": "Writes files to an SFTP server.",
      "type": "output",
      "version": "3.39.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The Slack Bot User OAuth token to use.",
            "kind": "scalar",
            "linter": "\n        root = if !this.has_prefix(\"xoxb-\") { [ \"field must start with xoxb-\" ] }\n      ",
            "name": "bot_token",
            "type": "string"
          },
          {
            "description": "The channel ID to post messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "channel_id",
            "type": "string"
          },
          {
            "default": "",
            "description": "Optional thread timestamp to post messages to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "thread_ts",
            "type": "string"
          },
          {
            "default": "",
            "description": "The text content of the message. Mutually exclusive with `blocks`.",
            "interpolated": true,
            "kind": "scalar",
            "name": "text",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A Bloblang query that should return a JSON array of Slack blocks (see https://api.slack.com/reference/block-kit/blocks[Blocks in Slack documentation]). Mutually exclusive with `text`.",
            "is_optional": true,
            "kind": "scalar",
            "name": "blocks",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enable markdown formatting in the message.",
            "kind": "scalar",
            "name": "markdown",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Enable link unfurling in the message.",
            "kind": "scalar",
            "name": "unfurl_links",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Enable media unfurling in the message.",
            "kind": "scalar",
            "name": "unfurl_media",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Enable link names in the message.",
            "kind": "scalar",
            "name": "link_names",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Post a new message to a Slack channel using https://api.slack.com/methods/chat.postMessage[^chat.postMessage]",
      "examples": [
        {
          "config": "\ninput:\n  slack:\n    app_token: \"${APP_TOKEN:xapp-demo}\"\n    bot_token: \"${BOT_TOKEN:xoxb-demo}\"\npipeline:\n  processors:\n    - mutation: |\n        # ignore hidden or non message events\n        if this.event.type != \"message\" || (this.event.hidden | false) {\n          root = deleted()\n        }\n        # Don't respond to our own messages\n        if this.authorizations.any(auth -> auth.user_id == this.event.user) {\n          root = deleted()\n        }\noutput:\n  slack_post:\n    bot_token: \"${BOT_TOKEN:xoxb-demo}\"\n    channel_id: \"${!this.event.channel}\"\n    thread_ts: \"${!this.event.ts}\"\n    text: \"ECHO: ${!this.event.text}\"\n    ",
          "summary": "A slackbot that echo messages from other users",
          "title": "Echo Slackbot"
        }
      ],
      "name": "slack_post",
      "plugin": true,
      "status": "experimental",
      "type": "output"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The Slack Bot User OAuth token to use.",
            "kind": "scalar",
            "linter": "\n        root = if !this.has_prefix(\"xoxb-\") { [ \"field must start with xoxb-\" ] }\n      ",
            "name": "bot_token",
            "type": "string"
          },
          {
            "description": "The channel ID containing the message to react to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "channel_id",
            "type": "string"
          },
          {
            "description": "The timestamp of the message to react to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "description": "The name of the emoji to react with (without colons).",
            "interpolated": true,
            "kind": "scalar",
            "name": "emoji",
            "type": "string"
          },
          {
            "default": "add",
            "description": "Whether to add or remove the reaction.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"add\": true,\n  \"remove\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "action",
            "options": [
              "add",
              "remove"
            ],
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Add or remove an emoji reaction to a Slack message using https://api.slack.com/methods/reactions.add[^reactions.add] and https://api.slack.com/methods/reactions.remove[^reactions.remove]",
      "name": "slack_reaction",
      "plugin": true,
      "status": "experimental",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "Account name, which is the same as the https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#where-are-account-identifiers-used[Account Identifier^].\nHowever, when using an https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account Locator^],\nthe Account Identifier is formatted as `<account_locator>.<region_id>.<cloud>` and this field needs to be\npopulated using the `<account_locator>` part.\n",
            "kind": "scalar",
            "name": "account",
            "type": "string"
          },
          {
            "description": "Optional region field which needs to be populated when using\nan https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account Locator^]\nand it must be set to the `<region_id>` part of the Account Identifier\n(`<account_locator>.<region_id>.<cloud>`).\n",
            "examples": [
              "us-west-2"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Optional cloud platform field which needs to be populated\nwhen using an https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account Locator^]\nand it must be set to the `<cloud>` part of the Account Identifier\n(`<account_locator>.<region_id>.<cloud>`).\n",
            "examples": [
              "aws",
              "gcp",
              "azure"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "cloud",
            "type": "string"
          },
          {
            "description": "Username.",
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "description": "An optional password.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The private SSH key. `private_key_pass` is required when using encrypted keys.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "private_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The path to a file containing the private SSH key. `private_key_pass` is required when using encrypted keys.",
            "is_optional": true,
            "kind": "scalar",
            "name": "private_key_file",
            "type": "string"
          },
          {
            "description": "An optional private SSH key passphrase.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "private_key_pass",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Role.",
            "kind": "scalar",
            "name": "role",
            "type": "string"
          },
          {
            "description": "Database.",
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "description": "Warehouse.",
            "kind": "scalar",
            "name": "warehouse",
            "type": "string"
          },
          {
            "description": "Schema.",
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          },
          {
            "description": "Stage name. Use either one of the\n\t\thttps://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage.html[supported^] stage types.",
            "interpolated": true,
            "kind": "scalar",
            "name": "stage",
            "type": "string"
          },
          {
            "default": "",
            "description": "Stage path.",
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          },
          {
            "default": "",
            "description": "Stage file name. Will be equal to the Request ID if not set or empty.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "file_name",
            "type": "string",
            "version": "v4.12.0"
          },
          {
            "default": "",
            "description": "Stage file extension. Will be derived from the configured `compression` if not set or empty.",
            "examples": [
              "csv",
              "parquet"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "file_extension",
            "type": "string",
            "version": "v4.12.0"
          },
          {
            "default": 4,
            "description": "Specifies the number of threads to use for uploading files.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this < 1 || this > 99 { [ \"upload_parallel_threads must be between 1 and 99\" ] }",
            "name": "upload_parallel_threads",
            "type": "int"
          },
          {
            "annotated_options": [
              [
                "AUTO",
                "Compression (gzip) is applied automatically by the output and messages must contain plain-text JSON. Default `file_extension`: `gz`."
              ],
              [
                "DEFLATE",
                "Messages must be pre-compressed using the zlib algorithm (with zlib header, RFC1950). Default `file_extension`: `deflate`."
              ],
              [
                "GZIP",
                "Messages must be pre-compressed using the gzip algorithm. Default `file_extension`: `gz`."
              ],
              [
                "NONE",
                "No compression is applied and messages must contain plain-text JSON. Default `file_extension`: `json`."
              ],
              [
                "RAW_DEFLATE",
                "Messages must be pre-compressed using the flate algorithm (without header, RFC1951). Default `file_extension`: `raw_deflate`."
              ],
              [
                "ZSTD",
                "Messages must be pre-compressed using the Zstandard algorithm. Default `file_extension`: `zst`."
              ]
            ],
            "default": "AUTO",
            "description": "Compression type.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"auto\": true,\n  \"deflate\": true,\n  \"gzip\": true,\n  \"none\": true,\n  \"raw_deflate\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "compression",
            "type": "string"
          },
          {
            "default": "",
            "description": "Request ID. Will be assigned a random UUID (v4) string if not set or empty.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "request_id",
            "type": "string",
            "version": "v4.12.0"
          },
          {
            "description": "An optional Snowpipe name. Use the `<snowpipe>` part from `<database>.<schema>.<snowpipe>`. `private_key` or `private_key_file` must be set when using this feature.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "snowpipe",
            "type": "string"
          },
          {
            "default": false,
            "description": "Enable Snowflake keepalive mechanism to prevent the client session from expiring after 4 hours (error 390114).",
            "is_advanced": true,
            "kind": "scalar",
            "name": "client_session_keep_alive",
            "type": "bool"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 1,
            "description": "The maximum number of parallel message batches to have in flight at any given time.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  (!this.exists(\"password\") || this.password == \"\") && (!this.exists(\"private_key\") || this.private_key == \"\") && (!this.exists(\"private_key_file\") || this.private_key_file == \"\") => [ \"either `password` or `private_key` or `private_key_file` must be set\" ],\n  this.exists(\"password\") && this.password != \"\" && (this.exists(\"private_key\") && this.private_key != \"\" || this.exists(\"private_key_file\") && this.private_key_file != \"\") => [ \"only one of `password`, `private_key` and `private_key_file` can be set\" ],\n  this.exists(\"snowpipe\") && this.snowpipe != \"\" && !((this.exists(\"private_key\") && this.private_key != \"\") || (this.exists(\"private_key_file\") && this.private_key_file != \"\")) => [ \"either `private_key` or `private_key_file` must be set when using `snowpipe`\" ],\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nIn order to use a different stage and / or Snowpipe for each message, you can use function interpolations as described in\nxref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries]. When using batching, messages are grouped by the calculated\nstage and Snowpipe and are streamed to individual files in their corresponding stage and, optionally, a Snowpipe\n`insertFiles` REST API call will be made for each individual file.\n\n== Credentials\n\nTwo authentication mechanisms are supported:\n\n- User/password\n- Key Pair Authentication\n\n=== User/password\n\nThis is a basic authentication mechanism which allows you to PUT data into a stage. However, it is not compatible with\nSnowpipe.\n\n=== Key pair authentication\n\nThis authentication mechanism allows Snowpipe functionality, but it does require configuring an SSH Private Key\nbeforehand. Please consult the https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[documentation^]\nfor details on how to set it up and assign the Public Key to your user.\n\nNote that the Snowflake documentation https://twitter.com/felipehoffa/status/1560811785606684672[used to suggest^]\nusing this command:\n\n```bash\nopenssl genrsa 2048 | openssl pkcs8 -topk8 -inform PEM -out rsa_key.p8\n```\n\nto generate an encrypted SSH private key. However, in this case, it uses an encryption algorithm called\n`pbeWithMD5AndDES-CBC`, which is part of the PKCS#5 v1.5 and is considered insecure. Due to this, Redpanda Connect does not\nsupport it and, if you wish to use password-protected keys directly, you must use PKCS#5 v2.0 to encrypt them by using\nthe following command (as the current Snowflake docs suggest):\n\n```bash\nopenssl genrsa 2048 | openssl pkcs8 -topk8 -v2 des3 -inform PEM -out rsa_key.p8\n```\n\nIf you have an existing key encrypted with PKCS#5 v1.5, you can re-encrypt it with PKCS#5 v2.0 using this command:\n\n```bash\nopenssl pkcs8 -in rsa_key_original.p8 -topk8 -v2 des3 -out rsa_key.p8\n```\n\nPlease consult the https://linux.die.net/man/1/pkcs8[pkcs8 command documentation^] for details on PKCS#5 algorithms.\n\n== Batching\n\nIt's common to want to upload messages to Snowflake as batched archives. The easiest way to do this is to batch your\nmessages at the output level and join the batch of messages with an\nxref:components:processors/archive.adoc[`archive`] and/or xref:components:processors/compress.adoc[`compress`]\nprocessor.\n\nFor the optimal batch size, please consult the Snowflake https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare.html[documentation^].\n\n== Snowpipe\n\nGiven a table called `BENTHOS_TBL` with one column of type `variant`:\n\n```sql\nCREATE OR REPLACE TABLE BENTHOS_DB.PUBLIC.BENTHOS_TBL(RECORD variant)\n```\n\nand the following `BENTHOS_PIPE` Snowpipe:\n\n```sql\nCREATE OR REPLACE PIPE BENTHOS_DB.PUBLIC.BENTHOS_PIPE AUTO_INGEST = FALSE AS COPY INTO BENTHOS_DB.PUBLIC.BENTHOS_TBL FROM (SELECT * FROM @%BENTHOS_TBL) FILE_FORMAT = (TYPE = JSON COMPRESSION = AUTO)\n```\n\nyou can configure Redpanda Connect to use the implicit table stage `@%BENTHOS_TBL` as the `stage` and\n`BENTHOS_PIPE` as the `snowpipe`. In this case, you must set `compression` to `AUTO` and, if\nusing message batching, you'll need to configure an xref:components:processors/archive.adoc[`archive`] processor\nwith the `concatenate` format. Since the `compression` is set to `AUTO`, the\nhttps://github.com/snowflakedb/gosnowflake[gosnowflake^] client library will compress the messages automatically so you\ndon't need to add a xref:components:processors/compress.adoc[`compress`] processor for message batches.\n\nIf you add `STRIP_OUTER_ARRAY = TRUE` in your Snowpipe `FILE_FORMAT`\ndefinition, then you must use `json_array` instead of `concatenate` as the archive processor format.\n\nNOTE: Only Snowpipes with `FILE_FORMAT` `TYPE` `JSON` are currently supported.\n\n== Snowpipe troubleshooting\n\nSnowpipe https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-apis.html[provides^] the `insertReport`\nand `loadHistoryScan` REST API endpoints which can be used to get information about recent Snowpipe calls. In\norder to query them, you'll first need to generate a valid JWT token for your Snowflake account. There are two methods\nfor doing so:\n\n- Using the `snowsql` https://docs.snowflake.com/en/user-guide/snowsql.html[utility^]:\n\n```bash\nsnowsql --private-key-path rsa_key.p8 --generate-jwt -a <account> -u <user>\n```\n\n- Using the Python `sql-api-generate-jwt` https://docs.snowflake.com/en/developer-guide/sql-api/authenticating.html#generating-a-jwt-in-python[utility^]:\n\n```bash\npython3 sql-api-generate-jwt.py --private_key_file_path=rsa_key.p8 --account=<account> --user=<user>\n```\n\nOnce you successfully generate a JWT token and store it into the `JWT_TOKEN` environment variable, then you can,\nfor example, query the `insertReport` endpoint using `curl`:\n\n```bash\ncurl -H \"Authorization: Bearer ${JWT_TOKEN}\" \"https://<account>.snowflakecomputing.com/v1/data/pipes/<database>.<schema>.<snowpipe>/insertReport\"\n```\n\nIf you need to pass in a valid `requestId` to any of these Snowpipe REST API endpoints, you can set a\nxref:guides:bloblang/functions.adoc#uuid_v4[uuid_v4()] string in a metadata field called\n`request_id`, log it via the xref:components:processors/log.adoc[`log`] processor and\nthen configure `request_id: ${ @request_id }` ). Alternatively, you can xref:components:logger/about.adoc[enable debug logging]\n and Redpanda Connect will print the Request IDs that it sends to Snowpipe.\n\n== General troubleshooting\n\nThe underlying https://github.com/snowflakedb/gosnowflake[`gosnowflake` driver^] requires write access to\nthe default directory to use for temporary files. Please consult the https://pkg.go.dev/os#TempDir[`os.TempDir`^]\ndocs for details on how to change this directory via environment variables.\n\nA silent failure can occur due to https://github.com/snowflakedb/gosnowflake/issues/701[this issue^], where the\nunderlying https://github.com/snowflakedb/gosnowflake[`gosnowflake` driver^] doesn't return an error and doesn't\nlog a failure if it can't figure out the current username. One way to trigger this behavior is by running Redpanda Connect in a\nDocker container with a non-existent user ID (such as `--user 1000:1000`).\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\ninput:\n  kafka:\n    addresses:\n      - localhost:9092\n    topics:\n      - foo\n    consumer_group: benthos\n    batching:\n      count: 10\n      period: 3s\n      processors:\n        - mapping: |\n            meta kafka_start_offset = meta(\"kafka_offset\").from(0)\n            meta kafka_end_offset = meta(\"kafka_offset\").from(-1)\n            meta batch_timestamp = if batch_index() == 0 { now() }\n        - mapping: |\n            meta batch_timestamp = if batch_index() != 0 { meta(\"batch_timestamp\").from(0) }\n\noutput:\n  snowflake_put:\n    account: benthos\n    user: test@benthos.dev\n    private_key_file: path_to_ssh_key.pem\n    role: ACCOUNTADMIN\n    database: BENTHOS_DB\n    warehouse: COMPUTE_WH\n    schema: PUBLIC\n    stage: \"@%BENTHOS_TBL\"\n    path: benthos/BENTHOS_TBL/${! @kafka_partition }\n    file_name: ${! @kafka_start_offset }_${! @kafka_end_offset }_${! meta(\"batch_timestamp\") }\n    upload_parallel_threads: 4\n    compression: NONE\n    snowpipe: BENTHOS_PIPE\n",
          "summary": "Upload message batches from realtime brokers such as Kafka persisting the batch partition and offsets in the stage path and filename similarly to the https://docs.snowflake.com/en/user-guide/kafka-connector-ts.html#step-1-view-the-copy-history-for-the-table[Kafka Connector scheme^] and call Snowpipe to load them into a table. When batching is configured at the input level, it is done per-partition.",
          "title": "Kafka / realtime brokers"
        },
        {
          "config": "\noutput:\n  snowflake_put:\n    account: benthos\n    user: test@benthos.dev\n    private_key_file: path_to_ssh_key.pem\n    role: ACCOUNTADMIN\n    database: BENTHOS_DB\n    warehouse: COMPUTE_WH\n    schema: PUBLIC\n    stage: \"@%BENTHOS_TBL\"\n    path: benthos\n    upload_parallel_threads: 4\n    compression: NONE\n    batching:\n      count: 10\n      period: 3s\n      processors:\n        - archive:\n            format: concatenate\n",
          "summary": "Upload concatenated messages into a `.json` file to a table stage without calling Snowpipe.",
          "title": "No compression"
        },
        {
          "config": "\noutput:\n  snowflake_put:\n    account: benthos\n    user: test@benthos.dev\n    private_key_file: path_to_ssh_key.pem\n    role: ACCOUNTADMIN\n    database: BENTHOS_DB\n    warehouse: COMPUTE_WH\n    schema: PUBLIC\n    stage: \"@%BENTHOS_TBL\"\n    path: benthos\n    file_extension: parquet\n    upload_parallel_threads: 4\n    compression: NONE\n    batching:\n      count: 10\n      period: 3s\n      processors:\n        - parquet_encode:\n            schema:\n              - name: ID\n                type: INT64\n              - name: CONTENT\n                type: BYTE_ARRAY\n            default_compression: snappy\n",
          "summary": "Upload concatenated messages into a `.parquet` file to a table stage without calling Snowpipe.",
          "title": "Parquet format with snappy compression"
        },
        {
          "config": "\noutput:\n  snowflake_put:\n    account: benthos\n    user: test@benthos.dev\n    private_key_file: path_to_ssh_key.pem\n    role: ACCOUNTADMIN\n    database: BENTHOS_DB\n    warehouse: COMPUTE_WH\n    schema: PUBLIC\n    stage: \"@%BENTHOS_TBL\"\n    path: benthos\n    upload_parallel_threads: 4\n    compression: AUTO\n    batching:\n      count: 10\n      period: 3s\n      processors:\n        - archive:\n            format: concatenate\n",
          "summary": "Upload concatenated messages compressed automatically into a `.gz` archive file to a table stage without calling Snowpipe.",
          "title": "Automatic compression"
        },
        {
          "config": "\noutput:\n  snowflake_put:\n    account: benthos\n    user: test@benthos.dev\n    private_key_file: path_to_ssh_key.pem\n    role: ACCOUNTADMIN\n    database: BENTHOS_DB\n    warehouse: COMPUTE_WH\n    schema: PUBLIC\n    stage: \"@%BENTHOS_TBL\"\n    path: benthos\n    upload_parallel_threads: 4\n    compression: DEFLATE\n    snowpipe: BENTHOS_PIPE\n    batching:\n      count: 10\n      period: 3s\n      processors:\n        - archive:\n            format: concatenate\n        - mapping: |\n            root = content().compress(\"zlib\")\n",
          "summary": "Upload concatenated messages compressed into a `.deflate` archive file to a table stage and call Snowpipe to load them into a table.",
          "title": "DEFLATE compression"
        },
        {
          "config": "\noutput:\n  snowflake_put:\n    account: benthos\n    user: test@benthos.dev\n    private_key_file: path_to_ssh_key.pem\n    role: ACCOUNTADMIN\n    database: BENTHOS_DB\n    warehouse: COMPUTE_WH\n    schema: PUBLIC\n    stage: \"@%BENTHOS_TBL\"\n    path: benthos\n    upload_parallel_threads: 4\n    compression: RAW_DEFLATE\n    snowpipe: BENTHOS_PIPE\n    batching:\n      count: 10\n      period: 3s\n      processors:\n        - archive:\n            format: concatenate\n        - mapping: |\n            root = content().compress(\"flate\")\n",
          "summary": "Upload concatenated messages compressed into a `.raw_deflate` archive file to a table stage and call Snowpipe to load them into a table.",
          "title": "RAW_DEFLATE compression"
        }
      ],
      "name": "snowflake_put",
      "plugin": true,
      "status": "beta",
      "summary": "Sends messages to Snowflake stages and, optionally, calls Snowpipe to load this data into one or more tables.",
      "type": "output",
      "version": "4.0.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The Snowflake https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account name^]. Which should be formatted as `<orgname>-<account_name>` where `<orgname>` is the name of your Snowflake organization and `<account_name>` is the unique name of your account within your organization.\n",
            "examples": [
              "ORG-ACCOUNT"
            ],
            "kind": "scalar",
            "name": "account",
            "type": "string"
          },
          {
            "description": "Override the default URL used to connect to Snowflake which is https://ORG-ACCOUNT.snowflakecomputing.com",
            "examples": [
              "https://org-account.privatelink.snowflakecomputing.com"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "description": "The user to run the Snowpipe Stream as. See https://docs.snowflake.com/en/user-guide/admin-user-management[Snowflake Documentation^] on how to create a user.",
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "description": "The role for the `user` field. The role must have the https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-overview#required-access-privileges[required privileges^] to call the Snowpipe Streaming APIs. See https://docs.snowflake.com/en/user-guide/admin-user-management#user-roles[Snowflake Documentation^] for more information about roles.",
            "examples": [
              "ACCOUNTADMIN"
            ],
            "kind": "scalar",
            "name": "role",
            "type": "string"
          },
          {
            "description": "The Snowflake database to ingest data into.",
            "examples": [
              "MY_DATABASE"
            ],
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "description": "The Snowflake schema to ingest data into.",
            "examples": [
              "PUBLIC"
            ],
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          },
          {
            "description": "The Snowflake table to ingest data into.",
            "examples": [
              "MY_TABLE"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "The PEM encoded private RSA key to use for authenticating with Snowflake. Either this or `private_key_file` must be specified.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "private_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The file to load the private RSA key from. This should be a `.p8` PEM encoded file. Either this or `private_key` must be specified.",
            "is_optional": true,
            "kind": "scalar",
            "name": "private_key_file",
            "type": "string"
          },
          {
            "description": "The RSA key passphrase if the RSA key is encrypted.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "private_key_pass",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A bloblang mapping to execute on each message.",
            "is_optional": true,
            "kind": "scalar",
            "name": "mapping",
            "type": "string"
          },
          {
            "description": "\nOptional SQL statements to execute immediately upon the first connection. This is a useful way to initialize tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS mytable (amount NUMBER);\n",
              "\nALTER TABLE t1 ALTER COLUMN c1 DROP NOT NULL;\nALTER TABLE t1 ADD COLUMN a2 NUMBER;\n"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "Whether schema evolution is enabled.",
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": true,
                "description": "If `true`, then new columns that are `null` are ignored and schema evolution is not triggered. If `false` then null columns trigger schema migrations in Snowflake. NOTE: unless you already know what type this column will be in advance, it's highly encouraged to ignore null values.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "ignore_nulls",
                "type": "bool"
              },
              {
                "bloblang": true,
                "description": "\nThe mapping function from Redpanda Connect type to column type in Snowflake. Overriding this can allow for customization of the datatype if there is specific information that you know about the data types in use. This mapping should result in the `root` variable being assigned a string with the data type for the new column in Snowflake.\n\n        The input to this mapping is either the output of `processors` if specified, otherwise it is an object with the value and the name of the new column, the original message and table being written too. The metadata is unchanged from the original message that caused the schema to change. For example: `{\"value\": 42.3, \"name\":\"new_data_field\", \"message\": {\"existing_data_field\": 42, \"new_data_field\": \"foo\"}, \"db\": MY_DATABASE\", \"schema\": \"MY_SCHEMA\", \"table\": \"MY_TABLE\"}",
                "is_deprecated": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "new_column_type_mapping",
                "type": "string"
              },
              {
                "description": "\nA series of processors to execute when new columns are added to the table. Specifying this can support running side effects when the schema evolves or enriching the message with additional data to guide the schema changes. For example, one could read the schema the message was produced with from the schema registry and use that to decide which type the new column in Snowflake should be.\n\n        The input to these processors is an object with the value and the name of the new column, the original message and table being written too. The metadata is unchanged from the original message that caused the schema to change. For example: `{\"value\": 42.3, \"name\":\"new_data_field\", \"message\": {\"existing_data_field\": 42, \"new_data_field\": \"foo\"}, \"db\": MY_DATABASE\", \"schema\": \"MY_SCHEMA\", \"table\": \"MY_TABLE\"}`. The output of these series of processors should be a single message, where the contents of the message is a string indicating the column data type to use (FLOAT, VARIANT, NUMBER(38, 0), etc. An ALTER TABLE statement will then be executed on the table in Snowflake to add the column with the corresponding data type.",
                "examples": [
                  [
                    {
                      "mapping": "root = match this.value.type() {\n  this == \"string\" => \"STRING\"\n  this == \"bytes\" => \"BINARY\"\n  this == \"number\" => \"DOUBLE\"\n  this == \"bool\" => \"BOOLEAN\"\n  this == \"timestamp\" => \"TIMESTAMP\"\n  _ => \"VARIANT\"\n}"
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "Options to control schema evolution within the pipeline as new columns are added to the pipeline.",
            "is_optional": true,
            "kind": "scalar",
            "name": "schema_evolution",
            "type": "object"
          },
          {
            "description": "The maximum amount of parallelism to use when building the output for Snowflake. The metric to watch to see if you need to change this is `snowflake_build_output_latency_ns`.",
            "is_advanced": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "parallelism",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 1,
                "description": "The maximum amount of parallelism to use.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "root = if this < 1 { [\"parallelism must be positive\"] }",
                "name": "parallelism",
                "type": "int"
              },
              {
                "default": 50000,
                "description": "The number of rows to chunk for parallelization.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "root = if this < 1 { [\"chunk_size must be positive\"] }",
                "name": "chunk_size",
                "type": "int"
              }
            ],
            "description": "Options to optimize the time to build output data that is sent to Snowflake. The metric to watch to see if you need to change this is `snowflake_build_output_latency_ns`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "build_options",
            "type": "object"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "default": 4,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "description": "The prefix to use when creating a channel name.\nDuplicate channel names will result in errors and prevent multiple instances of Redpanda Connect from writing at the same time.\nBy default if neither `channel_prefix` or `channel_name is specified then the output will create a channel name that is based on the table FQN so there will only be a single stream per table.\n\nAt most `max_in_flight` channels will be opened.\n\nThis option is mutually exclusive with `channel_name`.\n\nNOTE: There is a limit of 10,000 streams per table - if using more than 10k streams please reach out to Snowflake support.",
            "examples": [
              "channel-${HOST}"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "channel_prefix",
            "type": "string"
          },
          {
            "description": "The channel name to use.\nDuplicate channel names will result in errors and prevent multiple instances of Redpanda Connect from writing at the same time.\nNote that batches are assumed to all contain messages for the same channel, so this interpolation is only executed on the first\nmessage in each batch. It's recommended to batch at the input level to ensure that batches contain messages for the same channel\nif using an input that is partitioned (such as an Apache Kafka topic).\n\nThis option is mutually exclusive with `channel_prefix`.\n\nNOTE: There is a limit of 10,000 streams per table - if using more than 10k streams please reach out to Snowflake support.",
            "examples": [
              "partition-${!@kafka_partition}"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "channel_name",
            "type": "string"
          },
          {
            "description": "The offset token to use for exactly once delivery of data in the pipeline. When data is sent on a channel, each message in a batch's offset token\nis compared to the latest token for a channel. If the offset token is lexicographically less than the latest in the channel, it's assumed the message is a duplicate and\nis dropped. This means it is *very important* to have ordered delivery to the output, any out of order messages to the output will be seen as duplicates and dropped.\nSpecifically this means that retried messages could be seen as duplicates if later messages have succeeded in the meantime, so in most circumstances a dead letter queue\noutput should be employed for failed messages.\n\nNOTE: It's assumed that messages within a batch are in increasing order by offset token, additionally if you're using a numeric value as an offset token, make sure to pad\n      the value so that it's lexicographically ordered in its string representation, since offset tokens are compared in string form.\n\nFor more information about offset tokens, see https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-overview#offset-tokens[^Snowflake Documentation]",
            "examples": [
              "offset-${!\"%016X\".format(@kafka_offset)}",
              "postgres-${!@lsn}"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "offset_token",
            "type": "string"
          },
          {
            "default": "60s",
            "description": "The max duration to wait until the data has been asynchronously committed to Snowflake.",
            "examples": [
              "10s",
              "10m"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "commit_timeout",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  this.exists(\"channel_prefix\") && this.exists(\"channel_name\") => [ \"both `channel_prefix` and `channel_name` can't be set simultaneously\" ],\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nIngest data into Snowflake using Snowpipe Streaming.\n\n[%header,format=dsv]\n|===\nSnowflake column type:Allowed format in Redpanda Connect\nCHAR, VARCHAR:string\nBINARY:[]byte\nNUMBER:any numeric type, string\nFLOAT:any numeric type\nBOOLEAN:bool,any numeric type,string parsable according to `strconv.ParseBool`\nTIME,DATE,TIMESTAMP:unix or RFC 3339 with nanoseconds timestamps\nVARIANT,ARRAY,OBJECT:any data type is converted into JSON\nGEOGRAPHY,GEOMETRY: Not supported\n|===\n\nFor TIMESTAMP, TIME and DATE columns, you can parse different string formats using a bloblang `mapping`.\n\nAuthentication can be configured using a https://docs.snowflake.com/en/user-guide/key-pair-auth[RSA Key Pair^].\n\nThere are https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-overview#limitations[limitations^] of what data types can be loaded into Snowflake using this method.\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].\n\nIt is recommended that each batches results in at least 16MiB of compressed output being written to Snowflake.\nYou can monitor the output batch size using the `snowflake_compressed_output_size_bytes` metric.\n",
      "examples": [
        {
          "config": "\ninput:\n  postgres_cdc:\n    dsn: postgres://foouser:foopass@localhost:5432/foodb\n    schema: \"public\"\n    slot_name: \"my_repl_slot\"\n    tables: [\"my_pg_table\"]\n    # We want very large batches - each batch will be sent to Snowflake individually\n    # so to optimize query performance we want as big of files as we have memory for\n    batching:\n      count: 50000\n      period: 45s\n    # Prevent multiple batches from being in flight at once, so that we never send\n    # a batch while another batch is being retried, this is important to ensure that\n    # the Snowflake Snowpipe Streaming channel does not see older data - as it will\n    # assume that the older data is already committed.\n    checkpoint_limit: 1\noutput:\n  snowflake_streaming:\n    # We use the log sequence number in the WAL from Postgres to ensure we\n    # only upload data exactly once, these are already lexicographically\n    # ordered.\n    offset_token: \"${!@lsn}\"\n    # Since we're sending a single ordered log, we can only send one thing\n    # at a time to ensure that we're properly incrementing our offset_token\n    # and only using a single channel at a time.\n    max_in_flight: 1\n    account: \"MYSNOW-ACCOUNT\"\n    user: MYUSER\n    role: ACCOUNTADMIN\n    database: \"MYDATABASE\"\n    schema: \"PUBLIC\"\n    table: \"MY_PG_TABLE\"\n    private_key_file: \"my/private/key.p8\"\n",
          "summary": "How to send data from a PostgreSQL table into Snowflake exactly once using Postgres Logical Replication.\n\nNOTE: If attempting to do exactly-once it's important that rows are delivered in order to the output. Be sure to read the documentation for offset_token first.\nRemoving the offset_token is a safer option that will instruct Redpanda Connect to use its default at-least-once delivery model instead.",
          "title": "Exactly once CDC into Snowflake"
        },
        {
          "config": "\ninput:\n  redpanda_common:\n    topics: [\"my_topic_going_to_snow\"]\n    consumer_group: \"redpanda_connect_to_snowflake\"\n    # We want very large batches - each batch will be sent to Snowflake individually\n    # so to optimize query performance we want as big of files as we have memory for\n    fetch_max_bytes: 100MiB\n    fetch_min_bytes: 50MiB\n    partition_buffer_bytes: 100MiB\npipeline:\n  processors:\n    - schema_registry_decode:\n        url: \"redpanda.example.com:8081\"\n        basic_auth:\n          enabled: true\n          username: MY_USER_NAME\n          password: \"${TODO}\"\noutput:\n  fallback:\n    - snowflake_streaming:\n        # To ensure that we write an ordered stream each partition in kafka gets its own\n        # channel.\n        channel_name: \"partition-${!@kafka_partition}\"\n        # Ensure that our offsets are lexicographically sorted in string form by padding with\n        # leading zeros\n        offset_token: offset-${!\"%016X\".format(@kafka_offset)}\n        account: \"MYSNOW-ACCOUNT\"\n        user: MYUSER\n        role: ACCOUNTADMIN\n        database: \"MYDATABASE\"\n        schema: \"PUBLIC\"\n        table: \"MYTABLE\"\n        private_key_file: \"my/private/key.p8\"\n        schema_evolution:\n          enabled: true\n    # In order to prevent delivery orders from messing with the order of delivered records\n    # it's important that failures are immediately sent to a dead letter queue and not retried\n    # to Snowflake. See the ordering documentation for the \"redpanda\" input for more details.\n    - retry:\n        output:\n          redpanda_common:\n            topic: \"dead_letter_queue\"\n",
          "summary": "How to ingest data from Redpanda with consumer groups, decode the schema using the schema registry, then write the corresponding data into Snowflake exactly once.\n\nNOTE: If attempting to do exactly-once its important that records are delivered in order to the output and correctly partitioned. Be sure to read the documentation for\nchannel_name and offset_token first. Removing the offset_token is a safer option that will instruct Redpanda Connect to use its default at-least-once delivery model instead.",
          "title": "Ingesting data exactly once from Redpanda"
        },
        {
          "config": "\ninput:\n  http_server:\n    path: /snowflake\nbuffer:\n  memory:\n    # Max inflight data before applying backpressure\n    limit: 524288000 # 50MiB\n    # Batching policy, influences how large the generated files sent to Snowflake are\n    batch_policy:\n      enabled: true\n      byte_size: 33554432 # 32MiB\n      period: \"10s\"\noutput:\n  snowflake_streaming:\n    account: \"MYSNOW-ACCOUNT\"\n    user: MYUSER\n    role: ACCOUNTADMIN\n    database: \"MYDATABASE\"\n    schema: \"PUBLIC\"\n    table: \"MYTABLE\"\n    private_key_file: \"my/private/key.p8\"\n    # By default there is only a single channel per output table allowed\n    # if we want to have multiple Redpanda Connect streams writing data\n    # then we need a unique channel prefix per stream. We'll use the host\n    # name to get unique prefixes in this example.\n    channel_prefix: \"snowflake-channel-for-${HOST}\"\n    schema_evolution:\n      enabled: true\n",
          "summary": "This example demonstrates how to create an HTTP server input that can recieve HTTP PUT requests\nwith JSON payloads, that are buffered locally then written to Snowflake in batches.\n\nNOTE: This example uses a buffer to respond to the HTTP request immediately, so it's possible that failures to deliver data could result in data loss.\nSee the documentation about xref:components:buffers/memory.adoc[buffers] for more information, or remove the buffer entirely to respond to the HTTP request only once the data is written to Snowflake.",
          "title": "HTTP Server to push data to Snowflake"
        }
      ],
      "name": "snowflake_streaming",
      "plugin": true,
      "status": "experimental",
      "summary": "Ingest data into Snowflake using Snowpipe Streaming.",
      "type": "output",
      "version": "4.39.0"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "A network type to connect as.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"unix\": true,\n  \"tcp\": true,\n  \"udp\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "network",
            "options": [
              "unix",
              "tcp",
              "udp"
            ],
            "type": "string"
          },
          {
            "description": "The address to connect to.",
            "examples": [
              "/tmp/benthos.sock",
              "127.0.0.1:6000"
            ],
            "kind": "scalar",
            "name": "address",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "all-bytes",
                "Only applicable to file based outputs. Writes each message to a file in full, if the file already exists the old content is deleted."
              ],
              [
                "append",
                "Append each message to the output stream without any delimiter or special encoding."
              ],
              [
                "lines",
                "Append each message to the output stream followed by a line break."
              ],
              [
                "delim:x",
                "Append each message to the output stream followed by a custom delimiter."
              ]
            ],
            "default": "lines",
            "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar"
            ],
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "socket",
      "plugin": true,
      "status": "stable",
      "summary": "Connects to a (tcp/udp/unix) server and sends a continuous stream of data, dividing messages according to the specified codec.",
      "type": "output"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "Full HTTP Endpoint Collector (HEC) URL.",
            "examples": [
              "https://foobar.splunkcloud.com/services/collector/event"
            ],
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "description": "A bot token used for authentication.",
            "is_secret": true,
            "kind": "scalar",
            "name": "token",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": false,
            "description": "Enable gzip compression",
            "kind": "scalar",
            "name": "gzip",
            "type": "bool"
          },
          {
            "description": "Set the host value to assign to the event data. Overrides existing host field if present.",
            "is_optional": true,
            "kind": "scalar",
            "name": "event_host",
            "type": "string"
          },
          {
            "description": "Set the source value to assign to the event data. Overrides existing source field if present.",
            "is_optional": true,
            "kind": "scalar",
            "name": "event_source",
            "type": "string"
          },
          {
            "description": "Set the sourcetype value to assign to the event data. Overrides existing sourcetype field if present.",
            "is_optional": true,
            "kind": "scalar",
            "name": "event_sourcetype",
            "type": "string"
          },
          {
            "description": "Set the index value to assign to the event data. Overrides existing index field if present.",
            "is_optional": true,
            "kind": "scalar",
            "name": "event_index",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          },
          {
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "skip_cert_verify",
            "type": "bool"
          },
          {
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "batching_count",
            "type": "int"
          },
          {
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "batching_period",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "batching_byte_size",
            "type": "int"
          },
          {
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "name": "splunk_hec",
      "plugin": true,
      "status": "beta",
      "summary": "Publishes messages to a Splunk HTTP Endpoint Collector (HEC).",
      "type": "output",
      "version": "4.30.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "Data source name.",
            "kind": "scalar",
            "name": "data_source_name",
            "type": "string"
          },
          {
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
            "examples": [
              "INSERT INTO footable (foo, bar, baz) VALUES (?, ?, ?);"
            ],
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of inserts to run in parallel.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Alternatives\n\nFor basic inserts use the xref:components:outputs/sql.adoc[`sql_insert`] output. For more complex queries use the xref:components:outputs/sql_raw.adoc[`sql_raw`] output.",
      "name": "sql",
      "plugin": true,
      "status": "deprecated",
      "summary": "Executes an arbitrary SQL query for each message.",
      "type": "output",
      "version": "3.65.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The table to insert to.",
            "examples": [
              "foo"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "A list of columns to insert.",
            "examples": [
              [
                "foo",
                "bar",
                "baz"
              ]
            ],
            "kind": "array",
            "name": "columns",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of columns specified.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "An optional prefix to prepend to the insert query (before INSERT).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to the insert query.",
            "examples": [
              "ON CONFLICT (name) DO NOTHING"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "suffix",
            "type": "string"
          },
          {
            "description": "A list of keyword options to add before the INTO clause of the query.",
            "examples": [
              [
                "DELAYED",
                "IGNORE"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "options",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of inserts to run in parallel.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\noutput:\n  sql_insert:\n    driver: mysql\n    dsn: foouser:foopassword@tcp(localhost:3306)/foodb\n    table: footable\n    columns: [ id, name, topic ]\n    args_mapping: |\n      root = [\n        this.user.id,\n        this.user.name,\n        meta(\"kafka_topic\"),\n      ]\n",
          "summary": "\nHere we insert rows into a database by populating the columns id, name and topic with values extracted from messages and metadata:",
          "title": "Table Insert (MySQL)"
        }
      ],
      "name": "sql_insert",
      "plugin": true,
      "status": "stable",
      "summary": "Inserts a row into an SQL database for each message.",
      "type": "output",
      "version": "3.59.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
            "examples": [
              "INSERT INTO footable (foo, bar, baz) VALUES (?, ?, ?);"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to enable xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the query. Great care should be made to ensure your queries are defended against injection attacks.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "unsafe_dynamic_query",
            "type": "bool"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
                "kind": "scalar",
                "name": "query",
                "type": "string"
              },
              {
                "bloblang": true,
                "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
                "examples": [
                  "root = [ this.cat.meow, this.doc.woofs[0] ]",
                  "root = [ meta(\"user.id\") ]"
                ],
                "is_optional": true,
                "kind": "scalar",
                "name": "args_mapping",
                "type": "string"
              }
            ],
            "description": "A list of statements to run in addition to `query`. When specifying multiple statements, they are all executed within a transaction.",
            "is_optional": true,
            "kind": "array",
            "name": "queries",
            "type": "object"
          },
          {
            "default": 64,
            "description": "The maximum number of statements to execute in parallel.",
            "kind": "scalar",
            "name": "max_in_flight",
            "type": "int"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          },
          {
            "children": [
              {
                "default": 0,
                "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                "kind": "scalar",
                "name": "count",
                "type": "int"
              },
              {
                "default": 0,
                "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                "kind": "scalar",
                "name": "byte_size",
                "type": "int"
              },
              {
                "default": "",
                "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                "examples": [
                  "1s",
                  "1m",
                  "500ms"
                ],
                "kind": "scalar",
                "name": "period",
                "type": "string"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                "examples": [
                  "this.type == \"end_of_transaction\""
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                "examples": [
                  [
                    {
                      "archive": {
                        "format": "concatenate"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "lines"
                      }
                    }
                  ],
                  [
                    {
                      "archive": {
                        "format": "json_array"
                      }
                    }
                  ]
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
            "examples": [
              {
                "byte_size": 5000,
                "count": 0,
                "period": "1s"
              },
              {
                "count": 10,
                "period": "1s"
              },
              {
                "check": "this.contains(\"END BATCH\")",
                "count": 0,
                "period": "1m"
              }
            ],
            "kind": "",
            "name": "batching",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n        !this.exists(\"queries\") && !this.exists(\"query\") => [ \"either `query` or `queries` is required\" ],\n    }",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\noutput:\n  sql_raw:\n    driver: mysql\n    dsn: foouser:foopassword@tcp(localhost:3306)/foodb\n    query: \"INSERT INTO footable (id, name, topic) VALUES (?, ?, ?);\"\n    args_mapping: |\n      root = [\n        this.user.id,\n        this.user.name,\n        meta(\"kafka_topic\"),\n      ]\n",
          "summary": "\nHere we insert rows into a database by populating the columns id, name and topic with values extracted from messages and metadata:",
          "title": "Table Insert (MySQL)"
        },
        {
          "config": "\noutput:\n  processors:\n    - mapping: |\n        root = this\n        # Prevent SQL injection when using unsafe_dynamic_query\n        meta table_name = \"\\\"\" + metadata(\"table_name\").replace_all(\"\\\"\", \"\\\"\\\"\") + \"\\\"\"\n  sql_raw:\n    driver: postgres\n    dsn: postgres://localhost/postgres\n    unsafe_dynamic_query: true\n    queries:\n      - query: |\n          CREATE TABLE IF NOT EXISTS ${!metadata(\"table_name\")} (id varchar primary key, document jsonb);\n      - query: |\n          INSERT INTO ${!metadata(\"table_name\")} (id, document) VALUES ($1, $2)\n          ON CONFLICT (id) DO UPDATE SET document = EXCLUDED.document;\n        args_mapping: |\n          root = [ this.id, this.document.string() ]\n\n",
          "summary": "Here we dynamically create output tables transactionally with inserting a record into the newly created table.",
          "title": "Dynamically Creating Tables (PostgreSQL)"
        }
      ],
      "name": "sql_raw",
      "plugin": true,
      "status": "stable",
      "summary": "Executes an arbitrary SQL query for each message.",
      "type": "output",
      "version": "3.65.0"
    },
    {
      "categories": [
        "Local"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "all-bytes",
                "Only applicable to file based outputs. Writes each message to a file in full, if the file already exists the old content is deleted."
              ],
              [
                "append",
                "Append each message to the output stream without any delimiter or special encoding."
              ],
              [
                "lines",
                "Append each message to the output stream followed by a line break."
              ],
              [
                "delim:x",
                "Append each message to the output stream followed by a custom delimiter."
              ]
            ],
            "default": "lines",
            "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
            "examples": [
              "lines",
              "delim:\t",
              "delim:foobar"
            ],
            "kind": "scalar",
            "name": "codec",
            "type": "string",
            "version": "3.46.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "stdout",
      "plugin": true,
      "status": "stable",
      "summary": "Prints messages to stdout as a continuous stream of data.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The command to execute as a subprocess.",
            "kind": "scalar",
            "name": "name",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of arguments to provide the command.",
            "kind": "array",
            "name": "args",
            "type": "string"
          },
          {
            "default": "lines",
            "description": "The way in which messages should be written to the subprocess.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lines\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "codec",
            "options": [
              "lines"
            ],
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nMessages are written according to a specified codec. The process is expected to terminate gracefully when stdin is closed.\n\nIf the subprocess exits unexpectedly then Redpanda Connect will log anything printed to stderr and will log the exit code, and will attempt to execute the command again until success.\n\nThe execution environment of the subprocess is the same as the Redpanda Connect instance, including environment variables and the current working directory.",
      "name": "subprocess",
      "plugin": true,
      "status": "beta",
      "summary": "Executes a command, runs it as a subprocess, and writes messages to it over stdin.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": false,
            "description": "\nIf a selected output fails to send a message this field determines whether it is reattempted indefinitely. If set to false the error is instead propagated back to the input level.\n\nIf a message can be routed to >1 outputs it is usually best to set this to true in order to avoid duplicate messages being routed to an output.",
            "kind": "scalar",
            "name": "retry_until_success",
            "type": "bool"
          },
          {
            "default": false,
            "description": "This field determines whether an error should be reported if no condition is met. If set to true, an error is propagated back to the input level. The default behavior is false, which will drop the message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "strict_mode",
            "type": "bool"
          },
          {
            "children": [
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should be routed to the case output. If left empty the case always passes.",
                "examples": [
                  "this.type == \"foo\"",
                  "this.contents.urls.contains(\"https://benthos.dev/\")"
                ],
                "kind": "scalar",
                "name": "check",
                "type": "string"
              },
              {
                "description": "An xref:components:outputs/about.adoc[output] for messages that pass the check to be routed to.",
                "kind": "scalar",
                "name": "output",
                "type": "output"
              },
              {
                "default": false,
                "description": "Indicates whether, if this case passes for a message, the next case should also be tested.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "continue",
                "type": "bool"
              }
            ],
            "description": "A list of switch cases, outlining outputs that can be routed to.",
            "examples": [
              [
                {
                  "check": "this.urls.contains(\"http://benthos.dev\")",
                  "continue": true,
                  "output": {
                    "cache": {
                      "key": "${!json(\"id\")}",
                      "target": "foo"
                    }
                  }
                },
                {
                  "output": {
                    "s3": {
                      "bucket": "bar",
                      "path": "${!json(\"id\")}"
                    }
                  }
                }
              ]
            ],
            "kind": "array",
            "name": "cases",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "if this.exists(\"retry_until_success\") && this.retry_until_success {\n  if this.cases.or([]).any(oconf -> oconf.output.type.or(\"\") == \"reject\" || oconf.output.reject.type() == \"string\" ) {\n    \"a 'switch' output with a 'reject' case output must have the field 'switch.retry_until_success' set to 'false', otherwise the 'reject' child output will result in infinite retries\"\n  }\n}",
        "name": "",
        "type": "object"
      },
      "description": "Messages that do not pass the check of a single output case are effectively dropped. In order to prevent this outcome set the field <<strict_mode, `strict_mode`>> to `true`, in which case messages that do not pass at least one case are considered failed and will be nacked and/or reprocessed depending on your input.",
      "examples": [
        {
          "config": "\noutput:\n  switch:\n    cases:\n      - check: this.type == \"foo\"\n        output:\n          amqp_1:\n            urls: [ amqps://guest:guest@localhost:5672/ ]\n            target_address: queue:/the_foos\n\n      - check: this.type == \"bar\"\n        output:\n          gcp_pubsub:\n            project: dealing_with_mike\n            topic: mikes_bars\n\n      - output:\n          redis_streams:\n            url: tcp://localhost:6379\n            stream: everything_else\n          processors:\n            - mapping: |\n                root = this\n                root.type = this.type | \"unknown\"\n",
          "summary": "\nThe most common use for a switch output is to multiplex messages across a range of output destinations. The following config checks the contents of the field `type` of messages and sends `foo` type messages to an `amqp_1` output, `bar` type messages to a `gcp_pubsub` output, and everything else to a `redis_streams` output.\n\nOutputs can have their own processors associated with them, and in this example the `redis_streams` output has a processor that enforces the presence of a type field before sending it.",
          "title": "Basic Multiplexing"
        },
        {
          "config": "\noutput:\n  switch:\n    cases:\n      - check: 'this.user.interests.contains(\"walks\").catch(false)'\n        output:\n          amqp_1:\n            urls: [ amqps://guest:guest@localhost:5672/ ]\n            target_address: queue:/people_what_think_good\n        continue: true\n\n      - check: 'this.user.dislikes.contains(\"videogames\").catch(false)'\n        output:\n          gcp_pubsub:\n            project: people\n            topic: that_i_dont_want_to_hang_with\n",
          "summary": "\nThe `continue` field allows messages that have passed a case to be tested against the next one also. This can be useful when combining non-mutually-exclusive case checks.\n\nIn the following example a message that passes both the check of the first case as well as the second will be routed to both.",
          "title": "Control Flow"
        }
      ],
      "name": "switch",
      "plugin": true,
      "status": "stable",
      "summary": "The switch output type allows you to route messages to different outputs based on their contents.",
      "type": "output"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nFor most inputs this mechanism is ignored entirely, in which case the sync response is dropped without penalty. It is therefore safe to use this output even when combining input types that might not have support for sync responses. An example of an input able to utilize this is the `http_server`.\n\nIt is safe to combine this output with others using broker types. For example, with the `http_server` input we could send the payload to a Kafka topic and also send a modified payload back with:\n\n```yaml\ninput:\n  http_server:\n    path: /post\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n      - kafka:\n          addresses: [ TODO:9092 ]\n          topic: foo_topic\n      - sync_response: {}\n        processors:\n          - mapping: 'root = content().uppercase()'\n```\n\nUsing the above example and posting the message 'hello world' to the endpoint `/post` Redpanda Connect would send it unchanged to the topic `foo_topic` and also respond with 'HELLO WORLD'.\n\nFor more information please read xref:guides:sync_responses.adoc[synchronous responses].",
      "name": "sync_response",
      "plugin": true,
      "status": "stable",
      "summary": "Returns the final message payload back to the input origin of the message, where it is dealt with according to that specific input type.",
      "type": "output"
    },
    {
      "categories": [
        "Network"
      ],
      "config": {
        "children": [
          {
            "description": "The URL to connect to.",
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "An optional HTTP proxy URL.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "proxy_url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "websocket",
      "plugin": true,
      "status": "stable",
      "summary": "Sends messages to an HTTP server via a websocket connection.",
      "type": "output"
    }
  ],
  "processors": [
    {
      "categories": [
        "Parsing",
        "Utility"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "binary",
                "Archive messages to a https://github.com/redpanda-data/benthos/blob/main/internal/message/message.go#L96[binary blob format^]."
              ],
              [
                "concatenate",
                "Join the raw contents of each message into a single binary message."
              ],
              [
                "json_array",
                "Attempt to parse each message as a JSON document and append the result to an array, which becomes the contents of the resulting message."
              ],
              [
                "lines",
                "Join the raw contents of each message and insert a line break between each one."
              ],
              [
                "tar",
                "Archive messages to a unix standard tape archive."
              ],
              [
                "zip",
                "Archive messages to a zip file."
              ]
            ],
            "description": "The archiving format to apply.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"binary\": true,\n  \"concatenate\": true,\n  \"json_array\": true,\n  \"lines\": true,\n  \"tar\": true,\n  \"zip\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "format",
            "type": "string"
          },
          {
            "default": "",
            "description": "The path to set for each message in the archive (when applicable).",
            "examples": [
              "${!count(\"files\")}-${!timestamp_unix_nano()}.txt",
              "${!meta(\"kafka_key\")}-${!json(\"id\")}.json"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "path",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nSome archive formats (such as tar, zip) treat each archive item (message part) as a file with a path. Since message parts only contain raw data a unique path must be generated for each part. This can be done by using function interpolations on the 'path' field as described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries]. For types that aren't file based (such as binary) the file field is ignored.\n\nThe resulting archived message adopts the metadata of the _first_ message part of the batch.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - archive:\n        format: tar\n        path: ${!json(\"doc.id\")}.json\n",
          "summary": "\nIf we had JSON messages in a batch each of the form:\n\n```json\n{\"doc\":{\"id\":\"foo\",\"body\":\"hello world 1\"}}\n```\n\nAnd we wished to tar archive them, setting their filenames to their respective unique IDs (with the extension `.json`), our config might look like\nthis:",
          "title": "Tar Archive"
        }
      ],
      "name": "archive",
      "plugin": true,
      "status": "stable",
      "summary": "Archives all the messages of a batch into a single message according to the selected archive format.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "description": "The <<operators, operator>> to execute",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"to_json\": true,\n  \"from_json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "options": [
              "to_json",
              "from_json"
            ],
            "type": "string"
          },
          {
            "default": "textual",
            "description": "An Avro encoding format to use for conversions to and from a schema.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"textual\": true,\n  \"binary\": true,\n  \"single\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "encoding",
            "options": [
              "textual",
              "binary",
              "single"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "A full Avro schema to use.",
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          },
          {
            "default": "",
            "description": "The path of a schema document to apply. Use either this or the `schema` field.",
            "examples": [
              "file://path/to/spec.avsc",
              "http://localhost:8081/path/to/spec/versions/1"
            ],
            "kind": "scalar",
            "name": "schema_path",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nWARNING: If you are consuming or generating messages using a schema registry service then it is likely this processor will fail as those services require messages to be prefixed with the identifier of the schema version being used. Instead, try the xref:components:processors/schema_registry_encode.adoc[`schema_registry_encode`] and xref:components:processors/schema_registry_decode.adoc[`schema_registry_decode`] processors.\n\n== Operators\n\n=== `to_json`\n\nConverts Avro documents into a JSON structure. This makes it easier to\nmanipulate the contents of the document within Benthos. The encoding field\nspecifies how the source documents are encoded.\n\n=== `from_json`\n\nAttempts to convert JSON documents into Avro documents according to the\nspecified encoding.",
      "name": "avro",
      "plugin": true,
      "status": "beta",
      "summary": "Performs Avro based operations on messages based on a schema.",
      "type": "processor"
    },
    {
      "categories": [
        "Mapping"
      ],
      "config": {
        "children": [
          {
            "description": "A <<codecs,codec>> defines how messages should be inserted into the AWK program as variables. The codec does not change which <<awk-functions,custom Redpanda Connect functions>> are available. The `text` codec is the closest to a typical AWK use case.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"none\": true,\n  \"text\": true,\n  \"json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "codec",
            "options": [
              "none",
              "text",
              "json"
            ],
            "type": "string"
          },
          {
            "description": "An AWK program to execute",
            "kind": "scalar",
            "name": "program",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nWorks by feeding message contents as the program input based on a chosen <<codecs,codec>> and replaces the contents of each message with the result. If the result is empty (nothing is printed by the program) then the original message contents remain unchanged.\n\nComes with a wide range of <<awk-functions,custom functions>> for accessing message metadata, json fields, printing logs, etc. These functions can be overridden by functions within the program.\n\nCheck out the <<examples,examples section>> in order to see how this processor can be used.\n\nThis processor uses https://github.com/benhoyt/goawk[GoAWK^], in order to understand the differences in how the program works you can read more about it in https://github.com/benhoyt/goawk#differences-from-awk[goawk.differences^].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n  - awk:\n      codec: none\n      program: |\n        function map_add_vals() {\n          json_set_int(\"doc.result\", json_get(\"doc.val1\") + json_get(\"doc.val2\"));\n        }\n        function map_multiply_vals() {\n          json_set_int(\"doc.result\", json_get(\"doc.val1\") * json_get(\"doc.val2\"));\n        }\n        function map_unknown(type) {\n          json_set(\"error\",\"unknown document type\");\n          print_log(\"Document type not recognised: \" type, \"ERROR\");\n        }\n        {\n          type = json_get(\"type\");\n          if (type == \"add\")\n            map_add_vals();\n          else if (type == \"multiply\")\n            map_multiply_vals();\n          else\n            map_unknown(type);\n        }\n",
          "summary": "\nBecause AWK is a full programming language it's much easier to map documents and perform arithmetic with it than with other Redpanda Connect processors. For example, if we were expecting documents of the form:\n\n```json\n{\"doc\":{\"val1\":5,\"val2\":10},\"id\":\"1\",\"type\":\"add\"}\n{\"doc\":{\"val1\":5,\"val2\":10},\"id\":\"2\",\"type\":\"multiply\"}\n```\n\nAnd we wished to perform the arithmetic specified in the `type` field,\non the values `val1` and `val2` and, finally, map the result into the\ndocument, giving us the following resulting documents:\n\n```json\n{\"doc\":{\"result\":15,\"val1\":5,\"val2\":10},\"id\":\"1\",\"type\":\"add\"}\n{\"doc\":{\"result\":50,\"val1\":5,\"val2\":10},\"id\":\"2\",\"type\":\"multiply\"}\n```\n\nWe can do that with the following:",
          "title": "JSON Mapping and Arithmetic"
        },
        {
          "config": "\npipeline:\n  processors:\n  - awk:\n      codec: none\n      program: |\n        {\n          array_path = \"path.to.foos\"\n          array_len = json_length(array_path)\n\n          for (i = 0; i < array_len; i++) {\n            ele = json_get(array_path \".\" i)\n            if ( ! ( ele in seen ) ) {\n              json_append(array_path \"_unique\", ele)\n              seen[ele] = 1\n            }\n          }\n        }\n",
          "summary": "\nIt's possible to iterate JSON arrays by appending an index value to the path, this can be used to do things like removing duplicates from arrays. For example, given the following input document:\n\n```json\n{\"path\":{\"to\":{\"foos\":[\"one\",\"two\",\"three\",\"two\",\"four\"]}}}\n```\n\nWe could create a new array `foos_unique` from `foos` giving us the result:\n\n```json\n{\"path\":{\"to\":{\"foos\":[\"one\",\"two\",\"three\",\"two\",\"four\"],\"foos_unique\":[\"one\",\"two\",\"three\",\"four\"]}}}\n```\n\nWith the following config:",
          "title": "Stuff With Arrays"
        }
      ],
      "footnotes": "\n== Codecs\n\nThe chosen codec determines how the contents of the message are fed into the\nprogram. Codecs only impact the input string and variables initialized for your\nprogram, they do not change the range of custom functions available.\n\n=== `none`\n\nAn empty string is fed into the program. Functions can still be used in order to\nextract and mutate metadata and message contents.\n\nThis is useful for when your program only uses functions and doesn't need the\nfull text of the message to be parsed by the program, as it is significantly\nfaster.\n\n=== `text`\n\nThe full contents of the message are fed into the program as a string, allowing\nyou to reference tokenized segments of the message with variables ($0, $1, etc).\nCustom functions can still be used with this codec.\n\nThis is the default codec as it behaves most similar to typical usage of the awk\ncommand line tool.\n\n=== `json`\n\nAn empty string is fed into the program, and variables are automatically\ninitialized before execution of your program by walking the flattened JSON\nstructure. Each value is converted into a variable by taking its full path,\ne.g. the object:\n\n```json\n{\n\t\"foo\": {\n\t\t\"bar\": {\n\t\t\t\"value\": 10\n\t\t},\n\t\t\"created_at\": \"2018-12-18T11:57:32\"\n\t}\n}\n```\n\nWould result in the following variable declarations:\n\n```\nfoo_bar_value = 10\nfoo_created_at = \"2018-12-18T11:57:32\"\n```\n\nCustom functions can also still be used with this codec.\n\n== AWK functions\n\n=== `json_get`\n\nSignature: `json_get(path)`\n\nAttempts to find a JSON value in the input message payload by a\nxref:configuration:field_paths.adoc[dot separated path] and returns it as a string.\n\n=== `json_set`\n\nSignature: `json_set(path, value)`\n\nAttempts to set a JSON value in the input message payload identified by a\nxref:configuration:field_paths.adoc[dot separated path], the value argument will be interpreted\nas a string.\n\nIn order to set non-string values use one of the following typed varieties:\n\n- `json_set_int(path, value)`\n- `json_set_float(path, value)`\n- `json_set_bool(path, value)`\n\n=== `json_append`\n\nSignature: `json_append(path, value)`\n\nAttempts to append a value to an array identified by a\nxref:configuration:field_paths.adoc[dot separated path]. If the target does not\nexist it will be created. If the target exists but is not already an array then\nit will be converted into one, with its original contents set to the first\nelement of the array.\n\nThe value argument will be interpreted as a string. In order to append\nnon-string values use one of the following typed varieties:\n\n- `json_append_int(path, value)`\n- `json_append_float(path, value)`\n- `json_append_bool(path, value)`\n\n=== `json_delete`\n\nSignature: `json_delete(path)`\n\nAttempts to delete a JSON field from the input message payload identified by a\nxref:configuration:field_paths.adoc[dot separated path].\n\n=== `json_length`\n\nSignature: `json_length(path)`\n\nReturns the size of the string or array value of JSON field from the input\nmessage payload identified by a xref:configuration:field_paths.adoc[dot separated path].\n\nIf the target field does not exist, or is not a string or array type, then zero\nis returned. In order to explicitly check the type of a field use `json_type`.\n\n=== `json_type`\n\nSignature: `json_type(path)`\n\nReturns the type of a JSON field from the input message payload identified by a\nxref:configuration:field_paths.adoc[dot separated path].\n\nPossible values are: \"string\", \"int\", \"float\", \"bool\", \"undefined\", \"null\",\n\"array\", \"object\".\n\n=== `create_json_object`\n\nSignature: `create_json_object(key1, val1, key2, val2, ...)`\n\nGenerates a valid JSON object of key value pair arguments. The arguments are\nvariadic, meaning any number of pairs can be listed. The value will always\nresolve to a string regardless of the value type. E.g. the following call:\n\n`create_json_object(\"a\", \"1\", \"b\", 2, \"c\", \"3\")`\n\nWould result in this string:\n\n`\\{\"a\":\"1\",\"b\":\"2\",\"c\":\"3\"}`\n\n=== `create_json_array`\n\nSignature: `create_json_array(val1, val2, ...)`\n\nGenerates a valid JSON array of value arguments. The arguments are variadic,\nmeaning any number of values can be listed. The value will always resolve to a\nstring regardless of the value type. E.g. the following call:\n\n`create_json_array(\"1\", 2, \"3\")`\n\nWould result in this string:\n\n`[\"1\",\"2\",\"3\"]`\n\n=== `metadata_set`\n\nSignature: `metadata_set(key, value)`\n\nSet a metadata key for the message to a value. The value will always resolve to\na string regardless of the value type.\n\n=== `metadata_get`\n\nSignature: `metadata_get(key) string`\n\nGet the value of a metadata key from the message.\n\n=== `timestamp_unix`\n\nSignature: `timestamp_unix() int`\n\nReturns the current unix timestamp (the number of seconds since 01-01-1970).\n\n=== `timestamp_unix`\n\nSignature: `timestamp_unix(date) int`\n\nAttempts to parse a date string by detecting its format and returns the\nequivalent unix timestamp (the number of seconds since 01-01-1970).\n\n=== `timestamp_unix`\n\nSignature: `timestamp_unix(date, format) int`\n\nAttempts to parse a date string according to a format and returns the equivalent\nunix timestamp (the number of seconds since 01-01-1970).\n\nThe format is defined by showing how the reference time, defined to be\n`Mon Jan 2 15:04:05 -0700 MST 2006` would be displayed if it were the value.\n\n=== `timestamp_unix_nano`\n\nSignature: `timestamp_unix_nano() int`\n\nReturns the current unix timestamp in nanoseconds (the number of nanoseconds\nsince 01-01-1970).\n\n=== `timestamp_unix_nano`\n\nSignature: `timestamp_unix_nano(date) int`\n\nAttempts to parse a date string by detecting its format and returns the\nequivalent unix timestamp in nanoseconds (the number of nanoseconds since\n01-01-1970).\n\n=== `timestamp_unix_nano`\n\nSignature: `timestamp_unix_nano(date, format) int`\n\nAttempts to parse a date string according to a format and returns the equivalent\nunix timestamp in nanoseconds (the number of nanoseconds since 01-01-1970).\n\nThe format is defined by showing how the reference time, defined to be\n`Mon Jan 2 15:04:05 -0700 MST 2006` would be displayed if it were the value.\n\n=== `timestamp_format`\n\nSignature: `timestamp_format(unix, format) string`\n\nFormats a unix timestamp. The format is defined by showing how the reference\ntime, defined to be `Mon Jan 2 15:04:05 -0700 MST 2006` would be displayed if it\nwere the value.\n\nThe format is optional, and if omitted RFC3339 (`2006-01-02T15:04:05Z07:00`)\nwill be used.\n\n=== `timestamp_format_nano`\n\nSignature: `timestamp_format_nano(unixNano, format) string`\n\nFormats a unix timestamp in nanoseconds. The format is defined by showing how\nthe reference time, defined to be `Mon Jan 2 15:04:05 -0700 MST 2006` would be\ndisplayed if it were the value.\n\nThe format is optional, and if omitted RFC3339 (`2006-01-02T15:04:05Z07:00`)\nwill be used.\n\n=== `print_log`\n\nSignature: `print_log(message, level)`\n\nPrints a Redpanda Connect log message at a particular log level. The log level is\noptional, and if omitted the level `INFO` will be used.\n\n=== `base64_encode`\n\nSignature: `base64_encode(data)`\n\nEncodes the input data to a base64 string.\n\n=== `base64_decode`\n\nSignature: `base64_decode(data)`\n\nAttempts to base64-decode the input data and returns the decoded string if\nsuccessful. It will emit an error otherwise.\n\n",
      "name": "awk",
      "plugin": true,
      "status": "stable",
      "summary": "Executes an AWK program on messages. This processor is very powerful as it offers a range of <<awk-functions,custom functions>> for querying and mutating message contents and metadata.",
      "type": "processor"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "description": "The model ID to use. For a full list see the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html[AWS Bedrock documentation^].",
            "examples": [
              "amazon.titan-text-express-v1",
              "anthropic.claude-3-5-sonnet-20240620-v1:0",
              "cohere.command-text-v14",
              "meta.llama3-1-70b-instruct-v1:0",
              "mistral.mistral-large-2402-v1:0"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.",
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The system prompt to submit to the AWS Bedrock LLM.",
            "is_optional": true,
            "kind": "scalar",
            "name": "system_prompt",
            "type": "string"
          },
          {
            "description": "The maximum number of tokens to allow in the generated response.",
            "is_optional": true,
            "kind": "scalar",
            "name": "max_tokens",
            "type": "int"
          },
          {
            "description": "The likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model omre likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.",
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < 0 || this > 1 { [\"field must be between 0.0-1.0\"] }",
            "name": "temperature",
            "type": "float"
          },
          {
            "description": "A list of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "stop",
            "type": "string"
          },
          {
            "description": "The percentage of most-likely candidates that the model considers for the next token. For example, if you choose a value of 0.8, the model selects from the top 80% of the probability distribution of tokens that could be next in the sequence. ",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < 0 || this > 1 { [\"field must be between 0.0-1.0\"] }",
            "name": "top_p",
            "type": "float"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor sends prompts to your chosen large language model (LLM) and generates text from the responses, using the AWS Bedrock API.\nFor more information, see the https://docs.aws.amazon.com/bedrock/latest/userguide[AWS Bedrock documentation^].",
      "name": "aws_bedrock_chat",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates responses to messages in a chat conversation, using the AWS Bedrock API.",
      "type": "processor",
      "version": "4.34.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "description": "The model ID to use. For a full list see the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html[AWS Bedrock documentation^].",
            "examples": [
              "amazon.titan-embed-text-v1",
              "amazon.titan-embed-text-v2:0",
              "cohere.embed-english-v3",
              "cohere.embed-multilingual-v3"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.",
            "is_optional": true,
            "kind": "scalar",
            "name": "text",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor sends text to your chosen large language model (LLM) and computes vector embeddings, using the AWS Bedrock API.\nFor more information, see the https://docs.aws.amazon.com/bedrock/latest/userguide[AWS Bedrock documentation^].",
      "examples": [
        {
          "config": "input:\n  generate:\n    interval: 1s\n    mapping: |\n      root = {\"text\": fake(\"paragraph\")}\npipeline:\n  processors:\n  - branch:\n      request_map: |\n        root = this.text\n      processors:\n      - aws_bedrock_embeddings:\n          model: amazon.titan-embed-text-v1\n      result_map: |\n        root.embeddings = this\noutput:\n  sql_insert:\n    driver: clickhouse\n    dsn: \"clickhouse://localhost:9000\"\n    table: searchable_text\n    columns: [\"id\", \"text\", \"vector\"]\n    args_mapping: \"root = [uuid_v4(), this.text, this.embeddings]\"\n",
          "summary": "Compute embeddings for some generated data and store it within https://clickhouse.com/[Clickhouse^]",
          "title": "Store embedding vectors in Clickhouse"
        }
      ],
      "name": "aws_bedrock_embeddings",
      "plugin": true,
      "status": "experimental",
      "summary": "Computes vector embeddings on text, using the AWS Bedrock API.",
      "type": "processor",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "A PartiQL query to execute for each message.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to enable dynamic queries that support interpolation functions.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "unsafe_dynamic_query",
            "type": "bool"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that, for each message, creates a list of arguments to use with the query.",
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Both writes or reads are supported, when the query is a read the contents of the message will be replaced with the result. This processor is more efficient when messages are pre-batched as the whole batch will be executed in a single call.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - aws_dynamodb_partiql:\n        query: \"INSERT INTO footable VALUE {'foo':'?','bar':'?','baz':'?'}\"\n        args_mapping: |\n          root = [\n            { \"S\": this.foo },\n            { \"S\": meta(\"kafka_topic\") },\n            { \"S\": this.document.content },\n          ]\n",
          "summary": "The following example inserts rows into the table footable with the columns foo, bar and baz populated with values extracted from messages:",
          "title": "Insert"
        }
      ],
      "name": "aws_dynamodb_partiql",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a PartiQL expression against a DynamoDB table for each message.",
      "type": "processor",
      "version": "3.48.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether messages of a batch should be dispatched in parallel.",
            "kind": "scalar",
            "name": "parallel",
            "type": "bool"
          },
          {
            "description": "The function to invoke.",
            "kind": "scalar",
            "name": "function",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional xref:components:rate_limits/about.adoc[`rate_limit`] to throttle invocations by.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "description": "The AWS region to target.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "region",
            "type": "string"
          },
          {
            "description": "Allows you to specify a custom endpoint for the AWS API.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "A profile from `~/.aws/credentials` to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "profile",
                "type": "string"
              },
              {
                "description": "The ID of credentials to use.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "id",
                "type": "string"
              },
              {
                "description": "The secret for the credentials being used.",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "The token for the credentials being used, required when using short term credentials.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "token",
                "type": "string"
              },
              {
                "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "from_ec2_role",
                "type": "bool",
                "version": "4.2.0"
              },
              {
                "description": "A role ARN to assume.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role",
                "type": "string"
              },
              {
                "description": "An external ID to provide when assuming a role.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "role_external_id",
                "type": "string"
              }
            ],
            "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "credentials",
            "type": "object"
          },
          {
            "default": "5s",
            "description": "The maximum period of time to wait before abandoning an invocation.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of retry attempts for each message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The `rate_limit` field can be used to specify a rate limit xref:components:rate_limits/about.adoc[resource] to cap the rate of requests across parallel components service wide.\n\nIn order to map or encode the payload to a specific request body, and map the response back into the original payload instead of replacing it entirely, you can use the xref:components:processors/branch.adoc[`branch` processor].\n\n== Error handling\n\nWhen Redpanda Connect is unable to connect to the AWS endpoint or is otherwise unable to invoke the target lambda function it will retry the request according to the configured number of retries. Once these attempts have been exhausted the failed message will continue through the pipeline with it's contents unchanged, but flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, if the invocation of the function is successful but the function itself throws an error, then the message will have it's contents updated with a JSON payload describing the reason for the failure, and a metadata field `lambda_function_error` will be added to the message allowing you to detect and handle function errors with a xref:components:processors/branch.adoc[`branch`]:\n\n```yaml\npipeline:\n  processors:\n    - branch:\n        processors:\n          - aws_lambda:\n              function: foo\n        result_map: |\n          root = if meta().exists(\"lambda_function_error\") {\n            throw(\"Invocation failed due to %v: %v\".format(this.errorType, this.errorMessage))\n          } else {\n            this\n          }\noutput:\n  switch:\n    retry_until_success: false\n    cases:\n      - check: errored()\n        output:\n          reject: ${! error() }\n      - output:\n          resource: somewhere_else\n```\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: '{\"id\":this.doc.id,\"username\":this.user.name}'\n        processors:\n          - aws_lambda:\n              function: trigger_user_update\n",
          "summary": "\nThis example uses a xref:components:processors/branch.adoc[`branch` processor] to map a new payload for triggering a lambda function with an ID and username from the original message, and the result of the lambda is discarded, meaning the original message is unchanged.",
          "title": "Branched Invoke"
        }
      ],
      "name": "aws_lambda",
      "plugin": true,
      "status": "stable",
      "summary": "Invokes an AWS lambda for each message. The contents of the message is the payload of the request, and the result of the invocation will become the new contents of the message.",
      "type": "processor",
      "version": "3.36.0"
    },
    {
      "categories": [
        "Azure"
      ],
      "config": {
        "children": [
          {
            "description": "CosmosDB endpoint.",
            "examples": [
              "https://localhost:8081"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "endpoint",
            "type": "string"
          },
          {
            "description": "Account key.",
            "examples": [
              "C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw=="
            ],
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "account_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Connection string.",
            "examples": [
              "AccountEndpoint=https://localhost:8081/;AccountKey=C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==;"
            ],
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "connection_string",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Database.",
            "examples": [
              "testdb"
            ],
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "description": "Container.",
            "examples": [
              "testcontainer"
            ],
            "kind": "scalar",
            "name": "container",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a single partition key value or an array of partition key values of type string, integer or boolean. Currently, hierarchical partition keys are not supported so only one value may be provided.",
            "examples": [
              "root = \"blobfish\"",
              "root = 41",
              "root = true",
              "root = null",
              "root = json(\"blobfish\").depth"
            ],
            "kind": "scalar",
            "name": "partition_keys_map",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "Create",
                "Create operation."
              ],
              [
                "Delete",
                "Delete operation."
              ],
              [
                "Patch",
                "Patch operation."
              ],
              [
                "Read",
                "Read operation."
              ],
              [
                "Replace",
                "Replace operation."
              ],
              [
                "Upsert",
                "Upsert operation."
              ]
            ],
            "default": "Create",
            "description": "Operation.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"create\": true,\n  \"delete\": true,\n  \"patch\": true,\n  \"read\": true,\n  \"replace\": true,\n  \"upsert\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "type": "string"
          },
          {
            "children": [
              {
                "annotated_options": [
                  [
                    "Add",
                    "Add patch operation."
                  ],
                  [
                    "Increment",
                    "Increment patch operation."
                  ],
                  [
                    "Remove",
                    "Remove patch operation."
                  ],
                  [
                    "Replace",
                    "Replace patch operation."
                  ],
                  [
                    "Set",
                    "Set patch operation."
                  ]
                ],
                "default": "Add",
                "description": "Operation.",
                "is_advanced": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"add\": true,\n  \"increment\": true,\n  \"remove\": true,\n  \"replace\": true,\n  \"set\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "operation",
                "type": "string"
              },
              {
                "description": "Path.",
                "examples": [
                  "/foo/bar/baz"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "path",
                "type": "string"
              },
              {
                "bloblang": true,
                "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a value of any type that is supported by CosmosDB.",
                "examples": [
                  "root = \"blobfish\"",
                  "root = 41",
                  "root = true",
                  "root = json(\"blobfish\").depth",
                  "root = [1, 2, 3]"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "value_map",
                "type": "string"
              }
            ],
            "description": "Patch operations to be performed when `operation: Patch` .",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "patch_operations",
            "type": "object"
          },
          {
            "description": "Patch operation condition.",
            "examples": [
              "from c where not is_defined(c.blobfish)"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "patch_condition",
            "type": "string"
          },
          {
            "default": true,
            "description": "Automatically set the item `id` field to a random UUID v4. If the `id` field is already set, then it will not be overwritten. Setting this to `false` can improve performance, since the messages will not have to be parsed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auto_id",
            "type": "bool"
          },
          {
            "description": "ID of item to replace or delete. Only used by the Replace and Delete operations",
            "examples": [
              "${! json(\"id\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "item_id",
            "type": "string"
          },
          {
            "default": true,
            "description": "Enable content response on write operations. To save some bandwidth, set this to false if you don't need to receive the updated message(s) from the server, in which case the processor will not modify the content of the messages which are fed into it. Applies to every operation except Read.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "enable_content_response_on_write",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "linter": "root = []\nlet hasEndpoint = this.endpoint.or(\"\") != \"\"\nlet hasConnectionString = this.connection_string.or(\"\") != \"\"\n\nroot.\"-\" = if !$hasEndpoint && !$hasConnectionString {\n  \"Either `endpoint` or `connection_string` must be set.\"\n}\n\nlet hasItemID = this.item_id.or(\"\") != \"\"\nlet hasPatchOperations = this.patch_operations.length().or(0) > 0\nlet hasPatchCondition = this.patch_condition.or(\"\") != \"\"\n\nroot.\"-\" = if !$hasItemID && (this.operation == \"Replace\" || this.operation == \"Delete\" || this.operation == \"Read\" || this.operation == \"Patch\") {\n  \"The `item_id` field must be set for Replace, Delete, Read and Patch operations.\"\n}\n\nroot.\"-\" = if this.operation == \"Patch\" && !$hasPatchOperations {\n  \"At least one `patch_operations` must be set when `operation: Patch`.\"\n}\n\nroot.\"-\" = if $hasPatchCondition && (!$hasPatchOperations || this.operation != \"Patch\") {\n  \"The `patch_condition`  field only applies to `Patch` operations and it requires one or more `patch_operations`.\"\n}\n\nroot.\"-\" = if this.operation == \"Patch\" && this.patch_operations.any(o -> o.operation != \"Remove\" && o.value_map.or(\"\") == \"\") {\n  \"The `patch_operations` `value_map` field must be set when `operation` is not `Remove`.\"\n}\n\nroot.\"-\" = if this.operation == \"Patch\" && this.patch_operations.any(o -> o.operation == \"Remove\" && o.value_map.or(\"\") != \"\") {\n  \"The `patch_operations` `value_map` field must not be set when `operation` is `Remove`.\"\n}\n",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen creating documents, each message must have the `id` property (case-sensitive) set (or use `auto_id: true`). It is the unique name that identifies the document, that is, no two documents share the same `id` within a logical partition. The `id` field must not exceed 255 characters. https://learn.microsoft.com/en-us/rest/api/cosmos-db/documents[See details^].\n\nThe `partition_keys` field must resolve to the same value(s) across the entire message batch.\n\n\n== Credentials\n\nYou can use one of the following authentication mechanisms:\n\n- Set the `endpoint` field and the `account_key` field\n- Set only the `endpoint` field to use https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n- Set the `connection_string` field\n\n\n== Metadata\n\nThis component adds the following metadata fields to each message:\n```\n- activity_id\n- request_charge\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n\n== Batching\n\nCosmosDB limits the maximum batch size to 100 messages and the payload must not exceed 2MB (https://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits#per-request-limits[details here^]).\n",
      "examples": [
        {
          "config": "\ninput:\n  azure_cosmosdb:\n    endpoint: http://localhost:8080\n    account_key: C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==\n    database: blobbase\n    container: blobfish\n    partition_keys_map: root = \"AbyssalPlain\"\n    query: SELECT * FROM blobfish\n\n  processors:\n    - mapping: |\n        root = \"\"\n        meta habitat = json(\"habitat\")\n        meta id = this.id\n    - azure_cosmosdb:\n        endpoint: http://localhost:8080\n        account_key: C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==\n        database: testdb\n        container: blobfish\n        partition_keys_map: root = json(\"habitat\")\n        item_id: ${! meta(\"id\") }\n        operation: Patch\n        patch_operations:\n          # Add a new /diet field\n          - operation: Add\n            path: /diet\n            value_map: root = json(\"diet\")\n          # Remove the first location from the /locations array field\n          - operation: Remove\n            path: /locations/0\n          # Add new location at the end of the /locations array field\n          - operation: Add\n            path: /locations/-\n            value_map: root = \"Challenger Deep\"\n        # Return the updated document\n        enable_content_response_on_write: true\n",
          "summary": "Query documents from a container and patch them.",
          "title": "Patch documents"
        }
      ],
      "footnotes": "\n\n== CosmosDB emulator\n\nIf you wish to run the CosmosDB emulator that is referenced in the documentation https://learn.microsoft.com/en-us/azure/cosmos-db/linux-emulator[here^], the following Docker command should do the trick:\n\n```bash\n> docker run --rm -it -p 8081:8081 --name=cosmosdb -e AZURE_COSMOS_EMULATOR_PARTITION_COUNT=10 -e AZURE_COSMOS_EMULATOR_ENABLE_DATA_PERSISTENCE=false mcr.microsoft.com/cosmosdb/linux/azure-cosmos-emulator\n```\n\nNote: `AZURE_COSMOS_EMULATOR_PARTITION_COUNT` controls the number of partitions that will be supported by the emulator. The bigger the value, the longer it takes for the container to start up.\n\nAdditionally, instead of installing the container self-signed certificate which is exposed via `https://localhost:8081/_explorer/emulator.pem`, you can run https://mitmproxy.org/[mitmproxy^] like so:\n\n```bash\n> mitmproxy -k --mode \"reverse:https://localhost:8081\"\n```\n\nThen you can access the CosmosDB UI via `http://localhost:8080/_explorer/index.html` and use `http://localhost:8080` as the CosmosDB endpoint.\n",
      "name": "azure_cosmosdb",
      "plugin": true,
      "status": "experimental",
      "summary": "Creates or updates messages as JSON documents in https://learn.microsoft.com/en-us/azure/cosmos-db/introduction[Azure CosmosDB^].",
      "type": "processor",
      "version": "v4.25.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": "5s",
            "description": "How often to emit rolling statistics. If set to 0, only a summary will be logged when the processor shuts down.",
            "kind": "scalar",
            "name": "interval",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether or not to measure the number of bytes per second of throughput. Counting the number of bytes requires serializing structured data, which can cause an unnecessary performance hit if serialization is not required elsewhere in the pipeline.",
            "kind": "scalar",
            "name": "count_bytes",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Logs messages per second and bytes per second of messages that are processed at a regular interval. A summary of the amount of messages processed over the entire lifetime of the processor will also be printed when the processor shuts down.\n\nThe following metrics are exposed:\n- benchmark_messages_per_second (gauge): The current throughput in messages per second\n- benchmark_messages_total (counter): The total number of messages processed\n- benchmark_bytes_per_second (gauge): The current throughput in bytes per second\n- benchmark_bytes_total (counter): The total number of bytes processed",
      "name": "benchmark",
      "plugin": true,
      "status": "experimental",
      "summary": "Logs basic throughput statistics of messages that pass through this processor.",
      "type": "processor"
    },
    {
      "categories": [
        "Mapping",
        "Parsing"
      ],
      "config": {
        "bloblang": true,
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nBloblang is a powerful language that enables a wide range of mapping, transformation and filtering tasks. For more information see xref:guides:bloblang/about.adoc[].\n\nIf your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"<path>\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from.\n\n== Component rename\n\nThis processor was recently renamed to the xref:components:processors/mapping.adoc[`mapping` processor] in order to make the purpose of the processor more prominent. It is still valid to use the existing `bloblang` name but eventually it will be deprecated and replaced by the new name in example configs.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n  - bloblang: |\n      root = this\n      root.fans = this.fans.filter(fan -> fan.obsession > 0.5)\n",
          "summary": "\nGiven JSON documents containing an array of fans:\n\n```json\n{\n  \"id\":\"foo\",\n  \"description\":\"a show about foo\",\n  \"fans\":[\n    {\"name\":\"bev\",\"obsession\":0.57},\n    {\"name\":\"grace\",\"obsession\":0.21},\n    {\"name\":\"ali\",\"obsession\":0.89},\n    {\"name\":\"vic\",\"obsession\":0.43}\n  ]\n}\n```\n\nWe can reduce the fans to only those with an obsession score above 0.5, giving us:\n\n```json\n{\n  \"id\":\"foo\",\n  \"description\":\"a show about foo\",\n  \"fans\":[\n    {\"name\":\"bev\",\"obsession\":0.57},\n    {\"name\":\"ali\",\"obsession\":0.89}\n  ]\n}\n```\n\nWith the following config:",
          "title": "Mapping"
        },
        {
          "config": "\npipeline:\n  processors:\n    - bloblang: |\n        root.Cities = this.locations.\n                        filter(loc -> loc.state == \"WA\").\n                        map_each(loc -> loc.name).\n                        sort().join(\", \")\n",
          "summary": "\nWhen receiving JSON documents of the form:\n\n```json\n{\n  \"locations\": [\n    {\"name\": \"Seattle\", \"state\": \"WA\"},\n    {\"name\": \"New York\", \"state\": \"NY\"},\n    {\"name\": \"Bellevue\", \"state\": \"WA\"},\n    {\"name\": \"Olympia\", \"state\": \"WA\"}\n  ]\n}\n```\n\nWe could collapse the location names from the state of Washington into a field `Cities`:\n\n```json\n{\"Cities\": \"Bellevue, Olympia, Seattle\"}\n```\n\nWith the following config:",
          "title": "More Mapping"
        }
      ],
      "footnotes": "\n== Error handling\n\nBloblang mappings can fail, in which case the message remains unchanged, errors are logged, and the message is flagged as having failed, allowing you to use\nxref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, Bloblang itself also provides powerful ways of ensuring your mappings do not fail by specifying desired fallback behavior, which you can read about in xref:guides:bloblang/about#error-handling.adoc[Error handling].",
      "name": "bloblang",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a xref:guides:bloblang/about.adoc[Bloblang] mapping on messages.",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": 1073741824,
            "description": "The maximum size of a message to allow (in bytes)",
            "kind": "scalar",
            "name": "max_part_size",
            "type": "int"
          },
          {
            "default": 1,
            "description": "The minimum size of a message to allow (in bytes)",
            "kind": "scalar",
            "name": "min_part_size",
            "type": "int"
          },
          {
            "default": 100,
            "description": "The maximum size of message batches to allow (in message count)",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_parts",
            "type": "int"
          },
          {
            "default": 1,
            "description": "The minimum size of message batches to allow (in message count)",
            "is_advanced": true,
            "kind": "scalar",
            "name": "min_parts",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "bounds_check",
      "plugin": true,
      "status": "stable",
      "summary": "Removes messages (and batches) that do not fit within certain size boundaries.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "bloblang": true,
            "default": "",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how to create a request payload suitable for the child processors of this branch. If left empty then the branch will begin with an exact copy of the origin message (including metadata).",
            "examples": [
              "root = {\n\t\"id\": this.doc.id,\n\t\"content\": this.doc.body.text\n}",
              "root = if this.type == \"foo\" {\n\tthis.foo.request\n} else {\n\tdeleted()\n}"
            ],
            "kind": "scalar",
            "name": "request_map",
            "type": "string"
          },
          {
            "description": "A list of processors to apply to mapped requests. When processing message batches the resulting batch must match the size and ordering of the input batch, therefore filtering, grouping should not be performed within these processors.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how the resulting messages from branched processing should be mapped back into the original payload. If left empty the origin message will remain unchanged (including metadata).",
            "examples": [
              "meta foo_code = metadata(\"code\")\nroot.foo_result = this",
              "meta = metadata()\nroot.bar.body = this.body\nroot.bar.id = this.user.id",
              "root.raw_result = content().string()",
              "root.enrichments.foo = if metadata(\"request_failed\") != null {\n  throw(metadata(\"request_failed\"))\n} else {\n  this\n}",
              "# Retain only the updated metadata fields which were present in the origin message\nmeta = metadata().filter(v -> @.get(v.key) != null)"
            ],
            "kind": "scalar",
            "name": "result_map",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis is useful for preserving the original message contents when using processors that would otherwise replace the entire contents.\n\n== Metadata\n\nMetadata fields that are added to messages during branch processing will not be automatically copied into the resulting message. In order to do this you should explicitly declare in your `result_map` either a wholesale copy with `meta = metadata()`, or selective copies with `meta foo = metadata(\"bar\")` and so on. It is also possible to reference the metadata of the origin message in the `result_map` using the xref:guides:bloblang/about.adoc#metadata[`@` operator].\n\n== Error handling\n\nIf the `request_map` fails the child processors will not be executed. If the child processors themselves result in an (uncaught) error then the `result_map` will not be executed. If the `result_map` fails the message will remain unchanged. Under any of these conditions standard xref:configuration:error_handling.adoc[error handling methods] can be used in order to filter, DLQ or recover the failed messages.\n\n== Conditional branching\n\nIf the root of your request map is set to `deleted()` then the branch processors are skipped for the given message, this allows you to conditionally branch messages.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: 'root = \"\"'\n        processors:\n          - http:\n              url: https://hub.docker.com/v2/repositories/jeffail/benthos\n              verb: GET\n              headers:\n                Content-Type: application/json\n        result_map: root.image.pull_count = this.pull_count\n\n# Example input:  {\"id\":\"foo\",\"some\":\"pre-existing data\"}\n# Example output: {\"id\":\"foo\",\"some\":\"pre-existing data\",\"image\":{\"pull_count\":1234}}\n",
          "summary": "\nThis example strips the request message into an empty body, grabs an HTTP payload, and places the result back into the original message at the path `image.pull_count`:",
          "title": "HTTP Request"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: 'root = this.document.id'\n        processors:\n          - cache:\n              resource: descriptions_cache\n              key: ${! content() }\n              operator: get\n        result_map: root.document.description = content().string()\n\n# Example input:  {\"document\":{\"id\":\"foo\",\"content\":\"hello world\"}}\n# Example output: {\"document\":{\"id\":\"foo\",\"content\":\"hello world\",\"description\":\"this is a cool doc\"}}\n",
          "summary": "\nWhen the result of your branch processors is unstructured and you wish to simply set a resulting field to the raw output use the content function to obtain the raw bytes of the resulting message and then coerce it into your value type of choice:",
          "title": "Non Structured Results"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: '{\"id\":this.doc.id,\"username\":this.user.name}'\n        processors:\n          - aws_lambda:\n              function: trigger_user_update\n\n# Example input: {\"doc\":{\"id\":\"foo\",\"body\":\"hello world\"},\"user\":{\"name\":\"fooey\"}}\n# Output matches the input, which is unchanged\n",
          "summary": "\nThis example maps a new payload for triggering a lambda function with an ID and username from the original message, and the result of the lambda is discarded, meaning the original message is unchanged.",
          "title": "Lambda Function"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: |\n          meta id = this.id\n          root = if this.type == \"foo\" {\n            this.document\n          } else {\n            deleted()\n          }\n        processors:\n          - cache:\n              resource: TODO\n              operator: set\n              key: ${! @id }\n              value: ${! content() }\n",
          "summary": "\nThis example caches a document by a message ID only when the type of the document is a foo:",
          "title": "Conditional Caching"
        }
      ],
      "name": "branch",
      "plugin": true,
      "status": "stable",
      "summary": "The `branch` processor allows you to create a new request message via a xref:guides:bloblang/about.adoc[Bloblang mapping], execute a list of processors on the request messages, and, finally, map the result back into the source message using another mapping.",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The xref:components:caches/about.adoc[`cache` resource] to target with this processor.",
            "kind": "scalar",
            "name": "resource",
            "type": "string"
          },
          {
            "description": "The <<operators, operation>> to perform with the cache.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"set\": true,\n  \"add\": true,\n  \"get\": true,\n  \"delete\": true,\n  \"exists\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "options": [
              "set",
              "add",
              "get",
              "delete",
              "exists"
            ],
            "type": "string"
          },
          {
            "description": "A key to use with the cache.",
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "A value to use with the cache (when applicable).",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "value",
            "type": "string"
          },
          {
            "description": "The TTL of each individual item as a duration string. After this period an item will be eligible for removal during the next compaction. Not all caches support per-key TTLs, those that do will have a configuration field `default_ttl`, and those that do not will fall back to their generally configured TTL setting.",
            "examples": [
              "60s",
              "5m",
              "36h"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "ttl",
            "type": "string",
            "version": "3.33.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nFor use cases where you wish to cache the result of processors consider using the xref:components:processors/cached.adoc[`cached` processor] instead.\n\nThis processor will interpolate functions within the `key` and `value` fields individually for each message. This allows you to specify dynamic keys and values based on the contents of the message payloads and metadata. You can find a list of functions in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - cache:\n        resource: foocache\n        operator: add\n        key: '${! json(\"message.id\") }'\n        value: \"storeme\"\n    - mapping: root = if errored() { deleted() }\n\ncache_resources:\n  - label: foocache\n    redis:\n      url: tcp://TODO:6379\n",
          "summary": "\nDeduplication can be done using the add operator with a key extracted from the message payload, since it fails when a key already exists we can remove the duplicates using a xref:components:processors/mapping.adoc[`mapping` processor]:",
          "title": "Deduplication"
        },
        {
          "config": "\npipeline:\n  processors:\n    # Try and add one message to a cache that identifies the whole batch\n    - branch:\n        request_map: |\n          root = if batch_index() == 0 {\n            json(\"id\").from(0) + json(\"meta.tail_id\").from(-1)\n          } else { deleted() }\n        processors:\n          - cache:\n              resource: foocache\n              operator: add\n              key: ${! content() }\n              value: t\n    # Delete all messages if we failed\n    - mapping: |\n        root = if errored().from(0) {\n          deleted()\n        }\n",
          "summary": "\nSometimes it's necessary to deduplicate a batch of messages (also known as a window) by a single identifying value. This can be done by introducing a xref:components:processors/branch.adoc[`branch` processor], which executes the cache only once on behalf of the batch, in this case with a value make from a field extracted from the first and last messages of the batch:",
          "title": "Deduplication Batch-Wide"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - cache:\n              resource: foocache\n              operator: get\n              key: '${! json(\"message.document_id\") }'\n        result_map: 'root.message.document = this'\n\n        # NOTE: If the data stored in the cache is not valid JSON then use\n        # something like this instead:\n        # result_map: 'root.message.document = content().string()'\n\ncache_resources:\n  - label: foocache\n    memcached:\n      addresses: [ \"TODO:11211\" ]\n",
          "summary": "\nIt's possible to enrich payloads with content previously stored in a cache by using the xref:components:processors/branch.adoc[`branch`] processor:",
          "title": "Hydration"
        }
      ],
      "footnotes": "\n== Operators\n\n=== `set`\n\nSet a key in the cache to a value. If the key already exists the contents are\noverridden.\n\n=== `add`\n\nSet a key in the cache to a value. If the key already exists the action fails\nwith a 'key already exists' error, which can be detected with\nxref:configuration:error_handling.adoc[processor error handling].\n\n=== `get`\n\nRetrieve the contents of a cached key and replace the original message payload\nwith the result. If the key does not exist the action fails with an error, which\ncan be detected with xref:configuration:error_handling.adoc[processor error handling].\n\n=== `delete`\n\nDelete a key and its contents from the cache. If the key does not exist the\naction is a no-op and will not fail with an error.\n\n=== `exists`\n\nCheck if a given key exists in the cache and replace the original message payload\nwith `true` or `false`.",
      "name": "cache",
      "plugin": true,
      "status": "stable",
      "summary": "Performs operations against a xref:components:caches/about.adoc[cache resource] for each message, allowing you to store or retrieve data within message payloads.",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The cache resource to read and write processor results from.",
            "kind": "scalar",
            "name": "cache",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A condition that can be used to skip caching the results from the processors.",
            "examples": [
              "errored()"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "skip_on",
            "type": "string"
          },
          {
            "description": "A key to be resolved for each message, if the key already exists in the cache then the cached result is used, otherwise the processors are applied and the result is cached under this key. The key could be static and therefore apply generally to all messages or it could be an interpolated expression that is potentially unique for each message.",
            "examples": [
              "my_foo_result",
              "${! this.document.id }",
              "${! meta(\"kafka_key\") }",
              "${! meta(\"kafka_topic\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "description": "An optional expiry period to set for each cache entry. Some caches only have a general TTL and will therefore ignore this setting.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "ttl",
            "type": "string"
          },
          {
            "description": "The list of processors whose result will be cached.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The format of the data when stored within the cache is a custom and versioned schema chosen to balance performance and storage space. It is therefore not possible to point this processor to a cache that is pre-populated with data that this processor has not created itself.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - cached:\n              key: '${! meta(\"kafka_topic\") }-${! meta(\"kafka_partition\") }'\n              cache: foo_cache\n              processors:\n                - mapping: 'root = \"\"'\n                - http:\n                    url: http://example.com/enrichment/${! meta(\"kafka_topic\") }/${! meta(\"kafka_partition\") }\n                    verb: GET\n        result_map: 'root.enrichment = this'\n\ncache_resources:\n  - label: foo_cache\n    memory:\n      # Disable compaction so that cached items never expire\n      compaction_interval: \"\"\n",
          "summary": "In the following example we want to we enrich messages consumed from Kafka with data specific to the origin topic partition, we do this by placing an `http` processor within a `branch`, where the HTTP URL contains interpolation functions with the topic and partition in the path.\n\nHowever, it would be inefficient to make this HTTP request for every single message as the result is consistent for all data of a given topic partition. We can solve this by placing our enrichment call within a `cached` processor where the key contains the topic and partition, resulting in messages that originate from the same topic/partition combination using the cached result of the prior.",
          "title": "Cached Enrichment"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: 'root = \"\"'\n        processors:\n          - cached:\n              key: static_foo\n              cache: foo_cache\n              ttl: 10m\n              processors:\n                - http:\n                    url: http://example.com/get/foo.json\n                    verb: GET\n        result_map: 'root.foo = this'\n\ncache_resources:\n  - label: foo_cache\n    memory: {}\n",
          "summary": "In the following example we enrich all messages with the same data obtained from a static URL with an `http` processor within a `branch`. However, we expect the data from this URL to change roughly every 10 minutes, so we configure a `cached` processor with a static key (since this request is consistent for all messages) and a TTL of `10m`.",
          "title": "Periodic Global Enrichment"
        }
      ],
      "name": "cached",
      "plugin": true,
      "status": "experimental",
      "summary": "Cache the result of applying one or more processors to messages identified by a key. If the key already exists within the cache the contents of the message will be replaced with the cached result instead of applying the processors. This component is therefore useful in situations where an expensive set of processors need only be executed periodically.",
      "type": "processor",
      "version": "4.3.0"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "default": [],
        "kind": "array",
        "name": "",
        "type": "processor"
      },
      "description": "\nBehaves similarly to the xref:components:processors/for_each.adoc[`for_each`] processor, where a list of child processors are applied to individual messages of a batch. However, processors are only applied to messages that failed a processing step prior to the catch.\n\nFor example, with the following config:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo\n    - catch:\n      - resource: bar\n      - resource: baz\n```\n\nIf the processor `foo` fails for a particular message, that message will be fed into the processors `bar` and `baz`. Messages that do not fail for the processor `foo` will skip these processors.\n\nWhen messages leave the catch block their fail flags are cleared. This processor is useful for when it's possible to recover failed messages, or when special actions (such as logging/metrics) are required before dropping them.\n\nMore information about error handling can be found in xref:configuration:error_handling.adoc[].",
      "name": "catch",
      "plugin": true,
      "status": "stable",
      "summary": "Applies a list of child processors _only_ when a previous processing step has failed.",
      "type": "processor"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.cohere.com",
            "description": "The base URL to use for API requests.",
            "kind": "scalar",
            "name": "base_url",
            "type": "string"
          },
          {
            "description": "The API key for the Cohere API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the Cohere model to use.",
            "examples": [
              "command-r-plus",
              "command-r",
              "command",
              "command-light"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The user prompt you want to generate a response for. By default, the processor submits the entire payload as a string.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The system prompt to submit along with the user prompt.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "system_prompt",
            "type": "string"
          },
          {
            "description": "The maximum number of tokens that can be generated in the chat completion.",
            "is_optional": true,
            "kind": "scalar",
            "name": "max_tokens",
            "type": "int"
          },
          {
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or top_p but not both.",
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < 0 { [ \"field must be between 0 and 2\" ] }",
            "name": "temperature",
            "type": "float"
          },
          {
            "default": "text",
            "description": "Specify the model's output format. If `json_schema` is specified, then additionally a `json_schema` or `schema_registry` must be configured.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"text\": true,\n  \"json\": true,\n  \"json_schema\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "response_format",
            "options": [
              "text",
              "json",
              "json_schema"
            ],
            "type": "string"
          },
          {
            "description": "The JSON schema to use when responding in `json_schema` format. To learn more about what JSON schema is supported see the https://docs.cohere.com/docs/structured-outputs-json[Cohere documentation^].",
            "is_optional": true,
            "kind": "scalar",
            "name": "json_schema",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The base URL of the schema registry service.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "url",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "description": "The subject name to fetch the schema for.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "subject",
                "type": "string"
              },
              {
                "description": "The refresh rate for getting the latest schema. If not specified the schema does not refresh.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "refresh_interval",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to skip server side certificate verification.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "skip_cert_verify",
                    "type": "bool"
                  },
                  {
                    "default": false,
                    "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enable_renegotiation",
                    "type": "bool",
                    "version": "3.45.0"
                  },
                  {
                    "default": "",
                    "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "root_cas",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "./root_cas.pem"
                    ],
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "root_cas_file",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "default": "",
                        "description": "A plain text certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text certificate key to use.",
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "key",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate key to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "key_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                        "examples": [
                          "foo",
                          "${KEY_PASSWORD}"
                        ],
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "password",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      }
                    ],
                    "default": [],
                    "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                    "examples": [
                      [
                        {
                          "cert": "foo",
                          "key": "bar"
                        }
                      ],
                      [
                        {
                          "cert_file": "./example.pem",
                          "key_file": "./example.key"
                        }
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "client_certs",
                    "type": "object"
                  }
                ],
                "description": "Custom TLS settings can be used to override system defaults.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "tls",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to use OAuth version 1 in requests.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "A value used to identify the client to the service provider.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "consumer_key",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A secret used to establish ownership of the consumer key.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "consumer_secret",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A value used to gain access to the protected resources on behalf of the user.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "access_token",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A secret provided in order to establish ownership of a given access token.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "access_token_secret",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "Allows you to specify open authentication via OAuth version 1.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "oauth",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to use basic authentication in requests.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "A username to authenticate as.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "username",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A password to authenticate with.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "Allows you to specify basic authentication.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "basic_auth",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to use JWT authentication in requests.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "private_key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "signing_method",
                    "type": "string"
                  },
                  {
                    "default": {},
                    "description": "A value used to identify the claims that issued the JWT.",
                    "is_advanced": true,
                    "kind": "map",
                    "name": "claims",
                    "type": "unknown"
                  },
                  {
                    "default": {},
                    "description": "Add optional key/value headers to the JWT.",
                    "is_advanced": true,
                    "kind": "map",
                    "name": "headers",
                    "type": "unknown"
                  }
                ],
                "description": "BETA: Allows you to specify JWT authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "jwt",
                "type": "object"
              }
            ],
            "description": "The schema registry to dynamically load schemas from when responding in `json_schema` format. Schemas themselves must be in JSON format. To learn more about what JSON schema is supported see the https://docs.cohere.com/docs/structured-outputs-json[Cohere documentation^].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "schema_registry",
            "type": "object"
          },
          {
            "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 1 || this < 0 { [ \"field must be between 0 and 1\" ] }",
            "name": "top_p",
            "type": "float"
          },
          {
            "description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be less than 2 and greater than -2\" ] }",
            "name": "frequency_penalty",
            "type": "float"
          },
          {
            "description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be less than 2 and greater than -2\" ] }",
            "name": "presence_penalty",
            "type": "float"
          },
          {
            "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "seed",
            "type": "int"
          },
          {
            "description": "Up to 4 sequences where the API will stop generating further tokens.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "stop",
            "type": "string"
          },
          {
            "default": 10,
            "description": "Maximum number of tool calls the model can do.",
            "kind": "scalar",
            "name": "max_tool_calls",
            "type": "int"
          },
          {
            "children": [
              {
                "description": "The name of this tool.",
                "kind": "scalar",
                "name": "name",
                "type": "string"
              },
              {
                "description": "A description of this tool, the LLM uses this to decide if the tool should be used.",
                "kind": "scalar",
                "name": "description",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "The required parameters for this pipeline.",
                    "kind": "array",
                    "name": "required",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "The type of this parameter.",
                        "kind": "scalar",
                        "name": "type",
                        "type": "string"
                      },
                      {
                        "description": "A description of this parameter.",
                        "kind": "scalar",
                        "name": "description",
                        "type": "string"
                      },
                      {
                        "default": [],
                        "description": "Specifies that this parameter is an enum and only these specific values should be used.",
                        "kind": "array",
                        "name": "enum",
                        "type": "string"
                      }
                    ],
                    "description": "The properties for the processor's input data",
                    "kind": "map",
                    "name": "properties",
                    "type": "object"
                  }
                ],
                "description": "The parameters the LLM needs to provide to invoke this tool.",
                "kind": "scalar",
                "name": "parameters",
                "type": "object"
              },
              {
                "description": "The pipeline to execute when the LLM uses this tool.",
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "default": [],
            "description": "The tools to allow the LLM to invoke. This allows building subpipelines that the LLM can choose to invoke to execute agentic-like actions.",
            "kind": "array",
            "name": "tools",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "\n      root = match {\n        this.exists(\"json_schema\") && this.exists(\"schema_registry\") => [\"cannot set both `json_schema` and `schema_registry`\"]\n        this.response_format == \"json_schema\" && !this.exists(\"json_schema\") && !this.exists(\"schema_registry\") => [\"schema must be specified using either `json_schema` or `schema_registry`\"]\n      }\n    ",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends the contents of user prompts to the Cohere API, which generates responses. By default, the processor submits the entire payload of each message as a string, unless you use the `prompt` configuration field to customize it.\n\nTo learn more about chat completion, see the https://docs.cohere.com/docs/chat-api[Cohere API documentation^].",
      "name": "cohere_chat",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates responses to messages in a chat conversation, using the Cohere API.",
      "type": "processor",
      "version": "4.37.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.cohere.com",
            "description": "The base URL to use for API requests.",
            "kind": "scalar",
            "name": "base_url",
            "type": "string"
          },
          {
            "description": "The API key for the Cohere API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the Cohere model to use.",
            "examples": [
              "embed-english-v3.0",
              "embed-english-light-v3.0",
              "embed-multilingual-v3.0",
              "embed-multilingual-light-v3.0"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The text you want to generate a vector embedding for. By default, the processor submits the entire payload as a string.",
            "is_optional": true,
            "kind": "scalar",
            "name": "text_mapping",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "classification",
                "Used for embeddings passed through a text classifier."
              ],
              [
                "clustering",
                "Used for the embeddings run through a clustering algorithm."
              ],
              [
                "search_document",
                "Used for embeddings stored in a vector database for search use-cases."
              ],
              [
                "search_query",
                "Used for embeddings of search queries run against a vector DB to find relevant documents."
              ]
            ],
            "default": "search_document",
            "description": "Specifies the type of input passed to the model.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"classification\": true,\n  \"clustering\": true,\n  \"search_document\": true,\n  \"search_query\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "input_type",
            "type": "string"
          },
          {
            "description": "The number of dimensions of the output embedding. This is only available for embed-v4 and newer models. Possible values are 256, 512, 1024, and 1536.",
            "is_optional": true,
            "kind": "scalar",
            "name": "dimensions",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends text strings to the Cohere API, which generates vector embeddings. By default, the processor submits the entire payload of each message as a string, unless you use the `text_mapping` configuration field to customize it.\n\nTo learn more about vector embeddings, see the https://docs.cohere.com/docs/embeddings[Cohere API documentation^].",
      "examples": [
        {
          "config": "input:\n  generate:\n    interval: 1s\n    mapping: |\n      root = {\"text\": fake(\"paragraph\")}\npipeline:\n  processors:\n  - cohere_embeddings:\n      model: embed-english-v3\n      api_key: \"${COHERE_API_KEY}\"\n      text_mapping: \"root = this.text\"\noutput:\n  qdrant:\n    grpc_host: localhost:6334\n    collection_name: \"example_collection\"\n    id: \"root = uuid_v4()\"\n    vector_mapping: \"root = this\"",
          "summary": "Compute embeddings for some generated data and store it within xrefs:component:outputs/qdrant.adoc[Qdrant]",
          "title": "Store embedding vectors in Qdrant"
        }
      ],
      "name": "cohere_embeddings",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates vector embeddings to represent input text, using the Cohere API.",
      "type": "processor",
      "version": "4.37.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.cohere.com",
            "description": "The base URL to use for API requests.",
            "kind": "scalar",
            "name": "base_url",
            "type": "string"
          },
          {
            "description": "The API key for the Cohere API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the Cohere model to use.",
            "examples": [
              "rerank-v3.5"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The search query",
            "interpolated": true,
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A list of texts that will be compared to the query. For optimal performance Cohere recommends against sending more than 1000 documents in a single request. NOTE: structured data should be formatted as YAML for best performance.",
            "kind": "scalar",
            "name": "documents",
            "type": "string"
          },
          {
            "default": "0",
            "description": "The number of documents to return, if 0 all documents are returned.",
            "interpolated": true,
            "kind": "scalar",
            "name": "top_n",
            "type": "string"
          },
          {
            "default": 4096,
            "description": "Long documents will be automatically truncated to the specified number of tokens.",
            "kind": "scalar",
            "name": "max_tokens_per_doc",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends document strings to the Cohere API, which reranks them based on the relevance to the query.\n\nTo learn more about reranking, see the https://docs.cohere.com/docs/rerank-2[Cohere API documentation^].\n\nThe output of this processor is an array of objects, each containing a \"document\" field with the original document content, a \"relevance_score\" field indicating how relevant it is to the query, and an index field that refers to the document's position within the input documents array. The objects are ordered by their relevance score (highest first).\n\n\t\t",
      "examples": [
        {
          "config": "input:\n  generate:\n    interval: 1s\n    mapping: |\n      root = {\n        \"query\": fake(\"sentence\"),\n        \"docs\": [fake(\"paragraph\"), fake(\"paragraph\"), fake(\"paragraph\")],\n      }\npipeline:\n  processors:\n  - cohere_rerank:\n      model: rerank-v3.5\n      api_key: \"${COHERE_API_KEY}\"\n      query: \"${!this.query}\"\n      documents: \"root = this.docs\"\noutput:\n  stdout: {}",
          "summary": "Rerank some documents based on a query",
          "title": "Rerank some documents based on a query"
        }
      ],
      "name": "cohere_rerank",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates vector embeddings to represent input text, using the Cohere API.",
      "type": "processor",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The name of the command to execute.",
            "examples": [
              "bash",
              "go",
              "${! @command }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "name",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that, when specified, should resolve into an array of arguments to pass to the command. Command arguments are expressed this way in order to support dynamic behavior.",
            "examples": [
              "[ \"-c\", this.script_path ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe specified command is executed for each message processed, with the raw bytes of the message being fed into the stdin of the command process, and the resulting message having its contents replaced with the stdout of it.\n\n== Performance\n\nSince this processor executes a new process for each message performance will likely be an issue for high throughput streams. If this is the case then consider using the xref:components:processors/subprocess.adoc[`subprocess` processor] instead as it keeps the underlying process alive long term and uses codecs to insert and extract inputs and outputs to it via stdin/stdout.\n\n== Error handling\n\nIf a non-zero error code is returned by the command then an error containing the entirety of stderr (or a generic message if nothing is written) is set on the message. These failed messages will continue through the pipeline unchanged, but can be dropped or placed in a dead letter queue according to your config, you can read about xref:configuration:error_handling.adoc[these patterns].\n\nIf the command is successful but stderr is written to then a metadata field `command_stderr` is populated with its contents.\n",
      "examples": [
        {
          "config": "\ninput:\n  generate:\n    interval: '0,30 */2 * * * *'\n    mapping: 'root = \"\"' # Empty string as we do not need to pipe anything to stdin\n  processors:\n    - command:\n        name: df\n        args_mapping: '[ \"-h\" ]'\n",
          "summary": "This example uses a xref:components:inputs/generate.adoc[`generate` input] to trigger a command on a cron schedule:",
          "title": "Cron Scheduled Command"
        },
        {
          "config": "\npipeline:\n  processors:\n    - command:\n        name: ${! this.command }\n        args_mapping: 'this.args'\n",
          "summary": "This example config takes structured messages of the form `{\"command\":\"echo\",\"args\":[\"foo\"]}` and uses their contents to execute the contained command and arguments dynamically, replacing its contents with the command result printed to stdout:",
          "title": "Dynamic Command Execution"
        }
      ],
      "name": "command",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a command for each message.",
      "type": "processor",
      "version": "4.21.0"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "description": "The compression algorithm to use.",
            "kind": "scalar",
            "name": "algorithm",
            "options": [
              "flate",
              "gzip",
              "lz4",
              "pgzip",
              "snappy",
              "zlib"
            ],
            "type": "string"
          },
          {
            "default": -1,
            "description": "The level of compression to use. May not be applicable to all algorithms.",
            "kind": "scalar",
            "name": "level",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "The 'level' field might not apply to all algorithms.",
      "name": "compress",
      "plugin": true,
      "status": "stable",
      "summary": "Compresses messages according to the selected algorithm. Supported compression algorithms are: [flate gzip lz4 pgzip snappy zlib]",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "Couchbase connection string.",
            "examples": [
              "couchbase://localhost:11210"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "Username to connect to the cluster.",
            "is_optional": true,
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "description": "Password to connect to the cluster.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Couchbase bucket.",
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "description": "Bucket collection.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "description": "Bucket scope.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "scope",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "json",
                "JSONTranscoder implements the default transcoding behavior and applies JSON transcoding to all values. This will apply the following behavior to the value: binary ([]byte) -> error. default -> JSON value, JSON Flags."
              ],
              [
                "legacy",
                "LegacyTranscoder implements the behavior for a backward-compatible transcoder. This transcoder implements behavior matching that of gocb v1.This will apply the following behavior to the value: binary ([]byte) -> binary bytes, Binary expectedFlags. string -> string bytes, String expectedFlags. default -> JSON value, JSON expectedFlags."
              ],
              [
                "raw",
                "RawBinaryTranscoder implements passthrough behavior of raw binary data. This transcoder does not apply any serialization. This will apply the following behavior to the value: binary ([]byte) -> binary bytes, binary expectedFlags. default -> error."
              ],
              [
                "rawjson",
                "RawJSONTranscoder implements passthrough behavior of JSON data. This transcoder does not apply any serialization. It will forward data across the network without incurring unnecessary parsing costs. This will apply the following behavior to the value: binary ([]byte) -> JSON bytes, JSON expectedFlags. string -> JSON bytes, JSON expectedFlags. default -> error."
              ],
              [
                "rawstring",
                "RawStringTranscoder implements passthrough behavior of raw string data. This transcoder does not apply any serialization. This will apply the following behavior to the value: string -> string bytes, string expectedFlags. default -> error."
              ]
            ],
            "default": "legacy",
            "description": "Couchbase transcoder to use.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"json\": true,\n  \"legacy\": true,\n  \"raw\": true,\n  \"rawjson\": true,\n  \"rawstring\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transcoder",
            "type": "string"
          },
          {
            "default": "15s",
            "description": "Operation timeout.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "description": "Document id.",
            "examples": [
              "${! json(\"id\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "id",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "Document content.",
            "is_optional": true,
            "kind": "scalar",
            "name": "content",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "get",
                "fetch a document."
              ],
              [
                "insert",
                "insert a new document."
              ],
              [
                "remove",
                "delete a document."
              ],
              [
                "replace",
                "replace the contents of a document."
              ],
              [
                "upsert",
                "creates a new document if it does not exist, if it does exist then it updates it."
              ]
            ],
            "default": "get",
            "description": "Couchbase operation to perform.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"get\": true,\n  \"insert\": true,\n  \"remove\": true,\n  \"replace\": true,\n  \"upsert\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "root = if ((this.operation == \"insert\" || this.operation == \"replace\" || this.operation == \"upsert\") && !this.exists(\"content\")) { [ \"content must be set for insert, replace and upsert operations.\" ] }",
        "name": "",
        "type": "object"
      },
      "description": "When inserting, replacing or upserting documents, each must have the `content` property set.",
      "name": "couchbase",
      "plugin": true,
      "status": "experimental",
      "summary": "Performs operations against Couchbase for each message, allowing you to store or retrieve data within message payloads.",
      "type": "processor",
      "version": "4.11.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "interpolated": true,
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "name": "crash",
      "plugin": true,
      "status": "beta",
      "summary": "Crashes the process using a fatal log message. The log message can be set using function interpolations described in  xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries] which allows you to log the contents and metadata of messages.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "description": "The decompression algorithm to use.",
            "kind": "scalar",
            "name": "algorithm",
            "options": [
              "bzip2",
              "flate",
              "gzip",
              "lz4",
              "pgzip",
              "snappy",
              "zlib"
            ],
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "decompress",
      "plugin": true,
      "status": "stable",
      "summary": "Decompresses messages according to the selected algorithm. Supported decompression algorithms are: [bzip2 flate gzip lz4 pgzip snappy zlib]",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The xref:components:caches/about.adoc[`cache` resource] to target with this processor.",
            "kind": "scalar",
            "name": "cache",
            "type": "string"
          },
          {
            "description": "An interpolated string yielding the key to deduplicate by for each message.",
            "examples": [
              "${! meta(\"kafka_key\") }",
              "${! content().hash(\"xxhash64\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether messages should be dropped when the cache returns a general error such as a network issue.",
            "kind": "scalar",
            "name": "drop_on_err",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nCaches must be configured as resources, for more information check out the xref:components:caches/about.adoc[cache documentation].\n\nWhen using this processor with an output target that might fail you should always wrap the output within an indefinite xref:components:outputs/retry.adoc[`retry`] block. This ensures that during outages your messages aren't reprocessed after failures, which would result in messages being dropped.\n\n== Batch deduplication\n\nThis processor enacts on individual messages only, in order to perform a deduplication on behalf of a batch (or window) of messages instead use the xref:components:processors/cache.adoc#examples[`cache` processor].\n\n== Delivery guarantees\n\nPerforming deduplication on a stream using a distributed cache voids any at-least-once guarantees that it previously had. This is because the cache will preserve message signatures even if the message fails to leave the Redpanda Connect pipeline, which would cause message loss in the event of an outage at the output sink followed by a restart of the Redpanda Connect instance (or a server crash, etc).\n\nThis problem can be mitigated by using an in-memory cache and distributing messages to horizontally scaled Redpanda Connect pipelines partitioned by the deduplication key. However, in situations where at-least-once delivery guarantees are important it is worth avoiding deduplication in favour of implement idempotent behavior at the edge of your stream pipelines.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - dedupe:\n        cache: keycache\n        key: ${! meta(\"kafka_key\") }\n\ncache_resources:\n  - label: keycache\n    memory:\n      default_ttl: 60s\n",
          "summary": "The following configuration demonstrates a pipeline that deduplicates messages based on the Kafka key.",
          "title": "Deduplicate based on Kafka key"
        }
      ],
      "name": "dedupe",
      "plugin": true,
      "status": "stable",
      "summary": "Deduplicates messages by storing a key value in a cache using the `add` operator. If the key already exists within the cache it is dropped.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "default": [],
        "kind": "array",
        "name": "",
        "type": "processor"
      },
      "description": "\nThis is useful for forcing batch wide processors such as xref:components:processors/dedupe.adoc[`dedupe`] or interpolations such as the `value` field of the `metadata` processor to execute on individual message parts of a batch instead.\n\nPlease note that most processors already process per message of a batch, and this processor is not needed in those cases.",
      "name": "for_each",
      "plugin": true,
      "status": "stable",
      "summary": "A processor that applies a list of child processors to messages of a batch as though they were each a batch of one message.",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "GCP project where the query job will execute.",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "default": "",
            "description": "An optional field to set Google Service Account Credentials json.",
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "Fully-qualified BigQuery table name to query.",
            "examples": [
              "bigquery-public-data.samples.shakespeare"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "A list of columns to query.",
            "kind": "array",
            "name": "columns",
            "type": "string"
          },
          {
            "description": "An optional where clause to add. Placeholder arguments are populated with the `args_mapping` field. Placeholders should always be question marks (`?`).",
            "examples": [
              "type = ? and created_at > ?",
              "user_id = ?"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "where",
            "type": "string"
          },
          {
            "default": {},
            "description": "A list of labels to add to the query job.",
            "kind": "map",
            "name": "job_labels",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `where`.",
            "examples": [
              "root = [ \"article\", now().ts_format(\"2006-01-02\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "An optional prefix to prepend to the select query (before SELECT).",
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to the select query.",
            "is_optional": true,
            "kind": "scalar",
            "name": "suffix",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - gcp_bigquery_select:\n              project: test-project\n              table: bigquery-public-data.samples.shakespeare\n              columns:\n                - word\n                - sum(word_count) as total_count\n              where: word = ?\n              suffix: |\n                GROUP BY word\n                ORDER BY total_count DESC\n                LIMIT 10\n              args_mapping: root = [ this.term ]\n        result_map: |\n          root.count = this.get(\"0.total_count\")\n",
          "summary": "\nGiven a stream of English terms, enrich the messages with the word count from Shakespeare's public works:",
          "title": "Word count"
        }
      ],
      "name": "gcp_bigquery_select",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a `SELECT` query against BigQuery and replaces messages with the rows returned.",
      "type": "processor",
      "version": "3.64.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "GCP project ID to use",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "description": "An optional field to set google Service Account Credentials json.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The location of the model if using a fined tune model. For base models this can be omitted",
            "examples": [
              "us-central1"
            ],
            "kind": "scalar",
            "name": "location",
            "type": "string"
          },
          {
            "description": "The name of the LLM to use. For a full list of models, see the https://console.cloud.google.com/vertex-ai/model-garden[Vertex AI Model Garden].",
            "examples": [
              "gemini-1.5-pro-001",
              "gemini-1.5-flash-001"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The system prompt to submit to the Vertex AI LLM.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "system_prompt",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "Historical messages to include in the chat request. The result of the bloblang query should be an array of objects of the form of [{\"role\": \"\", \"content\":\"\"}], where role is \"user\" or \"model\".",
            "is_optional": true,
            "kind": "scalar",
            "name": "history",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "Additional data like an image to send with the prompt to the model. The result of the mapping must be a byte array, and the content type is automatically detected.",
            "examples": [
              "root = this.image.decode(\"base64\") # decode base64 encoded image"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "attachment",
            "type": "string",
            "version": "4.38.0"
          },
          {
            "description": "Controls the randomness of predications.",
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < 0 || this > 2 { [\"field must be between 0.0-2.0\"] }",
            "name": "temperature",
            "type": "float"
          },
          {
            "description": "The maximum number of output tokens to generate per message.",
            "is_optional": true,
            "kind": "scalar",
            "name": "max_tokens",
            "type": "int"
          },
          {
            "default": "text",
            "description": "The response format of generated type, the model must also be prompted to output the appropriate response type.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"text\": true,\n  \"json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "response_format",
            "options": [
              "text",
              "json"
            ],
            "type": "string"
          },
          {
            "description": "If specified, nucleus sampling will be used.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < 0 || this > 1 { [\"field must be between 0.0-1.0\"] }",
            "name": "top_p",
            "type": "float"
          },
          {
            "description": "If specified top-k sampling will be used.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < 1 || this > 40 { [\"field must be between 1-40\"] }",
            "name": "top_k",
            "type": "float"
          },
          {
            "description": "Stop sequences to when the model will stop generating further tokens.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "stop",
            "type": "string"
          },
          {
            "description": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < -2 || this > 2 { [\"field must be greater than -2.0 and less than 2.0\"] }",
            "name": "presence_penalty",
            "type": "float"
          },
          {
            "description": "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this < -2 || this > 2 { [\"field must be greater than -2.0 and less than 2.0\"] }",
            "name": "frequency_penalty",
            "type": "float"
          },
          {
            "default": 10,
            "description": "The maximum number of sequential tool calls.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this <= 0 { [\"field must be greater than zero\"] }",
            "name": "max_tool_calls",
            "type": "int"
          },
          {
            "children": [
              {
                "description": "The name of this tool.",
                "kind": "scalar",
                "name": "name",
                "type": "string"
              },
              {
                "description": "A description of this tool, the LLM uses this to decide if the tool should be used.",
                "kind": "scalar",
                "name": "description",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "The required parameters for this pipeline.",
                    "kind": "array",
                    "name": "required",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "The type of this parameter.",
                        "kind": "scalar",
                        "name": "type",
                        "type": "string"
                      },
                      {
                        "description": "A description of this parameter.",
                        "kind": "scalar",
                        "name": "description",
                        "type": "string"
                      },
                      {
                        "default": [],
                        "description": "Specifies that this parameter is an enum and only these specific values should be used.",
                        "kind": "array",
                        "name": "enum",
                        "type": "string"
                      }
                    ],
                    "description": "The properties for the processor's input data",
                    "kind": "map",
                    "name": "properties",
                    "type": "object"
                  }
                ],
                "description": "The parameters the LLM needs to provide to invoke this tool.",
                "kind": "scalar",
                "name": "parameters",
                "type": "object"
              },
              {
                "description": "The pipeline to execute when the LLM uses this tool.",
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "default": [],
            "description": "The tools to allow the LLM to invoke. This allows building subpipelines that the LLM can choose to invoke to execute agentic-like actions.",
            "kind": "array",
            "name": "tools",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor sends prompts to your chosen large language model (LLM) and generates text from the responses, using the Vertex AI API.\n\nFor more information, see the https://cloud.google.com/vertex-ai/docs[Vertex AI documentation^].",
      "examples": [
        {
          "config": "\ninput:\n  generate:\n    count: 1\n    mapping: |\n      root = \"What is the weather like in Chicago?\"\npipeline:\n  processors:\n    - gcp_vertex_ai_chat:\n        model: gemini-2.5-flash-preview-05-20\n        project: my-project\n        location: us-central1\n        prompt: \"${!content().string()}\"\n        tools:\n          - name: GetWeather\n            description: \"Retrieve the weather for a specific city\"\n            parameters:\n              required: [\"city\"]\n              properties:\n                city:\n                  type: string\n                  description: the city to lookup the weather for\n            processors:\n              - http:\n                  verb: GET\n                  url: 'https://wttr.in/${!this.city}?T'\n                  headers:\n                    # Spoof curl user-agent to get a plaintext text\n                    User-Agent: curl/8.11.1\noutput:\n  stdout: {}\n",
          "summary": "This example allows gemini to execute a subpipeline as a tool call to get more data.",
          "title": "Use processors as tool calls"
        }
      ],
      "name": "gcp_vertex_ai_chat",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates responses to messages in a chat conversation, using the Vertex AI API.",
      "type": "processor",
      "version": "4.34.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "GCP project ID to use",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "description": "An optional field to set google Service Account Credentials json.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "us-central1",
            "description": "The location of the model.",
            "kind": "scalar",
            "name": "location",
            "type": "string"
          },
          {
            "description": "The name of the LLM to use. For a full list of models, see the https://console.cloud.google.com/vertex-ai/model-garden[Vertex AI Model Garden].",
            "examples": [
              "text-embedding-004",
              "text-multilingual-embedding-002"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "CLASSIFICATION",
                "optimize for being able classify texts according to preset labels"
              ],
              [
                "CLUSTERING",
                "optimize for clustering texts based on their similarities"
              ],
              [
                "FACT_VERIFICATION",
                "optimize for queries that are proving or disproving a fact such as \"apples grow underground\""
              ],
              [
                "QUESTION_ANSWERING",
                "optimize for search proper questions such as \"Why is the sky blue?\""
              ],
              [
                "RETRIEVAL_DOCUMENT",
                "optimize for documents that will be searched (also known as a corpus)"
              ],
              [
                "RETRIEVAL_QUERY",
                "optimize for queries such as \"What is the best fish recipe?\" or \"best restaurant in Chicago\""
              ],
              [
                "SEMANTIC_SIMILARITY",
                "optimize for text similarity"
              ]
            ],
            "default": "RETRIEVAL_DOCUMENT",
            "description": "The way to optimize embeddings that the model generates for specific use cases.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"classification\": true,\n  \"clustering\": true,\n  \"fact_verification\": true,\n  \"question_answering\": true,\n  \"retrieval_document\": true,\n  \"retrieval_query\": true,\n  \"semantic_similarity\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "task_type",
            "type": "string"
          },
          {
            "description": "The text you want to compute vector embeddings for. By default, the processor submits the entire payload as a string.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "text",
            "type": "string"
          },
          {
            "description": "The maximum length for the output embedding size. If set, the output embeddings will be truncated to this size.",
            "is_optional": true,
            "kind": "scalar",
            "name": "output_dimensions",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor sends text strings to the Vertex AI API, which generates vector embeddings. By default, the processor submits the entire payload of each message as a string, unless you use the `text` configuration field to customize it.\n\nFor more information, see the https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings[Vertex AI documentation^].",
      "name": "gcp_vertex_ai_embeddings",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates vector embeddings to represent input text, using the Vertex AI API.",
      "type": "processor",
      "version": "4.37.0"
    },
    {
      "categories": [
        "Unstructured"
      ],
      "config": {
        "children": [
          {
            "description": "A service account credentials JSON file. If left unset then the application default credentials are used.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The file ID of the file to download.",
            "interpolated": true,
            "kind": "scalar",
            "name": "file_id",
            "type": "string"
          },
          {
            "description": "The mime type of the file in drive.",
            "interpolated": true,
            "kind": "scalar",
            "name": "mime_type",
            "type": "string"
          },
          {
            "default": {
              "application/vnd.google-apps.document": "text/markdown",
              "application/vnd.google-apps.drawing": "image/png",
              "application/vnd.google-apps.presentation": "application/pdf",
              "application/vnd.google-apps.script": "application/vnd.google-apps.script+json",
              "application/vnd.google-apps.spreadsheet": "text/csv"
            },
            "description": "A map of Google Drive MIME types to their export formats. The key is the MIME type, and the value is the export format. See https://developers.google.com/workspace/drive/api/guides/ref-export-formats[^Google Drive API Documentation] for a list of supported export types",
            "examples": [
              {
                "application/vnd.google-apps.document": "application/pdf",
                "application/vnd.google-apps.drawing": "application/pdf",
                "application/vnd.google-apps.presentation": "application/pdf",
                "application/vnd.google-apps.spreadsheet": "application/pdf"
              },
              {
                "application/vnd.google-apps.document": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                "application/vnd.google-apps.drawing": "image/svg+xml",
                "application/vnd.google-apps.presentation": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
                "application/vnd.google-apps.spreadsheet": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
              }
            ],
            "is_advanced": true,
            "kind": "map",
            "name": "export_mime_types",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nCan download a file from Google Drive based on a file ID.\n== Authentication\nBy default, this connector will use Google Application Default Credentials (ADC) to authenticate with Google APIs.\n\nTo use this mechanism locally, the following gcloud commands can be used:\n\n\t# Login for the application default credentials and add scopes for readonly drive access\n\tgcloud auth application-default login --scopes='openid,https://www.googleapis.com/auth/userinfo.email,https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/drive.readonly'\n\t# When logging in with a user account, you may need to set the quota project for the application default credentials\n\tgcloud auth application-default set-quota-project <project-id>\n\nOtherwise if using a service account, you can create a JSON key for the service account and set it in the `credentials_json` field.\nIn order for a service account to access files in Google Drive either files need to be explicitly shared with the service account email, otherwise https://support.google.com/a/answer/162106[^domain wide delegation] can be used to share all files within a Google Workspace.\n",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - google_drive_search:\n        query: \"name = 'Test Doc'\"\n    - google_drive_download:\n        file_id: \"${!this.id}\"\n        mime_type: \"${!this.mimeType}\"\n",
          "summary": "This examples downloads all the files from Google Drive",
          "title": "Download files from Google Drive"
        }
      ],
      "name": "google_drive_download",
      "plugin": true,
      "status": "experimental",
      "summary": "Downloads files from Google Drive",
      "type": "processor"
    },
    {
      "categories": [
        "Unstructured"
      ],
      "config": {
        "children": [
          {
            "description": "A service account credentials JSON file. If left unset then the application default credentials are used.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nCan list all labels from Google Drive.\n\t\t== Authentication\nBy default, this connector will use Google Application Default Credentials (ADC) to authenticate with Google APIs.\n\nTo use this mechanism locally, the following gcloud commands can be used:\n\n\t# Login for the application default credentials and add scopes for readonly drive access\n\tgcloud auth application-default login --scopes='openid,https://www.googleapis.com/auth/userinfo.email,https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/drive.labels.readonly'\n\t# When logging in with a user account, you may need to set the quota project for the application default credentials\n\tgcloud auth application-default set-quota-project <project-id>\n\nOtherwise if using a service account, you can create a JSON key for the service account and set it in the `credentials_json` field.\nIn order for a service account to access files in Google Drive either files need to be explicitly shared with the service account email, otherwise https://support.google.com/a/answer/162106[^domain wide delegation] can be used to share all files within a Google Workspace.\n",
      "name": "google_drive_list_labels",
      "plugin": true,
      "status": "experimental",
      "summary": "Lists labels for a file in Google Drive",
      "type": "processor"
    },
    {
      "categories": [
        "Unstructured"
      ],
      "config": {
        "children": [
          {
            "description": "A service account credentials JSON file. If left unset then the application default credentials are used.",
            "is_optional": true,
            "is_secret": true,
            "kind": "scalar",
            "name": "credentials_json",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The search query to use for finding files in Google Drive. Supports the same query format as the Google Drive UI.",
            "interpolated": true,
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": [
              "id",
              "name",
              "mimeType",
              "size",
              "labelInfo"
            ],
            "description": "The partial fields to include in the result.",
            "kind": "array",
            "name": "projection",
            "type": "string"
          },
          {
            "default": "",
            "description": "A comma delimited list of label IDs to include in the result",
            "interpolated": true,
            "kind": "scalar",
            "name": "include_label_ids",
            "type": "string"
          },
          {
            "default": 64,
            "description": "The maximum number of results to return.",
            "kind": "scalar",
            "name": "max_results",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor searches for files in Google Drive using the provided query.\n\nSearch results are emitted as message batch, where each message is a https://developers.google.com/workspace/drive/api/reference/rest/v3/files#File[^Google Drive File]\n\n== Authentication\nBy default, this connector will use Google Application Default Credentials (ADC) to authenticate with Google APIs.\n\nTo use this mechanism locally, the following gcloud commands can be used:\n\n\t# Login for the application default credentials and add scopes for readonly drive access\n\tgcloud auth application-default login --scopes='openid,https://www.googleapis.com/auth/userinfo.email,https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/drive.readonly'\n\t# When logging in with a user account, you may need to set the quota project for the application default credentials\n\tgcloud auth application-default set-quota-project <project-id>\n\nOtherwise if using a service account, you can create a JSON key for the service account and set it in the `credentials_json` field.\nIn order for a service account to access files in Google Drive either files need to be explicitly shared with the service account email, otherwise https://support.google.com/a/answer/162106[^domain wide delegation] can be used to share all files within a Google Workspace.\n",
      "examples": [
        {
          "config": "\ninput:\n  stdin: {}\npipeline:\n  processors:\n    - google_drive_search:\n        query: \"${!content().string()}\"\n    - mutation: 'meta path = this.name'\n    - google_drive_download:\n        file_id: \"${!this.id}\"\n        mime_type: \"${!this.mimeType}\"\noutput:\n  file:\n    path: \"${!@path}\"\n    codec: all-bytes\n",
          "summary": "This examples downloads all the files from Google Drive that are returned in the query",
          "title": "Search & download files from Google Drive"
        }
      ],
      "name": "google_drive_search",
      "plugin": true,
      "status": "experimental",
      "summary": "Searches Google Drive for files matching the provided query.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "description": "One or more Grok expressions to attempt against incoming messages. The first expression to match at least one value will be used to form a result.",
            "kind": "array",
            "name": "expressions",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of pattern definitions that can be referenced within `patterns`.",
            "kind": "map",
            "name": "pattern_definitions",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of paths to load Grok patterns from. This field supports wildcards, including super globs (double star).",
            "kind": "array",
            "name": "pattern_paths",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether to only capture values from named patterns.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "named_captures_only",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether to use a <<default-patterns, default set of patterns>>.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "use_default_patterns",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Whether to remove values that are empty from the resulting structure.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "remove_empty_values",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nType hints within patterns are respected, therefore with the pattern `%\\{WORD:first},%{INT:second:int}` and a payload of `foo,1` the resulting payload would be `\\{\"first\":\"foo\",\"second\":1}`.\n\n== Performance\n\nThis processor currently uses the https://golang.org/s/re2syntax[Go RE2^] regular expression engine, which is guaranteed to run in time linear to the size of the input. However, this property often makes it less performant than PCRE based implementations of grok. For more information, see https://swtch.com/~rsc/regexp/regexp1.html.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - grok:\n        expressions:\n          - '%{VPCFLOWLOG}'\n        pattern_definitions:\n          VPCFLOWLOG: '%{NUMBER:version:int} %{NUMBER:accountid} %{NOTSPACE:interfaceid} %{NOTSPACE:srcaddr} %{NOTSPACE:dstaddr} %{NOTSPACE:srcport:int} %{NOTSPACE:dstport:int} %{NOTSPACE:protocol:int} %{NOTSPACE:packets:int} %{NOTSPACE:bytes:int} %{NUMBER:start:int} %{NUMBER:end:int} %{NOTSPACE:action} %{NOTSPACE:logstatus}'\n",
          "summary": "\nGrok can be used to parse unstructured logs such as VPC flow logs that look like this:\n\n```text\n2 123456789010 eni-1235b8ca123456789 172.31.16.139 172.31.16.21 20641 22 6 20 4249 1418530010 1418530070 ACCEPT OK\n```\n\nInto structured objects that look like this:\n\n```json\n{\"accountid\":\"123456789010\",\"action\":\"ACCEPT\",\"bytes\":4249,\"dstaddr\":\"172.31.16.21\",\"dstport\":22,\"end\":1418530070,\"interfaceid\":\"eni-1235b8ca123456789\",\"logstatus\":\"OK\",\"packets\":20,\"protocol\":6,\"srcaddr\":\"172.31.16.139\",\"srcport\":20641,\"start\":1418530010,\"version\":2}\n```\n\nWith the following config:",
          "title": "VPC Flow Logs"
        }
      ],
      "footnotes": "\n== Default patterns\n\nFor summary of the default patterns on offer, see https://github.com/Jeffail/grok/blob/master/patterns.go#L5.",
      "name": "grok",
      "plugin": true,
      "status": "stable",
      "summary": "Parses messages into a structured format by attempting to apply a list of Grok expressions, the first expression to result in at least one value replaces the original message with a JSON object containing the values.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message belongs to a given group.",
            "examples": [
              "this.type == \"foo\"",
              "this.contents.urls.contains(\"https://benthos.dev/\")",
              "true"
            ],
            "kind": "scalar",
            "name": "check",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of xref:components:processors/about.adoc[processors] to execute on the newly formed group.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          }
        ],
        "kind": "array",
        "name": "",
        "type": "object"
      },
      "description": "\nOnce the groups are established a list of processors are applied to their respective grouped batch, which can be used to label the batch as per their grouping. Messages that do not pass the check of any specified group are placed in their own group.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - group_by:\n      - check: content().contains(\"this is a foo\")\n        processors:\n          - archive:\n              format: tar\n          - compress:\n              algorithm: gzip\n          - mapping: 'meta grouping = \"foo\"'\n\noutput:\n  switch:\n    cases:\n      - check: meta(\"grouping\") == \"foo\"\n        output:\n          gcp_pubsub:\n            project: foo_prod\n            topic: only_the_foos\n      - output:\n          gcp_pubsub:\n            project: somewhere_else\n            topic: no_foos_here\n",
          "summary": "Imagine we have a batch of messages that we wish to split into a group of foos and everything else, which should be sent to different output destinations based on those groupings. We also need to send the foos as a tar gzip archive. For this purpose we can use the `group_by` processor with a xref:components:outputs/switch.adoc[`switch`] output:",
          "title": "Grouped Processing"
        }
      ],
      "name": "group_by",
      "plugin": true,
      "status": "stable",
      "summary": "Splits a xref:configuration:batching.adoc[batch of messages] into N batches, where each resulting batch contains a group of messages determined by a xref:guides:bloblang/about.adoc[Bloblang query].",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "description": "The interpolated string to group based on.",
            "examples": [
              "${! meta(\"kafka_key\") }",
              "${! json(\"foo.bar\") }-${! meta(\"baz\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "value",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis allows you to group messages using arbitrary fields within their content or metadata, process them individually, and send them to unique locations as per their group.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "footnotes": "\n== Examples\n\nIf we were consuming Kafka messages and needed to group them by their key, archive the groups, and send them to S3 with the key as part of the path we could achieve that with the following:\n\n```yaml\npipeline:\n  processors:\n    - group_by_value:\n        value: ${! meta(\"kafka_key\") }\n    - archive:\n        format: tar\n    - compress:\n        algorithm: gzip\noutput:\n  aws_s3:\n    bucket: TODO\n    path: docs/${! meta(\"kafka_key\") }/${! count(\"files\") }-${! timestamp_unix_nano() }.tar.gz\n```",
      "name": "group_by_value",
      "plugin": true,
      "status": "stable",
      "summary": "Splits a batch of messages into N batches, where each resulting batch contains a group of messages determined by a xref:configuration:interpolation.adoc#bloblang-queries[function interpolated string] evaluated per message.",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The URL to connect to.",
            "interpolated": true,
            "kind": "scalar",
            "name": "url",
            "type": "string"
          },
          {
            "default": "POST",
            "description": "A verb to connect with",
            "examples": [
              "POST",
              "GET",
              "DELETE"
            ],
            "kind": "scalar",
            "name": "verb",
            "type": "string"
          },
          {
            "default": {},
            "description": "A map of headers to add to the request.",
            "examples": [
              {
                "Content-Type": "application/octet-stream",
                "traceparent": "${! tracing_span().traceparent }"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "headers",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Specify optional matching rules to determine which metadata keys should be added to the HTTP request as headers.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "",
            "description": "EXPERIMENTAL: Optionally set a level at which the request and response payload of each request made will be logged.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"trace\": true,\n  \"debug\": true,\n  \"info\": true,\n  \"warn\": true,\n  \"error\": true,\n  \"fatal\": true,\n  \"\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "dump_request_log_level",
            "options": [
              "TRACE",
              "DEBUG",
              "INFO",
              "WARN",
              "ERROR",
              "FATAL",
              ""
            ],
            "type": "string",
            "version": "4.12.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 2 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the token provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "client_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the client key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "client_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "The URL of the token provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "token_url",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "default": [],
                "description": "A list of optional requested permissions.",
                "is_advanced": true,
                "kind": "array",
                "name": "scopes",
                "type": "string",
                "version": "3.45.0"
              },
              {
                "default": {},
                "description": "A list of optional endpoint parameters, values should be arrays of strings.",
                "examples": [
                  {
                    "bar": [
                      "woof"
                    ],
                    "foo": [
                      "meow",
                      "quack"
                    ]
                  }
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "map",
                "linter": "\nroot = if this.type() == \"object\" {\n  this.values().map_each(ele -> if ele.type() != \"array\" {\n    \"field must be an object containing arrays of strings, got %s (%v)\".format(ele.format_json(no_indent: true), ele.type())\n  } else {\n    ele.map_each(str -> if str.type() != \"string\" {\n      \"field values must be strings, got %s (%v)\".format(str.format_json(no_indent: true), str.type())\n    } else { deleted() })\n  }).\n    flatten()\n}\n",
                "name": "endpoint_params",
                "type": "unknown",
                "version": "4.21.0"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 2 using the client credentials token flow.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth2",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Specify which response headers should be added to resulting messages as metadata. Header keys are lowercased before matching, so ensure that your patterns target lowercased versions of the header keys that you expect.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "extract_headers",
            "type": "object"
          },
          {
            "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
            "is_optional": true,
            "kind": "scalar",
            "name": "rate_limit",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "A static timeout to apply to requests.",
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": "1s",
            "description": "The base period to wait between failed requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_period",
            "type": "string"
          },
          {
            "default": "300s",
            "description": "The maximum period to wait between failed requests.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_retry_backoff",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of retry attempts to make.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "int"
          },
          {
            "default": true,
            "description": "Whether or not to transparently follow redirects, i.e. responses with 300-399 status codes. If disabled, the response message will contain the body, status, and headers from the redirect response and the processor will not make a request to the URL set in the Location header of the response.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "follow_redirects",
            "type": "bool"
          },
          {
            "default": [
              429
            ],
            "description": "A list of status codes whereby the request should be considered to have failed and retries should be attempted, but the period between them should be increased gradually.",
            "is_advanced": true,
            "kind": "array",
            "name": "backoff_on",
            "type": "int"
          },
          {
            "default": [],
            "description": "A list of status codes whereby the request should be considered to have failed but retries should not be attempted. This is useful for preventing wasted retries for requests that will never succeed. Note that with these status codes the _request_ is dropped, but _message_ that caused the request will not be dropped.",
            "is_advanced": true,
            "kind": "array",
            "name": "drop_on",
            "type": "int"
          },
          {
            "default": [],
            "description": "A list of status codes whereby the attempt should be considered successful, this is useful for dropping requests that return non-2XX codes indicating that the message has been dealt with, such as a 303 See Other or a 409 Conflict. All 2XX codes are considered successful unless they are present within `backoff_on` or `drop_on`, regardless of this field.",
            "is_advanced": true,
            "kind": "array",
            "name": "successful_on",
            "type": "int"
          },
          {
            "description": "An optional HTTP proxy URL.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "proxy_url",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether or not to disable disable HTTP/2",
            "is_advanced": true,
            "kind": "scalar",
            "name": "disable_http2",
            "type": "bool",
            "version": "4.44.0"
          },
          {
            "default": false,
            "description": "Send message batches as a single request using https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^].",
            "is_advanced": true,
            "kind": "scalar",
            "name": "batch_as_multipart",
            "type": "bool"
          },
          {
            "default": false,
            "description": "When processing batched messages, whether to send messages of the batch in parallel, otherwise they are sent serially.",
            "kind": "scalar",
            "name": "parallel",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe `rate_limit` field can be used to specify a rate limit xref:components:rate_limits/about.adoc[resource] to cap the rate of requests across all parallel components service wide.\n\nThe URL and header values of this type can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\nIn order to map or encode the payload to a specific request body, and map the response back into the original payload instead of replacing it entirely, you can use the xref:components:processors/branch.adoc[`branch` processor].\n\n== Response codes\n\nRedpanda Connect considers any response code between 200 and 299 inclusive to indicate a successful response, you can add more success status codes with the field `successful_on`.\n\nWhen a request returns a response code within the `backoff_on` field it will be retried after increasing intervals.\n\nWhen a request returns a response code within the `drop_on` field it will not be reattempted and is immediately considered a failed request.\n\n== Add metadata\n\nIf the request returns an error response code this processor sets a metadata field `http_status_code` on the resulting message.\n\nUse the field `extract_headers` to specify rules for which other headers should be copied into the resulting message from the response.\n\n== Error handling\n\nWhen all retry attempts for a message are exhausted the processor cancels the attempt. These failed messages will continue through the pipeline unchanged, but can be dropped or placed in a dead letter queue according to your config, you can read about xref:configuration:error_handling.adoc[these patterns].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        request_map: 'root = \"\"'\n        processors:\n          - http:\n              url: https://hub.docker.com/v2/repositories/jeffail/benthos\n              verb: GET\n              headers:\n                Content-Type: application/json\n        result_map: 'root.repo.status = this'\n",
          "summary": "This example uses a xref:components:processors/branch.adoc[`branch` processor] to strip the request message into an empty body, grab an HTTP payload, and place the result back into the original message at the path `repo.status`:",
          "title": "Branched Request"
        }
      ],
      "name": "http",
      "plugin": true,
      "status": "stable",
      "summary": "Performs an HTTP request using a message batch as the request body, and replaces the original message parts with the body of the response.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "default": -1,
            "description": "The index within the batch to insert the message at.",
            "kind": "scalar",
            "name": "index",
            "type": "int"
          },
          {
            "default": "",
            "description": "The content of the message being inserted.",
            "interpolated": true,
            "kind": "scalar",
            "name": "content",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe index can be negative, and if so the message will be inserted from the end counting backwards starting from -1. E.g. if index = -1 then the new message will become the last of the batch, if index = -2 then the new message will be inserted before the last message, and so on. If the negative index is greater than the length of the existing batch it will be inserted at the beginning.\n\nThe new message will have metadata copied from the first pre-existing message of the batch.\n\nThis processor will interpolate functions within the 'content' field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].",
      "name": "insert_part",
      "plugin": true,
      "status": "stable",
      "summary": "Insert a new message into a batch at an index. If the specified index is greater than the length of the existing batch it will be appended to the end.",
      "type": "processor"
    },
    {
      "categories": [
        "Mapping"
      ],
      "config": {
        "children": [
          {
            "description": "An inline JavaScript program to run. One of `code` or `file` must be defined.",
            "is_optional": true,
            "kind": "scalar",
            "name": "code",
            "type": "string"
          },
          {
            "description": "A file containing a JavaScript program to run. One of `code` or `file` must be defined.",
            "is_optional": true,
            "kind": "scalar",
            "name": "file",
            "type": "string"
          },
          {
            "default": [],
            "description": "List of folders that will be used to load modules from if the requested JS module is not found elsewhere.",
            "kind": "array",
            "name": "global_folders",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "\nlet codeLen = (this.code | \"\").length()\nlet fileLen = (this.file | \"\").length()\nroot = if $codeLen == 0 && $fileLen == 0 {\n  \"either the code or file field must be specified\"\n} else if $codeLen > 0 && $fileLen > 0 {\n  \"cannot specify both the code and file fields\"\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nThe https://github.com/dop251/goja[execution engine^] behind this processor provides full ECMAScript 5.1 support (including regex and strict mode). Most of the ECMAScript 6 spec is implemented but this is a work in progress.\n\nImports via `require` should work similarly to NodeJS, and access to the console is supported which will print via the Redpanda Connect logger. More caveats can be found on https://github.com/dop251/goja#known-incompatibilities-and-caveats[GitHub^].\n\nThis processor is implemented using the https://github.com/dop251/goja[github.com/dop251/goja^] library.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - javascript:\n        code: 'benthos.v0_msg_set_string(benthos.v0_msg_as_string() + \"hello world\");'\n",
          "summary": "In this example we define a simple function that performs a basic mutation against messages, treating their contents as raw strings.",
          "title": "Simple mutation"
        },
        {
          "config": "\npipeline:\n  processors:\n    - javascript:\n        code: |\n          (() => {\n            let thing = benthos.v0_msg_as_structured();\n            thing.num_keys = Object.keys(thing).length;\n            delete thing[\"b\"];\n            benthos.v0_msg_set_structured(thing);\n          })();\n",
          "summary": "In this example we define a function that performs basic mutations against a structured message. Note that we encapsulate the logic within an anonymous function that is called for each invocation, this is required in order to avoid duplicate variable declarations in the global state.",
          "title": "Structured mutation"
        }
      ],
      "footnotes": "\n== Runtime\n\nIn order to optimize code execution JS runtimes are created on demand (in order to support parallel execution) and are reused across invocations. Therefore, it is important to understand that global state created by your programs will outlive individual invocations. In order for your programs to avoid failing after the first invocation ensure that you do not define variables at the global scope.\n\nAlthough technically possible, it is recommended that you do not rely on the global state for maintaining state across invocations as the pooling nature of the runtimes will prevent deterministic behavior. We aim to support deterministic strategies for mutating global state in the future.\n\n== Functions\n\n### `benthos.v0_fetch`\n\nExecutes an HTTP request synchronously and returns the result as an object of the form `{\"status\":200,\"body\":\"foo\"}`.\n\n#### Parameters\n\n**`url`** &lt;string&gt; The URL to fetch  \n**`headers`** &lt;object(string,string)&gt; An object of string/string key/value pairs to add the request as headers.  \n**`method`** &lt;string&gt; The method of the request.  \n**`body`** &lt;(optional) string&gt; A body to send.  \n\n#### Examples\n\n```javascript\nlet result = benthos.v0_fetch(\"http://example.com\", {}, \"GET\", \"\")\nbenthos.v0_msg_set_structured(result);\n```\n\n### `benthos.v0_msg_as_string`\n\nObtain the raw contents of the processed message as a string.\n\n#### Examples\n\n```javascript\nlet contents = benthos.v0_msg_as_string();\n```\n\n### `benthos.v0_msg_as_structured`\n\nObtain the root of the processed message as a structured value. If the message is not valid JSON or has not already been expanded into a structured form this function will throw an error.\n\n#### Examples\n\n```javascript\nlet foo = benthos.v0_msg_as_structured().foo;\n```\n\n### `benthos.v0_msg_exists_meta`\n\nCheck that a metadata key exists.\n\n#### Parameters\n\n**`name`** &lt;string&gt; The metadata key to search for.  \n\n#### Examples\n\n```javascript\nif (benthos.v0_msg_exists_meta(\"kafka_key\")) {}\n```\n\n### `benthos.v0_msg_get_meta`\n\nGet the value of a metadata key from the processed message.\n\n#### Parameters\n\n**`name`** &lt;string&gt; The metadata key to search for.  \n\n#### Examples\n\n```javascript\nlet key = benthos.v0_msg_get_meta(\"kafka_key\");\n```\n\n### `benthos.v0_msg_set_meta`\n\nSet a metadata key on the processed message to a value.\n\n#### Parameters\n\n**`name`** &lt;string&gt; The metadata key to set.  \n**`value`** &lt;anything&gt; The value to set it to.  \n\n#### Examples\n\n```javascript\nbenthos.v0_msg_set_meta(\"thing\", \"hello world\");\n```\n\n### `benthos.v0_msg_set_string`\n\nSet the contents of the processed message to a given string.\n\n#### Parameters\n\n**`value`** &lt;string&gt; The value to set it to.  \n\n#### Examples\n\n```javascript\nbenthos.v0_msg_set_string(\"hello world\");\n```\n\n### `benthos.v0_msg_set_structured`\n\nSet the root of the processed message to a given value of any type.\n\n#### Parameters\n\n**`value`** &lt;anything&gt; The value to set it to.  \n\n#### Examples\n\n```javascript\nbenthos.v0_msg_set_structured({\n  \"foo\": \"a thing\",\n  \"bar\": \"something else\",\n  \"baz\": 1234\n});\n```\n\n",
      "name": "javascript",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a provided JavaScript code block or file for each message.",
      "type": "processor",
      "version": "4.14.0"
    },
    {
      "categories": [
        "Mapping"
      ],
      "config": {
        "children": [
          {
            "description": "The JMESPath query to apply to messages.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n[TIP]\n.Try out Bloblang\n====\nFor better performance and improved capabilities try native Redpanda Connect mapping with the xref:components:processors/mapping.adoc[`mapping` processor].\n====\n",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - jmespath:\n        query: \"locations[?state == 'WA'].name | sort(@) | {Cities: join(', ', @)}\"\n",
          "summary": "\nWhen receiving JSON documents of the form:\n\n```json\n{\n  \"locations\": [\n    {\"name\": \"Seattle\", \"state\": \"WA\"},\n    {\"name\": \"New York\", \"state\": \"NY\"},\n    {\"name\": \"Bellevue\", \"state\": \"WA\"},\n    {\"name\": \"Olympia\", \"state\": \"WA\"}\n  ]\n}\n```\n\nWe could collapse the location names from the state of Washington into a field `Cities`:\n\n```json\n{\"Cities\": \"Bellevue, Olympia, Seattle\"}\n```\n\nWith the following config:",
          "title": "Mapping"
        }
      ],
      "name": "jmespath",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a http://jmespath.org/[JMESPath query] on JSON documents and replaces the message with the resulting document.",
      "type": "processor"
    },
    {
      "categories": [
        "Mapping"
      ],
      "config": {
        "children": [
          {
            "description": "The jq query to filter and transform messages with.",
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to process the input as a raw string instead of as JSON.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "raw",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to output raw text (unquoted) instead of JSON strings when the emitted values are string types.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "output_raw",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n[TIP]\n.Try out Bloblang\n====\nFor better performance and improved capabilities try out native Redpanda Connect mapping with the xref:components:processors/mapping.adoc[`mapping` processor].\n====\n\nThe provided query is executed on each message, targeting either the contents as a structured JSON value or as a raw string using the field `raw`, and the message is replaced with the query result.\n\nMessage metadata is also accessible within the query from the variable `$metadata`.\n\nThis processor uses the https://github.com/itchyny/gojq[gojq library^], and therefore does not require jq to be installed as a dependency. However, this also means there are some https://github.com/itchyny/gojq#difference-to-jq[differences in how these queries are executed^] versus the jq cli.\n\nIf the query does not emit any value then the message is filtered, if the query returns multiple values then the resulting message will be an array containing all values.\n\nThe full query syntax is described in https://stedolan.github.io/jq/manual/[jq's documentation^].\n\n== Error handling\n\nQueries can fail, in which case the message remains unchanged, errors are logged, and the message is flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - jq:\n        query: '{Cities: .locations | map(select(.state == \"WA\").name) | sort | join(\", \") }'\n",
          "summary": "\nWhen receiving JSON documents of the form:\n\n```json\n{\n  \"locations\": [\n    {\"name\": \"Seattle\", \"state\": \"WA\"},\n    {\"name\": \"New York\", \"state\": \"NY\"},\n    {\"name\": \"Bellevue\", \"state\": \"WA\"},\n    {\"name\": \"Olympia\", \"state\": \"WA\"}\n  ]\n}\n```\n\nWe could collapse the location names from the state of Washington into a field `Cities`:\n\n```json\n{\"Cities\": \"Bellevue, Olympia, Seattle\"}\n```\n\nWith the following config:",
          "title": "Mapping"
        }
      ],
      "name": "jq",
      "plugin": true,
      "status": "stable",
      "summary": "Transforms and filters messages using jq queries.",
      "type": "processor"
    },
    {
      "categories": [
        "Mapping"
      ],
      "config": {
        "children": [
          {
            "description": "A schema to apply. Use either this or the `schema_path` field.",
            "is_optional": true,
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          },
          {
            "description": "The path of a schema document to apply. Use either this or the `schema` field.",
            "is_optional": true,
            "kind": "scalar",
            "name": "schema_path",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Please refer to the https://json-schema.org/[JSON Schema website^] for information and tutorials regarding the syntax of the schema.",
      "footnotes": "\n== Examples\n\nWith the following JSONSchema document:\n\n```json\n{\n\t\"$id\": \"https://example.com/person.schema.json\",\n\t\"$schema\": \"http://json-schema.org/draft-07/schema#\",\n\t\"title\": \"Person\",\n\t\"type\": \"object\",\n\t\"properties\": {\n\t  \"firstName\": {\n\t\t\"type\": \"string\",\n\t\t\"description\": \"The person's first name.\"\n\t  },\n\t  \"lastName\": {\n\t\t\"type\": \"string\",\n\t\t\"description\": \"The person's last name.\"\n\t  },\n\t  \"age\": {\n\t\t\"description\": \"Age in years which must be equal to or greater than zero.\",\n\t\t\"type\": \"integer\",\n\t\t\"minimum\": 0\n\t  }\n\t}\n}\n```\n\nAnd the following Redpanda Connect configuration:\n\n```yaml\npipeline:\n  processors:\n  - json_schema:\n      schema_path: \"file://path_to_schema.json\"\n  - catch:\n    - log:\n        level: ERROR\n        message: \"Schema validation failed due to: ${!error()}\"\n    - mapping: 'root = deleted()' # Drop messages that fail\n```\n\nIf a payload being processed looked like:\n\n```json\n{\"firstName\":\"John\",\"lastName\":\"Doe\",\"age\":-21}\n```\n\nThen a log message would appear explaining the fault and the payload would be\ndropped.",
      "name": "json_schema",
      "plugin": true,
      "status": "stable",
      "summary": "Checks messages against a provided JSONSchema definition but does not change the payload under any circumstances. If a message does not match the schema it can be caught using xref:configuration:error_handling.adoc[error handling methods].",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": "INFO",
            "description": "The log level to use.",
            "kind": "scalar",
            "name": "level",
            "options": [
              "ERROR",
              "WARN",
              "INFO",
              "DEBUG",
              "TRACE"
            ],
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that can be used to specify extra fields to add to the log. If log fields are also added with the `fields` field then those values will override matching keys from this mapping.",
            "examples": [
              "root.reason = \"cus I wana\"\nroot.id = this.id\nroot.age = this.user.age.number()\nroot.kafka_topic = meta(\"kafka_topic\")"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "fields_mapping",
            "type": "string"
          },
          {
            "default": "",
            "description": "The message to print.",
            "interpolated": true,
            "kind": "scalar",
            "name": "message",
            "type": "string"
          },
          {
            "description": "A map of fields to print along with the log message.",
            "interpolated": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "map",
            "name": "fields",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe `level` field determines the log level of the printed events and can be any of the following values: TRACE, DEBUG, INFO, WARN, ERROR.\n\n== Structured fields\n\nIt's also possible add custom fields to logs when the format is set to a structured form such as `json` or `logfmt` with the config field <<fields_mapping, `fields_mapping`>>:\n\n```yaml\npipeline:\n  processors:\n    - log:\n        level: DEBUG\n        message: hello world\n        fields_mapping: |\n          root.reason = \"cus I wana\"\n          root.id = this.id\n          root.age = this.user.age\n          root.kafka_topic = meta(\"kafka_topic\")\n```\n",
      "name": "log",
      "plugin": true,
      "status": "stable",
      "summary": "Prints a log event for each message. Messages always remain unchanged. The log message can be set using function interpolations described in  xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries] which allows you to log the contents and metadata of messages.",
      "type": "processor"
    },
    {
      "categories": [
        "Mapping",
        "Parsing"
      ],
      "config": {
        "bloblang": true,
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nBloblang is a powerful language that enables a wide range of mapping, transformation and filtering tasks. For more information, see xref:guides:bloblang/about.adoc[].\n\nIf your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"<path>\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from.\n\nNote: This processor is equivalent to the xref:components:processors/bloblang.adoc#component-rename[Bloblang] one. The latter will be deprecated in a future release.\n\n== Input document immutability\n\nMapping operates by creating an entirely new object during assignments, this has the advantage of treating the original referenced document as immutable and therefore queryable at any stage of your mapping. For example, with the following mapping:\n\n```coffeescript\nroot.id = this.id\nroot.invitees = this.invitees.filter(i -> i.mood >= 0.5)\nroot.rejected = this.invitees.filter(i -> i.mood < 0.5)\n```\n\nNotice that we mutate the value of `invitees` in the resulting document by filtering out objects with a lower mood. However, even after doing so we're still able to reference the unchanged original contents of this value from the input document in order to populate a second field. Within this mapping we also have the flexibility to reference the mutable mapped document by using the keyword `root` (i.e. `root.invitees`) on the right-hand side instead.\n\nMapping documents is advantageous in situations where the result is a document with a dramatically different shape to the input document, since we are effectively rebuilding the document in its entirety and might as well keep a reference to the unchanged input document throughout. However, in situations where we are only performing minor alterations to the input document, the rest of which is unchanged, it might be more efficient to use the xref:components:processors/mutation.adoc[`mutation` processor] instead.\n\n== Error handling\n\nBloblang mappings can fail, in which case the message remains unchanged, errors are logged, and the message is flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, Bloblang itself also provides powerful ways of ensuring your mappings do not fail by specifying desired xref:guides:bloblang/about.adoc#error-handling[fallback behavior].\n\t\t\t",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - mapping: |\n        root.id = this.id\n        root.fans = this.fans.filter(fan -> fan.obsession > 0.5)\n",
          "summary": "\nGiven JSON documents containing an array of fans:\n\n```json\n{\n  \"id\":\"foo\",\n  \"description\":\"a show about foo\",\n  \"fans\":[\n    {\"name\":\"bev\",\"obsession\":0.57},\n    {\"name\":\"grace\",\"obsession\":0.21},\n    {\"name\":\"ali\",\"obsession\":0.89},\n    {\"name\":\"vic\",\"obsession\":0.43}\n  ]\n}\n```\n\nWe can reduce the documents down to just the ID and only those fans with an obsession score above 0.5, giving us:\n\n```json\n{\n  \"id\":\"foo\",\n  \"fans\":[\n    {\"name\":\"bev\",\"obsession\":0.57},\n    {\"name\":\"ali\",\"obsession\":0.89}\n  ]\n}\n```\n\nWith the following config:",
          "title": "Mapping"
        },
        {
          "config": "\npipeline:\n  processors:\n    - mapping: |\n        root.Cities = this.locations.\n                        filter(loc -> loc.state == \"WA\").\n                        map_each(loc -> loc.name).\n                        sort().join(\", \")\n",
          "summary": "\nWhen receiving JSON documents of the form:\n\n```json\n{\n  \"locations\": [\n    {\"name\": \"Seattle\", \"state\": \"WA\"},\n    {\"name\": \"New York\", \"state\": \"NY\"},\n    {\"name\": \"Bellevue\", \"state\": \"WA\"},\n    {\"name\": \"Olympia\", \"state\": \"WA\"}\n  ]\n}\n```\n\nWe could collapse the location names from the state of Washington into a field `Cities`:\n\n```json\n{\"Cities\": \"Bellevue, Olympia, Seattle\"}\n```\n\nWith the following config:",
          "title": "More Mapping"
        }
      ],
      "name": "mapping",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a xref:guides:bloblang/about.adoc[Bloblang] mapping on messages, creating a new document that replaces (or filters) the original message.",
      "type": "processor",
      "version": "4.5.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The metric <<types, type>> to create.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"counter\": true,\n  \"counter_by\": true,\n  \"gauge\": true,\n  \"timing\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "type",
            "options": [
              "counter",
              "counter_by",
              "gauge",
              "timing"
            ],
            "type": "string"
          },
          {
            "description": "The name of the metric to create, this must be unique across all Redpanda Connect components otherwise it will overwrite those other metrics.",
            "kind": "scalar",
            "name": "name",
            "type": "string"
          },
          {
            "description": "A map of label names and values that can be used to enrich metrics. Labels are not supported by some metric destinations, in which case the metrics series are combined.",
            "examples": [
              {
                "topic": "${! meta(\"kafka_topic\") }",
                "type": "${! json(\"doc.type\") }"
              }
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "map",
            "name": "labels",
            "type": "string"
          },
          {
            "default": "",
            "description": "For some metric types specifies a value to set, increment. Certain metrics exporters such as Prometheus support floating point values, but those that do not will cast a floating point value into an integer.",
            "interpolated": true,
            "kind": "scalar",
            "name": "value",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor works by evaluating an xref:configuration:interpolation.adoc#bloblang-queries[interpolated field `value`] for each message and updating a emitted metric according to the <<types, type>>.\n\nCustom metrics such as these are emitted along with Redpanda Connect internal metrics, where you can customize where metrics are sent, which metric names are emitted and rename them as/when appropriate. For more information see the xref:components:metrics/about.adoc[metrics docs].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - metric:\n        name: Foos\n        type: counter\n        labels:\n          topic: ${! meta(\"kafka_topic\") }\n          partition: ${! meta(\"kafka_partition\") }\n          type: ${! json(\"document.type\").or(\"unknown\") }\n\nmetrics:\n  mapping: |\n    root = if ![\n      \"Foos\",\n      \"input_received\",\n      \"output_sent\"\n    ].contains(this) { deleted() }\n  aws_cloudwatch:\n    namespace: ProdConsumer\n",
          "summary": "In this example we emit a counter metric called `Foos`, which increments for every message processed, and we label the metric with some metadata about where the message came from and a field from the document that states what type it is. We also configure our metrics to emit to CloudWatch, and explicitly only allow our custom metric and some internal Redpanda Connect metrics to emit.",
          "title": "Counter"
        },
        {
          "config": "\npipeline:\n  processors:\n    - metric:\n        name: FooSize\n        type: gauge\n        labels:\n          topic: ${! meta(\"kafka_topic\") }\n        value: ${! json(\"foo.size\") }\n\nmetrics:\n  mapping: 'if this != \"FooSize\" { deleted() }'\n  prometheus: {}\n",
          "summary": "In this example we emit a gauge metric called `FooSize`, which is given a value extracted from JSON messages at the path `foo.size`. We then also configure our Prometheus metric exporter to only emit this custom metric and nothing else. We also label the metric with some metadata.",
          "title": "Gauge"
        }
      ],
      "footnotes": "\n== Types\n\n=== `counter`\n\nIncrements a counter by exactly 1, the contents of `value` are ignored\nby this type.\n\n=== `counter_by`\n\nIf the contents of `value` can be parsed as a positive integer value\nthen the counter is incremented by this value.\n\nFor example, the following configuration will increment the value of the\n`count.custom.field` metric by the contents of `field.some.value`:\n\n```yaml\npipeline:\n  processors:\n    - metric:\n        type: counter_by\n        name: CountCustomField\n        value: ${!json(\"field.some.value\")}\n```\n\n=== `gauge`\n\nIf the contents of `value` can be parsed as a positive integer value\nthen the gauge is set to this value.\n\nFor example, the following configuration will set the value of the\n`gauge.custom.field` metric to the contents of `field.some.value`:\n\n```yaml\npipeline:\n  processors:\n    - metric:\n        type: gauge\n        name: GaugeCustomField\n        value: ${!json(\"field.some.value\")}\n```\n\n=== `timing`\n\nEquivalent to `gauge` where instead the metric is a timing. It is recommended that timing values are recorded in nanoseconds in order to be consistent with standard Redpanda Connect timing metrics, as in some cases these values are automatically converted into other units such as when exporting timings as histograms with Prometheus metrics.",
      "name": "metric",
      "plugin": true,
      "status": "stable",
      "summary": "Emit custom metrics by extracting values from messages.",
      "type": "processor"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target MongoDB server.",
            "examples": [
              "mongodb://localhost:27017"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target MongoDB database.",
            "kind": "scalar",
            "name": "database",
            "type": "string"
          },
          {
            "default": "",
            "description": "The username to connect to the database.",
            "kind": "scalar",
            "name": "username",
            "type": "string"
          },
          {
            "default": "",
            "description": "The password to connect to the database.",
            "is_secret": true,
            "kind": "scalar",
            "name": "password",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "default": "benthos",
            "description": "The client application name.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "app_name",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The name of the target collection.",
            "kind": "scalar",
            "name": "collection",
            "type": "string"
          },
          {
            "default": "insert-one",
            "description": "The mongodb operation to perform.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"insert-one\": true,\n  \"delete-one\": true,\n  \"delete-many\": true,\n  \"replace-one\": true,\n  \"update-one\": true,\n  \"find-one\": true,\n  \"aggregate\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "options": [
              "insert-one",
              "delete-one",
              "delete-many",
              "replace-one",
              "update-one",
              "find-one",
              "aggregate"
            ],
            "type": "string"
          },
          {
            "children": [
              {
                "default": "majority",
                "description": "W requests acknowledgement that write operations propagate to the specified number of mongodb instances. Can be the string \"majority\" to wait for a calculated majority of nodes to acknowledge the write operation, or an integer value specifying an minimum number of nodes to acknowledge the operation, or a string specifying the name of a custom write concern configured in the cluster.",
                "kind": "scalar",
                "name": "w",
                "type": "string"
              },
              {
                "default": false,
                "description": "J requests acknowledgement from MongoDB that write operations are written to the journal.",
                "kind": "scalar",
                "name": "j",
                "type": "bool"
              },
              {
                "default": "",
                "description": "The write concern timeout.",
                "kind": "scalar",
                "name": "w_timeout",
                "type": "string"
              }
            ],
            "description": "The write concern settings for the mongo connection.",
            "kind": "scalar",
            "name": "write_concern",
            "type": "object"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A bloblang map representing a document to store within MongoDB, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The document map is required for the operations insert-one, replace-one, update-one and aggregate.",
            "examples": [
              "root.a = this.foo\nroot.b = this.bar"
            ],
            "kind": "scalar",
            "name": "document_map",
            "type": "string"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A bloblang map representing a filter for a MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The filter map is required for all operations except insert-one. It is used to find the document(s) for the operation. For example in a delete-one case, the filter map should have the fields required to locate the document to delete.",
            "examples": [
              "root.a = this.foo\nroot.b = this.bar"
            ],
            "kind": "scalar",
            "name": "filter_map",
            "type": "string"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A bloblang map representing the hint for the MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. This map is optional and is used with all operations except insert-one. It is used to improve performance of finding the documents in the mongodb.",
            "examples": [
              "root.a = this.foo\nroot.b = this.bar"
            ],
            "kind": "scalar",
            "name": "hint_map",
            "type": "string"
          },
          {
            "default": false,
            "description": "The upsert setting is optional and only applies for update-one and replace-one operations. If the filter specified in filter_map matches, the document is updated or replaced accordingly, otherwise it is created.",
            "kind": "scalar",
            "name": "upsert",
            "type": "bool",
            "version": "3.60.0"
          },
          {
            "annotated_options": [
              [
                "canonical",
                "A string format that emphasizes type preservation at the expense of readability and interoperability. That is, conversion from canonical to BSON will generally preserve type information except in certain specific cases. "
              ],
              [
                "relaxed",
                "A string format that emphasizes readability and interoperability at the expense of type preservation. That is, conversion from relaxed format to BSON can lose type information."
              ]
            ],
            "default": "canonical",
            "description": "The json_marshal_mode setting is optional and controls the format of the output message.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"canonical\": true,\n  \"relaxed\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "json_marshal_mode",
            "type": "string",
            "version": "3.60.0"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          },
          {
            "children": [
              {
                "default": "1s",
                "description": "The initial period to wait between retry attempts.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "5s",
                "description": "The maximum period to wait between retry attempts.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "30s",
                "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
                "is_advanced": true,
                "is_deprecated": true,
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Control time intervals between retry attempts.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "mongodb",
      "plugin": true,
      "status": "experimental",
      "summary": "Performs operations against MongoDB for each message, allowing you to store or retrieve data within message payloads.",
      "type": "processor",
      "version": "3.43.0"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "from_json",
                "Convert JSON messages to MessagePack format"
              ],
              [
                "to_json",
                "Convert MessagePack messages to JSON format"
              ]
            ],
            "description": "The operation to perform on messages.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"from_json\": true,\n  \"to_json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "msgpack",
      "plugin": true,
      "status": "beta",
      "summary": "Converts messages to or from the https://msgpack.org/[MessagePack^] format.",
      "type": "processor",
      "version": "3.59.0"
    },
    {
      "categories": [
        "Mapping",
        "Parsing"
      ],
      "config": {
        "bloblang": true,
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nBloblang is a powerful language that enables a wide range of mapping, transformation and filtering tasks. For more information, see xref:guides:bloblang/about.adoc[].\n\nIf your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"<path>\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from.\n\n== Input document mutability\n\nA mutation is a mapping that transforms input documents directly, this has the advantage of reducing the need to copy the data fed into the mapping. However, this also means that the referenced document is mutable and therefore changes throughout the mapping. For example, with the following Bloblang:\n\n```coffeescript\nroot.rejected = this.invitees.filter(i -> i.mood < 0.5)\nroot.invitees = this.invitees.filter(i -> i.mood >= 0.5)\n```\n\nNotice that we create a field `rejected` by copying the array field `invitees` and filtering out objects with a high mood. We then overwrite the field `invitees` by filtering out objects with a low mood, resulting in two array fields that are each a subset of the original. If we were to reverse the ordering of these assignments like so:\n\n```coffeescript\nroot.invitees = this.invitees.filter(i -> i.mood >= 0.5)\nroot.rejected = this.invitees.filter(i -> i.mood < 0.5)\n```\n\nThen the new field `rejected` would be empty as we have already mutated `invitees` to exclude the objects that it would be populated by. We can solve this problem either by carefully ordering our assignments or by capturing the original array using a variable (`let invitees = this.invitees`).\n\nMutations are advantageous over a standard mapping in situations where the result is a document with mostly the same shape as the input document, since we can avoid unnecessarily copying data from the referenced input document. However, in situations where we are creating an entirely new document shape it can be more convenient to use the traditional xref:components:processors/mapping.adoc[`mapping` processor] instead.\n\n== Error handling\n\nBloblang mappings can fail, in which case the error is logged and the message is flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, Bloblang itself also provides powerful ways of ensuring your mappings do not fail by specifying desired xref:guides:bloblang/about.adoc#error-handling[fallback behavior].\n\t\t\t",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - mutation: |\n        root.description = deleted()\n        root.fans = this.fans.filter(fan -> fan.obsession > 0.5)\n",
          "summary": "\nGiven JSON documents containing an array of fans:\n\n```json\n{\n  \"id\":\"foo\",\n  \"description\":\"a show about foo\",\n  \"fans\":[\n    {\"name\":\"bev\",\"obsession\":0.57},\n    {\"name\":\"grace\",\"obsession\":0.21},\n    {\"name\":\"ali\",\"obsession\":0.89},\n    {\"name\":\"vic\",\"obsession\":0.43}\n  ]\n}\n```\n\nWe can reduce the documents down to just the ID and only those fans with an obsession score above 0.5, giving us:\n\n```json\n{\n  \"id\":\"foo\",\n  \"fans\":[\n    {\"name\":\"bev\",\"obsession\":0.57},\n    {\"name\":\"ali\",\"obsession\":0.89}\n  ]\n}\n```\n\nWith the following config:",
          "title": "Mapping"
        },
        {
          "config": "\npipeline:\n  processors:\n    - mutation: |\n        root.Cities = this.locations.\n                        filter(loc -> loc.state == \"WA\").\n                        map_each(loc -> loc.name).\n                        sort().join(\", \")\n",
          "summary": "\nWhen receiving JSON documents of the form:\n\n```json\n{\n  \"locations\": [\n    {\"name\": \"Seattle\", \"state\": \"WA\"},\n    {\"name\": \"New York\", \"state\": \"NY\"},\n    {\"name\": \"Bellevue\", \"state\": \"WA\"},\n    {\"name\": \"Olympia\", \"state\": \"WA\"}\n  ]\n}\n```\n\nWe could collapse the location names from the state of Washington into a field `Cities`:\n\n```json\n{\"Cities\": \"Bellevue, Olympia, Seattle\"}\n```\n\nWith the following config:",
          "title": "More Mapping"
        }
      ],
      "name": "mutation",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a xref:guides:bloblang/about.adoc[Bloblang] mapping and directly transforms the contents of messages, mutating (or deleting) them.",
      "type": "processor",
      "version": "4.5.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "The name of the KV bucket.",
            "examples": [
              "my_kv_bucket"
            ],
            "kind": "scalar",
            "name": "bucket",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "create",
                "Adds the key/value pair if it does not exist. Returns an error if it already exists."
              ],
              [
                "delete",
                "Deletes the key/value pair, but keeps historical values."
              ],
              [
                "get",
                "Returns the latest value for `key`."
              ],
              [
                "get_revision",
                "Returns the value of `key` for the specified `revision`."
              ],
              [
                "history",
                "Returns historical values of `key` as an array of objects containing the following fields: `key`, `value`, `bucket`, `revision`, `delta`, `operation`, `created`."
              ],
              [
                "keys",
                "Returns the keys in the `bucket` which match the `keys_filter` as an array of strings."
              ],
              [
                "purge",
                "Deletes the key/value pair and all historical values."
              ],
              [
                "put",
                "Places a new value for the key into the store."
              ],
              [
                "update",
                "Updates the value for `key` only if the `revision` matches the latest revision."
              ]
            ],
            "description": "The operation to perform on the KV bucket.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"create\": true,\n  \"delete\": true,\n  \"get\": true,\n  \"get_revision\": true,\n  \"history\": true,\n  \"keys\": true,\n  \"purge\": true,\n  \"put\": true,\n  \"update\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operation",
            "type": "string"
          },
          {
            "description": "The key for each message. Supports https://docs.nats.io/nats-concepts/subjects#wildcards[wildcards^] for the `history` and `keys` operations.",
            "examples": [
              "foo",
              "foo.bar.baz",
              "foo.*",
              "foo.>",
              "foo.${! json(\"meta.type\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "linter": "if this == \"\" {[ \"'key' must be set to a non-empty string\" ]}",
            "name": "key",
            "type": "string"
          },
          {
            "description": "The revision of the key to operate on. Used for `get_revision` and `update` operations.",
            "examples": [
              "42",
              "${! @nats_kv_revision }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "revision",
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The maximum period to wait on an operation before aborting and returning an error.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n      [\"get_revision\", \"update\"].contains(this.operation) && !this.exists(\"revision\") => [ \"'revision' must be set when operation is '\" + this.operation + \"'\" ],\n      ![\"get_revision\", \"update\"].contains(this.operation) && this.exists(\"revision\") => [ \"'revision' cannot be set when operation is '\" + this.operation + \"'\" ],\n    }",
        "name": "",
        "type": "object"
      },
      "description": "\n== KV operations\n\nThe NATS KV processor supports a multitude of KV operations via the <<operation>> field. Along with `get`, `put`, and `delete`, this processor supports atomic operations like `update` and `create`, as well as utility operations like `purge`, `history`, and `keys`.\n\n== Metadata\n\nThis processor adds the following metadata fields to each message, depending on the chosen `operation`:\n\n=== get, get_revision\n``` text\n- nats_kv_key\n- nats_kv_bucket\n- nats_kv_revision\n- nats_kv_delta\n- nats_kv_operation\n- nats_kv_created\n```\n\n=== create, update, delete, purge\n``` text\n- nats_kv_key\n- nats_kv_bucket\n- nats_kv_revision\n- nats_kv_operation\n```\n\n=== keys\n``` text\n- nats_kv_bucket\n```\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_kv",
      "plugin": true,
      "status": "beta",
      "summary": "Perform operations on a NATS key-value bucket.",
      "type": "processor",
      "version": "4.12.0"
    },
    {
      "categories": [
        "Services"
      ],
      "config": {
        "children": [
          {
            "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
            "examples": [
              [
                "nats://127.0.0.1:4222"
              ],
              [
                "nats://username:password@127.0.0.1:4222"
              ]
            ],
            "kind": "array",
            "name": "urls",
            "type": "string"
          },
          {
            "description": "The maximum number of times to attempt to reconnect to the server. If negative, it will never stop trying to reconnect.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "max_reconnects",
            "type": "int"
          },
          {
            "description": "A subject to write to.",
            "examples": [
              "foo.bar.baz",
              "${! meta(\"kafka_topic\") }",
              "foo.${! json(\"meta.type\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "description": "Set an explicit inbox prefix for the response subject",
            "examples": [
              "_INBOX_joe"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "inbox_prefix",
            "type": "string"
          },
          {
            "default": {},
            "description": "Explicit message headers to add to messages.",
            "examples": [
              {
                "Content-Type": "application/json",
                "Timestamp": "${!meta(\"Timestamp\")}"
              }
            ],
            "interpolated": true,
            "kind": "map",
            "name": "headers",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "metadata",
            "type": "object"
          },
          {
            "default": "3s",
            "description": "A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as 300ms, -1.5h or 2h45m. Valid time units are ns, us (or µs), ms, s, m, h.",
            "is_optional": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": false,
            "description": "Perform a TLS handshake before sending the INFO protocol message.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls_handshake_first",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "An optional file containing a NKey seed.",
                "examples": [
                  "./seed.nk"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "nkey_file",
                "type": "string"
              },
              {
                "description": "The NKey seed.",
                "examples": [
                  "UDXU4RCSJNZOIQHZNWXHXORDPRTGNJAHAHFRGZNEEJCPQTT2M7NLCNF4"
                ],
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "nkey",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string",
                "version": "4.38.0"
              },
              {
                "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
                "examples": [
                  "./user.creds"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "user_credentials_file",
                "type": "string"
              },
              {
                "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_jwt",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
                "is_advanced": true,
                "is_optional": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "user_nkey_seed",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Optional configuration of NATS authentication parameters.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "auth",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- nats_subject\n- nats_sequence_stream\n- nats_sequence_consumer\n- nats_num_delivered\n- nats_num_pending\n- nats_domain\n- nats_timestamp_unix_nano\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "name": "nats_request_reply",
      "plugin": true,
      "status": "experimental",
      "summary": "Sends a message to a NATS subject and expects a reply, from a NATS subscriber acting as a responder, back.",
      "type": "processor",
      "version": "4.27.0"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "noop",
      "plugin": true,
      "status": "stable",
      "summary": "Noop is a processor that does nothing, the message passes through unchanged. Why? Sometimes doing nothing is the braver option.",
      "type": "processor"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "The name of the Ollama LLM to use. For a full list of models, see the https://ollama.com/models[Ollama website].",
            "examples": [
              "llama3.1",
              "gemma2",
              "qwen2",
              "phi3"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The system prompt to submit to the Ollama LLM.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "system_prompt",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The image to submit along with the prompt to the model. The result should be a byte array.",
            "examples": [
              "root = this.image.decode(\"base64\") # decode base64 encoded image"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "image",
            "type": "string",
            "version": "4.38.0"
          },
          {
            "default": "text",
            "description": "The format of the response that the Ollama model generates. If specifying JSON output, then the `prompt` should specify that the output should be in JSON as well.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"text\": true,\n  \"json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "response_format",
            "options": [
              "text",
              "json"
            ],
            "type": "string"
          },
          {
            "description": "The maximum number of tokens to predict and output. Limiting the amount of output means that requests are processed faster and have a fixed limit on the cost.",
            "is_optional": true,
            "kind": "scalar",
            "name": "max_tokens",
            "type": "int"
          },
          {
            "description": "The temperature of the model. Increasing the temperature makes the model answer more creatively.",
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < 0 { [ \"field must be between 0.0 and 2.0\" ] }",
            "name": "temperature",
            "type": "int"
          },
          {
            "description": "Specify the number of tokens from the initial prompt to retain when the model resets its internal context. By default, this value is set to `4`. Use `-1` to retain all tokens from the initial prompt.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "num_keep",
            "type": "int"
          },
          {
            "description": "Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt.",
            "examples": [
              42
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "seed",
            "type": "int"
          },
          {
            "description": "Reduces the probability of generating nonsense. A higher value, for example `100`, will give more diverse answers. A lower value, for example `10`, will be more conservative.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "top_k",
            "type": "int"
          },
          {
            "description": "Works together with `top-k`. A higher value, for example 0.95, will lead to more diverse text. A lower value, for example 0.5, will generate more focused and conservative text.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 1 || this < 0 { [ \"field must be between 0.0 and 1.0\" ] }",
            "name": "top_p",
            "type": "float"
          },
          {
            "description": "Sets how strongly to penalize repetitions. A higher value, for example 1.5, will penalize repetitions more strongly. A lower value, for example 0.9, will be more lenient.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be between -2.0 and 2.0\" ] }",
            "name": "repeat_penalty",
            "type": "float"
          },
          {
            "description": "Positive values penalize new tokens if they have appeared in the text so far. This increases the model's likelihood to talk about new topics.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be between -2.0 and 2.0\" ] }",
            "name": "presence_penalty",
            "type": "float"
          },
          {
            "description": "Positive values penalize new tokens based on the frequency of their appearance in the text so far. This decreases the model's likelihood to repeat the same line verbatim.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be between -2.0 and 2.0\" ] }",
            "name": "frequency_penalty",
            "type": "float"
          },
          {
            "description": "Sets the stop sequences to use. When this pattern is encountered the LLM stops generating text and returns the final response.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "stop",
            "type": "string"
          },
          {
            "default": false,
            "description": "If enabled the prompt is saved as @prompt metadata on the output message. If system_prompt is used it's also saved as @system_prompt",
            "kind": "scalar",
            "name": "save_prompt_metadata",
            "type": "bool"
          },
          {
            "bloblang": true,
            "description": "Historical messages to include in the chat request. The result of the bloblang query should be an array of objects of the form of [{\"role\": \"\", \"content\":\"\"}].",
            "is_optional": true,
            "kind": "scalar",
            "name": "history",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of sequential tool calls.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "root = if this <= 0 { [\"field must be greater than zero\"] }",
            "name": "max_tool_calls",
            "type": "int"
          },
          {
            "children": [
              {
                "description": "The name of this tool.",
                "kind": "scalar",
                "name": "name",
                "type": "string"
              },
              {
                "description": "A description of this tool, the LLM uses this to decide if the tool should be used.",
                "kind": "scalar",
                "name": "description",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "The required parameters for this pipeline.",
                    "kind": "array",
                    "name": "required",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "The type of this parameter.",
                        "kind": "scalar",
                        "name": "type",
                        "type": "string"
                      },
                      {
                        "description": "A description of this parameter.",
                        "kind": "scalar",
                        "name": "description",
                        "type": "string"
                      },
                      {
                        "default": [],
                        "description": "Specifies that this parameter is an enum and only these specific values should be used.",
                        "kind": "array",
                        "name": "enum",
                        "type": "string"
                      }
                    ],
                    "description": "The properties for the processor's input data",
                    "kind": "map",
                    "name": "properties",
                    "type": "object"
                  }
                ],
                "description": "The parameters the LLM needs to provide to invoke this tool.",
                "kind": "scalar",
                "name": "parameters",
                "type": "object"
              },
              {
                "description": "The pipeline to execute when the LLM uses this tool.",
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "default": [],
            "description": "The tools to allow the LLM to invoke. This allows building subpipelines that the LLM can choose to invoke to execute agentic-like actions.",
            "kind": "array",
            "name": "tools",
            "type": "object"
          },
          {
            "children": [
              {
                "description": "Sets the size of the context window used to generate the next token. Using a larger context window uses more memory and takes longer to processor.",
                "is_optional": true,
                "kind": "scalar",
                "name": "context_size",
                "type": "int"
              },
              {
                "description": "The maximum number of requests to process in parallel.",
                "is_optional": true,
                "kind": "scalar",
                "name": "batch_size",
                "type": "int"
              },
              {
                "description": "This option allows offloading some layers to the GPU for computation. This generally results in increased performance. By default, the runtime decides the number of layers dynamically.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "gpu_layers",
                "type": "int"
              },
              {
                "description": "Set the number of threads to use during generation. For optimal performance, it is recommended to set this value to the number of physical CPU cores your system has. By default, the runtime decides the optimal number of threads.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "threads",
                "type": "int"
              },
              {
                "description": "Map the model into memory. This is only support on unix systems and allows loading only the necessary parts of the model as needed.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "use_mmap",
                "type": "bool"
              }
            ],
            "description": "Options for the model runner that are used when the model is first loaded into memory.",
            "is_optional": true,
            "kind": "scalar",
            "name": "runner",
            "type": "object"
          },
          {
            "description": "The address of the Ollama server to use. Leave the field blank and the processor starts and runs a local Ollama server or specify the address of your own local or remote server.",
            "examples": [
              "http://127.0.0.1:11434"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "If `server_address` is not set - the directory to download the ollama binary and use as a model cache.",
            "examples": [
              "/opt/cache/connect/ollama"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "cache_directory",
            "type": "string"
          },
          {
            "description": "If `server_address` is not set - the URL to download the ollama binary from. Defaults to the offical Ollama GitHub release for this platform.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "download_url",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor sends prompts to your chosen Ollama large language model (LLM) and generates text from the responses, using the Ollama API.\n\nBy default, the processor starts and runs a locally installed Ollama server. Alternatively, to use an already running Ollama server, add your server details to the `server_address` field. You can https://ollama.com/download[download and install Ollama from the Ollama website^].\n\nFor more information, see the https://github.com/ollama/ollama/tree/main/docs[Ollama documentation^].",
      "examples": [
        {
          "config": "\ninput:\n  stdin:\n    scanner:\n      lines: {}\npipeline:\n  processors:\n    - http:\n        verb: GET\n        url: \"${!content().string()}\"\n    - ollama_chat:\n        model: llava\n        prompt: \"Describe the following image\"\n        image: \"root = content()\"\noutput:\n  stdout:\n    codec: lines\n",
          "summary": "This example fetches image URLs from stdin and has a multimodal LLM describe the image.",
          "title": "Use Llava to analyze an image"
        },
        {
          "config": "\ninput:\n  generate:\n    count: 1\n    mapping: |\n      root = \"What is the weather like in Chicago?\"\npipeline:\n  processors:\n    - ollama_chat:\n        model: llama3.2\n        prompt: \"${!content().string()}\"\n        tools:\n          - name: GetWeather\n            description: \"Retrieve the weather for a specific city\"\n            parameters:\n              required: [\"city\"]\n              properties:\n                city:\n                  type: string\n                  description: the city to lookup the weather for\n            processors:\n              - http:\n                  verb: GET\n                  url: 'https://wttr.in/${!this.city}?T'\n                  headers:\n                    # Spoof curl user-ageent to get a plaintext text\n                    User-Agent: curl/8.11.1\noutput:\n  stdout: {}\n",
          "summary": "This example allows llama3.2 to execute a subpipeline as a tool call to get more data.",
          "title": "Use subpipelines as tool calls"
        }
      ],
      "name": "ollama_chat",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates responses to messages in a chat conversation, using the Ollama API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "The name of the Ollama LLM to use. For a full list of models, see the https://ollama.com/models[Ollama website].",
            "examples": [
              "nomic-embed-text",
              "mxbai-embed-large",
              "snowflake-artic-embed",
              "all-minilm"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The text you want to create vector embeddings for. By default, the processor submits the entire payload as a string.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "text",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "Sets the size of the context window used to generate the next token. Using a larger context window uses more memory and takes longer to processor.",
                "is_optional": true,
                "kind": "scalar",
                "name": "context_size",
                "type": "int"
              },
              {
                "description": "The maximum number of requests to process in parallel.",
                "is_optional": true,
                "kind": "scalar",
                "name": "batch_size",
                "type": "int"
              },
              {
                "description": "This option allows offloading some layers to the GPU for computation. This generally results in increased performance. By default, the runtime decides the number of layers dynamically.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "gpu_layers",
                "type": "int"
              },
              {
                "description": "Set the number of threads to use during generation. For optimal performance, it is recommended to set this value to the number of physical CPU cores your system has. By default, the runtime decides the optimal number of threads.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "threads",
                "type": "int"
              },
              {
                "description": "Map the model into memory. This is only support on unix systems and allows loading only the necessary parts of the model as needed.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "use_mmap",
                "type": "bool"
              }
            ],
            "description": "Options for the model runner that are used when the model is first loaded into memory.",
            "is_optional": true,
            "kind": "scalar",
            "name": "runner",
            "type": "object"
          },
          {
            "description": "The address of the Ollama server to use. Leave the field blank and the processor starts and runs a local Ollama server or specify the address of your own local or remote server.",
            "examples": [
              "http://127.0.0.1:11434"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "If `server_address` is not set - the directory to download the ollama binary and use as a model cache.",
            "examples": [
              "/opt/cache/connect/ollama"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "cache_directory",
            "type": "string"
          },
          {
            "description": "If `server_address` is not set - the URL to download the ollama binary from. Defaults to the offical Ollama GitHub release for this platform.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "download_url",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor sends text to your chosen Ollama large language model (LLM) and creates vector embeddings, using the Ollama API. Vector embeddings are long arrays of numbers that represent values or objects, in this case text. \n\nBy default, the processor starts and runs a locally installed Ollama server. Alternatively, to use an already running Ollama server, add your server details to the `server_address` field. You can https://ollama.com/download[download and install Ollama from the Ollama website^].\n\nFor more information, see the https://github.com/ollama/ollama/tree/main/docs[Ollama documentation^].",
      "examples": [
        {
          "config": "input:\n  generate:\n    interval: 1s\n    mapping: |\n      root = {\"text\": fake(\"paragraph\")}\npipeline:\n  processors:\n  - ollama_embeddings:\n      model: snowflake-artic-embed\n      text: \"${!this.text}\"\noutput:\n  qdrant:\n    grpc_host: localhost:6334\n    collection_name: \"example_collection\"\n    id: \"root = uuid_v4()\"\n    vector_mapping: \"root = this\"\n",
          "summary": "Compute embeddings for some generated data and store it within xrefs:component:outputs/qdrant.adoc[Qdrant]",
          "title": "Store embedding vectors in Qdrant"
        },
        {
          "config": "input:\n  generate:\n    interval: 1s\n    mapping: |\n      root = {\"text\": fake(\"paragraph\")}\npipeline:\n  processors:\n  - branch:\n      processors:\n      - ollama_embeddings:\n          model: snowflake-artic-embed\n          text: \"${!this.text}\"\n      result_map: |\n        root.embeddings = this\noutput:\n  sql_insert:\n    driver: clickhouse\n    dsn: \"clickhouse://localhost:9000\"\n    table: searchable_text\n    columns: [\"id\", \"text\", \"vector\"]\n    args_mapping: \"root = [uuid_v4(), this.text, this.embeddings]\"\n",
          "summary": "Compute embeddings for some generated data and store it within https://clickhouse.com/[Clickhouse^]",
          "title": "Store embedding vectors in Clickhouse"
        }
      ],
      "name": "ollama_embeddings",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates vector embeddings from text, using the Ollama API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "llama-guard3",
                "When using llama-guard3, two pieces of metadata is added: @safe with the value of `yes` or `no` and the second being @category for the safety category violation. For more information see the https://ollama.com/library/llama-guard3[Llama Guard 3 Model Card]."
              ],
              [
                "shieldgemma",
                "When using shieldgemma, the model output is a single piece of metadata of @safe with a value of `yes` or `no` if the response is not in violation of its defined safety policies."
              ]
            ],
            "description": "The name of the Ollama LLM to use.",
            "examples": [
              "llama-guard3",
              "shieldgemma"
            ],
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"llama-guard3\": true,\n  \"shieldgemma\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The input prompt that was used with the LLM. If using `ollama_chat` the you can use `save_prompt_metadata` to safe the prompt as metadata.",
            "interpolated": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The LLM's response to classify if it contains safe or unsafe content.",
            "interpolated": true,
            "kind": "scalar",
            "name": "response",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "Sets the size of the context window used to generate the next token. Using a larger context window uses more memory and takes longer to processor.",
                "is_optional": true,
                "kind": "scalar",
                "name": "context_size",
                "type": "int"
              },
              {
                "description": "The maximum number of requests to process in parallel.",
                "is_optional": true,
                "kind": "scalar",
                "name": "batch_size",
                "type": "int"
              },
              {
                "description": "This option allows offloading some layers to the GPU for computation. This generally results in increased performance. By default, the runtime decides the number of layers dynamically.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "gpu_layers",
                "type": "int"
              },
              {
                "description": "Set the number of threads to use during generation. For optimal performance, it is recommended to set this value to the number of physical CPU cores your system has. By default, the runtime decides the optimal number of threads.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "threads",
                "type": "int"
              },
              {
                "description": "Map the model into memory. This is only support on unix systems and allows loading only the necessary parts of the model as needed.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "use_mmap",
                "type": "bool"
              }
            ],
            "description": "Options for the model runner that are used when the model is first loaded into memory.",
            "is_optional": true,
            "kind": "scalar",
            "name": "runner",
            "type": "object"
          },
          {
            "description": "The address of the Ollama server to use. Leave the field blank and the processor starts and runs a local Ollama server or specify the address of your own local or remote server.",
            "examples": [
              "http://127.0.0.1:11434"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "If `server_address` is not set - the directory to download the ollama binary and use as a model cache.",
            "examples": [
              "/opt/cache/connect/ollama"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "cache_directory",
            "type": "string"
          },
          {
            "description": "If `server_address` is not set - the URL to download the ollama binary from. Defaults to the offical Ollama GitHub release for this platform.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "download_url",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "This processor checks LLM response safety using either `llama-guard3` or `shieldgemma`. If you want to check if a given prompt is safe, then that can be done with the `ollama_chat` processor - this processor is for response classification only.\n\nBy default, the processor starts and runs a locally installed Ollama server. Alternatively, to use an already running Ollama server, add your server details to the `server_address` field. You can https://ollama.com/download[download and install Ollama from the Ollama website^].\n\nFor more information, see the https://github.com/ollama/ollama/tree/main/docs[Ollama documentation^].",
      "examples": [
        {
          "config": "\ninput:\n  stdin:\n    scanner:\n      lines: {}\npipeline:\n  processors:\n    - ollama_chat:\n        model: llava\n        prompt: \"${!content().string()}\"\n        save_prompt_metadata: true\n    - ollama_moderation:\n        model: llama-guard3\n        prompt: \"${!@prompt}\"\n        response: \"${!content().string()}\"\n    - mapping: |\n        root.response = content().string()\n        root.is_safe = @safe\noutput:\n  stdout:\n    codec: lines\n",
          "summary": "This example uses Llama Guard 3 to check if another model responded with a safe or unsafe content.",
          "title": "Use Llama Guard 3 classify a LLM response"
        }
      ],
      "name": "ollama_moderation",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates responses to messages in a chat conversation, using the Ollama API.",
      "type": "processor",
      "version": "4.42.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.openai.com/v1",
            "description": "The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.",
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "The API key for OpenAI API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the OpenAI model to use.",
            "examples": [
              "gpt-4o",
              "gpt-4o-mini",
              "gpt-4",
              "gpt4-turbo"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "description": "The user prompt you want to generate a response for. By default, the processor submits the entire payload as a string.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The system prompt to submit along with the user prompt.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "system_prompt",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The history of the prior conversation. A bloblang query that should result in an array of objects of the form: [{\"role\": \"user\", \"content\": \"<text>\"}, {\"role\":\"assistant\", \"content\":\"<text>\"}]",
            "is_optional": true,
            "kind": "scalar",
            "name": "history",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An image to send along with the prompt. The mapping result must be a byte array.",
            "examples": [
              "root = this.image.decode(\"base64\") # decode base64 encoded image"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "image",
            "type": "string",
            "version": "4.38.0"
          },
          {
            "description": "The maximum number of tokens that can be generated in the chat completion.",
            "is_optional": true,
            "kind": "scalar",
            "name": "max_tokens",
            "type": "int"
          },
          {
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or top_p but not both.",
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < 0 { [ \"field must be between 0 and 2\" ] }",
            "name": "temperature",
            "type": "float"
          },
          {
            "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "user",
            "type": "string"
          },
          {
            "default": "text",
            "description": "Specify the model's output format. If `json_schema` is specified, then additionally a `json_schema` or `schema_registry` must be configured.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"text\": true,\n  \"json\": true,\n  \"json_schema\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "response_format",
            "options": [
              "text",
              "json",
              "json_schema"
            ],
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The name of the schema.",
                "kind": "scalar",
                "name": "name",
                "type": "string"
              },
              {
                "description": "Additional description of the schema for the LLM.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "description",
                "type": "string"
              },
              {
                "description": "The JSON schema for the LLM to use when generating the output.",
                "kind": "scalar",
                "name": "schema",
                "type": "string"
              }
            ],
            "description": "The JSON schema to use when responding in `json_schema` format. To learn more about what JSON schema is supported see the https://platform.openai.com/docs/guides/structured-outputs/supported-schemas[OpenAI documentation^].",
            "is_optional": true,
            "kind": "scalar",
            "name": "json_schema",
            "type": "object"
          },
          {
            "children": [
              {
                "description": "The base URL of the schema registry service.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "url",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "default": "schema_registry_id_",
                "description": "The prefix of the name for this schema, the schema ID is used as a suffix.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "name_prefix",
                "type": "string"
              },
              {
                "description": "The subject name to fetch the schema for.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "subject",
                "type": "string"
              },
              {
                "description": "The refresh rate for getting the latest schema. If not specified the schema does not refresh.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "refresh_interval",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to skip server side certificate verification.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "skip_cert_verify",
                    "type": "bool"
                  },
                  {
                    "default": false,
                    "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enable_renegotiation",
                    "type": "bool",
                    "version": "3.45.0"
                  },
                  {
                    "default": "",
                    "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "root_cas",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                    "examples": [
                      "./root_cas.pem"
                    ],
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "root_cas_file",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "default": "",
                        "description": "A plain text certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text certificate key to use.",
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "key",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "cert_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "The path of a certificate key to use.",
                        "is_advanced": true,
                        "kind": "scalar",
                        "name": "key_file",
                        "type": "string"
                      },
                      {
                        "default": "",
                        "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                        "examples": [
                          "foo",
                          "${KEY_PASSWORD}"
                        ],
                        "is_advanced": true,
                        "is_secret": true,
                        "kind": "scalar",
                        "name": "password",
                        "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                        "type": "string"
                      }
                    ],
                    "default": [],
                    "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                    "examples": [
                      [
                        {
                          "cert": "foo",
                          "key": "bar"
                        }
                      ],
                      [
                        {
                          "cert_file": "./example.pem",
                          "key_file": "./example.key"
                        }
                      ]
                    ],
                    "is_advanced": true,
                    "kind": "array",
                    "name": "client_certs",
                    "type": "object"
                  }
                ],
                "description": "Custom TLS settings can be used to override system defaults.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "tls",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to use OAuth version 1 in requests.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "A value used to identify the client to the service provider.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "consumer_key",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A secret used to establish ownership of the consumer key.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "consumer_secret",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A value used to gain access to the protected resources on behalf of the user.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "access_token",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A secret provided in order to establish ownership of a given access token.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "access_token_secret",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "Allows you to specify open authentication via OAuth version 1.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "oauth",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to use basic authentication in requests.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "A username to authenticate as.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "username",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A password to authenticate with.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "description": "Allows you to specify basic authentication.",
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "basic_auth",
                "type": "object"
              },
              {
                "children": [
                  {
                    "default": false,
                    "description": "Whether to use JWT authentication in requests.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "enabled",
                    "type": "bool"
                  },
                  {
                    "default": "",
                    "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "private_key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "signing_method",
                    "type": "string"
                  },
                  {
                    "default": {},
                    "description": "A value used to identify the claims that issued the JWT.",
                    "is_advanced": true,
                    "kind": "map",
                    "name": "claims",
                    "type": "unknown"
                  },
                  {
                    "default": {},
                    "description": "Add optional key/value headers to the JWT.",
                    "is_advanced": true,
                    "kind": "map",
                    "name": "headers",
                    "type": "unknown"
                  }
                ],
                "description": "BETA: Allows you to specify JWT authentication.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "jwt",
                "type": "object"
              }
            ],
            "description": "The schema registry to dynamically load schemas from when responding in `json_schema` format. Schemas themselves must be in JSON format. To learn more about what JSON schema is supported see the https://platform.openai.com/docs/guides/structured-outputs/supported-schemas[OpenAI documentation^].",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "schema_registry",
            "type": "object"
          },
          {
            "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 1 || this < 0 { [ \"field must be between 0 and 1\" ] }",
            "name": "top_p",
            "type": "float"
          },
          {
            "description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be less than 2 and greater than -2\" ] }",
            "name": "frequency_penalty",
            "type": "float"
          },
          {
            "description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "root = if this > 2 || this < -2 { [ \"field must be less than 2 and greater than -2\" ] }",
            "name": "presence_penalty",
            "type": "float"
          },
          {
            "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "seed",
            "type": "int"
          },
          {
            "description": "Up to 4 sequences where the API will stop generating further tokens.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "stop",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The name of this tool.",
                "kind": "scalar",
                "name": "name",
                "type": "string"
              },
              {
                "description": "A description of this tool, the LLM uses this to decide if the tool should be used.",
                "kind": "scalar",
                "name": "description",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": [],
                    "description": "The required parameters for this pipeline.",
                    "kind": "array",
                    "name": "required",
                    "type": "string"
                  },
                  {
                    "children": [
                      {
                        "description": "The type of this parameter.",
                        "kind": "scalar",
                        "name": "type",
                        "type": "string"
                      },
                      {
                        "description": "A description of this parameter.",
                        "kind": "scalar",
                        "name": "description",
                        "type": "string"
                      },
                      {
                        "default": [],
                        "description": "Specifies that this parameter is an enum and only these specific values should be used.",
                        "kind": "array",
                        "name": "enum",
                        "type": "string"
                      }
                    ],
                    "description": "The properties for the processor's input data",
                    "kind": "map",
                    "name": "properties",
                    "type": "object"
                  }
                ],
                "default": [],
                "description": "The parameters the LLM needs to provide to invoke this tool.",
                "kind": "scalar",
                "name": "parameters",
                "type": "object"
              },
              {
                "description": "The pipeline to execute when the LLM uses this tool.",
                "is_optional": true,
                "kind": "array",
                "name": "processors",
                "type": "processor"
              }
            ],
            "description": "The tools to allow the LLM to invoke. This allows building subpipelines that the LLM can choose to invoke to execute agentic-like actions.",
            "kind": "array",
            "name": "tools",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "\n      root = match {\n        this.exists(\"json_schema\") && this.exists(\"schema_registry\") => [\"cannot set both `json_schema` and `schema_registry`\"]\n        this.response_format == \"json_schema\" && !this.exists(\"json_schema\") && !this.exists(\"schema_registry\") => [\"schema must be specified using either `json_schema` or `schema_registry`\"]\n      }\n    ",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends the contents of user prompts to the OpenAI API, which generates responses. By default, the processor submits the entire payload of each message as a string, unless you use the `prompt` configuration field to customize it.\n\nTo learn more about chat completion, see the https://platform.openai.com/docs/guides/chat-completions[OpenAI API documentation^].",
      "examples": [
        {
          "config": "\ninput:\n  stdin:\n    scanner:\n      lines: {}\npipeline:\n  processors:\n    - http:\n        verb: GET\n        url: \"${!content().string()}\"\n    - openai_chat_completion:\n        model: gpt-4o\n        api_key: TODO\n        prompt: \"Describe the following image\"\n        image: \"root = content()\"\noutput:\n  stdout:\n    codec: lines\n",
          "summary": "This example fetches image URLs from stdin and has GPT-4o describe the image.",
          "title": "Use GPT-4o analyze an image"
        },
        {
          "config": "\ninput:\n  stdin:\n    scanner:\n      lines: {}\npipeline:\n  processors:\n    - mapping: |\n        root.prompt = content().string()\n    - branch:\n        processors:\n          - cache:\n              resource: mem\n              operator: get\n              key: history\n          - catch:\n            - mapping: 'root = []'\n        result_map: 'root.history = this'\n    - branch:\n        processors:\n        - openai_chat_completion:\n            model: gpt-4o\n            api_key: TODO\n            prompt: \"${!this.prompt}\"\n            history: 'root = this.history'\n        result_map: 'root.response = content().string()'\n    - mutation: |\n        root.history = this.history.concat([\n          {\"role\": \"user\", \"content\": this.prompt},\n          {\"role\": \"assistant\", \"content\": this.response},\n        ])\n    - cache:\n        resource: mem\n        operator: set\n        key: history\n        value: '${!this.history}'\n    - mapping: |\n        root = this.response\noutput:\n  stdout:\n    codec: lines\n\ncache_resources:\n  - label: mem \n    memory: {}\n",
          "summary": "This pipeline provides a historical chat history to GPT-4o using a cache.",
          "title": "Provide historical chat history"
        },
        {
          "config": "\ninput:\n  generate:\n    count: 1\n    mapping: |\n      root = \"What is the weather like in Chicago?\"\npipeline:\n  processors:\n    - openai_chat_completion:\n        model: gpt-4o\n        api_key: \"${OPENAI_API_KEY}\"\n        prompt: \"${!content().string()}\"\n        tools:\n          - name: GetWeather\n            description: \"Retrieve the weather for a specific city\"\n            parameters:\n              required: [\"city\"]\n              properties:\n                city:\n                  type: string\n                  description: the city to look up the weather for\n            processors:\n              - http:\n                  verb: GET\n                  url: 'https://wttr.in/${!this.city}?T'\n                  headers:\n                    User-Agent: curl/8.11.1 # Returns a text string from the weather website\noutput:\n  stdout: {}\n",
          "summary": "This example asks GPT-4o to respond with the weather by invoking an HTTP processor to get the forecast.",
          "title": "Use GPT-4o to call a tool"
        }
      ],
      "name": "openai_chat_completion",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates responses to messages in a chat conversation, using the OpenAI API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.openai.com/v1",
            "description": "The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.",
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "The API key for OpenAI API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the OpenAI model to use.",
            "examples": [
              "text-embedding-3-large",
              "text-embedding-3-small",
              "text-embedding-ada-002"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The text you want to generate a vector embedding for. By default, the processor submits the entire payload as a string.",
            "is_optional": true,
            "kind": "scalar",
            "name": "text_mapping",
            "type": "string"
          },
          {
            "description": "The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.",
            "is_optional": true,
            "kind": "scalar",
            "name": "dimensions",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends text strings to the OpenAI API, which generates vector embeddings. By default, the processor submits the entire payload of each message as a string, unless you use the `text_mapping` configuration field to customize it.\n\nTo learn more about vector embeddings, see the https://platform.openai.com/docs/guides/embeddings[OpenAI API documentation^].",
      "examples": [
        {
          "config": "input:\n  generate:\n    interval: 1s\n    mapping: |\n      root = {\"text\": fake(\"paragraph\")}\npipeline:\n  processors:\n  - openai_embeddings:\n      model: text-embedding-3-large\n      api_key: \"${OPENAI_API_KEY}\"\n      text_mapping: \"root = this.text\"\noutput:\n  pinecone:\n    host: \"${PINECONE_HOST}\"\n    api_key: \"${PINECONE_API_KEY}\"\n    id: \"root = uuid_v4()\"\n    vector_mapping: \"root = this\"",
          "summary": "Compute embeddings for some generated data and store it within xrefs:component:outputs/pinecone.adoc[Pinecone]",
          "title": "Store embedding vectors in Pinecone"
        }
      ],
      "name": "openai_embeddings",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates vector embeddings to represent input text, using the OpenAI API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.openai.com/v1",
            "description": "The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.",
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "The API key for OpenAI API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the OpenAI model to use.",
            "examples": [
              "dall-e-3",
              "dall-e-2"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A text description of the image you want to generate. The `prompt` field accepts a maximum of 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.",
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          },
          {
            "description": "The quality of the image to generate. Use `hd` to create images with finer details and greater consistency across the image. This parameter is only supported for `dall-e-3` models.",
            "examples": [
              "standard",
              "hd"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "quality",
            "type": "string"
          },
          {
            "description": "The size of the generated image. Choose from `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Choose from `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.",
            "examples": [
              "1024x1024",
              "512x512",
              "1792x1024",
              "1024x1792"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "size",
            "type": "string"
          },
          {
            "description": "The style of the generated image. Choose from `vivid` or `natural`. Vivid causes the model to lean towards generating hyperreal and dramatic images. Natural causes the model to produce more natural, less hyperreal looking images. This parameter is only supported for `dall-e-3`.",
            "examples": [
              "vivid",
              "natural"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "style",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends an image description and other attributes, such as image size and quality to the OpenAI API, which generates an image. By default, the processor submits the entire payload of each message as a string, unless you use the `prompt` configuration field to customize it.\n\nTo learn more about image generation, see the https://platform.openai.com/docs/guides/images[OpenAI API documentation^].",
      "name": "openai_image_generation",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates an image from a text description and other attributes, using OpenAI API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.openai.com/v1",
            "description": "The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.",
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "The API key for OpenAI API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the OpenAI model to use.",
            "examples": [
              "tts-1",
              "tts-1-hd"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A text description of the audio you want to generate. The `input` field accepts a maximum of 4096 characters.",
            "is_optional": true,
            "kind": "scalar",
            "name": "input",
            "type": "string"
          },
          {
            "description": "The type of voice to use when generating the audio.",
            "examples": [
              "alloy",
              "echo",
              "fable",
              "onyx",
              "nova",
              "shimmer"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "voice",
            "type": "string"
          },
          {
            "description": "The format to generate audio in. Default is `mp3`.",
            "examples": [
              "mp3",
              "opus",
              "aac",
              "flac",
              "wav",
              "pcm"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "response_format",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends a text description and other attributes, such as a voice type and format to the OpenAI API, which generates audio. By default, the processor submits the entire payload of each message as a string, unless you use the `input` configuration field to customize it.\n\nTo learn more about turning text into spoken audio, see the https://platform.openai.com/docs/guides/text-to-speech[OpenAI API documentation^].",
      "name": "openai_speech",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates audio from a text description and other attributes, using OpenAI API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.openai.com/v1",
            "description": "The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.",
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "The API key for OpenAI API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the OpenAI model to use.",
            "examples": [
              "whisper-1"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The audio file object (not file name) to transcribe, in one of the following formats: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav`, or `webm`.",
            "kind": "scalar",
            "name": "file",
            "type": "string"
          },
          {
            "description": "The language of the input audio. Supplying the input language in ISO-639-1 format improves accuracy and latency.",
            "examples": [
              "en",
              "fr",
              "de",
              "zh"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "language",
            "type": "string"
          },
          {
            "description": "Optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends an audio file object along with the input language to OpenAI API to generate a transcription. By default, the processor submits the entire payload of each message as a string, unless you use the `file` configuration field to customize it.\n\nTo learn more about audio transcription, see the: https://platform.openai.com/docs/guides/speech-to-text[OpenAI API documentation^].",
      "name": "openai_transcription",
      "plugin": true,
      "status": "experimental",
      "summary": "Generates a transcription of spoken audio in the input language, using the OpenAI API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "default": "https://api.openai.com/v1",
            "description": "The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.",
            "kind": "scalar",
            "name": "server_address",
            "type": "string"
          },
          {
            "description": "The API key for OpenAI API.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_key",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "description": "The name of the OpenAI model to use.",
            "examples": [
              "whisper-1"
            ],
            "kind": "scalar",
            "name": "model",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The audio file object (not file name) to translate, in one of the following formats: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav`, or `webm`.",
            "is_optional": true,
            "kind": "scalar",
            "name": "file",
            "type": "string"
          },
          {
            "description": "Optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.",
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prompt",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor sends an audio file object to OpenAI API to generate a translation. By default, the processor submits the entire payload of each message as a string, unless you use the `file` configuration field to customize it.\n\nTo learn more about translation, see the https://platform.openai.com/docs/guides/speech-to-text[OpenAI API documentation^].",
      "name": "openai_translation",
      "plugin": true,
      "status": "experimental",
      "summary": "Translates spoken audio into English, using the OpenAI API.",
      "type": "processor",
      "version": "4.32.0"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "default": 0,
            "description": "The maximum number of messages to have processing at a given time.",
            "kind": "scalar",
            "name": "cap",
            "type": "int"
          },
          {
            "description": "A list of child processors to apply.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe field `cap`, if greater than zero, caps the maximum number of parallel processing threads.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching in xref:configuration:batching.adoc[].",
      "name": "parallel",
      "plugin": true,
      "status": "stable",
      "summary": "A processor that applies a list of child processors to messages of a batch as though they were each a batch of one message (similar to the xref:components:processors/for_each.adoc[`for_each`] processor), but where each message is processed in parallel.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "from_json",
                "Compress a batch of JSON documents into a file."
              ],
              [
                "to_json",
                "Expand a file into one or more JSON messages."
              ]
            ],
            "description": "Determines whether the processor converts messages into a parquet file or expands parquet files into messages. Converting into JSON allows subsequent processors and mappings to convert the data into any other format.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"from_json\": true,\n  \"to_json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "type": "string"
          },
          {
            "default": "snappy",
            "description": "The type of compression to use when writing parquet files, this field is ignored when consuming parquet files.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"uncompressed\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"lz4\": true,\n  \"zstd\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "compression",
            "options": [
              "uncompressed",
              "snappy",
              "gzip",
              "lz4",
              "zstd"
            ],
            "type": "string"
          },
          {
            "description": "A file path containing a schema used to describe the parquet files being generated or consumed, the format of the schema is a JSON document detailing the tag and fields of documents. The schema can be found at: https://pkg.go.dev/github.com/xitongsys/parquet-go#readme-json. Either a `schema_file` or `schema` field must be specified when creating Parquet files via the `from_json` operator.",
            "examples": [
              "schemas/foo.json"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "schema_file",
            "type": "string"
          },
          {
            "description": "A schema used to describe the parquet files being generated or consumed, the format of the schema is a JSON document detailing the tag and fields of documents. The schema can be found at: https://pkg.go.dev/github.com/xitongsys/parquet-go#readme-json. Either a `schema_file` or `schema` field must be specified when creating Parquet files via the `from_json` operator.",
            "examples": [
              "{\n  \"Tag\": \"name=root, repetitiontype=REQUIRED\",\n  \"Fields\": [\n    {\"Tag\":\"name=name,inname=NameIn,type=BYTE_ARRAY,convertedtype=UTF8, repetitiontype=REQUIRED\"},\n    {\"Tag\":\"name=age,inname=Age,type=INT32,repetitiontype=REQUIRED\"}\n  ]\n}"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "schema",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "\nroot = if this.operator == \"from_json\" && (this.schema | this.schema_file | \"\") == \"\" {\n\t\"a schema or schema_file must be specified when the operator is set to from_json\"\n}",
        "name": "",
        "type": "object"
      },
      "description": "\n== Alternatives\n\nThis processor is now deprecated, it's recommended that you use the new xref:components:processors/parquet_decode.adoc[`parquet_decode`] and xref:components:processors/parquet_encode.adoc[`parquet_encode`] processors as they provide a number of advantages, the most important of which is better error messages for when schemas are mismatched or files could not be consumed.\n\n== Troubleshooting\n\nThis processor is experimental and the error messages that it provides are often vague and unhelpful. An error message of the form `interface \\{} is nil, not <value type>` implies that a field of the given type was expected but not found in the processed message when writing parquet files.\n\nUnfortunately the name of the field will sometimes be missing from the error, in which case it's worth double checking the schema you provided to make sure that there are no typos in the field names, and if that doesn't reveal the issue it can help to mark fields as OPTIONAL in the schema and gradually change them back to REQUIRED until the error returns.\n\n== Define the schema\n\nThe schema must be specified as a JSON string, containing an object that describes the fields expected at the root of each document. Each field can itself have more fields defined, allowing for nested structures:\n\n```json\n{\n  \"Tag\": \"name=root, repetitiontype=REQUIRED\",\n  \"Fields\": [\n    {\"Tag\": \"name=name, inname=NameIn, type=BYTE_ARRAY, convertedtype=UTF8, repetitiontype=REQUIRED\"},\n    {\"Tag\": \"name=age, inname=Age, type=INT32, repetitiontype=REQUIRED\"},\n    {\"Tag\": \"name=id, inname=Id, type=INT64, repetitiontype=REQUIRED\"},\n    {\"Tag\": \"name=weight, inname=Weight, type=FLOAT, repetitiontype=REQUIRED\"},\n    {\n      \"Tag\": \"name=favPokemon, inname=FavPokemon, type=LIST, repetitiontype=OPTIONAL\",\n      \"Fields\": [\n        {\"Tag\": \"name=name, inname=PokeName, type=BYTE_ARRAY, convertedtype=UTF8, repetitiontype=REQUIRED\"},\n        {\"Tag\": \"name=coolness, inname=Coolness, type=FLOAT, repetitiontype=REQUIRED\"}\n      ]\n    }\n  ]\n}\n```\n\nA schema can be derived from a source file using https://github.com/xitongsys/parquet-go/tree/master/tool/parquet-tools:\n\n```sh\n./parquet-tools -cmd schema -file foo.parquet\n```",
      "name": "parquet",
      "plugin": true,
      "status": "deprecated",
      "summary": "Converts batches of documents to or from https://parquet.apache.org/docs/[Parquet files^].",
      "type": "processor",
      "version": "3.62.0"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether to extract BYTE_ARRAY and FIXED_LEN_BYTE_ARRAY values as strings rather than byte slices in all cases. Values with a logical type of UTF8 will automatically be extracted as strings irrespective of this field. Enabling this field makes serializing the data as JSON more intuitive as `[]byte` values are serialized as base64 encoded strings by default.",
            "is_deprecated": true,
            "kind": "scalar",
            "name": "byte_array_as_string",
            "type": "bool"
          },
          {
            "annotated_options": [
              [
                "v1",
                "No special handling of logical types"
              ],
              [
                "v2",
                "\n- TIMESTAMP - decodes as an RFC3339 string describing the time. If the `isAdjustedToUTC` flag is set to true in the parquet file, the time zone will be set to UTC. If it is set to false the time zone will be set to local time.\n- UUID - decodes as a string, i.e. `00112233-4455-6677-8899-aabbccddeeff`."
              ]
            ],
            "default": "v1",
            "description": "Whether to be smart about decoding logical types. In the Parquet format, logical types are stored as one of the standard physical types with some additional metadata describing the logical type. For example, UUIDs are stored in a FIXED_LEN_BYTE_ARRAY physical type, but there is metadata in the schema denoting that it is a UUID. By default, this logical type metadata will be ignored and values will be decoded directly from the physical type, which isn't always desirable. By enabling this option, logical types will be given special treatment and will decode into more useful values. The value for this field specifies a version, i.e. v0, v1... Any given version enables the logical type handling for that version and all versions below it, which allows the handling of new logical types to be introduced without breaking existing pipelines. We recommend enabling the newest version available of this feature when creating new pipelines.",
            "examples": [
              "v2"
            ],
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"v1\": true,\n  \"v2\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "handle_logical_types",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor uses https://github.com/parquet-go/parquet-go[https://github.com/parquet-go/parquet-go^], which is itself experimental. Therefore changes could be made into how this processor functions outside of major version releases.",
      "examples": [
        {
          "config": "\ninput:\n  aws_s3:\n    bucket: TODO\n    prefix: foos/\n    scanner:\n      to_the_end: {}\n    sqs:\n      url: TODO\n  processors:\n    - parquet_decode: {}\n\noutput:\n  file:\n    codec: lines\n    path: './foos/${! meta(\"s3_key\") }.jsonl'\n",
          "summary": "In this example we consume files from AWS S3 as they're written by listening onto an SQS queue for upload events. We make sure to use the `to_the_end` scanner which means files are read into memory in full, which then allows us to use a `parquet_decode` processor to expand each file into a batch of messages. Finally, we write the data out to local files as newline delimited JSON.",
          "title": "Reading Parquet Files from AWS S3"
        }
      ],
      "name": "parquet_decode",
      "plugin": true,
      "status": "experimental",
      "summary": "Decodes https://parquet.apache.org/docs/[Parquet files^] into a batch of structured messages.",
      "type": "processor",
      "version": "4.4.0"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "children": [
              {
                "description": "The name of the column.",
                "kind": "scalar",
                "name": "name",
                "type": "string"
              },
              {
                "description": "The type of the column, only applicable for leaf columns with no child fields. Some logical types can be specified here such as UTF8.",
                "is_optional": true,
                "kind": "scalar",
                "linter": "\nlet options = {\n  \"boolean\": true,\n  \"int32\": true,\n  \"int64\": true,\n  \"float\": true,\n  \"double\": true,\n  \"byte_array\": true,\n  \"utf8\": true,\n  \"timestamp\": true,\n  \"bson\": true,\n  \"enum\": true,\n  \"json\": true,\n  \"uuid\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
                "name": "type",
                "options": [
                  "BOOLEAN",
                  "INT32",
                  "INT64",
                  "FLOAT",
                  "DOUBLE",
                  "BYTE_ARRAY",
                  "UTF8",
                  "TIMESTAMP",
                  "BSON",
                  "ENUM",
                  "JSON",
                  "UUID"
                ],
                "type": "string"
              },
              {
                "default": false,
                "description": "Whether the field is repeated.",
                "kind": "scalar",
                "name": "repeated",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether the field is optional.",
                "kind": "scalar",
                "name": "optional",
                "type": "bool"
              },
              {
                "description": "A list of child fields.",
                "examples": [
                  [
                    {
                      "name": "foo",
                      "type": "INT64"
                    },
                    {
                      "name": "bar",
                      "type": "BYTE_ARRAY"
                    }
                  ]
                ],
                "is_optional": true,
                "kind": "array",
                "name": "fields",
                "type": "unknown"
              }
            ],
            "description": "Parquet schema.",
            "is_optional": true,
            "kind": "array",
            "name": "schema",
            "type": "object"
          },
          {
            "default": "",
            "description": "Optionally specify a metadata field containing a schema definition to use for encoding instead of a statically defined schema. For batches of messages, the first message's schema will be applied to all subsequent messages of the batch.",
            "kind": "scalar",
            "name": "schema_metadata",
            "type": "string"
          },
          {
            "default": "uncompressed",
            "description": "The default compression type to use for fields.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"uncompressed\": true,\n  \"snappy\": true,\n  \"gzip\": true,\n  \"brotli\": true,\n  \"zstd\": true,\n  \"lz4raw\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "default_compression",
            "options": [
              "uncompressed",
              "snappy",
              "gzip",
              "brotli",
              "zstd",
              "lz4raw"
            ],
            "type": "string"
          },
          {
            "default": "DELTA_LENGTH_BYTE_ARRAY",
            "description": "The default encoding type to use for fields. A custom default encoding is only necessary when consuming data with libraries that do not support `DELTA_LENGTH_BYTE_ARRAY` and is therefore best left unset where possible.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"delta_length_byte_array\": true,\n  \"plain\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "default_encoding",
            "options": [
              "DELTA_LENGTH_BYTE_ARRAY",
              "PLAIN"
            ],
            "type": "string",
            "version": "4.11.0"
          }
        ],
        "kind": "scalar",
        "linter": "root = if this.schema.or([]).length() == 0 && this.schema_metadata.or(\"\") == \"\" { \"either a schema or schema_metadata must be specified\" }",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor uses https://github.com/parquet-go/parquet-go[https://github.com/parquet-go/parquet-go^], which is itself experimental. Therefore changes could be made into how this processor functions outside of major version releases.\n",
      "examples": [
        {
          "config": "\noutput:\n  aws_s3:\n    bucket: TODO\n    path: 'stuff/${! timestamp_unix() }-${! uuid_v4() }.parquet'\n    batching:\n      count: 1000\n      period: 10s\n      processors:\n        - parquet_encode:\n            schema:\n              - name: id\n                type: INT64\n              - name: weight\n                type: DOUBLE\n              - name: content\n                type: BYTE_ARRAY\n            default_compression: zstd\n",
          "summary": "In this example we use the batching mechanism of an `aws_s3` output to collect a batch of messages in memory, which then converts it to a parquet file and uploads it.",
          "title": "Writing Parquet Files to AWS S3"
        }
      ],
      "name": "parquet_encode",
      "plugin": true,
      "status": "experimental",
      "summary": "Encodes https://parquet.apache.org/docs/[Parquet files^] from a batch of structured messages.",
      "type": "processor",
      "version": "4.4.0"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "description": "A common log <<formats, format>> to parse.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"syslog_rfc5424\": true,\n  \"syslog_rfc3164\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "format",
            "options": [
              "syslog_rfc5424",
              "syslog_rfc3164"
            ],
            "type": "string"
          },
          {
            "default": true,
            "description": "Still returns partially parsed messages even if an error occurs.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "best_effort",
            "type": "bool"
          },
          {
            "default": true,
            "description": "Also accept timestamps in rfc3339 format while parsing. Applicable to format `syslog_rfc3164`.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "allow_rfc3339",
            "type": "bool"
          },
          {
            "default": "current",
            "description": "Sets the strategy used to set the year for rfc3164 timestamps. Applicable to format `syslog_rfc3164`. When set to `current` the current year will be set, when set to an integer that value will be used. Leave this field empty to not set a default year at all.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "default_year",
            "type": "string"
          },
          {
            "default": "UTC",
            "description": "Sets the strategy to decide the timezone for rfc3164 timestamps. Applicable to format `syslog_rfc3164`. This value should follow the https://golang.org/pkg/time/#LoadLocation[time.LoadLocation^] format.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "default_timezone",
            "type": "string"
          },
          {
            "is_deprecated": true,
            "kind": "scalar",
            "name": "codec",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "footnotes": "\n== Codecs\n\nCurrently the only supported structured data codec is `json`.\n\n== Formats\n\n=== `syslog_rfc5424`\n\nAttempts to parse a log following the https://tools.ietf.org/html/rfc5424[Syslog RFC5424^] spec. The resulting structured document may contain any of the following fields:\n\n- `message` (string)\n- `timestamp` (string, RFC3339)\n- `facility` (int)\n- `severity` (int)\n- `priority` (int)\n- `version` (int)\n- `hostname` (string)\n- `procid` (string)\n- `appname` (string)\n- `msgid` (string)\n- `structureddata` (object)\n\n=== `syslog_rfc3164`\n\nAttempts to parse a log following the https://tools.ietf.org/html/rfc3164[Syslog rfc3164] spec. The resulting structured document may contain any of the following fields:\n\n- `message` (string)\n- `timestamp` (string, RFC3339)\n- `facility` (int)\n- `severity` (int)\n- `priority` (int)\n- `hostname` (string)\n- `procid` (string)\n- `appname` (string)\n- `msgid` (string)\n",
      "name": "parse_log",
      "plugin": true,
      "status": "stable",
      "summary": "Parses common log <<formats>> into <<codecs, structured data>>. This is easier and often much faster than xref:components:processors/grok.adoc[`grok`].",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "default": [],
        "kind": "array",
        "name": "",
        "type": "processor"
      },
      "description": "This processor is useful in situations where you want to collect several processors under a single resource identifier, whether it is for making your configuration easier to read and navigate, or for improving the testability of your configuration. The behavior of child processors will match exactly the behavior they would have under any other processors block.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - label: my_super_feature\n      processors:\n        - log:\n            message: \"Let's do something cool\"\n        - archive:\n            format: json_array\n        - mapping: root.items = this\n",
          "summary": "Imagine we have a collection of processors who cover a specific functionality. We could use this processor to group them together and make it easier to read and mock during testing by giving the whole block a label:",
          "title": "Grouped Processing"
        }
      ],
      "name": "processors",
      "plugin": true,
      "status": "stable",
      "summary": "A processor grouping several sub-processors.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "description": "The [operator](#operators) to execute",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"to_json\": true,\n  \"from_json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "options": [
              "to_json",
              "from_json"
            ],
            "type": "string"
          },
          {
            "description": "The fully qualified name of the protobuf message to convert to/from.",
            "kind": "scalar",
            "name": "message",
            "type": "string"
          },
          {
            "default": false,
            "description": "If `true`, the `from_json` operator discards fields that are unknown to the schema.",
            "kind": "scalar",
            "name": "discard_unknown",
            "type": "bool"
          },
          {
            "default": false,
            "description": "If `true`, the `to_json` operator deserializes fields exactly as named in schema file.",
            "kind": "scalar",
            "name": "use_proto_names",
            "type": "bool"
          },
          {
            "default": [],
            "description": "A list of directories containing .proto files, including all definitions required for parsing the target message. If left empty the current directory is used. Each directory listed will be walked with all found .proto files imported. Either this field or `bsr` must be populated.",
            "kind": "array",
            "name": "import_paths",
            "type": "string"
          },
          {
            "default": false,
            "description": "If `true`, the `to_json` operator deserializes enums as numerical values instead of string names.",
            "kind": "scalar",
            "name": "use_enum_numbers",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "Module to fetch from a Buf Schema Registry e.g. 'buf.build/exampleco/mymodule'.",
                "kind": "scalar",
                "name": "module",
                "type": "string"
              },
              {
                "default": "",
                "description": "Buf Schema Registry URL, leave blank to extract from module.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "url",
                "type": "string"
              },
              {
                "default": "",
                "description": "Buf Schema Registry server API key, can be left blank for a public registry.",
                "is_secret": true,
                "kind": "scalar",
                "name": "api_key",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "Version to retrieve from the Buf Schema Registry, leave blank for latest.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "version",
                "type": "string"
              }
            ],
            "default": [],
            "description": "Buf Schema Registry configuration. Either this field or `import_paths` must be populated. Note that this field is an array, and multiple BSR configurations can be provided.",
            "kind": "array",
            "name": "bsr",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "linter": "\nroot = match {\nthis.import_paths.type() == \"unknown\" && this.bsr.length() == 0 => [ \"at least one of `import_paths`and `bsr` must be set\" ],\nthis.import_paths.type() == \"array\" && this.import_paths.length() > 0 && this.bsr.length() > 0 => [ \"both `import_paths` and `bsr` can't be set simultaneously\" ],\n}",
        "name": "",
        "type": "object"
      },
      "description": "\nThe main functionality of this processor is to map to and from JSON documents, you can read more about JSON mapping of protobuf messages here: [https://developers.google.com/protocol-buffers/docs/proto3#json](https://developers.google.com/protocol-buffers/docs/proto3#json)\n\nUsing reflection for processing protobuf messages in this way is less performant than generating and using native code. Therefore when performance is critical it is recommended that you use Redpanda Connect plugins instead for processing protobuf messages natively, you can find an example of Redpanda Connect plugins at [https://github.com/redpanda-data/redpanda-connect-plugin-example](https://github.com/redpanda-data/redpanda-connect-plugin-example)\n\nThe processor will ignore any files that begin with a dot (\".\"g), a convention for hidden files, when loading protocol buffer definitions.\n== Operators\n\n=== `to_json`\n\nConverts protobuf messages into a generic JSON structure. This makes it easier to manipulate the contents of the document within Redpanda Connect.\n\n=== `from_json`\n\nAttempts to create a target protobuf message from a generic JSON structure.\n",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - protobuf:\n        operator: from_json\n        message: testing.Person\n        import_paths: [ testing/schema ]\n",
          "summary": "\nIf we have the following protobuf definition within a directory called `testing/schema`:\n\n```protobuf\nsyntax = \"proto3\";\npackage testing;\n\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Person {\n  string first_name = 1;\n  string last_name = 2;\n  string full_name = 3;\n  int32 age = 4;\n  int32 id = 5; // Unique ID number for this person.\n  string email = 6;\n\n  google.protobuf.Timestamp last_updated = 7;\n}\n```\n\nAnd a stream of JSON documents of the form:\n\n```json\n{\n\t\"firstName\": \"caleb\",\n\t\"lastName\": \"quaye\",\n\t\"email\": \"caleb@myspace.com\"\n}\n```\n\nWe can convert the documents into protobuf messages with the following config:",
          "title": "JSON to Protobuf using Schema from Disk"
        },
        {
          "config": "\npipeline:\n  processors:\n    - protobuf:\n        operator: to_json\n        message: testing.Person\n        import_paths: [ testing/schema ]\n",
          "summary": "\nIf we have the following protobuf definition within a directory called `testing/schema`:\n\n```protobuf\nsyntax = \"proto3\";\npackage testing;\n\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Person {\n  string first_name = 1;\n  string last_name = 2;\n  string full_name = 3;\n  int32 age = 4;\n  int32 id = 5; // Unique ID number for this person.\n  string email = 6;\n\n  google.protobuf.Timestamp last_updated = 7;\n}\n```\n\nAnd a stream of protobuf messages of the type `Person`, we could convert them into JSON documents of the format:\n\n```json\n{\n\t\"firstName\": \"caleb\",\n\t\"lastName\": \"quaye\",\n\t\"email\": \"caleb@myspace.com\"\n}\n```\n\nWith the following config:",
          "title": "Protobuf to JSON using Schema from Disk"
        },
        {
          "config": "\npipeline:\n  processors:\n    - protobuf:\n        operator: from_json\n        message: testing.Person\n        bsr:\n          - module: buf.build/exampleco/mymodule\n            api_key: xxx\n",
          "summary": "\nIf we have the following protobuf definition within a BSR module hosted at `buf.build/exampleco/mymodule`:\n\n```protobuf\nsyntax = \"proto3\";\npackage testing;\n\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Person {\n  string first_name = 1;\n  string last_name = 2;\n  string full_name = 3;\n  int32 age = 4;\n  int32 id = 5; // Unique ID number for this person.\n  string email = 6;\n\n  google.protobuf.Timestamp last_updated = 7;\n}\n```\n\nAnd a stream of JSON documents of the form:\n\n```json\n{\n\t\"firstName\": \"caleb\",\n\t\"lastName\": \"quaye\",\n\t\"email\": \"caleb@myspace.com\"\n}\n```\n\nWe can convert the documents into protobuf messages with the following config:",
          "title": "JSON to Protobuf using Buf Schema Registry"
        },
        {
          "config": "\npipeline:\n  processors:\n    - protobuf:\n        operator: to_json\n        message: testing.Person\n        bsr:\n          - module: buf.build/exampleco/mymodule\n            api_key: xxxx\n",
          "summary": "\nIf we have the following protobuf definition within a BSR module hosted at `buf.build/exampleco/mymodule`:\n```protobuf\nsyntax = \"proto3\";\npackage testing;\n\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Person {\n  string first_name = 1;\n  string last_name = 2;\n  string full_name = 3;\n  int32 age = 4;\n  int32 id = 5; // Unique ID number for this person.\n  string email = 6;\n\n  google.protobuf.Timestamp last_updated = 7;\n}\n```\n\nAnd a stream of protobuf messages of the type `Person`, we could convert them into JSON documents of the format:\n\n```json\n{\n\t\"firstName\": \"caleb\",\n\t\"lastName\": \"quaye\",\n\t\"email\": \"caleb@myspace.com\"\n}\n```\n\nWith the following config:",
          "title": "Protobuf to JSON using Buf Schema Registry"
        }
      ],
      "name": "protobuf",
      "plugin": true,
      "status": "stable",
      "summary": "\nPerforms conversions to or from a protobuf message. This processor uses reflection, meaning conversions can be made directly from the target .proto files.\n",
      "type": "processor"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "description": "The gRPC host of the Qdrant server.",
            "examples": [
              "localhost:6334",
              "xyz-example.eu-central.aws.cloud.qdrant.io:6334"
            ],
            "kind": "scalar",
            "name": "grpc_host",
            "type": "string"
          },
          {
            "default": "",
            "description": "The Qdrant API token for authentication. Defaults to an empty string.",
            "is_secret": true,
            "kind": "scalar",
            "name": "api_token",
            "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "TLS(HTTPS) config to use when connecting",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The name of the collection in Qdrant.",
            "interpolated": true,
            "kind": "scalar",
            "name": "collection_name",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "The mapping to extract the search vector from the document.",
            "examples": [
              "root = [1.2, 0.5, 0.76]",
              "root = this.vector",
              "root = [[0.352,0.532,0.532,0.234],[0.352,0.532,0.532,0.234]]",
              "root = {\"some_sparse\": {\"indices\":[23,325,532],\"values\":[0.352,0.532,0.532]}}",
              "root = {\"some_multi\": [[0.352,0.532,0.532,0.234],[0.352,0.532,0.532,0.234]]}",
              "root = {\"some_dense\": [0.352,0.532,0.532,0.234]}"
            ],
            "kind": "scalar",
            "name": "vector_mapping",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "Additional filtering to perform on the results. The mapping should return a valid filter (using the proto3 encoded form) in qdrant. See the https://qdrant.tech/documentation/concepts/filtering/[^Qdrant documentation] for examples.",
            "examples": [
              "\nroot.must = [\n\t{\"has_id\":{\"has_id\":[{\"num\": 8}, { \"uuid\":\"1234-5678-90ab-cdef\" }]}},\n\t{\"field\":{\"key\": \"city\", \"match\": {\"text\": \"London\"}}},\n]\n",
              "\nroot.must = [\n\t{\"field\":{\"key\": \"city\", \"match\": {\"text\": \"London\"}}},\n]\nroot.must_not = [\n\t{\"field\":{\"color\": \"city\", \"match\": {\"text\": \"red\"}}},\n]\n"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "filter",
            "type": "string"
          },
          {
            "default": [],
            "description": "The fields to include or exclude in returned result based on the `payload_filter`.",
            "kind": "array",
            "name": "payload_fields",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "exclude",
                "Exclude the payload fields specified in `payload_fields`."
              ],
              [
                "include",
                "Include the payload fields specified in `payload_fields`."
              ]
            ],
            "default": "include",
            "description": "The way the fields in `payload_fields` are filtered in the result.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"exclude\": true,\n  \"include\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "payload_filter",
            "type": "string"
          },
          {
            "default": 10,
            "description": "The maximum number of points to return.",
            "kind": "scalar",
            "name": "limit",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "qdrant",
      "plugin": true,
      "status": "experimental",
      "summary": "Query items within a https://qdrant.tech/[Qdrant^] collection.",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The target xref:components:rate_limits/about.adoc[`rate_limit` resource].",
            "kind": "scalar",
            "name": "resource",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "rate_limit",
      "plugin": true,
      "status": "stable",
      "summary": "Throttles the throughput of a pipeline according to a specified xref:components:rate_limits/about.adoc[`rate_limit`] resource. Rate limits are shared across components and therefore apply globally to all processing pipelines.",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "The command to execute.",
            "examples": [
              "scard",
              "incrby",
              "${! meta(\"command\") }"
            ],
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "command",
            "type": "string",
            "version": "4.3.0"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of arguments required for the specified Redis command.",
            "examples": [
              "root = [ this.key ]",
              "root = [ meta(\"kafka_key\"), this.count ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string",
            "version": "4.3.0"
          },
          {
            "annotated_options": [
              [
                "incrby",
                "Increments the number stored at `key` by the message content. If the key does not exist, it is set to `0` before performing the operation. Returns the value of `key` after the increment."
              ],
              [
                "keys",
                "Returns an array of strings containing all the keys that match the pattern specified by the `key` field."
              ],
              [
                "sadd",
                "Adds a new member to a set. Returns `1` if the member was added."
              ],
              [
                "scard",
                "Returns the cardinality of a set, or `0` if the key does not exist."
              ]
            ],
            "description": "The operator to apply.",
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"incrby\": true,\n  \"keys\": true,\n  \"sadd\": true,\n  \"scard\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "type": "string"
          },
          {
            "description": "A key to use for the target operator.",
            "interpolated": true,
            "is_deprecated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "key",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before abandoning a request.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "int"
          },
          {
            "default": "500ms",
            "description": "The time to wait before consecutive retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_period",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n  this.exists(\"operator\") == this.exists(\"command\") => [ \"one of 'operator' (old style) or 'command' (new style) fields must be specified\" ]\n  this.exists(\"args_mapping\") && this.exists(\"operator\") => [ \"field args_mapping is invalid with an operator set\" ],\n}",
        "name": "",
        "type": "object"
      },
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - redis:\n              url: TODO\n              command: scard\n              args_mapping: 'root = [ meta(\"set_key\") ]'\n        result_map: 'root.cardinality = this'\n",
          "summary": "If given payloads containing a metadata field `set_key` it's possible to query and store the cardinality of the set for each message using a xref:components:processors/branch.adoc[`branch` processor] in order to augment rather than replace the message contents:",
          "title": "Querying Cardinality"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - redis:\n              url: TODO\n              command: incrby\n              args_mapping: 'root = [ this.name, this.friends_visited ]'\n        result_map: 'root.total = this'\n",
          "summary": "If we have JSON data containing number of friends visited during covid 19:\n\n```json\n{\"name\":\"ash\",\"month\":\"feb\",\"year\":2019,\"friends_visited\":10}\n{\"name\":\"ash\",\"month\":\"apr\",\"year\":2019,\"friends_visited\":-2}\n{\"name\":\"bob\",\"month\":\"feb\",\"year\":2019,\"friends_visited\":3}\n{\"name\":\"bob\",\"month\":\"apr\",\"year\":2019,\"friends_visited\":1}\n```\n\nWe can add a field that contains the running total number of friends visited:\n\n```json\n{\"name\":\"ash\",\"month\":\"feb\",\"year\":2019,\"friends_visited\":10,\"total\":10}\n{\"name\":\"ash\",\"month\":\"apr\",\"year\":2019,\"friends_visited\":-2,\"total\":8}\n{\"name\":\"bob\",\"month\":\"feb\",\"year\":2019,\"friends_visited\":3,\"total\":3}\n{\"name\":\"bob\",\"month\":\"apr\",\"year\":2019,\"friends_visited\":1,\"total\":4}\n```\n\nUsing the `incrby` command:",
          "title": "Running Total"
        }
      ],
      "name": "redis",
      "plugin": true,
      "status": "stable",
      "summary": "Performs actions against Redis that aren't possible using a xref:components:processors/cache.adoc[`cache`] processor. Actions are\nperformed for each message and the message contents are replaced with the result. In order to merge the result into the original message compose this processor within a xref:components:processors/branch.adoc[`branch` processor].",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "description": "A script to use for the target operator. It has precedence over the 'command' field.",
            "examples": [
              "return redis.call('set', KEYS[1], ARGV[1])"
            ],
            "kind": "scalar",
            "name": "script",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of arguments required for the specified Redis script.",
            "examples": [
              "root = [ this.key ]",
              "root = [ meta(\"kafka_key\"), \"hardcoded_value\" ]"
            ],
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of keys matching in size to the number of arguments required for the specified Redis script.",
            "examples": [
              "root = [ this.key ]",
              "root = [ meta(\"kafka_key\"), this.count ]"
            ],
            "kind": "scalar",
            "name": "keys_mapping",
            "type": "string"
          },
          {
            "default": 3,
            "description": "The maximum number of retries before abandoning a request.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retries",
            "type": "int"
          },
          {
            "default": "500ms",
            "description": "The time to wait before consecutive retry attempts.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "retry_period",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Actions are performed for each message and the message contents are replaced with the result.\n\nIn order to merge the result into the original message compose this processor within a xref:components:processors/branch.adoc[`branch` processor].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - redis_script:\n        url: TODO\n        script: |\n          local value = redis.call(\"ZRANGE\", KEYS[1], '0', '0')\n\n          if next(elements) == nil then\n            return ''\n          end\n\n          redis.call(\"ZADD\", \"XX\", KEYS[1], ARGV[1], value)\n\n          return value\n        keys_mapping: 'root = [ meta(\"key\") ]'\n        args_mapping: 'root = [ timestamp_unix_nano() ]'\n",
          "summary": "The following example will use a script execution to get next element from a sorted set and set its score with timestamp unix nano value.",
          "title": "Running a script"
        }
      ],
      "name": "redis_script",
      "plugin": true,
      "status": "beta",
      "summary": "Performs actions against Redis using https://redis.io/docs/manual/programmability/eval-intro/[LUA scripts^].",
      "type": "processor",
      "version": "4.11.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The path of the target WASM module to execute.",
            "kind": "scalar",
            "name": "module_path",
            "type": "string"
          },
          {
            "description": "An optional key to populate for each message.",
            "interpolated": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "input_key",
            "type": "string"
          },
          {
            "description": "An optional name of metadata for an output message key.",
            "is_optional": true,
            "kind": "scalar",
            "name": "output_key",
            "type": "string"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) metadata values should be added to messages as headers.",
            "is_optional": true,
            "kind": "scalar",
            "name": "input_headers",
            "type": "object"
          },
          {
            "children": [
              {
                "default": [],
                "description": "Provide a list of explicit metadata key prefixes to match against.",
                "examples": [
                  [
                    "foo_",
                    "bar_"
                  ],
                  [
                    "kafka_"
                  ],
                  [
                    "content-"
                  ]
                ],
                "kind": "array",
                "name": "include_prefixes",
                "type": "string"
              },
              {
                "default": [],
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                "examples": [
                  [
                    ".*"
                  ],
                  [
                    "_timestamp_unix$"
                  ]
                ],
                "kind": "array",
                "name": "include_patterns",
                "type": "string"
              }
            ],
            "description": "Determine which (if any) message headers should be added to the output as metadata.",
            "is_optional": true,
            "kind": "scalar",
            "name": "output_metadata",
            "type": "object"
          },
          {
            "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
            "examples": [
              "${! timestamp_unix() }",
              "${! metadata(\"kafka_timestamp_ms\") }"
            ],
            "interpolated": true,
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "timestamp",
            "type": "string"
          },
          {
            "default": "10s",
            "description": "The maximum period of time for a message to be processed",
            "is_advanced": true,
            "kind": "scalar",
            "name": "timeout",
            "type": "string"
          },
          {
            "default": 1600,
            "description": "The maximum amount of wasm memory pages (64KiB) that an individual wasm module instance can use",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_memory_pages",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor executes a Redpanda Data Transform WebAssembly module, calling OnRecordWritten for each message being processed.\n\nYou can find out about how transforms work here: https://docs.redpanda.com/current/develop/data-transforms/how-transforms-work/[https://docs.redpanda.com/current/develop/data-transforms/how-transforms-work/^]\n",
      "name": "redpanda_data_transform",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a Redpanda Data Transform as a processor",
      "type": "processor",
      "version": "4.31.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": "",
        "kind": "scalar",
        "name": "",
        "type": "string"
      },
      "description": "\nThis processor allows you to reference the same configured processor resource in multiple places, and can also tidy up large nested configs. For example, the config:\n\n```yaml\npipeline:\n  processors:\n    - mapping: |\n        root.message = this\n        root.meta.link_count = this.links.length()\n        root.user.age = this.user.age.number()\n```\n\nIs equivalent to:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo_proc\n\nprocessor_resources:\n  - label: foo_proc\n    mapping: |\n      root.message = this\n      root.meta.link_count = this.links.length()\n      root.user.age = this.user.age.number()\n```\n\nYou can find out more about resources in xref:configuration:resources.adoc[]",
      "name": "resource",
      "plugin": true,
      "status": "stable",
      "summary": "Resource is a processor type that runs a processor resource identified by its label.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "children": [
              {
                "default": "500ms",
                "description": "The initial period to wait between retry attempts.",
                "examples": [
                  "50ms",
                  "1s"
                ],
                "kind": "scalar",
                "name": "initial_interval",
                "type": "string"
              },
              {
                "default": "10s",
                "description": "The maximum period to wait between retry attempts",
                "examples": [
                  "5s",
                  "1m"
                ],
                "kind": "scalar",
                "name": "max_interval",
                "type": "string"
              },
              {
                "default": "1m",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted. Setting this value to a zeroed duration (such as `0s`) will result in unbounded retries.",
                "examples": [
                  "1m",
                  "1h"
                ],
                "kind": "scalar",
                "name": "max_elapsed_time",
                "type": "string"
              }
            ],
            "description": "Determine time intervals and cut offs for retry attempts.",
            "kind": "scalar",
            "name": "backoff",
            "type": "object"
          },
          {
            "description": "A list of xref:components:processors/about.adoc[processors] to execute on each message.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          },
          {
            "default": false,
            "description": "When processing batches of messages these batches are ignored and the processors apply to each message sequentially. However, when this field is set to `true` each message will be processed in parallel. Caution should be made to ensure that batch sizes do not surpass a point where this would cause resource (CPU, memory, API limits) contention.",
            "kind": "scalar",
            "name": "parallel",
            "type": "bool"
          },
          {
            "default": 0,
            "description": "The maximum number of retry attempts before the request is aborted. Setting this value to `0` will result in unbounded number of retries.",
            "kind": "scalar",
            "name": "max_retries",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nExecutes child processors and if a resulting message is errored then, after a specified backoff period, the same original message will be attempted again through those same processors. If the child processors result in more than one message then the retry mechanism will kick in if _any_ of the resulting messages are errored.\n\nIt is important to note that any mutations performed on the message during these child processors will be discarded for the next retry, and therefore it is safe to assume that each execution of the child processors will always be performed on the data as it was when it first reached the retry processor.\n\nBy default the retry backoff has a specified <<backoffmax_elapsed_time,`max_elapsed_time`>>, if this time period is reached during retries and an error still occurs these errored messages will proceed through to the next processor after the retry (or your outputs). Normal xref:configuration:error_handling.adoc[error handling patterns] can be used on these messages.\n\nIn order to avoid permanent loops any error associated with messages as they first enter a retry processor will be cleared.\n\n== Metadata\n\nThis processor adds the following metadata fields to each message:\n\n```text\n- retry_count - The number of retry attempts.\n- backoff_duration - The total time (in nanoseconds) elapsed while performing retries.\n```\n\n[CAUTION]\n.Batching\n====\nIf you wish to wrap a batch-aware series of processors then take a look at the <<batching, batching section>>.\n====\n",
      "examples": [
        {
          "config": "\ninput:\n  generate:\n    interval: 1s\n    mapping: 'root.noise = [ \"woof\", \"meow\", \"moo\", \"quack\" ].index(random_int(min: 0, max: 3))'\n\npipeline:\n  processors:\n    - retry:\n        backoff:\n          initial_interval: 100ms\n          max_interval: 5s\n          max_elapsed_time: 0s\n        processors:\n          - http:\n              url: 'http://example.com/try/not/to/dox/taz'\n              verb: POST\n\noutput:\n  # Drop everything because it's junk data, I don't want it lol\n  drop: {}\n",
          "summary": "\nHere we have a config where I generate animal noises and send them to Taz via HTTP. Taz has a tendency to stop his servers whenever I dispatch my animals upon him, and therefore these HTTP requests sometimes fail. However, I have the retry processor and with this super power I can specify a back off policy and it will ensure that for each animal noise the HTTP processor is attempted until either it succeeds or my Redpanda Connect instance is stopped.\n\nI even go as far as to zero-out the maximum elapsed time field, which means that for each animal noise I will wait indefinitely, because I really really want Taz to receive every single animal noise that he is entitled to.",
          "title": "Stop ignoring me Taz"
        }
      ],
      "footnotes": "\n== Batching\n\nWhen messages are batched the child processors of a retry are executed for each individual message in isolation, performed serially by default but in parallel when the field <<parallel, `parallel`>> is set to `true`. This is an intentional limitation of the retry processor and is done in order to ensure that errors are correctly associated with a given input message. Otherwise, the archiving, expansion, grouping, filtering and so on of the child processors could obfuscate this relationship.\n\nIf the target behavior of your retried processors is \"batch aware\", in that you wish to perform some processing across the entire batch of messages and repeat it in the event of errors, you can use an xref:components:processors/archive.adoc[`archive` processor] to collapse the batch into an individual message. Then, within these child processors either perform your batch aware processing on the archive, or use an xref:components:processors/unarchive.adoc[`unarchive` processor] in order to expand the single message back out into a batch.\n\nFor example, if the retry processor were being used to wrap an HTTP request where the payload data is a batch archived into a JSON array it should look something like this:\n\n```yaml\npipeline:\n  processors:\n    - archive:\n        format: json_array\n    - retry:\n        processors:\n          - http:\n              url: example.com/nope\n              verb: POST\n    - unarchive:\n        format: json_array\n```\n",
      "name": "retry",
      "plugin": true,
      "status": "beta",
      "summary": "Attempts to execute a series of child processors until success.",
      "type": "processor",
      "version": "4.27.0"
    },
    {
      "categories": [
        "Parsing",
        "Integration"
      ],
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether Avro messages should be decoded into normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^]. If `true` the schema returned from the subject should be decoded as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard json^] instead of as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[avro json^]. There is a https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in goavro^], the https://github.com/linkedin/goavro[underlining library used for avro serialization^], that explains in more detail the difference between the standard json and avro json.",
            "is_advanced": true,
            "is_deprecated": true,
            "kind": "scalar",
            "name": "avro_raw_json",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "Whether avro messages should be decoded into normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[JSON as specified in the Avro Spec^].\n\nFor example, if there is a union schema `[\"null\", \"string\", \"Foo\"]` where `Foo` is a record name, with raw_unions as false (the default) you get:\n- `null` as `null`;\n- the string `\"a\"` as `{\"string\": \"a\"}`; and\n- a `Foo` instance as `{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nWhen raw_unions is set to true then the above union schema is decoded as the following:\n- `null` as `null`;\n- the string `\"a\"` as `\"a\"`; and\n- a `Foo` instance as `{...}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n",
                "is_optional": true,
                "kind": "scalar",
                "name": "raw_unions",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether logical types should be preserved or transformed back into their primitive type. By default, decimals are decoded as raw bytes and timestamps are decoded as plain integers. Setting this field to true keeps decimal types as numbers in bloblang and timestamps as time values.",
                "kind": "scalar",
                "name": "preserve_logical_types",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Only valid if preserve_logical_types is true. This decodes various Kafka Connect types into their bloblang equivalents when not representable by standard logical types according to the Avro standard.\n\nTypes that are currently translated:\n\n.Debezium Custom Temporal Types\n|===\n|Type Name |Bloblang Type |Description\n\n|io.debezium.time.Date\n|timestamp\n|Date without time (days since epoch)\n\n|io.debezium.time.Timestamp\n|timestamp\n|Timestamp without timezone (milliseconds since epoch)\n\n|io.debezium.time.MicroTimestamp\n|timestamp\n|Timestamp with microsecond precision\n\n|io.debezium.time.NanoTimestamp\n|timestamp\n|Timestamp with nanosecond precision\n\n|io.debezium.time.ZonedTimestamp\n|timestamp\n|Timestamp with timezone (ISO-8601 format)\n\n|io.debezium.time.Year\n|timestamp at January 1st at 00:00:00\n|Year value\n\n|io.debezium.time.Time\n|timestamp at the unix epoch\n|Time without date (milliseconds past midnight)\n\n|io.debezium.time.MicroTime\n|timestamp at the unix epoch\n|Time with microsecond precision\n\n|io.debezium.time.NanoTime\n|timestamp at the unix epoch\n|Time with nanosecond precision\n\n|===\n\n",
                "kind": "scalar",
                "name": "translate_kafka_connect_types",
                "type": "bool"
              },
              {
                "bloblang": true,
                "description": "A custom mapping to apply to Avro schemas JSON representation. This is useful to transform custom types emitted by other tools into standard avro.",
                "examples": [
                  "\nmap isDebeziumTimestampType {\n  root = this.type == \"long\" && this.\"connect.name\" == \"io.debezium.time.Timestamp\" && !this.exists(\"logicalType\")\n}\nmap debeziumTimestampToAvroTimestamp {\n  let mapped_fields = this.fields.or([]).map_each(item -> item.apply(\"debeziumTimestampToAvroTimestamp\"))\n  root = match {\n    this.type == \"record\" => this.assign({\"fields\": $mapped_fields})\n    this.type.type() == \"array\" => this.assign({\"type\": this.type.map_each(item -> item.apply(\"debeziumTimestampToAvroTimestamp\"))})\n    # Add a logical type so that it's decoded as a timestamp instead of a long.\n    this.type.type() == \"object\" && this.type.apply(\"isDebeziumTimestampType\") => this.merge({\"type\":{\"logicalType\": \"timestamp-millis\"}})\n    _ => this\n  }\n}\nroot = this.apply(\"debeziumTimestampToAvroTimestamp\")\n"
                ],
                "is_advanced": true,
                "is_optional": true,
                "kind": "scalar",
                "name": "mapping",
                "type": "string"
              },
              {
                "description": "Optionally store the schema used to decode messages as a metadata field under the given name. This field can later be referenced in other components such as a `parquet_encode` processor in order to automatically infer their schema.",
                "is_optional": true,
                "kind": "scalar",
                "name": "store_schema_metadata",
                "type": "string"
              }
            ],
            "description": "Configuration for how to decode schemas that are of type AVRO.",
            "kind": "scalar",
            "name": "avro",
            "type": "object"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Use proto field name instead of lowerCamelCase name.",
                "kind": "scalar",
                "name": "use_proto_names",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Emits enum values as numbers.",
                "kind": "scalar",
                "name": "use_enum_numbers",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to emit unpopulated fields. It does not emit unpopulated oneof fields or unpopulated extension fields.",
                "kind": "scalar",
                "name": "emit_unpopulated",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to emit default-valued primitive fields, empty lists, and empty maps. emit_unpopulated takes precedence over emit_default_values ",
                "kind": "scalar",
                "name": "emit_default_values",
                "type": "bool"
              }
            ],
            "description": "Configuration for how to decode schemas that are of type PROTOBUF.",
            "kind": "scalar",
            "name": "protobuf",
            "type": "object"
          },
          {
            "default": "10m",
            "description": "The duration after which a schema is considered stale and will be removed from the cache.",
            "examples": [
              "1h",
              "5m"
            ],
            "kind": "scalar",
            "name": "cache_duration",
            "type": "string"
          },
          {
            "description": "The base URL of the schema registry service.",
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "If set, this schema ID will be used when a message's schema header cannot be read (ErrBadHeader). If not set, schema header errors will be returned.",
            "is_optional": true,
            "kind": "scalar",
            "name": "default_schema_id",
            "type": "int"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object",
            "version": "4.7.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object",
            "version": "4.7.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object",
            "version": "4.7.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nDecodes messages automatically from a schema stored within a https://docs.confluent.io/platform/current/schema-registry/index.html[Confluent Schema Registry service^] by extracting a schema ID from the message and obtaining the associated schema from the registry. If a message fails to match against the schema then it will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].\n\nAvro, Protobuf and Json schemas are supported, all are capable of expanding from schema references as of v4.22.0.\n\n== Avro JSON format\n\nThis processor creates documents formatted as https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^] when decoding with Avro schemas. In this format the value of a union is encoded in JSON as follows:\n\n- if its type is `null`, then it is encoded as a JSON `null`;\n- otherwise it is encoded as a JSON object with one name/value pair whose name is the type's name and whose value is the recursively encoded value. For Avro's named types (record, fixed or enum) the user-specified name is used, for other types the type name is used.\n\nFor example, the union schema `[\"null\",\"string\",\"Foo\"]`, where `Foo` is a record name, would encode:\n\n- `null` as `null`;\n- the string `\"a\"` as `{\"string\": \"a\"}`; and\n- a `Foo` instance as `{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nHowever, it is possible to instead create documents in https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard/raw JSON format^] by setting the field <<avro_raw_json, `avro_raw_json`>> to `true`.\n\n== Protobuf format\n\nThis processor decodes protobuf messages to JSON documents, you can read more about JSON mapping of protobuf messages here: https://developers.google.com/protocol-buffers/docs/proto3#json\n\n== Metadata\n\nThis processor also adds the following metadata to each outgoing message:\n\nschema_id: the ID of the schema in the schema registry that was associated with the message.\n",
      "name": "schema_registry_decode",
      "plugin": true,
      "status": "beta",
      "summary": "Automatically decodes and validates messages with schemas from a Confluent Schema Registry service.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing",
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The base URL of the schema registry service.",
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "description": "The schema subject to derive schemas from.",
            "examples": [
              "foo",
              "${! meta(\"kafka_topic\") }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "subject",
            "type": "string"
          },
          {
            "default": "10m",
            "description": "The period after which a schema is refreshed for each subject, this is done by polling the schema registry service.",
            "examples": [
              "60s",
              "1h"
            ],
            "kind": "scalar",
            "name": "refresh_period",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether messages encoded in Avro format should be parsed as normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^]. If `true` the schema returned from the subject should be parsed as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard json^] instead of as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[avro json^]. There is a https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in goavro^], the https://github.com/linkedin/goavro[underlining library used for avro serialization^], that explains in more detail the difference between standard json and avro json.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "avro_raw_json",
            "type": "bool",
            "version": "3.59.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use OAuth version 1 in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A value used to identify the client to the service provider.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "consumer_key",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret used to establish ownership of the consumer key.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "consumer_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "A value used to gain access to the protected resources on behalf of the user.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "access_token",
                "type": "string"
              },
              {
                "default": "",
                "description": "A secret provided in order to establish ownership of a given access token.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "access_token_secret",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify open authentication via OAuth version 1.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "oauth",
            "type": "object",
            "version": "4.7.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use basic authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A username to authenticate as.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "username",
                "type": "string"
              },
              {
                "default": "",
                "description": "A password to authenticate with.",
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "password",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              }
            ],
            "description": "Allows you to specify basic authentication.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "basic_auth",
            "type": "object",
            "version": "4.7.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to use JWT authentication in requests.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": "",
                "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "private_key_file",
                "type": "string"
              },
              {
                "default": "",
                "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "signing_method",
                "type": "string"
              },
              {
                "default": {},
                "description": "A value used to identify the claims that issued the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "claims",
                "type": "unknown"
              },
              {
                "default": {},
                "description": "Add optional key/value headers to the JWT.",
                "is_advanced": true,
                "kind": "map",
                "name": "headers",
                "type": "unknown"
              }
            ],
            "description": "BETA: Allows you to specify JWT authentication.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "jwt",
            "type": "object",
            "version": "4.7.0"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nEncodes messages automatically from schemas obtains from a https://docs.confluent.io/platform/current/schema-registry/index.html[Confluent Schema Registry service^] by polling the service for the latest schema version for target subjects.\n\nIf a message fails to encode under the schema then it will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].\n\nAvro, Protobuf and Json schemas are supported, all are capable of expanding from schema references as of v4.22.0.\n\n== Avro JSON format\n\nBy default this processor expects documents formatted as https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^] when encoding with Avro schemas. In this format the value of a union is encoded in JSON as follows:\n\n- if its type is `null`, then it is encoded as a JSON `null`;\n- otherwise it is encoded as a JSON object with one name/value pair whose name is the type's name and whose value is the recursively encoded value. For Avro's named types (record, fixed or enum) the user-specified name is used, for other types the type name is used.\n\nFor example, the union schema `[\"null\",\"string\",\"Foo\"]`, where `Foo` is a record name, would encode:\n\n- `null` as `null`;\n- the string `\"a\"` as `\\{\"string\": \"a\"}`; and\n- a `Foo` instance as `\\{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nHowever, it is possible to instead consume documents in https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard/raw JSON format^] by setting the field <<avro_raw_json, `avro_raw_json`>> to `true`.\n\n=== Known issues\n\nImportant! There is an outstanding issue in the https://github.com/linkedin/goavro[avro serializing library^] that Redpanda Connect uses which means it https://github.com/linkedin/goavro/issues/252[doesn't encode logical types correctly^]. It's still possible to encode logical types that are in-line with the spec if `avro_raw_json` is set to true, though now of course non-logical types will not be in-line with the spec.\n\n== Protobuf format\n\nThis processor encodes protobuf messages either from any format parsed within Redpanda Connect (encoded as JSON by default), or from raw JSON documents, you can read more about JSON mapping of protobuf messages here: https://developers.google.com/protocol-buffers/docs/proto3#json\n\n=== Multiple message support\n\nWhen a target subject presents a protobuf schema that contains multiple messages it becomes ambiguous which message definition a given input data should be encoded against. In such scenarios Redpanda Connect will attempt to encode the data against each of them and select the first to successfully match against the data, this process currently *ignores all nested message definitions*. In order to speed up this exhaustive search the last known successful message will be attempted first for each subsequent input.\n\nWe will be considering alternative approaches in future so please https://redpanda.com/slack[get in touch^] with thoughts and feedback.\n",
      "name": "schema_registry_encode",
      "plugin": true,
      "status": "beta",
      "summary": "Automatically encodes and validates messages with schemas from a Confluent Schema Registry service.",
      "type": "processor",
      "version": "3.58.0"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": [],
            "description": "An array of message indexes of a batch. Indexes can be negative, and if so the part will be selected from the end counting backwards starting from -1.",
            "kind": "array",
            "name": "parts",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe selected parts are added to the new message batch in the same order as the selection array. E.g. with 'parts' set to [ 2, 0, 1 ] and the message parts [ '0', '1', '2', '3' ], the output will be [ '2', '0', '1' ].\n\nIf none of the selected parts exist in the input batch (resulting in an empty output message) the batch is dropped entirely.\n\nMessage indexes can be negative, and if so the part will be selected from the end counting backwards starting from -1. E.g. if index = -1 then the selected part will be the last part of the message, if index = -2 then the part before the last element with be selected, and so on.\n\nThis processor is only applicable to xref:configuration:batching.adoc[batched messages].",
      "name": "select_parts",
      "plugin": true,
      "status": "stable",
      "summary": "Cherry pick a set of messages from a batch by their index. Indexes larger than the number of messages are simply ignored.",
      "type": "processor"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": "",
            "description": "The DSN address to send sentry events to. If left empty, then SENTRY_DSN is used.",
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "A message to set on the sentry event",
            "examples": [
              "webhook event received",
              "failed to find product in database: ${! error() }"
            ],
            "interpolated": true,
            "kind": "scalar",
            "name": "message",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A mapping that must evaluate to an object-of-objects or `deleted()`. If this mapping produces a value, then it is set on a sentry event as additional context.",
            "examples": [
              "root = {\"order\": {\"product_id\": \"P93174\", \"quantity\": 5}}",
              "root = deleted()"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "context",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A mapping that must evaluate to an object. If this mapping produces a value, then it is set on a sentry event as extras.",
            "examples": [
              "root.foo = \"bar\"",
              "root = this.without(\"password\")"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "extras",
            "type": "string"
          },
          {
            "description": "Sets key/value string tags on an event. Unlike context, these are indexed and searchable on Sentry but have length limitations.",
            "interpolated": true,
            "is_optional": true,
            "kind": "map",
            "name": "tags",
            "type": "string"
          },
          {
            "default": "",
            "description": "The environment to be sent with events. If left empty, then SENTRY_ENVIRONMENT is used.",
            "kind": "scalar",
            "name": "environment",
            "type": "string"
          },
          {
            "default": "",
            "description": "The version of the code deployed to an environment. If left empty, then the Sentry client will attempt to detect the release from the environment.",
            "kind": "scalar",
            "name": "release",
            "type": "string"
          },
          {
            "default": "INFO",
            "description": "Sets the level on sentry events similar to logging levels.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"debug\": true,\n  \"info\": true,\n  \"warn\": true,\n  \"error\": true,\n  \"fatal\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "level",
            "options": [
              "DEBUG",
              "INFO",
              "WARN",
              "ERROR",
              "FATAL"
            ],
            "type": "string"
          },
          {
            "default": "async",
            "description": "Determines how events are sent. A sync transport will block when sending each event until a response is received from the Sentry server. The recommended async transport will enqueue events in a buffer and send them in the background.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"async\": true,\n  \"sync\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "transport_mode",
            "options": [
              "async",
              "sync"
            ],
            "type": "string"
          },
          {
            "default": "5s",
            "description": "The duration to wait when closing the processor to flush any remaining enqueued events.",
            "kind": "scalar",
            "name": "flush_timeout",
            "type": "string"
          },
          {
            "default": 1,
            "description": "The rate at which events are sent to the server. A value of 0 disables capturing sentry events entirely. A value of 1 results in sending all events to Sentry. Any value in between results sending some percentage of events.",
            "kind": "scalar",
            "linter": "root = if this < 0 || this > 1 { [\"sampling rate must be between 0.0 and 1.0\" ] }",
            "name": "sampling_rate",
            "type": "float"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "sentry_capture",
      "plugin": true,
      "status": "experimental",
      "summary": "Captures log events from messages and submits them to https://sentry.io/[Sentry^].",
      "type": "processor",
      "version": "4.16.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The Slack Bot User OAuth token to use.",
            "kind": "scalar",
            "linter": "\n        root = if !this.has_prefix(\"xoxb-\") { [ \"field must start with xoxb-\" ] }\n      ",
            "name": "bot_token",
            "type": "string"
          },
          {
            "description": "The channel ID to read messages from.",
            "interpolated": true,
            "kind": "scalar",
            "name": "channel_id",
            "type": "string"
          },
          {
            "description": "The thread timestamp to read the full thread of.",
            "interpolated": true,
            "kind": "scalar",
            "name": "thread_ts",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "Read a thread using the https://api.slack.com/methods/conversations.replies[^Slack API]",
      "name": "slack_thread",
      "plugin": true,
      "status": "experimental",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The duration of time to sleep for each execution.",
            "interpolated": true,
            "kind": "scalar",
            "name": "duration",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "sleep",
      "plugin": true,
      "status": "stable",
      "summary": "Sleep for a period of time specified as a duration string for each message. This processor will interpolate functions within the `duration` field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "default": 1,
            "description": "The target number of messages.",
            "kind": "scalar",
            "name": "size",
            "type": "int"
          },
          {
            "default": 0,
            "description": "An optional target of total message bytes.",
            "kind": "scalar",
            "name": "byte_size",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor is for breaking batches down into smaller ones. In order to break a single message out into multiple messages use the xref:components:processors/unarchive.adoc[`unarchive` processor].\n\nIf there is a remainder of messages after splitting a batch the remainder is also sent as a single batch. For example, if your target size was 10, and the processor received a batch of 95 message parts, the result would be 9 batches of 10 messages followed by a batch of 5 messages.",
      "name": "split",
      "plugin": true,
      "status": "stable",
      "summary": "Breaks message batches (synonymous with multiple part messages) into smaller batches. The size of the resulting batches are determined either by a discrete size or, if the field `byte_size` is non-zero, then by total size in bytes (which ever limit is reached first).",
      "type": "processor"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "Data source name.",
            "kind": "scalar",
            "name": "data_source_name",
            "type": "string"
          },
          {
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
            "examples": [
              "INSERT INTO footable (foo, bar, baz) VALUES (?, ?, ?);"
            ],
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to enable xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the query. Great care should be made to ensure your queries are defended against injection attacks.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "unsafe_dynamic_query",
            "type": "bool"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "default": "none",
            "description": "Result codec.",
            "kind": "scalar",
            "name": "result_codec",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIf the query fails to execute then the message will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].\n\n== Alternatives\n\nFor basic inserts or select queries use either the xref:components:processors/sql_insert.adoc[`sql_insert`] or the xref:components:processors/sql_select.adoc[`sql_select`] processor. For more complex queries use the xref:components:processors/sql_raw.adoc[`sql_raw`] processor.",
      "name": "sql",
      "plugin": true,
      "status": "deprecated",
      "summary": "Runs an arbitrary SQL query against a database and (optionally) returns the result as an array of objects, one for each row returned.",
      "type": "processor",
      "version": "3.65.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The table to insert to.",
            "examples": [
              "foo"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "A list of columns to insert.",
            "examples": [
              [
                "foo",
                "bar",
                "baz"
              ]
            ],
            "kind": "array",
            "name": "columns",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of columns specified.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "An optional prefix to prepend to the insert query (before INSERT).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to the insert query.",
            "examples": [
              "ON CONFLICT (name) DO NOTHING"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "suffix",
            "type": "string"
          },
          {
            "description": "A list of keyword options to add before the INTO clause of the query.",
            "examples": [
              [
                "DELAYED",
                "IGNORE"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "options",
            "type": "string"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIf the insert fails to execute then the message will still remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - sql_insert:\n        driver: mysql\n        dsn: foouser:foopassword@tcp(localhost:3306)/foodb\n        table: footable\n        columns: [ id, name, topic ]\n        args_mapping: |\n          root = [\n            this.user.id,\n            this.user.name,\n            meta(\"kafka_topic\"),\n          ]\n",
          "summary": "\nHere we insert rows into a database by populating the columns id, name and topic with values extracted from messages and metadata:",
          "title": "Table Insert (MySQL)"
        }
      ],
      "name": "sql_insert",
      "plugin": true,
      "status": "stable",
      "summary": "Inserts rows into an SQL database for each message, and leaves the message unchanged.",
      "type": "processor",
      "version": "3.59.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
            "examples": [
              "INSERT INTO footable (foo, bar, baz) VALUES (?, ?, ?);",
              "SELECT * FROM footable WHERE user_id = $1;"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "query",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to enable xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the query. Great care should be made to ensure your queries are defended against injection attacks.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "unsafe_dynamic_query",
            "type": "bool"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "Whether the query result should be discarded. When set to `true` the message contents will remain unchanged, which is useful in cases where you are executing inserts, updates, etc. By default this is true for the last query, and previous queries don't change the results. If set to true for any query but the last one, the subsequent `args_mappings` input is overwritten.",
            "is_optional": true,
            "kind": "scalar",
            "name": "exec_only",
            "type": "bool"
          },
          {
            "children": [
              {
                "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
                "kind": "scalar",
                "name": "query",
                "type": "string"
              },
              {
                "bloblang": true,
                "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
                "examples": [
                  "root = [ this.cat.meow, this.doc.woofs[0] ]",
                  "root = [ meta(\"user.id\") ]"
                ],
                "is_optional": true,
                "kind": "scalar",
                "name": "args_mapping",
                "type": "string"
              },
              {
                "description": "Whether the query result should be discarded. When set to `true` the message contents will remain unchanged, which is useful in cases where you are executing inserts, updates, etc. By default this is true for the last query, and previous queries don't change the results. If set to true for any query but the last one, the subsequent `args_mappings` input is overwritten.",
                "is_optional": true,
                "kind": "scalar",
                "name": "exec_only",
                "type": "bool"
              }
            ],
            "description": "A list of statements to run in addition to `query`. When specifying multiple statements, they are all executed within a transaction. The output of the processor is always the last query that runs, unless `exec_only` is used.",
            "is_optional": true,
            "kind": "array",
            "name": "queries",
            "type": "object"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "linter": "root = match {\n        !this.exists(\"queries\") && !this.exists(\"query\") => [ \"either `query` or `queries` is required\" ],\n    }",
        "name": "",
        "type": "object"
      },
      "description": "\nIf the query fails to execute then the message will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - sql_raw:\n        driver: mysql\n        dsn: foouser:foopassword@tcp(localhost:3306)/foodb\n        query: \"INSERT INTO footable (foo, bar, baz) VALUES (?, ?, ?);\"\n        args_mapping: '[ document.foo, document.bar, meta(\"kafka_topic\") ]'\n        exec_only: true\n",
          "summary": "The following example inserts rows into the table footable with the columns foo, bar and baz populated with values extracted from messages.",
          "title": "Table Insert (MySQL)"
        },
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - sql_raw:\n              driver: postgres\n              dsn: postgres://foouser:foopass@localhost:5432/testdb?sslmode=disable\n              query: \"SELECT * FROM footable WHERE user_id = $1;\"\n              args_mapping: '[ this.user.id ]'\n        result_map: 'root.foo_rows = this'\n",
          "summary": "Here we query a database for columns of footable that share a `user_id` with the message field `user.id`. A xref:components:processors/branch.adoc[`branch` processor] is used in order to insert the resulting array into the original message at the path `foo_rows`.",
          "title": "Table Query (PostgreSQL)"
        },
        {
          "config": "\npipeline:\n  processors:\n    - mapping: |\n        root = this\n        # Prevent SQL injection when using unsafe_dynamic_query\n        meta table_name = \"\\\"\" + metadata(\"table_name\").replace_all(\"\\\"\", \"\\\"\\\"\") + \"\\\"\"\n    - sql_raw:\n        driver: postgres\n        dsn: postgres://localhost/postgres\n        unsafe_dynamic_query: true\n        queries:\n          - query: |\n              CREATE TABLE IF NOT EXISTS ${!metadata(\"table_name\")} (id varchar primary key, document jsonb);\n          - query: |\n              INSERT INTO ${!metadata(\"table_name\")} (id, document) VALUES ($1, $2)\n              ON CONFLICT (id) DO UPDATE SET document = EXCLUDED.document;\n            args_mapping: |\n              root = [ this.id, this.document.string() ]\n",
          "summary": "Here we query a database for columns of footable that share a `user_id` with the message field `user.id`. A xref:components:processors/branch.adoc[`branch` processor] is used in order to insert the resulting array into the original message at the path `foo_rows`.",
          "title": "Dynamically Creating Tables (PostgreSQL)"
        }
      ],
      "name": "sql_raw",
      "plugin": true,
      "status": "stable",
      "summary": "Runs an arbitrary SQL query against a database and (optionally) returns the result as an array of objects, one for each row returned.",
      "type": "processor",
      "version": "3.65.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "A database <<drivers, driver>> to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"mysql\": true,\n  \"postgres\": true,\n  \"clickhouse\": true,\n  \"mssql\": true,\n  \"sqlite\": true,\n  \"oracle\": true,\n  \"snowflake\": true,\n  \"trino\": true,\n  \"gocosmos\": true,\n  \"spanner\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "driver",
            "options": [
              "mysql",
              "postgres",
              "clickhouse",
              "mssql",
              "sqlite",
              "oracle",
              "snowflake",
              "trino",
              "gocosmos",
              "spanner"
            ],
            "type": "string"
          },
          {
            "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1&...&paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1&...&paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname&param1=value1&...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param&=value1&...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2&server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value&...&paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=<cosmosdb-endpoint>;AccountKey=<cosmosdb-account-key>[;TimeoutMs=<timeout-in-ms>\\][;Version=<cosmosdb-api-version>\\][;DefaultDb/Db=<db-name>\\][;AutoId=<true/false>\\][;InsecureSkipVerify=<true/false>\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `<snowflake_user>@<snowflake_account>/<db_name>/<schema_name>?warehouse=<warehouse>&role=<role>&authenticator=snowflake_jwt&privateKey=<base64_url_encoded_private_key>`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
            "examples": [
              "clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&max_execution_time=60",
              "foouser:foopassword@tcp(localhost:3306)/foodb",
              "postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable",
              "oracle://foouser:foopass@localhost:1521/service_name"
            ],
            "kind": "scalar",
            "name": "dsn",
            "type": "string"
          },
          {
            "description": "The table to query.",
            "examples": [
              "foo"
            ],
            "kind": "scalar",
            "name": "table",
            "type": "string"
          },
          {
            "description": "A list of columns to query.",
            "examples": [
              [
                "*"
              ],
              [
                "foo",
                "bar",
                "baz"
              ]
            ],
            "kind": "array",
            "name": "columns",
            "type": "string"
          },
          {
            "description": "An optional where clause to add. Placeholder arguments are populated with the `args_mapping` field. Placeholders should always be question marks, and will automatically be converted to dollar syntax when the postgres or clickhouse drivers are used.",
            "examples": [
              "meow = ? and woof = ?",
              "user_id = ?"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "where",
            "type": "string"
          },
          {
            "bloblang": true,
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `where`.",
            "examples": [
              "root = [ this.cat.meow, this.doc.woofs[0] ]",
              "root = [ meta(\"user.id\") ]"
            ],
            "is_optional": true,
            "kind": "scalar",
            "name": "args_mapping",
            "type": "string"
          },
          {
            "description": "An optional prefix to prepend to the query (before SELECT).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "prefix",
            "type": "string"
          },
          {
            "description": "An optional suffix to append to the select query.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "suffix",
            "type": "string"
          },
          {
            "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              [
                "./init/*.sql"
              ],
              [
                "./foo.sql",
                "./bar.sql"
              ]
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "array",
            "name": "init_files",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
            "examples": [
              "\nCREATE TABLE IF NOT EXISTS some_table (\n  foo varchar(50) not null,\n  bar integer,\n  baz varchar(50),\n  primary key (foo)\n) WITHOUT ROWID;\n"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "init_statement",
            "type": "string",
            "version": "4.10.0"
          },
          {
            "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections idle time.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle_time",
            "type": "string"
          },
          {
            "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value <= 0`, connections are not closed due to a connections age.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_life_time",
            "type": "string"
          },
          {
            "default": 2,
            "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value <= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_idle",
            "type": "int"
          },
          {
            "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value <= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "conn_max_open",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nIf the query fails to execute then the message will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - branch:\n        processors:\n          - sql_select:\n              driver: postgres\n              dsn: postgres://foouser:foopass@localhost:5432/testdb?sslmode=disable\n              table: footable\n              columns: [ '*' ]\n              where: user_id = ?\n              args_mapping: '[ this.user.id ]'\n        result_map: 'root.foo_rows = this'\n",
          "summary": "\nHere we query a database for columns of footable that share a `user_id`\nwith the message `user.id`. A xref:components:processors/branch.adoc[`branch` processor]\nis used in order to insert the resulting array into the original message at the\npath `foo_rows`:",
          "title": "Table Query (PostgreSQL)"
        }
      ],
      "name": "sql_select",
      "plugin": true,
      "status": "stable",
      "summary": "Runs an SQL select query against a database and returns the result as an array of objects, one for each row returned, containing a key for each column queried and its value.",
      "type": "processor",
      "version": "3.59.0"
    },
    {
      "categories": [
        "Integration"
      ],
      "config": {
        "children": [
          {
            "description": "The command to execute as a subprocess.",
            "examples": [
              "cat",
              "sed",
              "awk"
            ],
            "kind": "scalar",
            "name": "name",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of arguments to provide the command.",
            "kind": "array",
            "name": "args",
            "type": "string"
          },
          {
            "default": 65536,
            "description": "The maximum expected response size.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_buffer",
            "type": "int"
          },
          {
            "default": "lines",
            "description": "Determines how messages written to the subprocess are encoded, which allows them to be logically separated.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lines\": true,\n  \"length_prefixed_uint32_be\": true,\n  \"netstring\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "codec_send",
            "options": [
              "lines",
              "length_prefixed_uint32_be",
              "netstring"
            ],
            "type": "string",
            "version": "3.37.0"
          },
          {
            "default": "lines",
            "description": "Determines how messages read from the subprocess are decoded, which allows them to be logically separated.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"lines\": true,\n  \"length_prefixed_uint32_be\": true,\n  \"netstring\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "codec_recv",
            "options": [
              "lines",
              "length_prefixed_uint32_be",
              "netstring"
            ],
            "type": "string",
            "version": "3.37.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n[NOTE]\n====\nThis processor keeps the subprocess alive and requires very specific behavior from the command executed. If you wish to simply execute a command for each message take a look at the xref:components:processors/command.adoc[`command` processor] instead.\n====\n\nThe subprocess must then either return a line over stdout or stderr. If a response is returned over stdout then its contents will replace the message. If a response is instead returned from stderr it will be logged and the message will continue unchanged and will be xref:configuration:error_handling.adoc[marked as failed].\n\nRather than separating data by a newline it's possible to specify alternative <<codec_send,`codec_send`>> and <<codec_recv,`codec_recv`>> values, which allow binary messages to be encoded for logical separation.\n\nThe execution environment of the subprocess is the same as the Redpanda Connect instance, including environment variables and the current working directory.\n\nThe field `max_buffer` defines the maximum response size able to be read from the subprocess. This value should be set significantly above the real expected maximum response size.\n\n== Subprocess requirements\n\nIt is required that subprocesses flush their stdout and stderr pipes for each line. Redpanda Connect will attempt to keep the process alive for as long as the pipeline is running. If the process exits early it will be restarted.\n\n== Messages containing line breaks\n\nIf a message contains line breaks each line of the message is piped to the subprocess and flushed, and a response is expected from the subprocess before another line is fed in.",
      "name": "subprocess",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a command as a subprocess and, for each message, will pipe its contents to the stdin stream of the process followed by a newline.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "bloblang": true,
            "default": "",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should have the processors of this case executed on it. If left empty the case always passes. If the check mapping throws an error the message will be flagged xref:configuration:error_handling.adoc[as having failed] and will not be tested against any other cases.",
            "examples": [
              "this.type == \"foo\"",
              "this.contents.urls.contains(\"https://benthos.dev/\")"
            ],
            "kind": "scalar",
            "name": "check",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of xref:components:processors/about.adoc[processors] to execute on a message.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          },
          {
            "default": false,
            "description": "Indicates whether, if this case passes for a message, the next case should also be executed.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "fallthrough",
            "type": "bool"
          }
        ],
        "kind": "array",
        "name": "",
        "type": "object"
      },
      "description": "For each switch case a xref:guides:bloblang/about.adoc[Bloblang query] is checked and, if the result is true (or the check is empty) the child processors are executed on the message.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - switch:\n        - check: this.user.name.first != \"George\"\n          processors:\n            - metric:\n                type: counter\n                name: MessagesWeCareAbout\n\n        - processors:\n            - metric:\n                type: gauge\n                name: GeorgesAnger\n                value: ${! json(\"user.anger\") }\n            - mapping: root = deleted()\n",
          "summary": "\nWe have a system where we're counting a metric for all messages that pass through our system. However, occasionally we get messages from George that we don't care about.\n\nFor George's messages we want to instead emit a metric that gauges how angry he is about being ignored and then we drop it.",
          "title": "Ignore George"
        }
      ],
      "footnotes": "\n== Batching\n\nWhen a switch processor executes on a xref:configuration:batching.adoc[batch of messages] they are checked individually and can be matched independently against cases. During processing the messages matched against a case are processed as a batch, although the ordering of messages during case processing cannot be guaranteed to match the order as received.\n\nAt the end of switch processing the resulting batch will follow the same ordering as the batch was received. If any child processors have split or otherwise grouped messages this grouping will be lost as the result of a switch is always a single batch. In order to perform conditional grouping and/or splitting use the xref:components:processors/group_by.adoc[`group_by` processor].",
      "name": "switch",
      "plugin": true,
      "status": "stable",
      "summary": "Conditionally processes messages based on their contents.",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nFor most inputs this mechanism is ignored entirely, in which case the sync response is dropped without penalty. It is therefore safe to use this processor even when combining input types that might not have support for sync responses. An example of an input able to utilize this is the `http_server`.\n\nFor more information please read xref:guides:sync_responses.adoc[synchronous responses].",
      "name": "sync_response",
      "plugin": true,
      "status": "stable",
      "summary": "Adds the payload in its current state as a synchronous response to the input source, where it is dealt with according to that specific input type.",
      "type": "processor"
    },
    {
      "categories": [
        "AI"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "markdown",
                "Split text by markdown headers."
              ],
              [
                "recursive_character",
                "Split text recursively by characters (defined in `separators`)."
              ],
              [
                "token",
                "Split text by tokens."
              ]
            ],
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"markdown\": true,\n  \"recursive_character\": true,\n  \"token\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "strategy",
            "type": "string"
          },
          {
            "default": 512,
            "description": "The maximum size of each chunk.",
            "kind": "scalar",
            "name": "chunk_size",
            "type": "int"
          },
          {
            "default": 100,
            "description": "The number of characters to overlap between chunks.",
            "kind": "scalar",
            "name": "chunk_overlap",
            "type": "int"
          },
          {
            "default": [
              "\n\n",
              "\n",
              " ",
              ""
            ],
            "description": "A list of strings that should be considered as separators between chunks.",
            "kind": "array",
            "name": "separators",
            "type": "string"
          },
          {
            "annotated_options": [
              [
                "graphemes",
                "Use unicode graphemes to determine the length of a string."
              ],
              [
                "runes",
                "Use the number of codepoints to determine the length of a string."
              ],
              [
                "token",
                "Use the number of tokens (using the `token_encoding` tokenizer) to determine the length of a string."
              ],
              [
                "utf8",
                "Determine the length of text using the number of utf8 bytes."
              ]
            ],
            "default": "runes",
            "description": "The method for measuring the length of a string.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"graphemes\": true,\n  \"runes\": true,\n  \"token\": true,\n  \"utf8\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "length_measure",
            "type": "string"
          },
          {
            "description": "The encoding to use for tokenization.",
            "examples": [
              "cl100k_base",
              "r50k_base"
            ],
            "is_advanced": true,
            "is_optional": true,
            "kind": "scalar",
            "name": "token_encoding",
            "type": "string"
          },
          {
            "default": [],
            "description": "A list of special tokens that are allowed in the output.",
            "is_advanced": true,
            "kind": "array",
            "name": "allowed_special",
            "type": "string"
          },
          {
            "default": [
              "all"
            ],
            "description": "A list of special tokens that are disallowed in the output.",
            "is_advanced": true,
            "kind": "array",
            "name": "disallowed_special",
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to include code blocks in the output.",
            "kind": "scalar",
            "name": "include_code_blocks",
            "type": "bool"
          },
          {
            "default": false,
            "description": "Whether to keep reference links in the output.",
            "kind": "scalar",
            "name": "keep_reference_links",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "A processor allowing splitting text into chunks based on several different strategies.",
      "name": "text_chunker",
      "plugin": true,
      "status": "experimental",
      "summary": "A processor that allows chunking and splitting text based on some strategy. Usually used for creating vector embeddings of large documents.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "default": [],
        "kind": "array",
        "name": "",
        "type": "processor"
      },
      "description": "\nThis processor behaves similarly to the xref:components:processors/for_each.adoc[`for_each`] processor, where a list of child processors are applied to individual messages of a batch. However, if a message has failed any prior processor (before or during the try block) then that message will skip all following processors.\n\nFor example, with the following config:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo\n    - try:\n      - resource: bar\n      - resource: baz\n      - resource: buz\n```\n\nIf the processor `bar` fails for a particular message, that message will skip the processors `baz` and `buz`. Similarly, if `bar` succeeds but `baz` does not then `buz` will be skipped. If the processor `foo` fails for a message then none of `bar`, `baz` or `buz` are executed on that message.\n\nThis processor is useful for when child processors depend on the successful output of previous processors. This processor can be followed with a xref:components:processors/catch.adoc[catch] processor for defining child processors to be applied only to failed messages.\n\nMore information about error handing can be found in xref:configuration:error_handling.adoc[].\n\n== Nest within a catch block\n\nIn some cases it might be useful to nest a try block within a catch block, since the xref:components:processors/catch.adoc[`catch` processor] only clears errors _after_ executing its child processors this means a nested try processor will not execute unless the errors are explicitly cleared beforehand.\n\nThis can be done by inserting an empty catch block before the try block like as follows:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo\n    - catch:\n      - log:\n          level: ERROR\n          message: \"Foo failed due to: ${! error() }\"\n      - catch: [] # Clear prior error\n      - try:\n        - resource: bar\n        - resource: baz\n```",
      "name": "try",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a list of child processors on messages only if no prior processors have failed (or the errors have been cleared).",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing",
        "Utility"
      ],
      "config": {
        "children": [
          {
            "annotated_options": [
              [
                "binary",
                "Extract messages from a https://github.com/redpanda-data/benthos/blob/main/internal/message/message.go#L96[binary blob format^]."
              ],
              [
                "csv",
                "Attempt to parse the message as a csv file (header required) and for each row in the file expands its contents into a json object in a new message."
              ],
              [
                "csv:x",
                "Attempt to parse the message as a csv file (header required) and for each row in the file expands its contents into a json object in a new message using a custom delimiter. The custom delimiter must be a single character, e.g. the format \"csv:\\t\" would consume a tab delimited file."
              ],
              [
                "json_array",
                "Attempt to parse a message as a JSON array, and extract each element into its own message."
              ],
              [
                "json_documents",
                "Attempt to parse a message as a stream of concatenated JSON documents. Each parsed document is expanded into a new message."
              ],
              [
                "json_map",
                "Attempt to parse the message as a JSON map and for each element of the map expands its contents into a new message. A metadata field is added to each message called `archive_key` with the relevant key from the top-level map."
              ],
              [
                "lines",
                "Extract the lines of a message each into their own message."
              ],
              [
                "tar",
                "Extract messages from a unix standard tape archive."
              ],
              [
                "zip",
                "Extract messages from a zip file."
              ]
            ],
            "description": "The unarchiving format to apply.",
            "kind": "scalar",
            "name": "format",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nWhen a message is unarchived the new messages replace the original message in the batch. Messages that are selected but fail to unarchive (invalid format) will remain unchanged in the message batch but will be flagged as having failed, allowing you to xref:configuration:error_handling.adoc[error handle them].\n\n== Metadata\n\nThe metadata found on the messages handled by this processor will be copied into the resulting messages. For the unarchive formats that contain file information (tar, zip), a metadata field is also added to each message called `archive_filename` with the extracted filename.\n",
      "name": "unarchive",
      "plugin": true,
      "status": "stable",
      "summary": "Unarchives messages according to the selected archive format into multiple messages within a xref:configuration:batching.adoc[batch].",
      "type": "processor"
    },
    {
      "categories": [
        "Utility"
      ],
      "config": {
        "children": [
          {
            "description": "The path of the target WASM module to execute.",
            "kind": "scalar",
            "name": "module_path",
            "type": "string"
          },
          {
            "default": "process",
            "description": "The name of the function exported by the target WASM module to run for each message.",
            "kind": "scalar",
            "name": "function",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThis processor uses https://github.com/tetratelabs/wazero[Wazero^] to execute a WASM module (with support for WASI), calling a specific function for each message being processed. From within the WASM module it is possible to query and mutate the message being processed via a suite of functions exported to the module.\n\nThis ecosystem is delicate as WASM doesn't have a single clearly defined way to pass strings back and forth between the host and the module. In order to remedy this we're gradually working on introducing libraries and examples for multiple languages which can be found in https://github.com/redpanda-data/benthos/tree/main/public/wasm/README.md[the codebase^].\n\nThese examples, as well as the processor itself, is a work in progress.\n\n== Parallelism\n\nIt's not currently possible to execute a single WASM runtime across parallel threads with this processor. Therefore, in order to support parallel processing this processor implements pooling of module runtimes. Ideally your WASM module shouldn't depend on any global state, but if it does then you need to ensure the processor xref:configuration:processing_pipelines.adoc[is only run on a single thread].\n",
      "name": "wasm",
      "plugin": true,
      "status": "experimental",
      "summary": "Executes a function exported by a WASM module for each message.",
      "type": "processor",
      "version": "4.11.0"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether to always run the child processors at least one time.",
            "kind": "scalar",
            "name": "at_least_once",
            "type": "bool"
          },
          {
            "default": 0,
            "description": "An optional maximum number of loops to execute. Helps protect against accidentally creating infinite loops.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "max_loops",
            "type": "int"
          },
          {
            "bloblang": true,
            "default": "",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether the while loop should execute again.",
            "examples": [
              "errored()",
              "this.urls.unprocessed.length() > 0"
            ],
            "kind": "scalar",
            "name": "check",
            "type": "string"
          },
          {
            "description": "A list of child processors to execute on each loop.",
            "kind": "array",
            "name": "processors",
            "type": "processor"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\nThe field `at_least_once`, if true, ensures that the child processors are always executed at least one time (like a do .. while loop.)\n\nThe field `max_loops`, if greater than zero, caps the number of loops for a message batch to this value.\n\nIf following a loop execution the number of messages in a batch is reduced to zero the loop is exited regardless of the condition result. If following a loop execution there are more than 1 message batches the query is checked against the first batch only.\n\nThe conditions of this processor are applied across entire message batches. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "name": "while",
      "plugin": true,
      "status": "stable",
      "summary": "A processor that checks a xref:guides:bloblang/about.adoc[Bloblang query] against each batch of messages and executes child processors on them for as long as the query resolves to true.",
      "type": "processor"
    },
    {
      "categories": [
        "Composition"
      ],
      "config": {
        "children": [
          {
            "default": "meta.workflow",
            "description": "A xref:configuration:field_paths.adoc[dot path] indicating where to store and reference <<structured-metadata, structured metadata>> about the workflow execution.",
            "kind": "scalar",
            "name": "meta_path",
            "type": "string"
          },
          {
            "default": [],
            "description": "An explicit declaration of branch ordered tiers, which describes the order in which parallel tiers of branches should be executed. Branches should be identified by the name as they are configured in the field `branches`. It's also possible to specify branch processors configured <<resources, as a resource>>.",
            "examples": [
              [
                [
                  "foo",
                  "bar"
                ],
                [
                  "baz"
                ]
              ],
              [
                [
                  "foo"
                ],
                [
                  "bar"
                ],
                [
                  "baz"
                ]
              ]
            ],
            "kind": "2darray",
            "name": "order",
            "type": "string"
          },
          {
            "default": [],
            "description": "An optional list of xref:components:processors/branch.adoc[`branch` processor] names that are configured as <<resources>>. These resources will be included in the workflow with any branches configured inline within the <<branches, `branches`>> field. The order and parallelism in which branches are executed is automatically resolved based on the mappings of each branch. When using resources with an explicit order it is not necessary to list resources in this field.",
            "is_advanced": true,
            "kind": "array",
            "name": "branch_resources",
            "type": "string",
            "version": "3.38.0"
          },
          {
            "children": [
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how to create a request payload suitable for the child processors of this branch. If left empty then the branch will begin with an exact copy of the origin message (including metadata).",
                "examples": [
                  "root = {\n\t\"id\": this.doc.id,\n\t\"content\": this.doc.body.text\n}",
                  "root = if this.type == \"foo\" {\n\tthis.foo.request\n} else {\n\tdeleted()\n}"
                ],
                "kind": "scalar",
                "name": "request_map",
                "type": "string"
              },
              {
                "description": "A list of processors to apply to mapped requests. When processing message batches the resulting batch must match the size and ordering of the input batch, therefore filtering, grouping should not be performed within these processors.",
                "kind": "array",
                "name": "processors",
                "type": "processor"
              },
              {
                "bloblang": true,
                "default": "",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how the resulting messages from branched processing should be mapped back into the original payload. If left empty the origin message will remain unchanged (including metadata).",
                "examples": [
                  "meta foo_code = metadata(\"code\")\nroot.foo_result = this",
                  "meta = metadata()\nroot.bar.body = this.body\nroot.bar.id = this.user.id",
                  "root.raw_result = content().string()",
                  "root.enrichments.foo = if metadata(\"request_failed\") != null {\n  throw(metadata(\"request_failed\"))\n} else {\n  this\n}",
                  "# Retain only the updated metadata fields which were present in the origin message\nmeta = metadata().filter(v -> @.get(v.key) != null)"
                ],
                "kind": "scalar",
                "name": "result_map",
                "type": "string"
              }
            ],
            "default": {},
            "description": "An object of named xref:components:processors/branch.adoc[`branch` processors] that make up the workflow. The order and parallelism in which branches are executed can either be made explicit with the field `order`, or if omitted an attempt is made to automatically resolve an ordering based on the mappings of each branch.",
            "kind": "map",
            "name": "branches",
            "type": "object"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Why use a workflow\n\n=== Performance\n\nMost of the time the best way to compose processors is also the simplest, just configure them in series. This is because processors are often CPU bound, low-latency, and you can gain vertical scaling by increasing the number of processor pipeline threads, allowing Redpanda Connect to process xref:configuration:processing_pipelines.adoc[multiple messages in parallel].\n\nHowever, some processors such as xref:components:processors/http.adoc[`http`], xref:components:processors/aws_lambda.adoc[`aws_lambda`] or xref:components:processors/cache.adoc[`cache`] interact with external services and therefore spend most of their time waiting for a response. These processors tend to be high-latency and low CPU activity, which causes messages to process slowly.\n\nWhen a processing pipeline contains multiple network processors that aren't dependent on each other we can benefit from performing these processors in parallel for each individual message, reducing the overall message processing latency.\n\n=== Simplifying processor topology\n\nA workflow is often expressed as a https://en.wikipedia.org/wiki/Directed_acyclic_graph[DAG^] of processing stages, where each stage can result in N possible next stages, until finally the flow ends at an exit node.\n\nFor example, if we had processing stages A, B, C and D, where stage A could result in either stage B or C being next, always followed by D, it might look something like this:\n\n```text\n     /--> B --\\\nA --|          |--> D\n     \\--> C --/\n```\n\nThis flow would be easy to express in a standard Redpanda Connect config, we could simply use a xref:components:processors/switch.adoc[`switch` processor] to route to either B or C depending on a condition on the result of A. However, this method of flow control quickly becomes unfeasible as the DAG gets more complicated, imagine expressing this flow using switch processors:\n\n```text\n      /--> B -------------|--> D\n     /                   /\nA --|          /--> E --|\n     \\--> C --|          \\\n               \\----------|--> F\n```\n\nAnd imagine doing so knowing that the diagram is subject to change over time. Yikes! Instead, with a workflow we can either trust it to automatically resolve the DAG or express it manually as simply as `order: [ [ A ], [ B, C ], [ E ], [ D, F ] ]`, and the conditional logic for determining if a stage is executed is defined as part of the branch itself.",
      "examples": [
        {
          "config": "\npipeline:\n  processors:\n    - workflow:\n        meta_path: meta.workflow\n        branches:\n          foo:\n            request_map: 'root = \"\"'\n            processors:\n              - http:\n                  url: TODO\n            result_map: 'root.foo = this'\n\n          bar:\n            request_map: 'root = this.body'\n            processors:\n              - aws_lambda:\n                  function: TODO\n            result_map: 'root.bar = this'\n\n          baz:\n            request_map: |\n              root.fooid = this.foo.id\n              root.barstuff = this.bar.content\n            processors:\n              - cache:\n                  resource: TODO\n                  operator: set\n                  key: ${! json(\"fooid\") }\n                  value: ${! json(\"barstuff\") }\n",
          "summary": "\nWhen the field `order` is omitted a best attempt is made to determine a dependency tree between branches based on their request and result mappings. In the following example the branches foo and bar will be executed first in parallel, and afterwards the branch baz will be executed.",
          "title": "Automatic Ordering"
        },
        {
          "config": "\npipeline:\n  processors:\n    - workflow:\n        branches:\n          A:\n            request_map: |\n              root = if this.document.type != \"foo\" {\n                  deleted()\n              }\n            processors:\n              - http:\n                  url: TODO\n            result_map: 'root.tmp.result = this'\n\n          B:\n            request_map: |\n              root = if this.document.type == \"foo\" {\n                  deleted()\n              }\n            processors:\n              - aws_lambda:\n                  function: TODO\n            result_map: 'root.tmp.result = this'\n\n          C:\n            request_map: |\n              root = if this.tmp.result != null {\n                  deleted()\n              }\n            processors:\n              - http:\n                  url: TODO_SOMEWHERE_ELSE\n            result_map: 'root.tmp.result = this'\n",
          "summary": "\nBranches of a workflow are skipped when the `request_map` assigns `deleted()` to the root. In this example the branch A is executed when the document type is \"foo\", and branch B otherwise. Branch C is executed afterwards and is skipped unless either A or B successfully provided a result at `tmp.result`.",
          "title": "Conditional Branches"
        },
        {
          "config": "\npipeline:\n  processors:\n    - workflow:\n        order: [ [ foo, bar ], [ baz ] ]\n        branches:\n          bar:\n            request_map: 'root = this.body'\n            processors:\n              - aws_lambda:\n                  function: TODO\n            result_map: 'root.bar = this'\n\nprocessor_resources:\n  - label: foo\n    branch:\n      request_map: 'root = \"\"'\n      processors:\n        - http:\n            url: TODO\n      result_map: 'root.foo = this'\n\n  - label: baz\n    branch:\n      request_map: |\n        root.fooid = this.foo.id\n        root.barstuff = this.bar.content\n      processors:\n        - cache:\n            resource: TODO\n            operator: set\n            key: ${! json(\"fooid\") }\n            value: ${! json(\"barstuff\") }\n",
          "summary": "\nThe `order` field can be used in order to refer to <<resources, branch processor resources>>, this can sometimes make your pipeline configuration cleaner, as well as allowing you to reuse branch configurations in order places. It's also possible to mix and match branches configured within the workflow and configured as resources.",
          "title": "Resources"
        }
      ],
      "footnotes": "\n== Structured metadata\n\nWhen the field `meta_path` is non-empty the workflow processor creates an object describing which workflows were successful, skipped or failed for each message and stores the object within the message at the end.\n\nThe object is of the following form:\n\n```json\n{\n\t\"succeeded\": [ \"foo\" ],\n\t\"skipped\": [ \"bar\" ],\n\t\"failed\": {\n\t\t\"baz\": \"the error message from the branch\"\n\t}\n}\n```\n\nIf a message already has a meta object at the given path when it is processed then the object is used in order to determine which branches have already been performed on the message (or skipped) and can therefore be skipped on this run.\n\nThis is a useful pattern when replaying messages that have failed some branches previously. For example, given the above example object the branches foo and bar would automatically be skipped, and baz would be reattempted.\n\nThe previous meta object will also be preserved in the field `<meta_path>.previous` when the new meta object is written, preserving a full record of all workflow executions.\n\nIf a field `<meta_path>.apply` exists in the meta object for a message and is an array then it will be used as an explicit list of stages to apply, all other stages will be skipped.\n\n== Resources\n\nIt's common to configure processors (and other components) xref:configuration:resources.adoc[as resources] in order to keep the pipeline configuration cleaner. With the workflow processor you can include branch processors configured as resources within your workflow either by specifying them by name in the field `order`, if Redpanda Connect doesn't find a branch within the workflow configuration of that name it'll refer to the resources.\n\nAlternatively, if you do not wish to have an explicit ordering, you can add resource names to the field `branch_resources` and they will be included in the workflow with automatic DAG resolution along with any branches configured in the `branches` field.\n\n=== Resource error conditions\n\nThere are two error conditions that could potentially occur when resources included in your workflow are mutated, and if you are planning to mutate resources in your workflow it is important that you understand them.\n\nThe first error case is that a resource in the workflow is removed and not replaced, when this happens the workflow will still be executed but the individual branch will fail. This should only happen if you explicitly delete a branch resource, as any mutation operation will create the new resource before removing the old one.\n\nThe second error case is when automatic DAG resolution is being used and a resource in the workflow is changed in a way that breaks the DAG (circular dependencies, etc). When this happens it is impossible to execute the workflow and therefore the processor will fail, which is possible to capture and handle using xref:configuration:error_handling.adoc[standard error handling patterns].\n\n== Error handling\n\nThe recommended approach to handle failures within a workflow is to query against the <<structured-metadata, structured metadata>> it provides, as it provides granular information about exactly which branches failed and which ones succeeded and therefore aren't necessary to perform again.\n\nFor example, if our meta object is stored at the path `meta.workflow` and we wanted to check whether a message has failed for any branch we can do that using a xref:guides:bloblang/about.adoc[Bloblang query] like `this.meta.workflow.failed.length() | 0 > 0`, or to check whether a specific branch failed we can use `this.exists(\"meta.workflow.failed.foo\")`.\n\nHowever, if structured metadata is disabled by setting the field `meta_path` to empty then the workflow processor instead adds a general error flag to messages when any executed branch fails. In this case it's possible to handle failures using xref:configuration:error_handling.adoc[standard error handling patterns].\n\n",
      "name": "workflow",
      "plugin": true,
      "status": "stable",
      "summary": "Executes a topology of xref:components:processors/branch.adoc[`branch` processors], performing them in parallel where possible.",
      "type": "processor"
    },
    {
      "categories": [
        "Parsing"
      ],
      "config": {
        "children": [
          {
            "default": "",
            "description": "An XML <<operators, operation>> to apply to messages.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"to_json\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "operator",
            "options": [
              "to_json"
            ],
            "type": "string"
          },
          {
            "default": false,
            "description": "Whether to try to cast values that are numbers and booleans to the right type. Default: all values are strings.",
            "kind": "scalar",
            "name": "cast",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Operators\n\n=== `to_json`\n\nConverts an XML document into a JSON structure, where elements appear as keys of an object according to the following rules:\n\n- If an element contains attributes they are parsed by prefixing a hyphen, `-`, to the attribute label.\n- If the element is a simple element and has attributes, the element value is given the key `#text`.\n- XML comments, directives, and process instructions are ignored.\n- When elements are repeated the resulting JSON value is an array.\n\nFor example, given the following XML:\n\n```xml\n<root>\n  <title>This is a title</title>\n  <description tone=\"boring\">This is a description</description>\n  <elements id=\"1\">foo1</elements>\n  <elements id=\"2\">foo2</elements>\n  <elements>foo3</elements>\n</root>\n```\n\nThe resulting JSON structure would look like this:\n\n```json\n{\n  \"root\":{\n    \"title\":\"This is a title\",\n    \"description\":{\n      \"#text\":\"This is a description\",\n      \"-tone\":\"boring\"\n    },\n    \"elements\":[\n      {\"#text\":\"foo1\",\"-id\":\"1\"},\n      {\"#text\":\"foo2\",\"-id\":\"2\"},\n      \"foo3\"\n    ]\n  }\n}\n```\n\nWith cast set to true, the resulting JSON structure would look like this:\n\n```json\n{\n  \"root\":{\n    \"title\":\"This is a title\",\n    \"description\":{\n      \"#text\":\"This is a description\",\n      \"-tone\":\"boring\"\n    },\n    \"elements\":[\n      {\"#text\":\"foo1\",\"-id\":1},\n      {\"#text\":\"foo2\",\"-id\":2},\n      \"foo3\"\n    ]\n  }\n}\n```",
      "name": "xml",
      "plugin": true,
      "status": "beta",
      "summary": "Parses messages as an XML document, performs a mutation on the data, and then overwrites the previous contents with the new value.",
      "type": "processor"
    }
  ],
  "rate-limits": [
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": 1000,
            "description": "The maximum number of requests to allow for a given period of time.",
            "kind": "scalar",
            "name": "count",
            "type": "int"
          },
          {
            "default": "1s",
            "description": "The time window to limit requests by.",
            "kind": "scalar",
            "name": "interval",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "local",
      "plugin": true,
      "status": "stable",
      "summary": "The local rate limit is a simple X every Y type rate limit that can be shared across any number of components within the pipeline but does not support distributed rate limits across multiple running instances of Benthos.",
      "type": "rate_limit"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
            "examples": [
              "redis://:6379",
              "redis://localhost:6379",
              "redis://foousername:foopassword@redisplace:6379",
              "redis://:foopassword@redisplace:6379",
              "redis://localhost:6379/1",
              "redis://localhost:6379/1,redis://localhost:6380/1"
            ],
            "kind": "scalar",
            "name": "url",
            "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
            "type": "string"
          },
          {
            "default": "simple",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
            "is_advanced": true,
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"simple\": true,\n  \"cluster\": true,\n  \"failover\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "kind",
            "options": [
              "simple",
              "cluster",
              "failover"
            ],
            "type": "string"
          },
          {
            "default": "",
            "description": "Name of the redis master when `kind` is `failover`",
            "examples": [
              "mymaster"
            ],
            "is_advanced": true,
            "kind": "scalar",
            "name": "master",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether custom TLS settings are enabled.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to skip server side certificate verification.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "skip_cert_verify",
                "type": "bool"
              },
              {
                "default": false,
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                "is_advanced": true,
                "kind": "scalar",
                "name": "enable_renegotiation",
                "type": "bool",
                "version": "3.45.0"
              },
              {
                "default": "",
                "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
                ],
                "is_advanced": true,
                "is_secret": true,
                "kind": "scalar",
                "name": "root_cas",
                "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                "type": "string"
              },
              {
                "default": "",
                "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                "examples": [
                  "./root_cas.pem"
                ],
                "is_advanced": true,
                "kind": "scalar",
                "name": "root_cas_file",
                "type": "string"
              },
              {
                "children": [
                  {
                    "default": "",
                    "description": "A plain text certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text certificate key to use.",
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "key",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "cert_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "The path of a certificate key to use.",
                    "is_advanced": true,
                    "kind": "scalar",
                    "name": "key_file",
                    "type": "string"
                  },
                  {
                    "default": "",
                    "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                    "examples": [
                      "foo",
                      "${KEY_PASSWORD}"
                    ],
                    "is_advanced": true,
                    "is_secret": true,
                    "kind": "scalar",
                    "name": "password",
                    "scrubber": "root = if this != null && this != \"\" && !this.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n} else if this == null { \"\" }",
                    "type": "string"
                  }
                ],
                "default": [],
                "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                "examples": [
                  [
                    {
                      "cert": "foo",
                      "key": "bar"
                    }
                  ],
                  [
                    {
                      "cert_file": "./example.pem",
                      "key_file": "./example.key"
                    }
                  ]
                ],
                "is_advanced": true,
                "kind": "array",
                "name": "client_certs",
                "type": "object"
              }
            ],
            "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "tls",
            "type": "object"
          },
          {
            "default": 1000,
            "description": "The maximum number of messages to allow for a given period of time.",
            "kind": "scalar",
            "linter": "root = if this <= 0 { [ \"count must be larger than zero\" ] }",
            "name": "count",
            "type": "int"
          },
          {
            "default": "1s",
            "description": "The time window to limit requests by.",
            "kind": "scalar",
            "name": "interval",
            "type": "string"
          },
          {
            "description": "The key to use for the rate limit.",
            "kind": "scalar",
            "name": "key",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "redis",
      "plugin": true,
      "status": "experimental",
      "summary": "A rate limit implementation using Redis. It works by using a simple token bucket algorithm to limit the number of requests to a given count within a given time period. The rate limit is shared across all instances of Redpanda Connect that use the same Redis instance, which must all have a consistent count and interval.",
      "type": "rate_limit",
      "version": "4.12.0"
    }
  ],
  "scanners": [
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": false,
            "description": "Whether messages should be decoded into normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^]. If `true` the schema returned from the subject should be decoded as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard json^] instead of as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[avro json^]. There is a https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in goavro^], the https://github.com/linkedin/goavro[underlining library used for avro serialization^], that explains in more detail the difference between the standard json and avro json.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "raw_json",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Avro JSON format\n\nThis scanner yields documents formatted as https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^] when decoding with Avro schemas. In this format the value of a union is encoded in JSON as follows:\n\n- if its type is `null`, then it is encoded as a JSON `null`;\n- otherwise it is encoded as a JSON object with one name/value pair whose name is the type's name and whose value is the recursively encoded value. For Avro's named types (record, fixed or enum) the user-specified name is used, for other types the type name is used.\n\nFor example, the union schema `[\"null\",\"string\",\"Foo\"]`, where `Foo` is a record name, would encode:\n\n- `null` as `null`;\n- the string `\"a\"` as `{\"string\": \"a\"}`; and\n- a `Foo` instance as `{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nHowever, it is possible to instead create documents in https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard/raw JSON format^] by setting the field <<avro_raw_json,`avro_raw_json`>> to `true`.\n\nThis scanner also emits the canonical Avro schema as `@avro_schema` metadata, along with the schema's fingerprint available via `@avro_schema_fingerprint`.\n",
      "name": "avro",
      "plugin": true,
      "status": "stable",
      "summary": "Consume a stream of Avro OCF datum.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The size of each chunk in bytes.",
            "kind": "scalar",
            "name": "size",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "chunker",
      "plugin": true,
      "status": "stable",
      "summary": "Split an input stream into chunks of a given number of bytes.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "Use a provided custom delimiter instead of the default comma.",
            "is_optional": true,
            "kind": "scalar",
            "name": "custom_delimiter",
            "type": "string"
          },
          {
            "default": true,
            "description": "Whether to reference the first row as a header row. If set to true the output structure for messages will be an object where field keys are determined by the header row. Otherwise, each message will consist of an array of values from the corresponding CSV row.",
            "kind": "scalar",
            "name": "parse_header_row",
            "type": "bool"
          },
          {
            "default": false,
            "description": "If set to `true`, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field.",
            "kind": "scalar",
            "name": "lazy_quotes",
            "type": "bool"
          },
          {
            "default": false,
            "description": "If a row fails to parse due to any error emit an empty message marked with the error and then continue consuming subsequent rows when possible. This can sometimes be useful in situations where input data contains individual rows which are malformed. However, when a row encounters a parsing error it is impossible to guarantee that following rows are valid, as this indicates that the input data is unreliable and could potentially emit misaligned rows.",
            "kind": "scalar",
            "name": "continue_on_error",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis scanner adds the following metadata to each message:\n\n- `csv_row` The index of each row, beginning at 0.\n\n",
      "name": "csv",
      "plugin": true,
      "status": "stable",
      "summary": "Consume comma-separated values row by row, including support for custom delimiters.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "One of `gzip`, `pgzip`, `zlib`, `bzip2`, `flate`, `snappy`, `lz4`, `zstd`.",
            "kind": "scalar",
            "name": "algorithm",
            "type": "string"
          },
          {
            "default": {
              "to_the_end": {}
            },
            "description": "The child scanner to feed the decompressed stream into.",
            "kind": "scalar",
            "name": "into",
            "type": "scanner"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "decompress",
      "plugin": true,
      "status": "stable",
      "summary": "Decompress the stream of bytes according to an algorithm, before feeding it into a child scanner.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "json_array",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes a stream of one or more JSON elements within a top level array.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "json_documents",
      "plugin": true,
      "status": "stable",
      "summary": "Consumes a stream of one or more JSON documents.",
      "type": "scanner",
      "version": "4.27.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "Use a provided custom delimiter for detecting the end of a line rather than a single line break.",
            "is_optional": true,
            "kind": "scalar",
            "name": "custom_delimiter",
            "type": "string"
          },
          {
            "default": 65536,
            "description": "Set the maximum buffer size for storing line data, this limits the maximum size that a line can be without causing an error.",
            "kind": "scalar",
            "name": "max_buffer_size",
            "type": "int"
          },
          {
            "default": false,
            "description": "Omit empty lines.",
            "kind": "scalar",
            "name": "omit_empty",
            "type": "bool"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "lines",
      "plugin": true,
      "status": "stable",
      "summary": "Split an input stream into a message per line of data.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The pattern to match against.",
            "examples": [
              "(?m)^\\d\\d:\\d\\d:\\d\\d"
            ],
            "kind": "scalar",
            "name": "pattern",
            "type": "string"
          },
          {
            "default": 65536,
            "description": "Set the maximum buffer size for storing line data, this limits the maximum size that a message can be without causing an error.",
            "kind": "scalar",
            "name": "max_buffer_size",
            "type": "int"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "re_match",
      "plugin": true,
      "status": "stable",
      "summary": "Split an input stream into segments matching against a regular expression.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": {
              "to_the_end": {}
            },
            "description": "The child scanner to feed the resulting stream into.",
            "kind": "scalar",
            "name": "into",
            "type": "scanner"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "skip_bom",
      "plugin": true,
      "status": "stable",
      "summary": "Skip one or more byte order marks for each opened child scanner.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "A regular expression to test against the name of each source of data fed into the scanner (filename or equivalent). If this pattern matches the child scanner is selected.",
            "is_optional": true,
            "kind": "scalar",
            "name": "re_match_name",
            "type": "string"
          },
          {
            "description": "The scanner to activate if this candidate passes.",
            "kind": "scalar",
            "name": "scanner",
            "type": "scanner"
          }
        ],
        "kind": "array",
        "name": "",
        "type": "object"
      },
      "description": "This scanner outlines a list of potential child scanner candidates to be chosen, and for each source of data the first candidate to pass will be selected. A candidate without any conditions acts as a catch-all and will pass for every source, it is recommended to always have a catch-all scanner at the end of your list. If a given source of data does not pass a candidate an error is returned and the data is rejected.",
      "examples": [
        {
          "config": "\ninput:\n  file:\n    paths: [ ./data/* ]\n    scanner:\n      switch:\n        - re_match_name: '\\.avro$'\n          scanner: { avro: {} }\n\n        - re_match_name: '\\.csv$'\n          scanner: { csv: {} }\n\n        - re_match_name: '\\.csv.gz$'\n          scanner:\n            decompress:\n              algorithm: gzip\n              into:\n                csv: {}\n\n        - re_match_name: '\\.tar$'\n          scanner: { tar: {} }\n\n        - re_match_name: '\\.tar.gz$'\n          scanner:\n            decompress:\n              algorithm: gzip\n              into:\n                tar: {}\n\n        - scanner: { to_the_end: {} }\n",
          "summary": "In this example a file input chooses a scanner based on the extension of each file",
          "title": "Switch based on file name"
        }
      ],
      "name": "switch",
      "plugin": true,
      "status": "stable",
      "summary": "Select a child scanner dynamically for source data based on factors such as the filename.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n== Metadata\n\nThis scanner adds the following metadata to each message:\n\n- `tar_name`\n\n",
      "name": "tar",
      "plugin": true,
      "status": "stable",
      "summary": "Consume a tar archive file by file.",
      "type": "scanner"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "description": "\n[CAUTION]\n====\nSome sources of data may not have a logical end, therefore caution should be made to exclusively use this scanner when the end of an input stream is clearly defined (and well within memory).\n====\n",
      "name": "to_the_end",
      "plugin": true,
      "status": "stable",
      "summary": "Read the input stream all the way until the end and deliver it as a single message.",
      "type": "scanner"
    }
  ],
  "tracers": [
    {
      "categories": null,
      "config": {
        "children": [
          {
            "description": "The google project with Cloud Trace API enabled. If this is omitted then the Google Cloud SDK will attempt auto-detect it from the environment.",
            "kind": "scalar",
            "name": "project",
            "type": "string"
          },
          {
            "default": 1,
            "description": "Sets the ratio of traces to sample. Tuning the sampling ratio is recommended for high-volume production workloads.",
            "examples": [
              1
            ],
            "kind": "scalar",
            "name": "sampling_ratio",
            "type": "float"
          },
          {
            "default": {},
            "description": "A map of tags to add to tracing spans.",
            "is_advanced": true,
            "kind": "map",
            "name": "tags",
            "type": "string"
          },
          {
            "description": "The period of time between each flush of tracing spans.",
            "is_optional": true,
            "kind": "scalar",
            "name": "flush_interval",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "gcp_cloudtrace",
      "plugin": true,
      "status": "experimental",
      "summary": "Send tracing events to a https://cloud.google.com/trace[Google Cloud Trace^].",
      "type": "tracer",
      "version": "4.2.0"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": "",
            "description": "The address of a Jaeger agent to send tracing events to.",
            "examples": [
              "jaeger-agent:6831"
            ],
            "kind": "scalar",
            "name": "agent_address",
            "type": "string"
          },
          {
            "default": "",
            "description": "The URL of a Jaeger collector to send tracing events to. If set, this will override `agent_address`.",
            "examples": [
              "https://jaeger-collector:14268/api/traces"
            ],
            "kind": "scalar",
            "name": "collector_url",
            "type": "string",
            "version": "3.38.0"
          },
          {
            "annotated_options": [
              [
                "const",
                "Sample a percentage of traces. 1 or more means all traces are sampled, 0 means no traces are sampled and anything in between means a percentage of traces are sampled. Tuning the sampling rate is recommended for high-volume production workloads."
              ]
            ],
            "default": "const",
            "description": "The sampler type to use.",
            "kind": "scalar",
            "linter": "\nlet options = {\n  \"const\": true,\n}\n\nroot = if !$options.exists(this.string().lowercase()) {\n  {\"type\": 2, \"what\": \"value %v is not a valid option for this field\".format(this.string())}\n}\n",
            "name": "sampler_type",
            "type": "string"
          },
          {
            "default": 1,
            "description": "A parameter to use for sampling. This field is unused for some sampling types.",
            "is_advanced": true,
            "kind": "scalar",
            "name": "sampler_param",
            "type": "float"
          },
          {
            "default": {},
            "description": "A map of tags to add to tracing spans.",
            "is_advanced": true,
            "kind": "map",
            "name": "tags",
            "type": "string"
          },
          {
            "description": "The period of time between each flush of tracing spans.",
            "is_optional": true,
            "kind": "scalar",
            "name": "flush_interval",
            "type": "string"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "jaeger",
      "plugin": true,
      "status": "stable",
      "summary": "Send tracing events to a https://www.jaegertracing.io/[Jaeger^] agent or collector.",
      "type": "tracer"
    },
    {
      "categories": null,
      "config": {
        "default": {},
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "none",
      "plugin": true,
      "status": "stable",
      "summary": "Do not send tracing events anywhere.",
      "type": "tracer"
    },
    {
      "categories": null,
      "config": {
        "children": [
          {
            "default": "benthos",
            "description": "The name of the service in traces.",
            "kind": "scalar",
            "name": "service",
            "type": "string"
          },
          {
            "children": [
              {
                "description": "The endpoint of a collector to send tracing events to.",
                "examples": [
                  "localhost:4318"
                ],
                "is_optional": true,
                "kind": "scalar",
                "name": "address",
                "type": "string"
              },
              {
                "default": "localhost:4318",
                "description": "The URL of a collector to send tracing events to.",
                "is_deprecated": true,
                "kind": "scalar",
                "name": "url",
                "type": "string"
              },
              {
                "default": false,
                "description": "Connect to the collector over HTTPS",
                "kind": "scalar",
                "name": "secure",
                "type": "bool"
              }
            ],
            "description": "A list of http collectors.",
            "kind": "array",
            "name": "http",
            "type": "object"
          },
          {
            "children": [
              {
                "description": "The endpoint of a collector to send tracing events to.",
                "examples": [
                  "localhost:4317"
                ],
                "is_optional": true,
                "kind": "scalar",
                "name": "address",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "default": "localhost:4317",
                "description": "The URL of a collector to send tracing events to.",
                "is_deprecated": true,
                "kind": "scalar",
                "name": "url",
                "scrubber": "\nlet pass = this.parse_url().user.password.or(\"\")\nroot = if $pass != \"\" && !$pass.trim().re_match(\"\"\"^\\${[0-9A-Za-z_.]+(:((\\${[^}]+})|[^}])*)?}$\"\"\") {\n  \"!!!SECRET_SCRUBBED!!!\"\n}\n",
                "type": "string"
              },
              {
                "default": false,
                "description": "Connect to the collector with client transport security",
                "kind": "scalar",
                "name": "secure",
                "type": "bool"
              }
            ],
            "description": "A list of grpc collectors.",
            "kind": "array",
            "name": "grpc",
            "type": "object"
          },
          {
            "default": {},
            "description": "A map of tags to add to all tracing spans.",
            "is_advanced": true,
            "kind": "map",
            "name": "tags",
            "type": "string"
          },
          {
            "children": [
              {
                "default": false,
                "description": "Whether to enable sampling.",
                "kind": "scalar",
                "name": "enabled",
                "type": "bool"
              },
              {
                "description": "Sets the ratio of traces to sample.",
                "examples": [
                  0.85,
                  0.5
                ],
                "is_optional": true,
                "kind": "scalar",
                "name": "ratio",
                "type": "float"
              }
            ],
            "description": "Settings for trace sampling. Sampling is recommended for high-volume production workloads.",
            "kind": "scalar",
            "name": "sampling",
            "type": "object",
            "version": "4.25.0"
          }
        ],
        "kind": "scalar",
        "name": "",
        "type": "object"
      },
      "name": "open_telemetry_collector",
      "plugin": true,
      "status": "experimental",
      "summary": "Send tracing events to an https://opentelemetry.io/docs/collector/[Open Telemetry collector^].",
      "type": "tracer"
    }
  ],
  "version": "4.65.0"
}
